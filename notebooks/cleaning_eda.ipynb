{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc13cc7-0c33-46d0-b275-368f8d2df404",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Phase 1: Initial Data Cleaning</h1>  \n",
    "<h3 align=\"center\"> Basic data cleaning before eda</h3>  \n",
    "<h3 align=\"center\">Fixing column names, handling duplicate records</h3>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb41264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requried libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d3a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Rating</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Median Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist - AIML</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Director AI/ML Engineer</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹3L – ₹7L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BP Energy</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist Manager</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurf...</td>\n",
       "      <td>₹7L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zelis</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Science Engineer / Healthcare Data Analyst</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>About Us\\nZelis is modernizing the healthcare ...</td>\n",
       "      <td>₹2L – ₹7L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Name  Company Rating  \\\n",
       "0        Optum             3.5   \n",
       "1        Optum             3.5   \n",
       "2        Optum             3.5   \n",
       "3    BP Energy             3.9   \n",
       "4        Zelis             3.7   \n",
       "\n",
       "                                         Job Title   Location  \\\n",
       "0                            Senior Data Scientist      Noida   \n",
       "1                     Senior Data Scientist - AIML    Gurgaon   \n",
       "2                          Director AI/ML Engineer  Bengaluru   \n",
       "3                           Data Scientist Manager       Pune   \n",
       "4  Data Science Engineer / Healthcare Data Analyst  Hyderābād   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Optum is a global organization that delivers c...   \n",
       "1  Optum is a global organization that delivers c...   \n",
       "2  Optum is a global organization that delivers c...   \n",
       "3  Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurf...   \n",
       "4  About Us\\nZelis is modernizing the healthcare ...   \n",
       "\n",
       "                    Salary Range  Median Salary  \n",
       "0  ₹2L – ₹9L/yr (Glassdoor Est.)  ₹4L/yr Median  \n",
       "1  ₹2L – ₹9L/yr (Glassdoor Est.)  ₹4L/yr Median  \n",
       "2  ₹3L – ₹7L/yr (Glassdoor Est.)  ₹5L/yr Median  \n",
       "3  ₹7L – ₹9L/yr (Glassdoor Est.)  ₹8L/yr Median  \n",
       "4  ₹2L – ₹7L/yr (Glassdoor Est.)  ₹3L/yr Median  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "df_copy = df.copy()\n",
    "\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469151f",
   "metadata": {},
   "source": [
    "## Target variable and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df8e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name\n",
      "Company Rating\n",
      "Job Title\n",
      "Location\n",
      "Description\n",
      "Salary Range\n",
      "Median Salary\n"
     ]
    }
   ],
   "source": [
    "for col in df_copy.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72ae35",
   "metadata": {},
   "source": [
    "#### Target variable: \n",
    "\n",
    "- Salary Range column contains the range of salary i.e minimum and maximum salary of the job posting. \n",
    "- Median Salary column contains only the median/average salary of the job posting. \n",
    "- Therefore we cannot use Salary Range column as a target varible.\n",
    "- We can either use Median Salary column as a target variable or create an average/Median salary for each job postings using the Salary Range column (bycalculating the average from Salary Range column).\n",
    "\n",
    "\n",
    "#### Independent variables:\n",
    "- Company_Rating, Location, Job_title columns can be used as independent varibles.\n",
    "- During data transformaton and preprocessing phase we can explore on creating new features from the available information of Description, Job title, Location columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b42d90",
   "metadata": {},
   "source": [
    "## 1. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f443dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(835, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86efe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 835 entries, 0 to 834\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Company Name    835 non-null    object \n",
      " 1   Company Rating  717 non-null    float64\n",
      " 2   Job Title       835 non-null    object \n",
      " 3   Location        835 non-null    object \n",
      " 4   Description     834 non-null    object \n",
      " 5   Salary Range    601 non-null    object \n",
      " 6   Median Salary   517 non-null    object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c14481",
   "metadata": {},
   "source": [
    "- Our dataset contains 834 rows and 7 columns which is relatively a small dataset, therefore we cannot afford to remove any rows from the dataset.\n",
    "- Out of the 7 columnes only one column is numerical i.e Company Rating and the rest are categorical columns which tells us intensive data preprocessing is required. \n",
    "- Null values are found in Company Rating, Description, Salary Range, Median Salary, columns we cannot drop the null values therefore we have to find a strategic way to impute the null values. \n",
    "- Salary Range, Median Salary columns require preprocessing as the data type should be numerical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89519b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    717.000000\n",
       "mean       3.887169\n",
       "std        0.486353\n",
       "min        1.000000\n",
       "25%        3.600000\n",
       "50%        3.900000\n",
       "75%        4.200000\n",
       "max        5.000000\n",
       "Name: Company Rating, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company Rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d443a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company Name      579\n",
       "Company Rating     28\n",
       "Job Title         372\n",
       "Location           40\n",
       "Description       753\n",
       "Salary Range      155\n",
       "Median Salary      57\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d899e",
   "metadata": {},
   "source": [
    "## 2. Fixing columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4f0cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company Name', 'Company Rating', 'Job Title', 'Location',\n",
       "       'Description', 'Salary Range', 'Median Salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72a21747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.rename(columns={'Company Name': 'Company_Name',\n",
    "                          'Company Rating': 'Company_Rating',\n",
    "                          'Job Title': 'Job_Title',\n",
    "                          'Salary Range': 'Salary_Range',\n",
    "                          'Median Salary': 'Median_Salary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65412671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e0e5b",
   "metadata": {},
   "source": [
    "## 2. Handling Duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69a78563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_dupli = df_copy[df_copy.duplicated(keep='first')]\n",
    "df_copy_dupli = df_copy_dupli.sort_values(by=df_copy.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "708388c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy_dupli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c4f5934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>BP Energy</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist Manager</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurf...</td>\n",
       "      <td>₹7L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  Company_Rating  \\\n",
       "212                BP Energy             3.9   \n",
       "90   Boston Consulting Group             4.2   \n",
       "240  Boston Consulting Group             4.2   \n",
       "360  Boston Consulting Group             4.2   \n",
       "421  Boston Consulting Group             4.2   \n",
       "541  Boston Consulting Group             4.2   \n",
       "633  Boston Consulting Group             4.2   \n",
       "153  Boston Consulting Group             4.2   \n",
       "274  Boston Consulting Group             4.2   \n",
       "332  Boston Consulting Group             4.2   \n",
       "\n",
       "                                           Job_Title Location  \\\n",
       "212                           Data Scientist Manager     Pune   \n",
       "90   AI Engineer / Senior AI Engineer, India - BCG X  Gurgaon   \n",
       "240  AI Engineer / Senior AI Engineer, India - BCG X  Gurgaon   \n",
       "360  AI Engineer / Senior AI Engineer, India - BCG X  Gurgaon   \n",
       "421  AI Engineer / Senior AI Engineer, India - BCG X  Gurgaon   \n",
       "541  AI Engineer / Senior AI Engineer, India - BCG X  Gurgaon   \n",
       "633  AI Engineer / Senior AI Engineer, India - BCG X  Gurgaon   \n",
       "153  AI Engineer / Senior AI Engineer, India - BCG X   Mumbai   \n",
       "274  AI Engineer / Senior AI Engineer, India - BCG X   Mumbai   \n",
       "332  AI Engineer / Senior AI Engineer, India - BCG X   Mumbai   \n",
       "\n",
       "                                           Description  \\\n",
       "212  Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurf...   \n",
       "90   Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "240  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "360  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "421  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "541  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "633  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "153  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "274  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "332  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "\n",
       "                      Salary_Range  Median_Salary  \n",
       "212  ₹7L – ₹9L/yr (Glassdoor Est.)  ₹8L/yr Median  \n",
       "90                             NaN            NaN  \n",
       "240                            NaN            NaN  \n",
       "360                            NaN            NaN  \n",
       "421                            NaN            NaN  \n",
       "541                            NaN            NaN  \n",
       "633                            NaN            NaN  \n",
       "153                            NaN            NaN  \n",
       "274                            NaN            NaN  \n",
       "332                            NaN            NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy_dupli[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9801d",
   "metadata": {},
   "source": [
    "- There are totally 60 duplicates and all 60 are **Exact Duplicate**.\n",
    "- **Exact Duplcates** are those duplicate rows where the values are exactly the same in all of the 7 columns.\n",
    "- Since our project is a regression problem and regression algorithms are prone to bias therefore its best to remove the duplicates, as duplicates (especially exact duplicates) leads to overfitting / bias.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "988b2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    print(f\"Before removing duplicate rows: {df.shape}\")\n",
    "    df.drop_duplicates(subset=None, keep='first', inplace=True)   # removing duplicate rows except the first occurrence \n",
    "    print(f\"After removing duplicate rows: {df.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9759c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicate rows: (835, 7)\n",
      "After removing duplicate rows: (775, 7)\n"
     ]
    }
   ],
   "source": [
    "remove_duplicates(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995cb20-eac8-4dfb-bc96-5899e60c6675",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Phase 2: Light EDA</h1>  \n",
    "<h3 align=\"center\"> Understanding the data before advanced data cleaning</h3>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d2334",
   "metadata": {},
   "source": [
    "# 1. Company Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "794b5ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist - AIML</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Director AI/ML Engineer</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹3L – ₹7L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BP Energy</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist Manager</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurf...</td>\n",
       "      <td>₹7L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zelis</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Science Engineer / Healthcare Data Analyst</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>About Us\\nZelis is modernizing the healthcare ...</td>\n",
       "      <td>₹2L – ₹7L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Name  Company_Rating  \\\n",
       "0        Optum             3.5   \n",
       "1        Optum             3.5   \n",
       "2        Optum             3.5   \n",
       "3    BP Energy             3.9   \n",
       "4        Zelis             3.7   \n",
       "\n",
       "                                         Job_Title   Location  \\\n",
       "0                            Senior Data Scientist      Noida   \n",
       "1                     Senior Data Scientist - AIML    Gurgaon   \n",
       "2                          Director AI/ML Engineer  Bengaluru   \n",
       "3                           Data Scientist Manager       Pune   \n",
       "4  Data Science Engineer / Healthcare Data Analyst  Hyderābād   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Optum is a global organization that delivers c...   \n",
       "1  Optum is a global organization that delivers c...   \n",
       "2  Optum is a global organization that delivers c...   \n",
       "3  Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurf...   \n",
       "4  About Us\\nZelis is modernizing the healthcare ...   \n",
       "\n",
       "                    Salary_Range  Median_Salary  \n",
       "0  ₹2L – ₹9L/yr (Glassdoor Est.)  ₹4L/yr Median  \n",
       "1  ₹2L – ₹9L/yr (Glassdoor Est.)  ₹4L/yr Median  \n",
       "2  ₹3L – ₹7L/yr (Glassdoor Est.)  ₹5L/yr Median  \n",
       "3  ₹7L – ₹9L/yr (Glassdoor Est.)  ₹8L/yr Median  \n",
       "4  ₹2L – ₹7L/yr (Glassdoor Est.)  ₹3L/yr Median  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25667c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "821c1d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name\n",
       "Boston Consulting Group               9\n",
       "Optum                                 8\n",
       "Microsoft                             7\n",
       "Maruti Suzuki India Ltd               7\n",
       "LSEG (London Stock Exchange Group)    6\n",
       "EY                                    5\n",
       "Amazon.com                            5\n",
       "Apple                                 4\n",
       "Kinaxis Inc.                          4\n",
       "Barclays                              4\n",
       "Mastercard                            4\n",
       "Accenture                             4\n",
       "Citi                                  4\n",
       "Michelin                              4\n",
       "Natwest                               4\n",
       "JPMorganChase                         4\n",
       "Analytics Vidhya                      4\n",
       "Optimspace                            3\n",
       "Hitachi Solutions                     3\n",
       "KPMG                                  3\n",
       "Rockwell Automation                   3\n",
       "Brillio                               3\n",
       "Kraft Heinz Company                   3\n",
       "SigTuple Technologies                 3\n",
       "Bosch Group                           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Name'].value_counts().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ae382",
   "metadata": {},
   "source": [
    "- There are 579 unique company names in the dataset.\n",
    "- Since the objective is to predict the salary for data science roles, company name feature may not significantly contribute to the model's predictive powers.\n",
    "- Therefore we can drop this column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07353589",
   "metadata": {},
   "source": [
    "# 2. Company rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fac03c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    657.000000\n",
       "mean       3.879756\n",
       "std        0.499391\n",
       "min        1.000000\n",
       "25%        3.600000\n",
       "50%        3.900000\n",
       "75%        4.100000\n",
       "max        5.000000\n",
       "Name: Company_Rating, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14fe7b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.8\n",
       "Name: Company_Rating, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a590ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24939140401677992"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c44cb6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49939103317618744"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c94b771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Rating\n",
       "5.0    19\n",
       "4.9     3\n",
       "4.8     5\n",
       "4.7    11\n",
       "4.6     6\n",
       "4.5    16\n",
       "4.4    16\n",
       "4.3    30\n",
       "4.2    51\n",
       "4.1    73\n",
       "4.0    62\n",
       "3.9    51\n",
       "3.8    82\n",
       "3.7    63\n",
       "3.6    51\n",
       "3.5    33\n",
       "3.4    34\n",
       "3.3    12\n",
       "3.2     7\n",
       "3.1     8\n",
       "3.0     5\n",
       "2.9     6\n",
       "2.8     2\n",
       "2.7     2\n",
       "2.6     2\n",
       "2.3     1\n",
       "2.1     1\n",
       "1.0     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29b6382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Company Rating')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df_copy['Company_Rating'].dropna(), bins=20, kde=True)\n",
    "plt.title('Distribution of Company Ratings')\n",
    "plt.xlabel('Company Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c819d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Company_Rating'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=df_copy['Company_Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bde73c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e1286ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Analyst Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vcars auto private limited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Collection and Preparation:\\nInterns help...</td>\n",
       "      <td>₹6L – ₹19L/yr (Employer provided)</td>\n",
       "      <td>₹12L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Science Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Predigle-An Esper Group Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>As part of our new AI team, you will have the ...</td>\n",
       "      <td>₹5L – ₹10L/yr (Employer provided)</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine Learning intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Machine Learning Intern (Remote) – Optimspace\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Phenomenal HR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>We’re looking for a hands-on Data Scientist or...</td>\n",
       "      <td>₹6L – ₹12L/yr (Employer provided)</td>\n",
       "      <td>₹9L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Digitalxc.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analysts</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description: Data Analyst role\\nPosition O...</td>\n",
       "      <td>₹6L – ₹15L/yr (Employer provided)</td>\n",
       "      <td>₹11L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Aligned Automation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Key Responsibilities:\\nBuild, train, and valid...</td>\n",
       "      <td>₹8L – ₹30L/yr (Employer provided)</td>\n",
       "      <td>₹19L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Infolexus Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>We are seeking a highly motivated and analytic...</td>\n",
       "      <td>₹4L – ₹10L/yr (Employer provided)</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DIATOZ Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>We are seeking a highly motivated Junior Data ...</td>\n",
       "      <td>₹60K – ₹1L/mo (Employer provided)</td>\n",
       "      <td>₹80K/mo Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company_Name  Company_Rating                Job_Title  \\\n",
       "8                        Optimspace             NaN      Data Analyst Intern   \n",
       "9        Vcars auto private limited             NaN    Data Scientist Intern   \n",
       "10                       Optimspace             NaN      Data Science Intern   \n",
       "13  Predigle-An Esper Group Company             NaN           Data Scientist   \n",
       "22                       Optimspace             NaN  Machine Learning intern   \n",
       "28                    Phenomenal HR             NaN           Data Scientist   \n",
       "45                    Digitalxc.com             NaN            Data Analysts   \n",
       "49               Aligned Automation             NaN           Data Scientist   \n",
       "57              Infolexus Solutions             NaN           Data Scientist   \n",
       "58                 DIATOZ Solutions             NaN    Junior Data Scientist   \n",
       "\n",
       "     Location                                        Description  \\\n",
       "8      Remote  Data Analyst Intern (Remote) – Optimspace\\nAbo...   \n",
       "9     Chennai  Data Collection and Preparation:\\nInterns help...   \n",
       "10     Remote  Data Science Intern (Remote) – Optimspace\\nAbo...   \n",
       "13     Remote  As part of our new AI team, you will have the ...   \n",
       "22     Remote  Machine Learning Intern (Remote) – Optimspace\\...   \n",
       "28     Remote  We’re looking for a hands-on Data Scientist or...   \n",
       "45  Bengaluru  Job Description: Data Analyst role\\nPosition O...   \n",
       "49      India  Key Responsibilities:\\nBuild, train, and valid...   \n",
       "57      India  We are seeking a highly motivated and analytic...   \n",
       "58    Gurgaon  We are seeking a highly motivated Junior Data ...   \n",
       "\n",
       "                         Salary_Range   Median_Salary  \n",
       "8                                 NaN             NaN  \n",
       "9   ₹6L – ₹19L/yr (Employer provided)  ₹12L/yr Median  \n",
       "10                                NaN             NaN  \n",
       "13  ₹5L – ₹10L/yr (Employer provided)   ₹8L/yr Median  \n",
       "22                                NaN             NaN  \n",
       "28  ₹6L – ₹12L/yr (Employer provided)   ₹9L/yr Median  \n",
       "45  ₹6L – ₹15L/yr (Employer provided)  ₹11L/yr Median  \n",
       "49  ₹8L – ₹30L/yr (Employer provided)  ₹19L/yr Median  \n",
       "57  ₹4L – ₹10L/yr (Employer provided)   ₹7L/yr Median  \n",
       "58  ₹60K – ₹1L/mo (Employer provided)  ₹80K/mo Median  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Rating'].isnull()][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5976cf",
   "metadata": {},
   "source": [
    "- Overview of company rating:\n",
    "    - The mean company rating is 3.8 and the median is 3.9 and the mode is 3.8.\n",
    "    - So the average company rating across all companies is 3.8 out of 5, suggesting that most companies are rated moderately well. \n",
    "\n",
    "- Distribution of company rating:\n",
    "    - The minimum/lowest company rating is 1.0 and the maximum/highest company rating is 5.0. \n",
    "    - The variance of 0.24 is relatively low, which means that most of the data points are close to the mean, there is less variability in company rating column \n",
    "    - The standard deviation of company rating is 0.49 which is again relatively low, this confirms -most ratings are close to the mean. Most company ratings fall within ±0.5 of the average rating of 3.8 — so between 3.3 and 4.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89201e50",
   "metadata": {},
   "source": [
    "# 3. Job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57f1eb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Job_Title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f17a7",
   "metadata": {},
   "source": [
    "## Different types of job titles \n",
    "1. Intern\n",
    "2. Data Analyst\n",
    "3. Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18d7ad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Analyst Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vcars auto private limited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Collection and Preparation:\\nInterns help...</td>\n",
       "      <td>₹6L – ₹19L/yr (Employer provided)</td>\n",
       "      <td>₹12L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Science Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TECACS IT GROUP PVT LTD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Internships in AI &amp; Data Science</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>An internship in Artificial Intelligence (AI) ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine Learning intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Machine Learning Intern (Remote) – Optimspace\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hypersonix</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>About Us\\nJoin Hypersonix, the premier AI-driv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Applied Scientist I, International Machine Lea...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>DESCRIPTION\\nAmazon is looking for a passionat...</td>\n",
       "      <td>₹3L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Augusta Hitech Soft Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intern Data Scientist</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Industry: IT\\nQualification: PhD\\nRequired Ski...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Beckman Coulter Life Sciences</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Bring more to life.\\nAre you ready to accelera...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Houlihan Lokey</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Business Unit:\\nFinancial and Valuation Adviso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company_Name  Company_Rating  \\\n",
       "8                      Optimspace             NaN   \n",
       "9      Vcars auto private limited             NaN   \n",
       "10                     Optimspace             NaN   \n",
       "18        TECACS IT GROUP PVT LTD             5.0   \n",
       "22                     Optimspace             NaN   \n",
       "24                     Hypersonix             4.8   \n",
       "42                     Amazon.com             3.6   \n",
       "70  Augusta Hitech Soft Solutions             NaN   \n",
       "81  Beckman Coulter Life Sciences             3.4   \n",
       "98                 Houlihan Lokey             4.0   \n",
       "\n",
       "                                            Job_Title    Location  \\\n",
       "8                                 Data Analyst Intern      Remote   \n",
       "9                               Data Scientist Intern     Chennai   \n",
       "10                                Data Science Intern      Remote   \n",
       "18                   Internships in AI & Data Science      Cochin   \n",
       "22                            Machine Learning intern      Remote   \n",
       "24                              Data Science - Intern      Remote   \n",
       "42  Applied Scientist I, International Machine Lea...     Gurgaon   \n",
       "70                              Intern Data Scientist  Coimbatore   \n",
       "81                              Data Science - Intern   Bengaluru   \n",
       "98                                Data Science Intern      Mumbai   \n",
       "\n",
       "                                          Description  \\\n",
       "8   Data Analyst Intern (Remote) – Optimspace\\nAbo...   \n",
       "9   Data Collection and Preparation:\\nInterns help...   \n",
       "10  Data Science Intern (Remote) – Optimspace\\nAbo...   \n",
       "18  An internship in Artificial Intelligence (AI) ...   \n",
       "22  Machine Learning Intern (Remote) – Optimspace\\...   \n",
       "24  About Us\\nJoin Hypersonix, the premier AI-driv...   \n",
       "42  DESCRIPTION\\nAmazon is looking for a passionat...   \n",
       "70  Industry: IT\\nQualification: PhD\\nRequired Ski...   \n",
       "81  Bring more to life.\\nAre you ready to accelera...   \n",
       "98  Business Unit:\\nFinancial and Valuation Adviso...   \n",
       "\n",
       "                         Salary_Range   Median_Salary  \n",
       "8                                 NaN             NaN  \n",
       "9   ₹6L – ₹19L/yr (Employer provided)  ₹12L/yr Median  \n",
       "10                                NaN             NaN  \n",
       "18                                NaN             NaN  \n",
       "22                                NaN             NaN  \n",
       "24                                NaN             NaN  \n",
       "42            ₹3L/yr (Glassdoor Est.)             NaN  \n",
       "70                                NaN             NaN  \n",
       "81                                NaN             NaN  \n",
       "98                                NaN             NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy_intern = df_copy[df_copy['Job_Title'].str.contains('Intern', case=False)]\n",
    "print(df_copy_intern.shape)\n",
    "df_copy_intern.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d22cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zelis</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Science Engineer / Healthcare Data Analyst</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>About Us\\nZelis is modernizing the healthcare ...</td>\n",
       "      <td>₹2L – ₹7L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Digitalxc.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analysts</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description: Data Analyst role\\nPosition O...</td>\n",
       "      <td>₹6L – ₹15L/yr (Employer provided)</td>\n",
       "      <td>₹11L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Tecvesten Consulting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist / Data Analyst / BI</td>\n",
       "      <td>India</td>\n",
       "      <td>About Us\\nTecvesten Consulting, a collective y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Virtusa</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Brand Analytics – Data Analyst</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>You will develop a deep understanding of inter...</td>\n",
       "      <td>₹4L – ₹6L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Splashgain</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist/ Data Analyst</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Working Experience: 0 to 5 Years\\nAny candidat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Indium Software</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist/Data Engineer/Data Analyst</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Job Information\\nDate Opened\\n04/10/2025\\nJob ...</td>\n",
       "      <td>₹5L – ₹8L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>MidTown Software</td>\n",
       "      <td>5.0</td>\n",
       "      <td>DATA ANALYST/ SCIENTIST</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>Our new Data Analyst will help us grow, engage...</td>\n",
       "      <td>₹2L – ₹6L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>JSG Consulting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Overview\\nWe are seeking a skilled and analyti...</td>\n",
       "      <td>₹95K – ₹98K/mo (Employer provided)</td>\n",
       "      <td>₹97K/mo Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>coolboots</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Junior Data Analyst (F)</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Job Title: Junior Data Analyst -DOOH and CTV A...</td>\n",
       "      <td>₹3L – ₹8L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Infolexus Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>Job Description:\\nWe are seeking a highly moti...</td>\n",
       "      <td>₹20K – ₹40K/mo (Employer provided)</td>\n",
       "      <td>₹30K/mo Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company_Name  Company_Rating  \\\n",
       "4                   Zelis             3.7   \n",
       "45          Digitalxc.com             NaN   \n",
       "67   Tecvesten Consulting             NaN   \n",
       "208               Virtusa             3.7   \n",
       "226            Splashgain             3.7   \n",
       "237       Indium Software             4.0   \n",
       "278      MidTown Software             5.0   \n",
       "284        JSG Consulting             NaN   \n",
       "319             coolboots             2.6   \n",
       "326   Infolexus Solutions             NaN   \n",
       "\n",
       "                                           Job_Title   Location  \\\n",
       "4    Data Science Engineer / Healthcare Data Analyst  Hyderābād   \n",
       "45                                     Data Analysts  Bengaluru   \n",
       "67                Data Scientist / Data Analyst / BI      India   \n",
       "208                   Brand Analytics – Data Analyst    Chennai   \n",
       "226                     Data Scientist/ Data Analyst    Gujarat   \n",
       "237        Data Scientist/Data Engineer/Data Analyst    Chennai   \n",
       "278                          DATA ANALYST/ SCIENTIST     Mohali   \n",
       "284                                     Data Analyst  Bengaluru   \n",
       "319                          Junior Data Analyst (F)    Gurgaon   \n",
       "326                                     Data Analyst      India   \n",
       "\n",
       "                                           Description  \\\n",
       "4    About Us\\nZelis is modernizing the healthcare ...   \n",
       "45   Job Description: Data Analyst role\\nPosition O...   \n",
       "67   About Us\\nTecvesten Consulting, a collective y...   \n",
       "208  You will develop a deep understanding of inter...   \n",
       "226  Working Experience: 0 to 5 Years\\nAny candidat...   \n",
       "237  Job Information\\nDate Opened\\n04/10/2025\\nJob ...   \n",
       "278  Our new Data Analyst will help us grow, engage...   \n",
       "284  Overview\\nWe are seeking a skilled and analyti...   \n",
       "319  Job Title: Junior Data Analyst -DOOH and CTV A...   \n",
       "326  Job Description:\\nWe are seeking a highly moti...   \n",
       "\n",
       "                           Salary_Range   Median_Salary  \n",
       "4         ₹2L – ₹7L/yr (Glassdoor Est.)   ₹3L/yr Median  \n",
       "45    ₹6L – ₹15L/yr (Employer provided)  ₹11L/yr Median  \n",
       "67                                  NaN             NaN  \n",
       "208       ₹4L – ₹6L/yr (Glassdoor Est.)   ₹5L/yr Median  \n",
       "226                                 NaN             NaN  \n",
       "237       ₹5L – ₹8L/yr (Glassdoor Est.)   ₹6L/yr Median  \n",
       "278       ₹2L – ₹6L/yr (Glassdoor Est.)   ₹3L/yr Median  \n",
       "284  ₹95K – ₹98K/mo (Employer provided)  ₹97K/mo Median  \n",
       "319       ₹3L – ₹8L/yr (Glassdoor Est.)   ₹5L/yr Median  \n",
       "326  ₹20K – ₹40K/mo (Employer provided)  ₹30K/mo Median  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy_DA = df_copy[\n",
    "    df_copy['Job_Title'].str.contains('Data Analyst', case=False) & \n",
    "    ~df_copy['Job_Title'].str.contains('Intern', case=False)\n",
    "]\n",
    "print(df_copy_DA.shape)\n",
    "df_copy_DA.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "815f3e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist - AIML</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BP Energy</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist Manager</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurf...</td>\n",
       "      <td>₹7L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist - Gen AI</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Join our Team\\nAbout this opportunity:\\nWe are...</td>\n",
       "      <td>₹4L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>The Company\\nPayPal has been revolutionizing c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Predigle-An Esper Group Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>As part of our new AI team, you will have the ...</td>\n",
       "      <td>₹5L – ₹10L/yr (Employer provided)</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>QuantumBricks</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Data Scientist with Machine Learning specializ...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Key Responsibilities:\\nDesign, develop, and de...</td>\n",
       "      <td>₹8L – ₹18L/yr (Employer provided)</td>\n",
       "      <td>₹13L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Maruti Suzuki India Ltd</td>\n",
       "      <td>3.8</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>About the Company:\\nMaruti Suzuki India Limite...</td>\n",
       "      <td>₹3L – ₹10L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Arch Systems, LLC</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist/ Data Specialist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Role: Senior Data Scientist / Data Specialist\\...</td>\n",
       "      <td>₹1.20K – ₹2.00K/hr (Employer provided)</td>\n",
       "      <td>₹1.60K/hr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Intellion Technologies Pvt Ltd</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Part-Time Freelance Data Scientist (Remote)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Job Title: Part-Time Freelance Data Scientist ...</td>\n",
       "      <td>₹25K – ₹30K/mo (Employer provided)</td>\n",
       "      <td>₹28K/mo Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company_Name  Company_Rating  \\\n",
       "0                             Optum             3.5   \n",
       "1                             Optum             3.5   \n",
       "3                         BP Energy             3.9   \n",
       "11                         Ericsson             4.0   \n",
       "12                           PayPal             3.7   \n",
       "13  Predigle-An Esper Group Company             NaN   \n",
       "14                    QuantumBricks             4.7   \n",
       "15          Maruti Suzuki India Ltd             3.8   \n",
       "16                Arch Systems, LLC             4.2   \n",
       "17   Intellion Technologies Pvt Ltd             5.0   \n",
       "\n",
       "                                            Job_Title Location  \\\n",
       "0                               Senior Data Scientist    Noida   \n",
       "1                        Senior Data Scientist - AIML  Gurgaon   \n",
       "3                              Data Scientist Manager     Pune   \n",
       "11                            Data Scientist - Gen AI  Chennai   \n",
       "12                                     Data Scientist  Chennai   \n",
       "13                                     Data Scientist   Remote   \n",
       "14  Data Scientist with Machine Learning specializ...   Remote   \n",
       "15                                     DATA SCIENTIST  Gurgaon   \n",
       "16                    Data Scientist/ Data Specialist   Remote   \n",
       "17        Part-Time Freelance Data Scientist (Remote)   Remote   \n",
       "\n",
       "                                          Description  \\\n",
       "0   Optum is a global organization that delivers c...   \n",
       "1   Optum is a global organization that delivers c...   \n",
       "3   Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurf...   \n",
       "11  Join our Team\\nAbout this opportunity:\\nWe are...   \n",
       "12  The Company\\nPayPal has been revolutionizing c...   \n",
       "13  As part of our new AI team, you will have the ...   \n",
       "14  Key Responsibilities:\\nDesign, develop, and de...   \n",
       "15  About the Company:\\nMaruti Suzuki India Limite...   \n",
       "16  Role: Senior Data Scientist / Data Specialist\\...   \n",
       "17  Job Title: Part-Time Freelance Data Scientist ...   \n",
       "\n",
       "                              Salary_Range     Median_Salary  \n",
       "0            ₹2L – ₹9L/yr (Glassdoor Est.)     ₹4L/yr Median  \n",
       "1            ₹2L – ₹9L/yr (Glassdoor Est.)     ₹4L/yr Median  \n",
       "3            ₹7L – ₹9L/yr (Glassdoor Est.)     ₹8L/yr Median  \n",
       "11           ₹4L – ₹9L/yr (Glassdoor Est.)     ₹6L/yr Median  \n",
       "12                                     NaN               NaN  \n",
       "13       ₹5L – ₹10L/yr (Employer provided)     ₹8L/yr Median  \n",
       "14       ₹8L – ₹18L/yr (Employer provided)    ₹13L/yr Median  \n",
       "15          ₹3L – ₹10L/yr (Glassdoor Est.)     ₹6L/yr Median  \n",
       "16  ₹1.20K – ₹2.00K/hr (Employer provided)  ₹1.60K/hr Median  \n",
       "17      ₹25K – ₹30K/mo (Employer provided)    ₹28K/mo Median  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy_DS = df_copy[\n",
    "    df_copy['Job_Title'].str.contains('Data Scientist', case=False) & \n",
    "    ~df_copy['Job_Title'].str.contains('Intern', case=False)\n",
    "]\n",
    "print(df_copy_DS.shape)\n",
    "df_copy_DS.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d292c1",
   "metadata": {},
   "source": [
    "## Seniority Levels\n",
    "1. Junior\n",
    "2. Senior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f99a87cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cravita Technologies India</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Strong proficiency in programming languages su...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are looking for a skilled Data Scientist to...</td>\n",
       "      <td>₹10L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DIATOZ Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>We are seeking a highly motivated Junior Data ...</td>\n",
       "      <td>₹60K – ₹1L/mo (Employer provided)</td>\n",
       "      <td>₹80K/mo Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Marktine Technology Solutions</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Job Information\\nDate Opened\\n07/12/2024\\nJob ...</td>\n",
       "      <td>₹3L – ₹5L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Global scientific company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior Machine Learning Engineer</td>\n",
       "      <td>India</td>\n",
       "      <td>Chennai location only, tamil candidates\\nFresh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Imurgence</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Junior Data Science Team Member</td>\n",
       "      <td>India</td>\n",
       "      <td>Duties &amp; Responsibilities:\\n1. Work closely wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>DAZN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Description\\n\\nWe are seeking a passionate and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>DAZN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Description\\n\\nWe are seeking a passionate and...</td>\n",
       "      <td>₹6L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>CIS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Department\\nArtificial Intelligence Jobs - AI ...</td>\n",
       "      <td>₹2L – ₹10L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Sri Sathya Sai Sanjeevani Hospital</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Qualification: M.Sc/ MTech in any Biological S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  Company_Rating  \\\n",
       "19           Cravita Technologies India             4.1   \n",
       "20   LSEG (London Stock Exchange Group)             3.7   \n",
       "58                     DIATOZ Solutions             NaN   \n",
       "66        Marktine Technology Solutions             4.2   \n",
       "140           Global scientific company             NaN   \n",
       "163                           Imurgence             4.0   \n",
       "181                                DAZN             2.9   \n",
       "183                                DAZN             NaN   \n",
       "189                                 CIS             1.0   \n",
       "265  Sri Sathya Sai Sanjeevani Hospital             3.4   \n",
       "\n",
       "                            Job_Title   Location  \\\n",
       "19              Junior Data Scientist      India   \n",
       "20              Junior Data Scientist  Bengaluru   \n",
       "58              Junior Data Scientist    Gurgaon   \n",
       "66              Junior Data Scientist     Jaipur   \n",
       "140  Junior Machine Learning Engineer      India   \n",
       "163   Junior Data Science Team Member      India   \n",
       "181             Junior Data Scientist  Hyderābād   \n",
       "183             Junior Data Scientist  Hyderābād   \n",
       "189             Junior Data Scientist     Indore   \n",
       "265             Junior Data Scientist      India   \n",
       "\n",
       "                                           Description  \\\n",
       "19   Strong proficiency in programming languages su...   \n",
       "20   We are looking for a skilled Data Scientist to...   \n",
       "58   We are seeking a highly motivated Junior Data ...   \n",
       "66   Job Information\\nDate Opened\\n07/12/2024\\nJob ...   \n",
       "140  Chennai location only, tamil candidates\\nFresh...   \n",
       "163  Duties & Responsibilities:\\n1. Work closely wi...   \n",
       "181  Description\\n\\nWe are seeking a passionate and...   \n",
       "183  Description\\n\\nWe are seeking a passionate and...   \n",
       "189  Department\\nArtificial Intelligence Jobs - AI ...   \n",
       "265  Qualification: M.Sc/ MTech in any Biological S...   \n",
       "\n",
       "                          Salary_Range   Median_Salary  \n",
       "19                                 NaN             NaN  \n",
       "20            ₹10L/yr (Glassdoor Est.)             NaN  \n",
       "58   ₹60K – ₹1L/mo (Employer provided)  ₹80K/mo Median  \n",
       "66       ₹3L – ₹5L/yr (Glassdoor Est.)   ₹4L/yr Median  \n",
       "140                                NaN             NaN  \n",
       "163                                NaN             NaN  \n",
       "181                                NaN             NaN  \n",
       "183      ₹6L – ₹9L/yr (Glassdoor Est.)   ₹7L/yr Median  \n",
       "189     ₹2L – ₹10L/yr (Glassdoor Est.)   ₹4L/yr Median  \n",
       "265                                NaN             NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy_Ju = df_copy[df_copy['Job_Title'].str.contains('Junior', case=False)]\n",
    "print(df_copy_Ju.shape)\n",
    "df_copy_Ju.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0de29daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist - AIML</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Global Cybersecurity Senior Manager - AI Archi...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners w...</td>\n",
       "      <td>₹6L – ₹8L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Senior Software Developer, Machine Learning</td>\n",
       "      <td>India</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior AI or ML Engineer</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹3L – ₹7L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>QuantumBricks</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Job Summary:\\nWe are seeking a highly motivate...</td>\n",
       "      <td>₹9L – ₹23L/yr (Employer provided)</td>\n",
       "      <td>₹16L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mastercard</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Our Purpose\\nMastercard powers economies and e...</td>\n",
       "      <td>₹2L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5x Data</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>At 5X, we help companies organize their data a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company_Name  Company_Rating  \\\n",
       "0                     Optum             3.5   \n",
       "1                     Optum             3.5   \n",
       "6   Boston Consulting Group             4.2   \n",
       "7              Kinaxis Inc.             4.1   \n",
       "33  Boston Consulting Group             4.2   \n",
       "34                    Optum             3.5   \n",
       "43            QuantumBricks             4.7   \n",
       "46               Mastercard             4.2   \n",
       "63  Boston Consulting Group             4.2   \n",
       "97                  5x Data             4.8   \n",
       "\n",
       "                                            Job_Title   Location  \\\n",
       "0                               Senior Data Scientist      Noida   \n",
       "1                        Senior Data Scientist - AIML    Gurgaon   \n",
       "6   Global Cybersecurity Senior Manager - AI Archi...    Gurgaon   \n",
       "7         Senior Software Developer, Machine Learning      India   \n",
       "33    AI Engineer / Senior AI Engineer, India - BCG X    Gurgaon   \n",
       "34                           Senior AI or ML Engineer  Bengaluru   \n",
       "43                              Senior Data Scientist     Remote   \n",
       "46                              Senior Data Scientist    Gurgaon   \n",
       "63    AI Engineer / Senior AI Engineer, India - BCG X     Mumbai   \n",
       "97                              Senior Data Scientist     Remote   \n",
       "\n",
       "                                          Description  \\\n",
       "0   Optum is a global organization that delivers c...   \n",
       "1   Optum is a global organization that delivers c...   \n",
       "6   Who We Are\\nBoston Consulting Group partners w...   \n",
       "7   About Kinaxis:\\nAbout Kinaxis\\nElevate your ca...   \n",
       "33  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "34  Optum is a global organization that delivers c...   \n",
       "43  Job Summary:\\nWe are seeking a highly motivate...   \n",
       "46  Our Purpose\\nMastercard powers economies and e...   \n",
       "63  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nB...   \n",
       "97  At 5X, we help companies organize their data a...   \n",
       "\n",
       "                         Salary_Range   Median_Salary  \n",
       "0       ₹2L – ₹9L/yr (Glassdoor Est.)   ₹4L/yr Median  \n",
       "1       ₹2L – ₹9L/yr (Glassdoor Est.)   ₹4L/yr Median  \n",
       "6       ₹6L – ₹8L/yr (Glassdoor Est.)   ₹7L/yr Median  \n",
       "7                                 NaN             NaN  \n",
       "33                                NaN             NaN  \n",
       "34      ₹3L – ₹7L/yr (Glassdoor Est.)   ₹5L/yr Median  \n",
       "43  ₹9L – ₹23L/yr (Employer provided)  ₹16L/yr Median  \n",
       "46            ₹2L/yr (Glassdoor Est.)             NaN  \n",
       "63                                NaN             NaN  \n",
       "97                                NaN             NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy_Si = df_copy[df_copy['Job_Title'].str.contains('Senior', case=False)]\n",
    "print(df_copy_Si.shape)\n",
    "df_copy_Si.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47865564",
   "metadata": {},
   "source": [
    "# 4. Location\n",
    "- Location with highest number of job postings \n",
    "- Correlation between location and salary, does location of the company influence salary range?\n",
    "- Correlation between location and rating of the company, does companies in better cities have high ratings?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27dfd46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8b590f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "Bengaluru             249\n",
       "India                  85\n",
       "Gurgaon                65\n",
       "Chennai                63\n",
       "Hyderābād              62\n",
       "Pune                   58\n",
       "Remote                 51\n",
       "Mumbai                 28\n",
       "Noida                  22\n",
       "Ahmedabad              14\n",
       "Delhi                   9\n",
       "Cochin                  8\n",
       "Mohali                  7\n",
       "Coimbatore              7\n",
       "Gujarat                 4\n",
       "Karnataka               4\n",
       "Indore                  4\n",
       "Vadodara                4\n",
       "Thiruvananthapuram      3\n",
       "Navi Mumbai             3\n",
       "Jamshedpur              2\n",
       "Calcutta                2\n",
       "Chandigarh              2\n",
       "Bhubaneshwar            2\n",
       "Kālkāji Devi            2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Location'].value_counts().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c5b95b",
   "metadata": {},
   "source": [
    "# 5. Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33c8a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 775 entries, 0 to 834\n",
      "Series name: Description\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "774 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 12.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_copy['Description'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1800a4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>Invokhr</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist- Chennai</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>₹3L – ₹5L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name  Company_Rating                Job_Title Location  \\\n",
       "721      Invokhr             4.0  Data Scientist- Chennai  Chennai   \n",
       "\n",
       "    Description                   Salary_Range  Median_Salary  \n",
       "721         NaN  ₹3L – ₹5L/yr (Glassdoor Est.)  ₹4L/yr Median  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Description'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429e808",
   "metadata": {},
   "source": [
    "- Handling missing value in description column:\n",
    "    - There is only one row with missing value in description column.\n",
    "    - While the primary purpose of this column is to extract valuable insights (eg., skills, experience,), this particular row contains salary-related information which is crucial for our analysis.\n",
    "    - Therefore removing this row is not a better decision given its importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8c41d",
   "metadata": {},
   "source": [
    "# 6. Salary range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70f65055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary_Range\n",
       "₹3L – ₹8L/yr (Glassdoor Est.)     31\n",
       "₹4L – ₹8L/yr (Glassdoor Est.)     24\n",
       "₹10L/yr (Glassdoor Est.)          21\n",
       "₹4L – ₹10L/yr (Glassdoor Est.)    20\n",
       "₹7L – ₹10L/yr (Glassdoor Est.)    18\n",
       "₹3L – ₹5L/yr (Glassdoor Est.)     18\n",
       "₹5L – ₹10L/yr (Glassdoor Est.)    17\n",
       "₹5L – ₹8L/yr (Glassdoor Est.)     16\n",
       "₹8L – ₹10L/yr (Glassdoor Est.)    15\n",
       "₹7L – ₹9L/yr (Glassdoor Est.)     14\n",
       "₹3L – ₹10L/yr (Glassdoor Est.)    13\n",
       "₹5L – ₹9L/yr (Glassdoor Est.)     13\n",
       "₹5L – ₹7L/yr (Glassdoor Est.)     12\n",
       "₹6L – ₹7L/yr (Glassdoor Est.)     12\n",
       "₹6L – ₹10L/yr (Glassdoor Est.)    11\n",
       "₹2L – ₹8L/yr (Glassdoor Est.)     11\n",
       "₹2L – ₹6L/yr (Glassdoor Est.)     10\n",
       "₹2L – ₹9L/yr (Glassdoor Est.)     10\n",
       "₹2L – ₹10L/yr (Glassdoor Est.)     9\n",
       "₹3L – ₹6L/yr (Glassdoor Est.)      9\n",
       "₹6L – ₹8L/yr (Glassdoor Est.)      9\n",
       "₹1L – ₹10L/yr (Glassdoor Est.)     9\n",
       "₹6L – ₹9L/yr (Glassdoor Est.)      9\n",
       "₹4L – ₹9L/yr (Glassdoor Est.)      9\n",
       "₹4L – ₹7L/yr (Glassdoor Est.)      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range'].value_counts().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afa540e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Senior Software Developer, Machine Learning</td>\n",
       "      <td>India</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Analyst Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Science Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>The Company\\nPayPal has been revolutionizing c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TECACS IT GROUP PVT LTD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Internships in AI &amp; Data Science</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>An internship in Artificial Intelligence (AI) ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company_Name  Company_Rating  \\\n",
       "7              Kinaxis Inc.             4.1   \n",
       "8                Optimspace             NaN   \n",
       "10               Optimspace             NaN   \n",
       "12                   PayPal             3.7   \n",
       "18  TECACS IT GROUP PVT LTD             5.0   \n",
       "\n",
       "                                      Job_Title Location  \\\n",
       "7   Senior Software Developer, Machine Learning    India   \n",
       "8                           Data Analyst Intern   Remote   \n",
       "10                          Data Science Intern   Remote   \n",
       "12                               Data Scientist  Chennai   \n",
       "18             Internships in AI & Data Science   Cochin   \n",
       "\n",
       "                                          Description Salary_Range  \\\n",
       "7   About Kinaxis:\\nAbout Kinaxis\\nElevate your ca...          NaN   \n",
       "8   Data Analyst Intern (Remote) – Optimspace\\nAbo...          NaN   \n",
       "10  Data Science Intern (Remote) – Optimspace\\nAbo...          NaN   \n",
       "12  The Company\\nPayPal has been revolutionizing c...          NaN   \n",
       "18  An internship in Artificial Intelligence (AI) ...          NaN   \n",
       "\n",
       "   Median_Salary  \n",
       "7            NaN  \n",
       "8            NaN  \n",
       "10           NaN  \n",
       "12           NaN  \n",
       "18           NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range'].isnull()][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd1f69",
   "metadata": {},
   "source": [
    "# 7. Median Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a0b0ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Median_Salary\n",
       "₹6L/yr Median     89\n",
       "₹4L/yr Median     75\n",
       "₹5L/yr Median     69\n",
       "₹7L/yr Median     66\n",
       "₹8L/yr Median     48\n",
       "₹9L/yr Median     29\n",
       "₹3L/yr Median     23\n",
       "₹10L/yr Median     8\n",
       "₹2L/yr Median      6\n",
       "₹13L/yr Median     6\n",
       "₹12L/yr Median     4\n",
       "₹16L/yr Median     3\n",
       "₹18L/yr Median     3\n",
       "₹30K/mo Median     3\n",
       "₹45K/mo Median     2\n",
       "₹80K/mo Median     2\n",
       "₹1L/mo Median      2\n",
       "₹11L/yr Median     2\n",
       "₹28L/yr Median     2\n",
       "₹20K/mo Median     2\n",
       "₹24L/yr Median     2\n",
       "₹15L/yr Median     2\n",
       "₹25L/yr Median     2\n",
       "₹23K/mo Median     1\n",
       "₹9K/mo Median      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary'].value_counts().sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d3a2663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Senior Software Developer, Machine Learning</td>\n",
       "      <td>India</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Analyst Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Science Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>The Company\\nPayPal has been revolutionizing c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TECACS IT GROUP PVT LTD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Internships in AI &amp; Data Science</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>An internship in Artificial Intelligence (AI) ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cravita Technologies India</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Strong proficiency in programming languages su...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are looking for a skilled Data Scientist to...</td>\n",
       "      <td>₹10L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sumeru</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Job Title:- Data Scientist/Data Analyst\\nJob L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine Learning intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Machine Learning Intern (Remote) – Optimspace\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Immersive Infotech Pvt. Ltd</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Scientist (2–4 Years Exp) | AI &amp; Optimiza...</td>\n",
       "      <td>₹12L/yr (Employer provided)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company_Name  Company_Rating  \\\n",
       "7                         Kinaxis Inc.             4.1   \n",
       "8                           Optimspace             NaN   \n",
       "10                          Optimspace             NaN   \n",
       "12                              PayPal             3.7   \n",
       "18             TECACS IT GROUP PVT LTD             5.0   \n",
       "19          Cravita Technologies India             4.1   \n",
       "20  LSEG (London Stock Exchange Group)             3.7   \n",
       "21                              Sumeru             3.3   \n",
       "22                          Optimspace             NaN   \n",
       "23         Immersive Infotech Pvt. Ltd             4.9   \n",
       "\n",
       "                                      Job_Title   Location  \\\n",
       "7   Senior Software Developer, Machine Learning      India   \n",
       "8                           Data Analyst Intern     Remote   \n",
       "10                          Data Science Intern     Remote   \n",
       "12                               Data Scientist    Chennai   \n",
       "18             Internships in AI & Data Science     Cochin   \n",
       "19                        Junior Data Scientist      India   \n",
       "20                        Junior Data Scientist  Bengaluru   \n",
       "21                       Data Scientist/Analyst     Remote   \n",
       "22                      Machine Learning intern     Remote   \n",
       "23                               Data Scientist     Remote   \n",
       "\n",
       "                                          Description  \\\n",
       "7   About Kinaxis:\\nAbout Kinaxis\\nElevate your ca...   \n",
       "8   Data Analyst Intern (Remote) – Optimspace\\nAbo...   \n",
       "10  Data Science Intern (Remote) – Optimspace\\nAbo...   \n",
       "12  The Company\\nPayPal has been revolutionizing c...   \n",
       "18  An internship in Artificial Intelligence (AI) ...   \n",
       "19  Strong proficiency in programming languages su...   \n",
       "20  We are looking for a skilled Data Scientist to...   \n",
       "21  Job Title:- Data Scientist/Data Analyst\\nJob L...   \n",
       "22  Machine Learning Intern (Remote) – Optimspace\\...   \n",
       "23  Data Scientist (2–4 Years Exp) | AI & Optimiza...   \n",
       "\n",
       "                   Salary_Range Median_Salary  \n",
       "7                           NaN           NaN  \n",
       "8                           NaN           NaN  \n",
       "10                          NaN           NaN  \n",
       "12                          NaN           NaN  \n",
       "18                          NaN           NaN  \n",
       "19                          NaN           NaN  \n",
       "20     ₹10L/yr (Glassdoor Est.)           NaN  \n",
       "21                          NaN           NaN  \n",
       "22                          NaN           NaN  \n",
       "23  ₹12L/yr (Employer provided)           NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary'].isnull()][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7dd776a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are looking for a skilled Data Scientist to...</td>\n",
       "      <td>₹10L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Immersive Infotech Pvt. Ltd</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Scientist (2–4 Years Exp) | AI &amp; Optimiza...</td>\n",
       "      <td>₹12L/yr (Employer provided)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Applied Scientist I, International Machine Lea...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>DESCRIPTION\\nAmazon is looking for a passionat...</td>\n",
       "      <td>₹3L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mastercard</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Our Purpose\\nMastercard powers economies and e...</td>\n",
       "      <td>₹2L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Specialist Data Scientist - TM</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Transport is at the core of modern society. Im...</td>\n",
       "      <td>₹10L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Excelher -Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Transport is at the core of modern society. Im...</td>\n",
       "      <td>₹10L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Engineer - Global People Analytics</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners w...</td>\n",
       "      <td>₹5L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Futuremug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-Time Experience - 3 - 5 Years Location: R...</td>\n",
       "      <td>₹60K/mo (Employer provided)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Radioso Resources</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data / ML Scientist (Clustering, Trends &amp; Root...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Qualifications\\n● 4 + years in data science or...</td>\n",
       "      <td>₹20L/yr (Employer provided)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Visa</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist (BI Engineer)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Company Description\\n\\nVisa is a world leader ...</td>\n",
       "      <td>₹3L/yr (Glassdoor Est.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  Company_Rating  \\\n",
       "20   LSEG (London Stock Exchange Group)             3.7   \n",
       "23          Immersive Infotech Pvt. Ltd             4.9   \n",
       "42                           Amazon.com             3.6   \n",
       "46                           Mastercard             4.2   \n",
       "47                          Volvo Group             4.1   \n",
       "54                          Volvo Group             4.1   \n",
       "62              Boston Consulting Group             4.2   \n",
       "74                            Futuremug             NaN   \n",
       "89                    Radioso Resources             NaN   \n",
       "112                                Visa             3.8   \n",
       "\n",
       "                                             Job_Title   Location  \\\n",
       "20                               Junior Data Scientist  Bengaluru   \n",
       "23                                      Data Scientist     Remote   \n",
       "42   Applied Scientist I, International Machine Lea...    Gurgaon   \n",
       "46                               Senior Data Scientist    Gurgaon   \n",
       "47                      Specialist Data Scientist - TM  Bengaluru   \n",
       "54                            Excelher -Data Scientist  Bengaluru   \n",
       "62             Data Engineer - Global People Analytics    Gurgaon   \n",
       "74                                      Data Scientist     Remote   \n",
       "89   Data / ML Scientist (Clustering, Trends & Root...     Remote   \n",
       "112                       Data Scientist (BI Engineer)  Bengaluru   \n",
       "\n",
       "                                           Description  \\\n",
       "20   We are looking for a skilled Data Scientist to...   \n",
       "23   Data Scientist (2–4 Years Exp) | AI & Optimiza...   \n",
       "42   DESCRIPTION\\nAmazon is looking for a passionat...   \n",
       "46   Our Purpose\\nMastercard powers economies and e...   \n",
       "47   Transport is at the core of modern society. Im...   \n",
       "54   Transport is at the core of modern society. Im...   \n",
       "62   Who We Are\\nBoston Consulting Group partners w...   \n",
       "74   Full-Time Experience - 3 - 5 Years Location: R...   \n",
       "89   Qualifications\\n● 4 + years in data science or...   \n",
       "112  Company Description\\n\\nVisa is a world leader ...   \n",
       "\n",
       "                    Salary_Range Median_Salary  \n",
       "20      ₹10L/yr (Glassdoor Est.)           NaN  \n",
       "23   ₹12L/yr (Employer provided)           NaN  \n",
       "42       ₹3L/yr (Glassdoor Est.)           NaN  \n",
       "46       ₹2L/yr (Glassdoor Est.)           NaN  \n",
       "47      ₹10L/yr (Glassdoor Est.)           NaN  \n",
       "54      ₹10L/yr (Glassdoor Est.)           NaN  \n",
       "62       ₹5L/yr (Glassdoor Est.)           NaN  \n",
       "74   ₹60K/mo (Employer provided)           NaN  \n",
       "89   ₹20L/yr (Employer provided)           NaN  \n",
       "112      ₹3L/yr (Glassdoor Est.)           NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary'].isnull() & df_copy['Salary_Range'].notnull()][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38377650",
   "metadata": {},
   "source": [
    "- Handling missing values in Median Salary column:\n",
    "    - There are totally 291 missing values in the median salary column.\n",
    "    - we can use salary related information present in Description and Salary Range columns to impute these missing values.\n",
    "    - Or we can totally remove the Median Salary column and create a new feature by calculating the average from Salary Range column. By this way we can focus only on imputing the missing values in Salary Range column and create a new feature for Median Salary by calculating the average. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b749a81-afe2-40e2-a804-ecf6126e16cf",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Phase 3: Advanced Data Cleaning / Feature Engineering</h1>    \n",
    "<h3 align=\"center\">Handling missing values, parsing columns, removing unwanted characters, creating new features</h3>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2493d1",
   "metadata": {},
   "source": [
    "# 1. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd939ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name        0\n",
       "Company_Rating    118\n",
       "Job_Title           0\n",
       "Location            0\n",
       "Description         1\n",
       "Salary_Range      209\n",
       "Median_Salary     291\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580587f0",
   "metadata": {},
   "source": [
    "# Handle missing values in Company Rating\n",
    "- Impute missing values in company rating column:\n",
    "    - Since multiple job posting often exist for the same company, we can leverage this by imputing missing company ratings with the available rating of other job posting from the same company. \n",
    "    - By doing so we preserve the integrity of company-level information without introducing external assumptions or generic averages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3061110e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Aligned Automation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Key Responsibilities:\\nBuild, train, and valid...</td>\n",
       "      <td>₹8L – ₹30L/yr (Employer provided)</td>\n",
       "      <td>₹19L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Application Square Infotech Pvt Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Job Summary:\\nWe are seeking a skilled Data Sc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Augusta Hitech Soft Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intern Data Scientist</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Industry: IT\\nQualification: PhD\\nRequired Ski...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DIATOZ Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>We are seeking a highly motivated Junior Data ...</td>\n",
       "      <td>₹60K – ₹1L/mo (Employer provided)</td>\n",
       "      <td>₹80K/mo Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Digitalxc.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analysts</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description: Data Analyst role\\nPosition O...</td>\n",
       "      <td>₹6L – ₹15L/yr (Employer provided)</td>\n",
       "      <td>₹11L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ESJ Asthra Edutech Pvt Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Job Title: Data Scientist\\nJob Type: Full-Time...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Futuremug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-Time Experience - 3 - 5 Years Location: R...</td>\n",
       "      <td>₹60K/mo (Employer provided)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Global scientific company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior Machine Learning Engineer</td>\n",
       "      <td>India</td>\n",
       "      <td>Chennai location only, tamil candidates\\nFresh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Infolexus Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>We are seeking a highly motivated and analytic...</td>\n",
       "      <td>₹4L – ₹10L/yr (Employer provided)</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Jabit Soft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>We are hiring a Senior Data Scientist with str...</td>\n",
       "      <td>₹15L – ₹20L/yr (Employer provided)</td>\n",
       "      <td>₹18L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Lightrains Technolabs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist (ML &amp; AI)</td>\n",
       "      <td>Thiruvananthapuram</td>\n",
       "      <td>Engineering\\nData Scientist (ML &amp; AI)\\nThu Jul...</td>\n",
       "      <td>₹4L – ₹8L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Analyst Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine Learning intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Machine Learning Intern (Remote) – Optimspace\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Science Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Phenomenal HR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>We’re looking for a hands-on Data Scientist or...</td>\n",
       "      <td>₹6L – ₹12L/yr (Employer provided)</td>\n",
       "      <td>₹9L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Predigle-An Esper Group Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>As part of our new AI team, you will have the ...</td>\n",
       "      <td>₹5L – ₹10L/yr (Employer provided)</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Radioso Resources</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data / ML Scientist (Clustering, Trends &amp; Root...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Qualifications\\n● 4 + years in data science or...</td>\n",
       "      <td>₹20L/yr (Employer provided)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>TRIUMPH EDGE INNOVATION PRIVATE LIMITED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI/ML Engineer Data Scientist</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>AI/ML Engineer / Data Scientist\\nCompany: Triu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Tecvesten Consulting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist / Data Analyst / BI</td>\n",
       "      <td>India</td>\n",
       "      <td>About Us\\nTecvesten Consulting, a collective y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vcars auto private limited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Collection and Preparation:\\nInterns help...</td>\n",
       "      <td>₹6L – ₹19L/yr (Employer provided)</td>\n",
       "      <td>₹12L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Company_Name  Company_Rating  \\\n",
       "49                        Aligned Automation             NaN   \n",
       "143      Application Square Infotech Pvt Ltd             NaN   \n",
       "70             Augusta Hitech Soft Solutions             NaN   \n",
       "58                          DIATOZ Solutions             NaN   \n",
       "45                             Digitalxc.com             NaN   \n",
       "106               ESJ Asthra Edutech Pvt Ltd             NaN   \n",
       "74                                 Futuremug             NaN   \n",
       "140                Global scientific company             NaN   \n",
       "57                       Infolexus Solutions             NaN   \n",
       "113                               Jabit Soft             NaN   \n",
       "88                     Lightrains Technolabs             NaN   \n",
       "8                                 Optimspace             NaN   \n",
       "22                                Optimspace             NaN   \n",
       "10                                Optimspace             NaN   \n",
       "28                             Phenomenal HR             NaN   \n",
       "13           Predigle-An Esper Group Company             NaN   \n",
       "89                         Radioso Resources             NaN   \n",
       "148  TRIUMPH EDGE INNOVATION PRIVATE LIMITED             NaN   \n",
       "67                      Tecvesten Consulting             NaN   \n",
       "9                 Vcars auto private limited             NaN   \n",
       "\n",
       "                                             Job_Title            Location  \\\n",
       "49                                      Data Scientist               India   \n",
       "143                                     Data Scientist               India   \n",
       "70                               Intern Data Scientist          Coimbatore   \n",
       "58                               Junior Data Scientist             Gurgaon   \n",
       "45                                       Data Analysts           Bengaluru   \n",
       "106                                     Data Scientist          Coimbatore   \n",
       "74                                      Data Scientist              Remote   \n",
       "140                   Junior Machine Learning Engineer               India   \n",
       "57                                      Data Scientist               India   \n",
       "113                                 Sr. Data Scientist               India   \n",
       "88                            Data Scientist (ML & AI)  Thiruvananthapuram   \n",
       "8                                  Data Analyst Intern              Remote   \n",
       "22                             Machine Learning intern              Remote   \n",
       "10                                 Data Science Intern              Remote   \n",
       "28                                      Data Scientist              Remote   \n",
       "13                                      Data Scientist              Remote   \n",
       "89   Data / ML Scientist (Clustering, Trends & Root...              Remote   \n",
       "148                      AI/ML Engineer Data Scientist              Cochin   \n",
       "67                  Data Scientist / Data Analyst / BI               India   \n",
       "9                                Data Scientist Intern             Chennai   \n",
       "\n",
       "                                           Description  \\\n",
       "49   Key Responsibilities:\\nBuild, train, and valid...   \n",
       "143  Job Summary:\\nWe are seeking a skilled Data Sc...   \n",
       "70   Industry: IT\\nQualification: PhD\\nRequired Ski...   \n",
       "58   We are seeking a highly motivated Junior Data ...   \n",
       "45   Job Description: Data Analyst role\\nPosition O...   \n",
       "106  Job Title: Data Scientist\\nJob Type: Full-Time...   \n",
       "74   Full-Time Experience - 3 - 5 Years Location: R...   \n",
       "140  Chennai location only, tamil candidates\\nFresh...   \n",
       "57   We are seeking a highly motivated and analytic...   \n",
       "113  We are hiring a Senior Data Scientist with str...   \n",
       "88   Engineering\\nData Scientist (ML & AI)\\nThu Jul...   \n",
       "8    Data Analyst Intern (Remote) – Optimspace\\nAbo...   \n",
       "22   Machine Learning Intern (Remote) – Optimspace\\...   \n",
       "10   Data Science Intern (Remote) – Optimspace\\nAbo...   \n",
       "28   We’re looking for a hands-on Data Scientist or...   \n",
       "13   As part of our new AI team, you will have the ...   \n",
       "89   Qualifications\\n● 4 + years in data science or...   \n",
       "148  AI/ML Engineer / Data Scientist\\nCompany: Triu...   \n",
       "67   About Us\\nTecvesten Consulting, a collective y...   \n",
       "9    Data Collection and Preparation:\\nInterns help...   \n",
       "\n",
       "                           Salary_Range   Median_Salary  \n",
       "49    ₹8L – ₹30L/yr (Employer provided)  ₹19L/yr Median  \n",
       "143                                 NaN             NaN  \n",
       "70                                  NaN             NaN  \n",
       "58    ₹60K – ₹1L/mo (Employer provided)  ₹80K/mo Median  \n",
       "45    ₹6L – ₹15L/yr (Employer provided)  ₹11L/yr Median  \n",
       "106                                 NaN             NaN  \n",
       "74          ₹60K/mo (Employer provided)             NaN  \n",
       "140                                 NaN             NaN  \n",
       "57    ₹4L – ₹10L/yr (Employer provided)   ₹7L/yr Median  \n",
       "113  ₹15L – ₹20L/yr (Employer provided)  ₹18L/yr Median  \n",
       "88        ₹4L – ₹8L/yr (Glassdoor Est.)   ₹6L/yr Median  \n",
       "8                                   NaN             NaN  \n",
       "22                                  NaN             NaN  \n",
       "10                                  NaN             NaN  \n",
       "28    ₹6L – ₹12L/yr (Employer provided)   ₹9L/yr Median  \n",
       "13    ₹5L – ₹10L/yr (Employer provided)   ₹8L/yr Median  \n",
       "89          ₹20L/yr (Employer provided)             NaN  \n",
       "148                                 NaN             NaN  \n",
       "67                                  NaN             NaN  \n",
       "9     ₹6L – ₹19L/yr (Employer provided)  ₹12L/yr Median  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Rating'].isnull()][:20].sort_values(by='Company_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19178e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Company names where ratings are null \n",
    "rating_company_null = df_copy[df_copy['Company_Rating'].isnull()]['Company_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cbcd530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Optimspace', 'Vcars auto private limited',\n",
       "       'Predigle-An Esper Group Company', 'Phenomenal HR',\n",
       "       'Digitalxc.com', 'Aligned Automation', 'Infolexus Solutions',\n",
       "       'DIATOZ Solutions', 'Tecvesten Consulting',\n",
       "       'Augusta Hitech Soft Solutions'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_company_null[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b0dc398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating_company_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "daba339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# company names where ratings are not null\n",
    "rating_company_not_null = df_copy[df_copy['Company_Rating'].notnull()]['Company_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb4237e4-19f2-461c-b036-2b28815699dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Optum', 'BP Energy', 'Zelis', 'Navodaya Education Trust',\n",
       "       'Boston Consulting Group', 'Kinaxis Inc.', 'Ericsson', 'PayPal',\n",
       "       'QuantumBricks', 'Maruti Suzuki India Ltd'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_company_not_null[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2bb4df1e-f1a2-4fe8-94fd-3beb52970a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating_company_not_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91347db7-74b0-4c6a-88af-63d424916444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common companies\n",
    "common_companies = list(set(rating_company_null) & set(rating_company_not_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0898a1e1-1494-4221-8400-47747a02a52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DAZN']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee36903d-2646-47f1-8546-1c31bd096f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>DAZN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Description\\n\\nWe are seeking a passionate and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>DAZN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Description\\n\\nWe are seeking a passionate and...</td>\n",
       "      <td>₹6L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>DAZN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>We are seeking a passionate and experienced Da...</td>\n",
       "      <td>₹6L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name  Company_Rating              Job_Title   Location  \\\n",
       "181         DAZN             2.9  Junior Data Scientist  Hyderābād   \n",
       "183         DAZN             NaN  Junior Data Scientist  Hyderābād   \n",
       "201         DAZN             2.9         Data Scientist  Hyderābād   \n",
       "\n",
       "                                           Description  \\\n",
       "181  Description\\n\\nWe are seeking a passionate and...   \n",
       "183  Description\\n\\nWe are seeking a passionate and...   \n",
       "201  We are seeking a passionate and experienced Da...   \n",
       "\n",
       "                      Salary_Range  Median_Salary  \n",
       "181                            NaN            NaN  \n",
       "183  ₹6L – ₹9L/yr (Glassdoor Est.)  ₹7L/yr Median  \n",
       "201  ₹6L – ₹9L/yr (Glassdoor Est.)  ₹7L/yr Median  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains(\"DAZN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be531334-5a08-4825-b8cf-5fa1f3e7bfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description\n",
      "\n",
      "We are seeking a passionate and experienced Data Scientist / Machine Learning Engineer with a strong foundation in Machine Learning, Deep Learning, and Generative AI (GenAI). The ideal candidate will have hands-on experience with modern AI frameworks and libraries, a proven ability to design, develop, and deploy scalable ML solutions, and expertise in working with Large Language Models (LLMs).\n",
      "You will leverage your skills to drive impactful solutions, staying at the forefront of advancements in ML, DL, and GenAI. You will work on cutting-edge projects, incorporating the latest technologies into production-ready systems. If you are excited about advancing your career in a dynamic, innovation-driven environment, we invite you to join us!\n",
      "Description\n",
      "\n",
      "We are seeking a passionate and experienced Data Scientist / Machine Learning Engineer with a strong foundation in Machine Learning, Deep Learning, and Generative AI (GenAI). The ideal candidate will have hands-on experience with modern AI frameworks and libraries, a proven ability to design, develop, and deploy scalable ML solutions, and expertise in working with Large Language Models (LLMs).\n",
      "You will leverage your skills to drive impactful solutions, staying at the forefront of advancements in ML, DL, and GenAI. You will work on cutting-edge projects, incorporating the latest technologies into production-ready systems. If you are excited about advancing your career in a dynamic, innovation-driven environment, we invite you to join us!\n"
     ]
    }
   ],
   "source": [
    "print(df_copy['Description'][181])\n",
    "print(df_copy['Description'][183])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0456e7-c0d0-4f6b-aee6-a6d350ed15ca",
   "metadata": {},
   "source": [
    "- We tried to find those records which has both null values and not null values in company_rating with the same company name (same job posting), but suprisingly we found that there is a duplicate record with the company name 'DAZN' and we missed the duplicate record in initial data cleaning because one record has a rating value and the other record has a missing value in the rating column.\n",
    "- We can drop 181-th row, as there are missing values present in Salary_Range, Median_Salary column and keep the 183-rd row as it has salary values in Salary_Range and Median_Salary columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21d423a9-4aa7-4a1d-9208-3065447d8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the rating value in 183-rd row with 2.9 (derived from 181-th job posting)\n",
    "df_copy.loc[183, 'Company_Rating'] = 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4000ddb3-b52a-4cbf-bcc3-d807ccf11e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>DAZN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Description\\n\\nWe are seeking a passionate and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Macquarie Group Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>In this role, you will leverage your expertise...</td>\n",
       "      <td>₹4L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>DAZN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Description\\n\\nWe are seeking a passionate and...</td>\n",
       "      <td>₹6L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  Company_Rating              Job_Title  \\\n",
       "181                     DAZN             2.9  Junior Data Scientist   \n",
       "182  Macquarie Group Limited             3.8         Data Scientist   \n",
       "183                     DAZN             2.9  Junior Data Scientist   \n",
       "\n",
       "      Location                                        Description  \\\n",
       "181  Hyderābād  Description\\n\\nWe are seeking a passionate and...   \n",
       "182    Gurgaon  In this role, you will leverage your expertise...   \n",
       "183  Hyderābād  Description\\n\\nWe are seeking a passionate and...   \n",
       "\n",
       "                      Salary_Range  Median_Salary  \n",
       "181                            NaN            NaN  \n",
       "182  ₹4L – ₹9L/yr (Glassdoor Est.)  ₹6L/yr Median  \n",
       "183  ₹6L – ₹9L/yr (Glassdoor Est.)  ₹7L/yr Median  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[181:183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c3dd2922-0e1b-4466-ab15-7ea647bdff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can remove the 181-th row \n",
    "df_copy.drop(181, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8786c556-50ef-4291-9c22-282e5a996010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum is a global organization that delivers c...</td>\n",
       "      <td>₹2L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Macquarie Group Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>In this role, you will leverage your expertise...</td>\n",
       "      <td>₹4L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>DAZN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Description\\n\\nWe are seeking a passionate and...</td>\n",
       "      <td>₹6L – ₹9L/yr (Glassdoor Est.)</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  Company_Rating                 Job_Title  \\\n",
       "180                    Optum             3.5  Associate Data Scientist   \n",
       "182  Macquarie Group Limited             3.8            Data Scientist   \n",
       "183                     DAZN             2.9     Junior Data Scientist   \n",
       "\n",
       "      Location                                        Description  \\\n",
       "180      Noida  Optum is a global organization that delivers c...   \n",
       "182    Gurgaon  In this role, you will leverage your expertise...   \n",
       "183  Hyderābād  Description\\n\\nWe are seeking a passionate and...   \n",
       "\n",
       "                      Salary_Range  Median_Salary  \n",
       "180  ₹2L – ₹9L/yr (Glassdoor Est.)  ₹4L/yr Median  \n",
       "182  ₹4L – ₹9L/yr (Glassdoor Est.)  ₹6L/yr Median  \n",
       "183  ₹6L – ₹9L/yr (Glassdoor Est.)  ₹7L/yr Median  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[180:183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ce203aa-8516-4695-9655-8926de50c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(774, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4f145-e1cf-4ea8-83a4-43d380948617",
   "metadata": {},
   "source": [
    " - There are some outliers present in the company_rating column and company_rating column does not follow a normal distribution, therefore we cannot use mean which is biased.\n",
    "- Lets use median (more robust to outliers) to impute the missing values in company rating column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0441153-9801-48a1-8543-c1f271959b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8797564687975648"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "30ee97c0-81ec-4ac7-9606-b0cbf9ba6c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.8\n",
       "Name: Company_Rating, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ebbaf34b-58d8-4fee-80bb-fba1b77ff0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_median = df_copy['Company_Rating'].median()\n",
    "rating_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3a0357db-0d76-4780-9d5e-d7ea41b2c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Company_Rating'] = df_copy['Company_Rating'].fillna(rating_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8334a99b-f7f7-48e0-b209-002d859bd33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Company_Rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d923d5-4008-40a9-8a36-f41addae5489",
   "metadata": {},
   "source": [
    "# Handle missing values in Salary Range\n",
    "- Handling missing values in Salary Range column:\n",
    "    - The missing values in Salary range column do not appear to follow any specific pattern.\n",
    "    - However, based on observations during data collection phase, description column often contains salary-related information as well. \n",
    "    - Therefore we can explore extracting salary details from the description column to impute the missing values in salary range column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448e10a-8351-4de7-b900-2f5ed9befb0a",
   "metadata": {},
   "source": [
    "## Extracting salary-related information from description column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ccba6d6-44f4-4838-9692-4c0a6a7820cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Desc-salary'] = df_copy[df_copy['Salary_Range'].isnull()]['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "70be8b3b-9a84-4040-b4d1-cdf88ff14701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   NaN\n",
       "1                                                   NaN\n",
       "2                                                   NaN\n",
       "3                                                   NaN\n",
       "4                                                   NaN\n",
       "5                                                   NaN\n",
       "6                                                   NaN\n",
       "7     About Kinaxis:\\nAbout Kinaxis\\nElevate your ca...\n",
       "8     Data Analyst Intern (Remote) – Optimspace\\nAbo...\n",
       "9                                                   NaN\n",
       "10    Data Science Intern (Remote) – Optimspace\\nAbo...\n",
       "11                                                  NaN\n",
       "12    The Company\\nPayPal has been revolutionizing c...\n",
       "13                                                  NaN\n",
       "14                                                  NaN\n",
       "15                                                  NaN\n",
       "16                                                  NaN\n",
       "17                                                  NaN\n",
       "18    An internship in Artificial Intelligence (AI) ...\n",
       "19    Strong proficiency in programming languages su...\n",
       "Name: Desc-salary, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Desc-salary'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ce93277d-a110-4872-9a81-8bc17c8912bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Desc-salary'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "683447fe-e994-40e5-b4ca-cc27f2e4efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary_info_fixed(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    patterns = [\n",
    "        r'(?:salary|pay|ctc|compensation)[:\\s-]*₹?\\s?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?\\s*[-to–]\\s*₹?\\s?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?\\s*(?:per\\s?(month|year|annum))',\n",
    "        r'(?:salary|pay|ctc|compensation)[:\\s-]*Rs\\.?\\s?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?(?:\\s*[-to–]\\s*Rs\\.?\\s?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)?\\s*(?:per\\s?(month|year|annum))?',\n",
    "        r'(?:salary|pay|ctc|compensation)[:\\s-]*INR\\s?\\d{1,3}(?:,\\d{3})+(?:\\s*[-to–]\\s*INR\\s?\\d{1,3}(?:,\\d{3})+)?\\s*(?:per\\s?(month|year|annum))?',\n",
    "        r'(?:salary|pay|ctc|compensation)[:\\s-]*\\d+(?:\\.\\d+)?\\s?(?:lpa|lakh|lakhs)\\s*(?:per\\s?(month|year|annum))?',\n",
    "        r'\\b₹\\s?\\d{1,3}(?:,\\d{3})+(?:\\.\\d+)?\\s*[-to–]\\s*₹?\\s?\\d{1,3}(?:,\\d{3})+(?:\\.\\d+)?\\s*(?:per\\s?(month|year|annum))',\n",
    "        r'\\b\\d{2,3}K\\s*(?:per\\s?(month|year|annum))',\n",
    "        r'\\b\\d+(?:\\.\\d+)?\\s?(?:lpa|lakh|lakhs)\\b',\n",
    "    ]\n",
    "\n",
    "    # Combine and search entire phrases, not fragments\n",
    "    full_pattern = '|'.join(f'(?:{p})' for p in patterns)\n",
    "    match = re.search(full_pattern, text, flags=re.IGNORECASE)\n",
    "\n",
    "    return match.group(0).strip() if match else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bc7211da-6c9e-4cb8-99c2-93759fc18e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['salary info'] = df_copy['Desc-salary'].apply(extract_salary_info_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e8c9762c-d90a-4aa2-a298-5ab869d94198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18         Pay: ₹8,086.00 - ₹59,064.56 per month\n",
       "140    Pay: ₹244,623.13 - ₹1,415,105.56 per year\n",
       "148    Pay: ₹266,866.36 - ₹1,794,918.81 per year\n",
       "268         Pay: ₹8,000.00 - ₹10,000.00 per year\n",
       "365    Pay: ₹568,752.26 - ₹3,519,554.93 per year\n",
       "704         Pay: ₹1,000.00 - ₹2,000.00 per month\n",
       "Name: salary info, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_copy['salary info'] != 'None') & (df_copy['salary info'].notna())\n",
    "df_copy[mask]['salary info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7121bd7d-7f7d-4c0d-a9f2-e8e7269d5cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(774,)\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "print(df_copy['salary info'].shape)\n",
    "print(df_copy['salary info'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7848ea0-ed54-43e7-be04-391a6d124761",
   "metadata": {},
   "source": [
    "\n",
    "- From performing text extraction on Description column on those rows where there are missing values in Salary Range column, we were able to find the salary for 6 rows only.  \n",
    "- Out of 209 missing values, we now have 6 salary values to impute in the missing fields.   \n",
    "- lets clean and impute those values respectively.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a590ca6a-82c1-4344-b6e2-1d6d8cd019dd",
   "metadata": {},
   "source": [
    "## Cleaning the extracted salary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53bfdfa4-55f1-4e37-b69e-86eb22562523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'Pay: ' from the values in salary info column \n",
    "df_copy['salary info'] = df_copy['salary info'].str.replace('Pay:', '', regex=False).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7ea98029-b0ce-4283-8ad7-e4198b2addb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '₹8,086.00 - ₹59,064.56 per month',\n",
       "       '₹244,623.13 - ₹1,415,105.56 per year',\n",
       "       '₹266,866.36 - ₹1,794,918.81 per year',\n",
       "       '₹8,000.00 - ₹10,000.00 per year',\n",
       "       '₹568,752.26 - ₹3,519,554.93 per year',\n",
       "       '₹1,000.00 - ₹2,000.00 per month'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['salary info'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0cbc61ef-6289-4fab-a445-5d7357a2d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '₹8,086.00 - ₹59,064.56 per month',\n",
       "       '₹244,623.13 - ₹1,415,105.56', '₹266,866.36 - ₹1,794,918.81',\n",
       "       '₹8,000.00 - ₹10,000.00', '₹568,752.26 - ₹3,519,554.93',\n",
       "       '₹1,000.00 - ₹2,000.00 per month'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'per year' from the values \n",
    "df_copy['salary info'] = df_copy['salary info'].str.replace(\" per year\", \"\", regex=False)\n",
    "df_copy['salary info'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c2f5bf04-5346-4d55-9fe5-0b74087d9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert monthly values to yearly by multiplying them with 12 \n",
    "def convert_mthly_to_yrly(val):\n",
    "    if pd.isna(val) or val is None:\n",
    "        return val\n",
    "\n",
    "    if 'per month' in val:\n",
    "        clean_val = val.replace(' per month', '')\n",
    "\n",
    "        # split the range and convert each part\n",
    "        if ' - ' in clean_val:\n",
    "            parts = clean_val.split(' - ')\n",
    "            # remove ₹ and , then multiple with 12 and convert to float\n",
    "            min_val = float(parts[0].replace('₹', '').replace(',', '')) * 12\n",
    "            max_val = float(parts[1].replace('₹', '').replace(',', '')) * 12\n",
    "\n",
    "            return f'₹{min_val:,.2f} - ₹{max_val:,.2f}'\n",
    "        else:\n",
    "            clean_num = float(clean_val.replace('₹', '')) * 12\n",
    "            return f'₹{clean_num:,.2f}'\n",
    "\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e9ed50c8-596d-45c0-b12d-1f166388830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['salary info'] = df_copy['salary info'].apply(convert_mthly_to_yrly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d2be3a00-f22d-4581-93b2-e59d87f7a0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '₹97,032.00 - ₹708,774.72', '₹244,623.13 - ₹1,415,105.56',\n",
       "       '₹266,866.36 - ₹1,794,918.81', '₹8,000.00 - ₹10,000.00',\n",
       "       '₹568,752.26 - ₹3,519,554.93', '₹12,000.00 - ₹24,000.00'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['salary info'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "28249a72-2de1-452c-a3ec-b8c14f468739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round decimal values in salary info columns\n",
    "\n",
    "def round_salary_values(val):\n",
    "    if pd.isna(val) or val is None:\n",
    "        return val\n",
    "    \n",
    "    # Split on ' - ' to handle ranges\n",
    "    parts = val.split(' - ')\n",
    "    rounded_parts = []\n",
    "    \n",
    "    for part in parts:\n",
    "        if '₹' in part and '.' in part:\n",
    "            # Remove currency symbol and commas BEFORE converting to float\n",
    "            number_str = part.replace('₹', '').replace(',', '')\n",
    "            rounded_number = int(round(float(number_str)))\n",
    "            rounded_part = f'₹{rounded_number:,}'\n",
    "            rounded_parts.append(rounded_part)\n",
    "        else:\n",
    "            rounded_parts.append(part)\n",
    "    \n",
    "    return ' - '.join(rounded_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bcd0c56b-382a-47bf-a9c4-7ad1e086845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['salary info'] = df_copy['salary info'].apply(round_salary_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3dcefb4a-21be-4249-8880-d4228b7daaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '₹97,032 - ₹708,775', '₹244,623 - ₹1,415,106',\n",
       "       '₹266,866 - ₹1,794,919', '₹8,000 - ₹10,000',\n",
       "       '₹568,752 - ₹3,519,555', '₹12,000 - ₹24,000'], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['salary info'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57251ac7-50d8-4031-abf2-fc3deb867920",
   "metadata": {},
   "source": [
    "## Impute the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "19f7150b-81ab-41a0-8d30-6e5fe49bfe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "36bfcad3-83c5-4dda-805b-8f17f2fd5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute salary_range with salary_info where salary_range is NaN\n",
    "df_copy['Salary_Range'] = df_copy['Salary_Range'].fillna(df_copy['salary info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6b96ea47-a03c-4a6d-b574-23bfc0c78d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0d83ec93-05e7-43bf-9e41-400d1a7462b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted columns\n",
    "df_copy.drop(['salary info', 'Desc-salary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fc0f98c6-20d8-40c1-b111-86ac46a379b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c560b6-6af6-4b17-a9a2-4fa5871e88c0",
   "metadata": {},
   "source": [
    "## Clean Salary_Range column \n",
    "- Removing salary source details and storing them in a separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e8fdb6e-d339-44dc-9d1f-3adfa1b799e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ₹2L – ₹9L/yr (Glassdoor Est.)\n",
       "1        ₹2L – ₹9L/yr (Glassdoor Est.)\n",
       "2        ₹3L – ₹7L/yr (Glassdoor Est.)\n",
       "3        ₹7L – ₹9L/yr (Glassdoor Est.)\n",
       "4        ₹2L – ₹7L/yr (Glassdoor Est.)\n",
       "5     ₹1L – ₹2L/mo (Employer provided)\n",
       "6        ₹6L – ₹8L/yr (Glassdoor Est.)\n",
       "7                                 None\n",
       "8                                 None\n",
       "9    ₹6L – ₹19L/yr (Employer provided)\n",
       "Name: Salary_Range, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean Salary_Range column \n",
    "df_copy['Salary_Range'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e8a00c7b-94c1-47e4-af2b-47715e43dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract salary source label\n",
    "df_copy['Salary_Source'] = df_copy['Salary_Range'].str.extract(r'\\((.*?)\\)', expand=False)\n",
    "\n",
    "# Remove label from salary range\n",
    "df_copy['Salary_Range'] = df_copy['Salary_Range'].str.replace(r'\\s*\\(.*?\\)', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "54062877-ca86-4354-8323-adc6fbdf284e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ₹2L – ₹9L/yr\n",
       "1     ₹2L – ₹9L/yr\n",
       "2     ₹3L – ₹7L/yr\n",
       "3     ₹7L – ₹9L/yr\n",
       "4     ₹2L – ₹7L/yr\n",
       "5     ₹1L – ₹2L/mo\n",
       "6     ₹6L – ₹8L/yr\n",
       "7             None\n",
       "8             None\n",
       "9    ₹6L – ₹19L/yr\n",
       "Name: Salary_Range, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2388c978-e8f4-4ff2-bcaf-ce78e7ced959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Glassdoor Est.', 'Employer provided', None, nan], dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e0e0aa-cad1-4126-b049-68761f039466",
   "metadata": {},
   "source": [
    "### Handling yearly, monthly, hourly estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0846813d-aa9d-4eaa-a9fa-bf8b793c6af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/yr', '/mo', '/hr'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range'].str.extract(r'(/[^,\\s)]+)')[0].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c69d743-c77d-45dc-8629-ee2c54d93ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "yr    516\n",
       "mo     44\n",
       "hr      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range'].str.extract(r'/(\\w+)')[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d45082-bde2-495e-b814-74cd3b317e4b",
   "metadata": {},
   "source": [
    "### Converting monthly to yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e5fe7be-7781-4852-bf79-28ab488516d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_salary = df_copy[df_copy['Salary_Range'].str.contains('/mo', regex=False, na=False) ]['Salary_Range']\n",
    "monthly_index = monthly_salary.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6445ded1-a778-458d-a611-454ecc3d797f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  5,  17,  58,  74, 157, 238, 259, 264, 283, 284, 306, 307, 315, 326,\n",
       "       329, 456, 467, 469, 492, 503, 504, 507, 510, 514, 526, 546, 573, 587,\n",
       "       611, 620, 672, 710, 725, 726, 759, 770, 773, 775, 787, 789, 790, 799,\n",
       "       806, 816],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "af7fc3f0-33db-4b1b-b679-0a9460219442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(monthly_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f4e5826f-dc55-404c-bb68-75f5c8aaaaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5        ₹1L – ₹2L/mo\n",
       "17     ₹25K – ₹30K/mo\n",
       "58      ₹60K – ₹1L/mo\n",
       "74            ₹60K/mo\n",
       "157            ₹2L/mo\n",
       "238    ₹45K – ₹55K/mo\n",
       "259           ₹90K/mo\n",
       "264           ₹10K/mo\n",
       "283            ₹5K/mo\n",
       "284    ₹95K – ₹98K/mo\n",
       "Name: Salary_Range, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_salary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "54d5c02a-9924-45bb-aeae-ea3495d2c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_salary_value(s):\n",
    "    s = s.lower().strip()\n",
    "    if 'k' in s:\n",
    "        return float(s.replace('k', '').replace('₹', '').strip()) * 1_000\n",
    "    elif 'l' in s:\n",
    "        return float(s.replace('l', '').replace('₹', '').strip()) * 100_000\n",
    "    else:\n",
    "        return float(s.replace('₹', '').replace(',', '').strip())\n",
    "\n",
    "\n",
    "def convert_monthly_to_yearly(salary):\n",
    "    if not isinstance(salary, str) or '/mo' not in salary.lower():\n",
    "        return salary  # Leave other formats untouched\n",
    "\n",
    "    # Clean text\n",
    "    salary_clean = salary.lower().replace('/mo', '').strip()\n",
    "\n",
    "    # Split ranges (supports hyphen or en dash) \n",
    "    # there are values with '-'    and    without '-' but with '/' \n",
    "    # ₹60K – ₹1L/mo             &      ₹60K/mo \n",
    "    parts = re.split(r'–|-', salary_clean)\n",
    "\n",
    "    try:\n",
    "        if len(parts) == 2:\n",
    "            min_val = normalize_salary_value(parts[0])\n",
    "            max_val = normalize_salary_value(parts[1])\n",
    "            return f\"₹{int(min_val*12):,} – ₹{int(max_val*12):,}/yr\"\n",
    "        else:\n",
    "            single_val = normalize_salary_value(parts[0])\n",
    "            return f\"₹{int(single_val*12):,}/yr\"\n",
    "    except:\n",
    "        return None  # Return None if parsing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4b8a4dc6-e54a-4921-97e7-e15dbeef90e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Salary_Range_Standardized'] = df_copy['Salary_Range'].apply(convert_monthly_to_yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "28af450c-44f1-4837-9aa6-3b10e2fb153b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>₹1L – ₹2L/mo</td>\n",
       "      <td>₹1,200,000 – ₹2,400,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>₹25K – ₹30K/mo</td>\n",
       "      <td>₹300,000 – ₹360,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>₹60K – ₹1L/mo</td>\n",
       "      <td>₹720,000 – ₹1,200,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>₹60K/mo</td>\n",
       "      <td>₹720,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>₹2L/mo</td>\n",
       "      <td>₹2,400,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>₹45K – ₹55K/mo</td>\n",
       "      <td>₹540,000 – ₹660,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>₹90K/mo</td>\n",
       "      <td>₹1,080,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>₹120,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>₹5K/mo</td>\n",
       "      <td>₹60,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>₹95K – ₹98K/mo</td>\n",
       "      <td>₹1,140,000 – ₹1,176,000/yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Salary_Range   Salary_Range_Standardized\n",
       "5      ₹1L – ₹2L/mo  ₹1,200,000 – ₹2,400,000/yr\n",
       "17   ₹25K – ₹30K/mo      ₹300,000 – ₹360,000/yr\n",
       "58    ₹60K – ₹1L/mo    ₹720,000 – ₹1,200,000/yr\n",
       "74          ₹60K/mo                 ₹720,000/yr\n",
       "157          ₹2L/mo               ₹2,400,000/yr\n",
       "238  ₹45K – ₹55K/mo      ₹540,000 – ₹660,000/yr\n",
       "259         ₹90K/mo               ₹1,080,000/yr\n",
       "264         ₹10K/mo                 ₹120,000/yr\n",
       "283          ₹5K/mo                  ₹60,000/yr\n",
       "284  ₹95K – ₹98K/mo  ₹1,140,000 – ₹1,176,000/yr"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[monthly_index[:10], ['Salary_Range', 'Salary_Range_Standardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c337bcb6-689a-4535-bc43-b694b25f9af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ce4d0371-8a0d-4b7f-8800-c55b1e9162f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/yr', '/hr'], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].str.extract(r'(/[^,\\s)]+)')[0].dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4f88d-5d16-4d3e-88c1-18df9e593ea6",
   "metadata": {},
   "source": [
    "**As we can see that all the 44 records with monthly salary Range has been converted to yearly salary range**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10d4ec-364c-4360-835d-eb914b9eb76f",
   "metadata": {},
   "source": [
    "### Converting hourly to yearly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8faccd27-d63a-4b3f-889a-15f886f20dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "yr    560\n",
       "hr      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].str.extract(r'/(\\w+)')[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0a837313-1d51-40b0-8643-e66430317626",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_salary = df_copy[df_copy['Salary_Range_Standardized'].str.contains('/hr', regex=False, na=False)]['Salary_Range_Standardized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4e12699d-dd3f-40c2-939c-6888ac3b87ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hourly_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "03ede83f-2e2e-4a07-bbcb-3553c9dcea3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16       ₹1.20K – ₹2.00K/hr\n",
       "166      ₹25.00 – ₹35.00/hr\n",
       "414    ₹700.00 – ₹900.00/hr\n",
       "470    ₹500.00 – ₹700.00/hr\n",
       "476              ₹250.00/hr\n",
       "610              ₹250.00/hr\n",
       "Name: Salary_Range_Standardized, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a9007378-ce8d-42ee-a07e-1aa4c0298835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hr_to_yr(salary_str):\n",
    "    if not isinstance(salary_str, str) or '/hr' not in salary_str:\n",
    "        return salary_str  # Return unchanged\n",
    "\n",
    "    # Extract numeric range (handles ₹ and K)\n",
    "    pattern = r'₹?\\s?([\\d,.]+(?:K)?)\\s*(?:–|-to-)\\s*₹?\\s?([\\d,.]+(?:K)?)|₹?\\s?([\\d,.]+(?:K)?)'\n",
    "    match = re.search(pattern, salary_str)\n",
    "\n",
    "    def parse_amount(val):\n",
    "        if not val:\n",
    "            return None\n",
    "        val = val.replace(',', '').strip().upper()\n",
    "        if 'K' in val:\n",
    "            return float(val.replace('K', '')) * 1000\n",
    "        return float(val)\n",
    "\n",
    "    if match:\n",
    "        if match.group(1) and match.group(2):  # Range case\n",
    "            low = parse_amount(match.group(1))\n",
    "            high = parse_amount(match.group(2))\n",
    "            if low and high: \n",
    "                return f\"₹{int(low * 2080):,} – ₹{int(high * 2080):,}/yr\"      # 8 hrs per day, 5 days per week, 52 weeks per year = 2080\n",
    "        elif match.group(3):  # Single value case                              # hourly wage * 2080 = yearly salary\n",
    "            val = parse_amount(match.group(3))\n",
    "            if val:\n",
    "                return f\"₹{int(val * 2080):,}/yr\"\n",
    "\n",
    "    return salary_str  # fallback if nothing matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "22907148-3b4b-40fc-b92e-b1b989fd1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Salary_Range_Standardized'] = df_copy['Salary_Range_Standardized'].apply(convert_hr_to_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f601f4ce-b3a7-40a4-bae3-d1aa2a5a76ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].str.contains('/hr', regex=False, na=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6b1a1e27-2973-410a-a2b9-0ac2008bab38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([16, 166, 414, 470, 476, 610], dtype='int64')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_index = hourly_salary.index\n",
    "hourly_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aceab0ad-37cc-4669-be0c-19903fe9ada3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>₹1.20K – ₹2.00K/hr</td>\n",
       "      <td>₹2,496,000 – ₹4,160,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>₹25.00 – ₹35.00/hr</td>\n",
       "      <td>₹52,000 – ₹72,800/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>₹700.00 – ₹900.00/hr</td>\n",
       "      <td>₹1,456,000 – ₹1,872,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>₹500.00 – ₹700.00/hr</td>\n",
       "      <td>₹1,040,000 – ₹1,456,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>₹250.00/hr</td>\n",
       "      <td>₹520,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>₹250.00/hr</td>\n",
       "      <td>₹520,000/yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Salary_Range   Salary_Range_Standardized\n",
       "16     ₹1.20K – ₹2.00K/hr  ₹2,496,000 – ₹4,160,000/yr\n",
       "166    ₹25.00 – ₹35.00/hr        ₹52,000 – ₹72,800/yr\n",
       "414  ₹700.00 – ₹900.00/hr  ₹1,456,000 – ₹1,872,000/yr\n",
       "470  ₹500.00 – ₹700.00/hr  ₹1,040,000 – ₹1,456,000/yr\n",
       "476            ₹250.00/hr                 ₹520,000/yr\n",
       "610            ₹250.00/hr                 ₹520,000/yr"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[hourly_index, ['Salary_Range', 'Salary_Range_Standardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "522bed5b-083f-418e-9569-1d8704d46d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "yr    566\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].str.extract(r'/(\\w+)')[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f984e7bf-509e-4f37-9729-3e93926da242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 16, 166, 414, 470, 476, 610,   5,  17,  58,  74, 157, 238, 259, 264,\n",
       "       283, 284, 306, 307, 315, 326, 329, 456, 467, 469, 492, 503, 504, 507,\n",
       "       510, 514, 526, 546, 573, 587, 611, 620, 672, 710, 725, 726, 759, 770,\n",
       "       773, 775, 787, 789, 790, 799, 806, 816],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_index = hourly_index.append(monthly_index)  \n",
    "total_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "78c3a3ac-540f-42d4-9720-e5c870c443fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>₹1.20K – ₹2.00K/hr</td>\n",
       "      <td>₹2,496,000 – ₹4,160,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>₹25.00 – ₹35.00/hr</td>\n",
       "      <td>₹52,000 – ₹72,800/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>₹700.00 – ₹900.00/hr</td>\n",
       "      <td>₹1,456,000 – ₹1,872,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>₹500.00 – ₹700.00/hr</td>\n",
       "      <td>₹1,040,000 – ₹1,456,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>₹250.00/hr</td>\n",
       "      <td>₹520,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>₹250.00/hr</td>\n",
       "      <td>₹520,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>₹1L – ₹2L/mo</td>\n",
       "      <td>₹1,200,000 – ₹2,400,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>₹25K – ₹30K/mo</td>\n",
       "      <td>₹300,000 – ₹360,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>₹60K – ₹1L/mo</td>\n",
       "      <td>₹720,000 – ₹1,200,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>₹60K/mo</td>\n",
       "      <td>₹720,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>₹2L/mo</td>\n",
       "      <td>₹2,400,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>₹45K – ₹55K/mo</td>\n",
       "      <td>₹540,000 – ₹660,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>₹90K/mo</td>\n",
       "      <td>₹1,080,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>₹120,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>₹5K/mo</td>\n",
       "      <td>₹60,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>₹95K – ₹98K/mo</td>\n",
       "      <td>₹1,140,000 – ₹1,176,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>₹10K – ₹20K/mo</td>\n",
       "      <td>₹120,000 – ₹240,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>₹120,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>₹15K/mo</td>\n",
       "      <td>₹180,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>₹20K – ₹40K/mo</td>\n",
       "      <td>₹240,000 – ₹480,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>₹120,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>₹15K – ₹25K/mo</td>\n",
       "      <td>₹180,000 – ₹300,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>₹40K/mo</td>\n",
       "      <td>₹480,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>₹8K – ₹10K/mo</td>\n",
       "      <td>₹96,000 – ₹120,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>₹1L/mo</td>\n",
       "      <td>₹1,200,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>₹30K – ₹60K/mo</td>\n",
       "      <td>₹360,000 – ₹720,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>₹120,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>₹16K – ₹50K/mo</td>\n",
       "      <td>₹192,000 – ₹600,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>₹20K – ₹40K/mo</td>\n",
       "      <td>₹240,000 – ₹480,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>₹8K – ₹12K/mo</td>\n",
       "      <td>₹96,000 – ₹144,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>₹120,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>₹30K – ₹60K/mo</td>\n",
       "      <td>₹360,000 – ₹720,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>₹15K – ₹30K/mo</td>\n",
       "      <td>₹180,000 – ₹360,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>₹2L/mo</td>\n",
       "      <td>₹2,400,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>₹20K – ₹40K/mo</td>\n",
       "      <td>₹240,000 – ₹480,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>₹25K/mo</td>\n",
       "      <td>₹300,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>₹90K – ₹1L/mo</td>\n",
       "      <td>₹1,080,000 – ₹1,200,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>₹30K – ₹50K/mo</td>\n",
       "      <td>₹360,000 – ₹600,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>₹46K – ₹86K/mo</td>\n",
       "      <td>₹552,000 – ₹1,032,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>₹20K – ₹30K/mo</td>\n",
       "      <td>₹240,000 – ₹360,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>₹2L – ₹3L/mo</td>\n",
       "      <td>₹2,400,000 – ₹3,600,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>₹16K – ₹25K/mo</td>\n",
       "      <td>₹192,000 – ₹300,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>₹15K – ₹20K/mo</td>\n",
       "      <td>₹180,000 – ₹240,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>₹1L – ₹2L/mo</td>\n",
       "      <td>₹1,200,000 – ₹2,400,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>₹22K – ₹60K/mo</td>\n",
       "      <td>₹264,000 – ₹720,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>₹25K/mo</td>\n",
       "      <td>₹300,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>₹40K – ₹70K/mo</td>\n",
       "      <td>₹480,000 – ₹840,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>₹40K – ₹80K/mo</td>\n",
       "      <td>₹480,000 – ₹960,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>₹75K – ₹85K/mo</td>\n",
       "      <td>₹900,000 – ₹1,020,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>₹15K/mo</td>\n",
       "      <td>₹180,000/yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Salary_Range   Salary_Range_Standardized\n",
       "16     ₹1.20K – ₹2.00K/hr  ₹2,496,000 – ₹4,160,000/yr\n",
       "166    ₹25.00 – ₹35.00/hr        ₹52,000 – ₹72,800/yr\n",
       "414  ₹700.00 – ₹900.00/hr  ₹1,456,000 – ₹1,872,000/yr\n",
       "470  ₹500.00 – ₹700.00/hr  ₹1,040,000 – ₹1,456,000/yr\n",
       "476            ₹250.00/hr                 ₹520,000/yr\n",
       "610            ₹250.00/hr                 ₹520,000/yr\n",
       "5            ₹1L – ₹2L/mo  ₹1,200,000 – ₹2,400,000/yr\n",
       "17         ₹25K – ₹30K/mo      ₹300,000 – ₹360,000/yr\n",
       "58          ₹60K – ₹1L/mo    ₹720,000 – ₹1,200,000/yr\n",
       "74                ₹60K/mo                 ₹720,000/yr\n",
       "157                ₹2L/mo               ₹2,400,000/yr\n",
       "238        ₹45K – ₹55K/mo      ₹540,000 – ₹660,000/yr\n",
       "259               ₹90K/mo               ₹1,080,000/yr\n",
       "264               ₹10K/mo                 ₹120,000/yr\n",
       "283                ₹5K/mo                  ₹60,000/yr\n",
       "284        ₹95K – ₹98K/mo  ₹1,140,000 – ₹1,176,000/yr\n",
       "306        ₹10K – ₹20K/mo      ₹120,000 – ₹240,000/yr\n",
       "307               ₹10K/mo                 ₹120,000/yr\n",
       "315               ₹15K/mo                 ₹180,000/yr\n",
       "326        ₹20K – ₹40K/mo      ₹240,000 – ₹480,000/yr\n",
       "329               ₹10K/mo                 ₹120,000/yr\n",
       "456        ₹15K – ₹25K/mo      ₹180,000 – ₹300,000/yr\n",
       "467               ₹40K/mo                 ₹480,000/yr\n",
       "469         ₹8K – ₹10K/mo       ₹96,000 – ₹120,000/yr\n",
       "492                ₹1L/mo               ₹1,200,000/yr\n",
       "503        ₹30K – ₹60K/mo      ₹360,000 – ₹720,000/yr\n",
       "504               ₹10K/mo                 ₹120,000/yr\n",
       "507        ₹16K – ₹50K/mo      ₹192,000 – ₹600,000/yr\n",
       "510        ₹20K – ₹40K/mo      ₹240,000 – ₹480,000/yr\n",
       "514         ₹8K – ₹12K/mo       ₹96,000 – ₹144,000/yr\n",
       "526               ₹10K/mo                 ₹120,000/yr\n",
       "546        ₹30K – ₹60K/mo      ₹360,000 – ₹720,000/yr\n",
       "573        ₹15K – ₹30K/mo      ₹180,000 – ₹360,000/yr\n",
       "587                ₹2L/mo               ₹2,400,000/yr\n",
       "611        ₹20K – ₹40K/mo      ₹240,000 – ₹480,000/yr\n",
       "620               ₹25K/mo                 ₹300,000/yr\n",
       "672         ₹90K – ₹1L/mo  ₹1,080,000 – ₹1,200,000/yr\n",
       "710        ₹30K – ₹50K/mo      ₹360,000 – ₹600,000/yr\n",
       "725        ₹46K – ₹86K/mo    ₹552,000 – ₹1,032,000/yr\n",
       "726        ₹20K – ₹30K/mo      ₹240,000 – ₹360,000/yr\n",
       "759          ₹2L – ₹3L/mo  ₹2,400,000 – ₹3,600,000/yr\n",
       "770        ₹16K – ₹25K/mo      ₹192,000 – ₹300,000/yr\n",
       "773        ₹15K – ₹20K/mo      ₹180,000 – ₹240,000/yr\n",
       "775          ₹1L – ₹2L/mo  ₹1,200,000 – ₹2,400,000/yr\n",
       "787        ₹22K – ₹60K/mo      ₹264,000 – ₹720,000/yr\n",
       "789               ₹25K/mo                 ₹300,000/yr\n",
       "790        ₹40K – ₹70K/mo      ₹480,000 – ₹840,000/yr\n",
       "799        ₹40K – ₹80K/mo      ₹480,000 – ₹960,000/yr\n",
       "806        ₹75K – ₹85K/mo    ₹900,000 – ₹1,020,000/yr\n",
       "816               ₹15K/mo                 ₹180,000/yr"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[total_index, ['Salary_Range', 'Salary_Range_Standardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97349d-7d9b-4ae7-b717-aca2895e2264",
   "metadata": {},
   "source": [
    "**All the records with hourly and monthly salary range has been converted to yearly salary range**  \n",
    "**Now lets clean the 'Salary_Range_Standardized' column further more**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3755159e-a879-471c-8712-1f9837889306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   ₹2L – ₹9L/yr\n",
       "1                   ₹2L – ₹9L/yr\n",
       "2                   ₹3L – ₹7L/yr\n",
       "3                   ₹7L – ₹9L/yr\n",
       "4                   ₹2L – ₹7L/yr\n",
       "5     ₹1,200,000 – ₹2,400,000/yr\n",
       "6                   ₹6L – ₹8L/yr\n",
       "7                           None\n",
       "8                           None\n",
       "9                  ₹6L – ₹19L/yr\n",
       "10                          None\n",
       "11                  ₹4L – ₹9L/yr\n",
       "12                          None\n",
       "13                 ₹5L – ₹10L/yr\n",
       "14                 ₹8L – ₹18L/yr\n",
       "15                 ₹3L – ₹10L/yr\n",
       "16    ₹2,496,000 – ₹4,160,000/yr\n",
       "17        ₹300,000 – ₹360,000/yr\n",
       "18            ₹97,032 - ₹708,775\n",
       "19                          None\n",
       "Name: Salary_Range_Standardized, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2838dd0c-5868-430e-a463-9baac76e4ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815             None\n",
       "816      ₹180,000/yr\n",
       "817    ₹6L – ₹10L/yr\n",
       "818     ₹4L – ₹8L/yr\n",
       "819    ₹3L – ₹10L/yr\n",
       "820             None\n",
       "821             None\n",
       "822    ₹8L – ₹10L/yr\n",
       "823     ₹3L – ₹8L/yr\n",
       "824     ₹6L – ₹7L/yr\n",
       "825          ₹10L/yr\n",
       "826     ₹2L – ₹8L/yr\n",
       "827             None\n",
       "828     ₹2L – ₹9L/yr\n",
       "829             None\n",
       "830    ₹4L – ₹10L/yr\n",
       "831             None\n",
       "832     ₹4L – ₹9L/yr\n",
       "833    ₹3L – ₹13L/yr\n",
       "834     ₹6L – ₹7L/yr\n",
       "Name: Salary_Range_Standardized, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "272e9cf1-bb86-4505-9ecf-69a52239256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert L to actual lakhs \n",
    "\n",
    "def convert_lakh_to_number(val):\n",
    "    if not isinstance(val, str) or 'L' not in val:\n",
    "        return val    # return the value unchanged\n",
    "\n",
    "    pattern = r'(\\d+(?:\\.\\d+)?)L(?:\\s*[-–to]+\\s*(\\d+(?:\\.\\d+)?)L)?'\n",
    "\n",
    "    def replace(match):\n",
    "        val1 = float(match.group(1)) * 100000\n",
    "        val2 = match.group(2)\n",
    "        if val2:\n",
    "            val2 = float(val2) * 100000\n",
    "            return f\"{int(val1)} - {int(val2)}\"\n",
    "        return f\"{int(val1)}\"\n",
    "\n",
    "    return re.sub(pattern, replace, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "47530782-4cc7-4307-b410-5ffc1bb1c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Salary_Range_Standardized'] = df_copy['Salary_Range_Standardized'].apply(convert_lakh_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "70248ec8-398e-4097-a5da-ee8d8f35e27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          ₹200000 – ₹900000/yr\n",
       "1          ₹200000 – ₹900000/yr\n",
       "2          ₹300000 – ₹700000/yr\n",
       "3          ₹700000 – ₹900000/yr\n",
       "4          ₹200000 – ₹700000/yr\n",
       "5    ₹1,200,000 – ₹2,400,000/yr\n",
       "6          ₹600000 – ₹800000/yr\n",
       "7                          None\n",
       "8                          None\n",
       "9         ₹600000 – ₹1900000/yr\n",
       "Name: Salary_Range_Standardized, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8847810e-f54b-4eb2-9e83-ceb5e8ac8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '/yr' from Salary_Range_Standardized' \n",
    "\n",
    "df_copy['Salary_Range_Standardized'] = (\n",
    "    df_copy['Salary_Range_Standardized']\n",
    "    .str.replace('/yr', '', regex=False)\n",
    "    .str.replace('₹', '', regex=False)\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5704265a-4b13-4de7-89ae-b21e3ba9d15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621    50K – 800000\n",
       "655       68K – 86K\n",
       "678    40K – 900000\n",
       "771    72K – 100000\n",
       "Name: Salary_Range_Standardized, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'[^0-9,\\-\\s–]+'\n",
    "df_copy[df_copy['Salary_Range_Standardized'].str.contains(pattern, na=False)]['Salary_Range_Standardized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d4bfa30c-18be-4fcf-8023-1cd936024750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the \"K\" to actual thousands\n",
    "\n",
    "def convert_K_to_numbers(val):\n",
    "    if not isinstance(val, str) or 'K' not in val:\n",
    "        return val\n",
    "\n",
    "    pattern = r'(\\d+(?:\\.\\d+)?)K'\n",
    "    return re.sub(pattern, lambda m: str(int(float(m.group(1)) * 1000)), val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0cc129c5-00d1-40c1-97be-97ba67b06ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Salary_Range_Standardized'] = df_copy['Salary_Range_Standardized'].apply(convert_K_to_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "80d51a04-8a1e-45f1-94a6-f180a0ae18af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Salary_Range_Standardized, dtype: object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'[^0-9,\\-\\s–]+'\n",
    "df_copy[df_copy['Salary_Range_Standardized'].str.contains(pattern, na=False)]['Salary_Range_Standardized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f76b5c1b-3b8b-40e7-87f9-a06a852b48ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621    50000 – 800000\n",
       "655     68000 – 86000\n",
       "678    40000 – 900000\n",
       "771    72000 – 100000\n",
       "Name: Salary_Range_Standardized, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].loc[[621, 655, 678, 771]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f8f56301-a77e-4276-8a36-3a0e67d78390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           200000 – 900000\n",
       "1           200000 – 900000\n",
       "2           300000 – 700000\n",
       "3           700000 – 900000\n",
       "4           200000 – 700000\n",
       "5     1,200,000 – 2,400,000\n",
       "6           600000 – 800000\n",
       "7                      None\n",
       "8                      None\n",
       "9          600000 – 1900000\n",
       "10                     None\n",
       "11          400000 – 900000\n",
       "12                     None\n",
       "13         500000 – 1000000\n",
       "14         800000 – 1800000\n",
       "15         300000 – 1000000\n",
       "16    2,496,000 – 4,160,000\n",
       "17        300,000 – 360,000\n",
       "18         97,032 - 708,775\n",
       "19                     None\n",
       "Name: Salary_Range_Standardized, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e9b29522-d97f-459d-a47d-9e8693b7a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all ',' from the values\n",
    "df_copy['Salary_Range_Standardized'] = df_copy['Salary_Range_Standardized'].str.replace(',', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e12705f3-2df3-4993-9371-297351fbecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       200000 – 900000\n",
       "1       200000 – 900000\n",
       "2       300000 – 700000\n",
       "3       700000 – 900000\n",
       "4       200000 – 700000\n",
       "5     1200000 – 2400000\n",
       "6       600000 – 800000\n",
       "7                  None\n",
       "8                  None\n",
       "9      600000 – 1900000\n",
       "10                 None\n",
       "11      400000 – 900000\n",
       "12                 None\n",
       "13     500000 – 1000000\n",
       "14     800000 – 1800000\n",
       "15     300000 – 1000000\n",
       "16    2496000 – 4160000\n",
       "17      300000 – 360000\n",
       "18       97032 - 708775\n",
       "19                 None\n",
       "Name: Salary_Range_Standardized, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5cdd8d64-b46b-4297-b41d-20b70a27d497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary_Range_Standardized    202\n",
       "Median_Salary                290\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[['Salary_Range_Standardized', 'Median_Salary']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60540146-bd8c-46d1-a4dc-b7a4506820a6",
   "metadata": {},
   "source": [
    "# Handle missing values in Median Salary\n",
    "## Cleaning Median_Salary columns\n",
    "### Handling monthly, hourly estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eb4e401c-0599-4f8e-ab3a-9808578d08dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/yr', '/mo', '/hr'], dtype=object)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary'].str.extract(r'(/[^,\\s)]+)')[0].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d93671da-8214-4091-b528-0bd083f4ff24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "yr    452\n",
       "mo     28\n",
       "hr      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary'].str.extract(r'/(\\w+)')[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b29955-3fc2-4098-bef7-ea11243fb834",
   "metadata": {},
   "source": [
    "### Converting monthly to yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c2c344aa-1fc2-41ff-b08f-93de8f47144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_monthly = df_copy[df_copy['Median_Salary'].str.contains('mo', na=False)]['Median_Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a0ac47d9-9662-4e0c-ae34-f1da9bf8c2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       ₹1L/mo Median\n",
       "17     ₹28K/mo Median\n",
       "58     ₹80K/mo Median\n",
       "238    ₹50K/mo Median\n",
       "284    ₹97K/mo Median\n",
       "306    ₹15K/mo Median\n",
       "326    ₹30K/mo Median\n",
       "456    ₹20K/mo Median\n",
       "469     ₹9K/mo Median\n",
       "503    ₹45K/mo Median\n",
       "507    ₹33K/mo Median\n",
       "510    ₹30K/mo Median\n",
       "514    ₹10K/mo Median\n",
       "546    ₹45K/mo Median\n",
       "573    ₹23K/mo Median\n",
       "611    ₹30K/mo Median\n",
       "672    ₹95K/mo Median\n",
       "710    ₹40K/mo Median\n",
       "725    ₹66K/mo Median\n",
       "726    ₹25K/mo Median\n",
       "759     ₹2L/mo Median\n",
       "770    ₹20K/mo Median\n",
       "773    ₹18K/mo Median\n",
       "775     ₹1L/mo Median\n",
       "787    ₹41K/mo Median\n",
       "790    ₹55K/mo Median\n",
       "799    ₹60K/mo Median\n",
       "806    ₹80K/mo Median\n",
       "Name: Median_Salary, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d9b8de78-41b5-4d7d-9a35-b5d8dcbc6f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(median_monthly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5a853807-1ec3-4d99-a841-4675dc4f83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert monthly to yearly and clean the value (remove unwanted characters)\n",
    "\n",
    "def median_mon_to_year(val):\n",
    "    if not isinstance(val, str) or 'mo' not in val:\n",
    "        return val\n",
    "\n",
    "    # remove unwanted characters\n",
    "    val = val.replace('₹', '').replace('/mo', '').replace('Median', '').strip()\n",
    "\n",
    "    # handle K and L \n",
    "    if 'K' in val:\n",
    "        val = val.replace('K', '')\n",
    "        try:\n",
    "            return f\"{int(float(val) * 1000 * 12):,}\"\n",
    "        except valueError:\n",
    "            return None\n",
    "    \n",
    "    elif 'L' in val:\n",
    "        val = val.replace('L', '')\n",
    "        try:\n",
    "            return f\"{int(float(val) * 100000 * 12):,}\"\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    # handle plain number \n",
    "    try:\n",
    "        return f\"{int(float(val) * 12):,}\"\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "15c04d3d-b400-451c-9678-7d88433d9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Median_Salary_Standardized'] = df_copy['Median_Salary'].apply(median_mon_to_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fe811990-0ad7-43cf-9ec0-0f1202fd4d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>₹1L/mo Median</td>\n",
       "      <td>1,200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>₹28K/mo Median</td>\n",
       "      <td>336,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>₹80K/mo Median</td>\n",
       "      <td>960,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>₹50K/mo Median</td>\n",
       "      <td>600,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>₹15K/mo Median</td>\n",
       "      <td>180,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>₹30K/mo Median</td>\n",
       "      <td>360,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>₹20K/mo Median</td>\n",
       "      <td>240,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>₹9K/mo Median</td>\n",
       "      <td>108,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>₹45K/mo Median</td>\n",
       "      <td>540,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Median_Salary Median_Salary_Standardized\n",
       "5     ₹1L/mo Median                  1,200,000\n",
       "17   ₹28K/mo Median                    336,000\n",
       "58   ₹80K/mo Median                    960,000\n",
       "238  ₹50K/mo Median                    600,000\n",
       "306  ₹15K/mo Median                    180,000\n",
       "326  ₹30K/mo Median                    360,000\n",
       "456  ₹20K/mo Median                    240,000\n",
       "469   ₹9K/mo Median                    108,000\n",
       "503  ₹45K/mo Median                    540,000"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[5, 17, 58, 238, 306, 326, 456, 469, 503], ['Median_Salary', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "14c8f480-2099-4f63-a73b-96f9f15ac36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "yr    452\n",
       "hr      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].str.extract(r'/(\\w+)')[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df197156-c53a-4ae1-b65d-4d6d10830cb7",
   "metadata": {},
   "source": [
    "### Convert hourly to yearly estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9a617dfb-a4f9-4fda-8b45-2169445ac01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16      ₹1.60K/hr Median\n",
       "166     ₹30.00/hr Median\n",
       "414    ₹800.00/hr Median\n",
       "470    ₹600.00/hr Median\n",
       "Name: Median_Salary, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].str.contains('/hr', regex=False, na=False)]['Median_Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "18d4e946-2ae9-47e9-bd40-674ed451698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert hourly wages to yearly and clean the values \n",
    "\n",
    "def median_hr_to_yr(val):\n",
    "    if not isinstance(val, str) or 'hr' not in val:\n",
    "        return val\n",
    "\n",
    "    val = val.replace('/hr', '').replace('₹', '').replace('Median', '').strip()\n",
    "\n",
    "    # there are only 'K' in hourly Median_Salary\n",
    "    try: \n",
    "        if 'K' in val:\n",
    "            val = val.replace('K', '')\n",
    "            hourly = float(val) * 1000\n",
    "        else:                                  \n",
    "            hourly = float(val)\n",
    "\n",
    "        yearly = int(hourly * 2080)           # 8 hrs a day, 5 days a week, 52 weeks a year (8 * 5 * 52 = 2080)\n",
    "        return f\"{yearly:,}\"         # with commmas\n",
    "    except ValueError:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5704e6ee-0fac-4253-a635-70fe1f32d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Median_Salary_Standardized'] = df_copy['Median_Salary_Standardized'].apply(median_hr_to_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "93d10cb2-df65-42e0-a261-940b99aadf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "yr    452\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].str.extract(r'/(\\w+)')[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3b5879e2-0d46-4465-8d97-7a9f1356ee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ₹4L/yr Median\n",
       "1     ₹4L/yr Median\n",
       "2     ₹5L/yr Median\n",
       "3     ₹8L/yr Median\n",
       "4     ₹3L/yr Median\n",
       "5         1,200,000\n",
       "6     ₹7L/yr Median\n",
       "7               NaN\n",
       "8               NaN\n",
       "9    ₹12L/yr Median\n",
       "Name: Median_Salary_Standardized, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ae37c-1d23-4b60-996d-2b93c806e289",
   "metadata": {},
   "source": [
    "### Convert L & K to numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "153d2df3-9f78-4165-a5a4-0cbe163fb3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows containing 'K': 2\n",
      "Rows containing 'L': 450\n"
     ]
    }
   ],
   "source": [
    "num_k = df_copy['Median_Salary_Standardized'].str.contains('K', na=False).sum()\n",
    "num_l = df_copy['Median_Salary_Standardized'].str.contains('L', na=False).sum()\n",
    "\n",
    "print(f\"Rows containing 'K': {num_k}\")\n",
    "print(f\"Rows containing 'L': {num_l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f7672654-35c7-4860-9a06-cb541193ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655    ₹77K/yr Median\n",
       "771    ₹93K/yr Median\n",
       "Name: Median_Salary_Standardized, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].str.contains('K', na=False)]['Median_Salary_Standardized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b373b4e6-ec84-40a7-94eb-511a5b16d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert L & K to numbers\n",
    "\n",
    "def median_normalize(val):\n",
    "    if not isinstance(val, str) or ('K' not in val and 'L' not in val):\n",
    "        return val\n",
    "\n",
    "    clean_val = val.replace('₹', '').replace('/yr', '').replace('Median', '').strip()\n",
    "\n",
    "    try:\n",
    "        if 'K' in clean_val:\n",
    "            raw_val = clean_val.replace('K', '')\n",
    "            return int(float(raw_val) * 1000)\n",
    "            \n",
    "        elif 'L' in clean_val:\n",
    "            raw_val = clean_val.replace('L', '')\n",
    "            return int(float(raw_val) * 100000)\n",
    "    \n",
    "    except ValueError:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1283fd87-cb7d-41eb-9642-5584d329d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Median_Salary_Standardized'] = df_copy[\"Median_Salary_Standardized\"].apply(median_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "179afd37-0a20-42d4-9888-0f3119c7996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400000</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400000</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800000</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1,200,000</td>\n",
       "      <td>₹1L/mo Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700000</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1200000</td>\n",
       "      <td>₹12L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Median_Salary_Standardized   Median_Salary\n",
       "0                     400000   ₹4L/yr Median\n",
       "1                     400000   ₹4L/yr Median\n",
       "2                     500000   ₹5L/yr Median\n",
       "3                     800000   ₹8L/yr Median\n",
       "4                     300000   ₹3L/yr Median\n",
       "5                  1,200,000   ₹1L/mo Median\n",
       "6                     700000   ₹7L/yr Median\n",
       "7                        NaN             NaN\n",
       "8                        NaN             NaN\n",
       "9                    1200000  ₹12L/yr Median"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[['Median_Salary_Standardized', 'Median_Salary']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "05e6d0f2-d4cf-479b-aa00-0103af2f5aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      1,200,000\n",
       "16     3,328,000\n",
       "17       336,000\n",
       "58       960,000\n",
       "166       62,400\n",
       "238      600,000\n",
       "284    1,164,000\n",
       "306      180,000\n",
       "326      360,000\n",
       "414    1,664,000\n",
       "456      240,000\n",
       "469      108,000\n",
       "470    1,248,000\n",
       "503      540,000\n",
       "507      396,000\n",
       "510      360,000\n",
       "514      120,000\n",
       "546      540,000\n",
       "573      276,000\n",
       "611      360,000\n",
       "672    1,140,000\n",
       "710      480,000\n",
       "725      792,000\n",
       "726      300,000\n",
       "759    2,400,000\n",
       "770      240,000\n",
       "773      216,000\n",
       "775    1,200,000\n",
       "787      492,000\n",
       "790      660,000\n",
       "799      720,000\n",
       "806      960,000\n",
       "Name: Median_Salary_Standardized, dtype: object"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pattern to match anything except digits and spaces\n",
    "pattern = r'[^0-9\\s]'\n",
    "df_copy[df_copy['Median_Salary_Standardized'].str.contains(pattern, regex=True, na=False)]['Median_Salary_Standardized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "076f01f0-33dd-4fcf-9933-b2b1d4d8e200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        400000\n",
       "1        400000\n",
       "2        500000\n",
       "3        800000\n",
       "4        300000\n",
       "5     1,200,000\n",
       "6        700000\n",
       "7           NaN\n",
       "8           NaN\n",
       "9       1200000\n",
       "10          NaN\n",
       "11       600000\n",
       "12          NaN\n",
       "13       800000\n",
       "14      1300000\n",
       "15       600000\n",
       "16    3,328,000\n",
       "17      336,000\n",
       "18          NaN\n",
       "19          NaN\n",
       "Name: Median_Salary_Standardized, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "901c5c92-8032-47a4-909e-9b471b739aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0f19291d-6f64-437b-a079-7c3a854975c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values with ',' are strings and without ',' are numeric therefore we have to apply the code only to string values\n",
    "\n",
    "df_copy['Median_Salary_Standardized'] = df_copy['Median_Salary_Standardized'].apply(lambda x: str(x).replace(',', '') \n",
    "                                                                                    if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3450cd91-75cb-4d8b-aabf-316da3dcd491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      400000\n",
       "1      400000\n",
       "2      500000\n",
       "3      800000\n",
       "4      300000\n",
       "5     1200000\n",
       "6      700000\n",
       "7         NaN\n",
       "8         NaN\n",
       "9     1200000\n",
       "10        NaN\n",
       "11     600000\n",
       "12        NaN\n",
       "13     800000\n",
       "14    1300000\n",
       "15     600000\n",
       "16    3328000\n",
       "17     336000\n",
       "18        NaN\n",
       "19        NaN\n",
       "Name: Median_Salary_Standardized, dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5a2e3a4e-00a1-4154-992b-5477e34d0565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Median_Salary_Standardized, dtype: object)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pattern to match anything except digits \n",
    "pattern = r'[^0-9]'\n",
    "df_copy[df_copy['Median_Salary_Standardized'].str.contains(pattern, regex=True, na=False)]['Median_Salary_Standardized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f9856429-5a80-4f67-8399-2bb8d9d06b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>Median_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400000</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400000</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800000</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1200000</td>\n",
       "      <td>₹1L/mo Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700000</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1200000</td>\n",
       "      <td>₹12L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600000</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>800000</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1300000</td>\n",
       "      <td>₹13L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600000</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3328000</td>\n",
       "      <td>₹1.60K/hr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>336000</td>\n",
       "      <td>₹28K/mo Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>600000</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1200000</td>\n",
       "      <td>₹12L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>900000</td>\n",
       "      <td>₹9L/yr Median</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>400000</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Median_Salary_Standardized     Median_Salary\n",
       "0                      400000     ₹4L/yr Median\n",
       "1                      400000     ₹4L/yr Median\n",
       "2                      500000     ₹5L/yr Median\n",
       "3                      800000     ₹8L/yr Median\n",
       "4                      300000     ₹3L/yr Median\n",
       "5                     1200000     ₹1L/mo Median\n",
       "6                      700000     ₹7L/yr Median\n",
       "7                         NaN               NaN\n",
       "8                         NaN               NaN\n",
       "9                     1200000    ₹12L/yr Median\n",
       "10                        NaN               NaN\n",
       "11                     600000     ₹6L/yr Median\n",
       "12                        NaN               NaN\n",
       "13                     800000     ₹8L/yr Median\n",
       "14                    1300000    ₹13L/yr Median\n",
       "15                     600000     ₹6L/yr Median\n",
       "16                    3328000  ₹1.60K/hr Median\n",
       "17                     336000    ₹28K/mo Median\n",
       "18                        NaN               NaN\n",
       "19                        NaN               NaN\n",
       "20                        NaN               NaN\n",
       "21                        NaN               NaN\n",
       "22                        NaN               NaN\n",
       "23                        NaN               NaN\n",
       "24                        NaN               NaN\n",
       "25                     600000     ₹6L/yr Median\n",
       "26                        NaN               NaN\n",
       "27                    1200000    ₹12L/yr Median\n",
       "28                     900000     ₹9L/yr Median\n",
       "29                     400000     ₹4L/yr Median"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[['Median_Salary_Standardized', 'Median_Salary']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490fd20-943b-4467-9c94-385f94a527e4",
   "metadata": {},
   "source": [
    "## Strategy to Imputing missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "03214465-5086-4b50-945d-240c307408d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9662f4ee-c313-4c70-8bdf-49c194aa4e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8e73c01b-1396-4801-9db1-e7ab34f120cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "290+484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "440e789a-5a1d-495d-85c0-6e046ad632e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary_Range_Standardized     202\n",
      "Median_Salary_Standardized    290\n",
      "dtype: int64\n",
      "Salary_Range_Standardized     572\n",
      "Median_Salary_Standardized    484\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_copy[['Salary_Range_Standardized', 'Median_Salary_Standardized']].isnull().sum())\n",
    "print(df_copy[['Salary_Range_Standardized', 'Median_Salary_Standardized']].notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7531260b-3e67-40b1-8403-f70936951b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 774 entries, 0 to 834\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Company_Name                774 non-null    object \n",
      " 1   Company_Rating              774 non-null    float64\n",
      " 2   Job_Title                   774 non-null    object \n",
      " 3   Location                    774 non-null    object \n",
      " 4   Description                 773 non-null    object \n",
      " 5   Salary_Range                572 non-null    object \n",
      " 6   Median_Salary               484 non-null    object \n",
      " 7   Salary_Source               566 non-null    object \n",
      " 8   Salary_Range_Standardized   572 non-null    object \n",
      " 9   Median_Salary_Standardized  484 non-null    object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 82.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1c0e0011-52c2-4b68-a35b-e4b441429718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary_Range_Standardized\n",
       "300000 – 800000     31\n",
       "400000 – 800000     24\n",
       "1000000             23\n",
       "400000 – 1000000    21\n",
       "500000 – 1000000    21\n",
       "700000 – 1000000    20\n",
       "500000 – 800000     18\n",
       "300000 – 500000     18\n",
       "800000 – 1000000    15\n",
       "700000 – 900000     14\n",
       "300000 – 1000000    14\n",
       "500000 – 900000     13\n",
       "600000 – 700000     12\n",
       "500000 – 700000     12\n",
       "200000 – 800000     11\n",
       "600000 – 1000000    11\n",
       "200000 – 900000     10\n",
       "200000 – 600000     10\n",
       "100000 – 1000000     9\n",
       "400000 – 700000      9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Range_Standardized'].value_counts().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee228f-cde7-49d4-afb9-701bde38b244",
   "metadata": {},
   "source": [
    "## Imputing missing values of Median_Salary_Standardized column of 'Intern' job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1baff6fc-6e24-4896-be46-4ae7645fc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\bIntern(?:s|ship|ships)?\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "55caeb2f-b173-46ec-ada0-4386ffbcb70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intern jobs with missing Salary_Range_Standardized\n",
    "\n",
    "df_copy[df_copy['Salary_Range_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "32eb7f03-7f2f-4711-8264-45095e436b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intern jobs with missing Median_Salary_Standardized\n",
    "\n",
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "be17679f-1899-4b9e-87e1-2a7cb3f6408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range_Standardized'].notnull() & \n",
    "        df_copy['Median_Salary_Standardized'].isnull() & \n",
    "        df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c394614e-12d9-43f7-9e7b-91fd8fcea8ed",
   "metadata": {},
   "source": [
    "- There are 21 intern job postings with missing values in Salary_Range_Standardized column.\n",
    "\n",
    "- There are 32 intern job postings with missing values in Median_Salary_Standardized column. \n",
    "\n",
    "- There are 11 intern job postings with recorded values in Salary_Range_Standardized & missing values in Median_Salary_Standardized.\n",
    "\n",
    "- We shall impute the missing values in 'Median_Salary_Standardized' column of 11 intern job postings by calculating the average salary from the recorded values in 'Salary_Range_Standardized' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a581f44-6248-4953-b58a-63ae968522ec",
   "metadata": {},
   "source": [
    "### Imputing missing values of Median_Salary_Standardized by calculating avg \n",
    "**Using average salary from Salary_Range_Standardized**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9cdff60f-7bf5-41a9-863e-dbca6c23c4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>97032 - 708775</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>8000 - 10000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>180000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>200000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>12000 - 24000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Salary_Range_Standardized Median_Salary_Standardized\n",
       "18             97032 - 708775                        NaN\n",
       "264                    120000                        NaN\n",
       "268              8000 - 10000                        NaN\n",
       "315                    180000                        NaN\n",
       "329                    120000                        NaN\n",
       "447                    500000                        NaN\n",
       "461                    200000                        NaN\n",
       "504                    120000                        NaN\n",
       "526                    120000                        NaN\n",
       "704             12000 - 24000                        NaN\n",
       "789                    300000                        NaN"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intern jobs with missing Salary_Range_Standardized & missing Median_Salary_Standardized \n",
    "\n",
    "intern_missing = df_copy[df_copy['Salary_Range_Standardized'].notnull() & \n",
    "                        df_copy['Median_Salary_Standardized'].isnull() & \n",
    "                        df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)] \\\n",
    "                        [['Salary_Range_Standardized', 'Median_Salary_Standardized']]\n",
    "\n",
    "intern_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5b770744-445b-46d5-8986-586c2a511a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sal(val):\n",
    "    if not isinstance(val, str) or pd.isna(val):\n",
    "        return np.nan\n",
    "        \n",
    "    if '-' in val or '–' in val:  \n",
    "        parts = re.split(r'[–-]', val)\n",
    "        try:\n",
    "            return(int(parts[0].strip()) + int(parts[1].strip())) // 2\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    try:\n",
    "        return int(val.strip())\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "82137b0e-7389-4bc6-9640-460b08e5865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the average salary \n",
    "\n",
    "pattern = r'\\bIntern(?:s|ship|ships)?\\b'\n",
    "\n",
    "intern_mask = df_copy['Job_Title'].str.contains(pattern, regex=True, na=False) & \\\n",
    "              df_copy['Salary_Range_Standardized'].notna() & df_copy['Median_Salary_Standardized'].isna()\n",
    "\n",
    "df_copy.loc[intern_mask, 'avg_sal'] = df_copy.loc[intern_mask, 'Salary_Range_Standardized'].apply(avg_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d8437ebb-8a7d-4ca6-8fa1-a8cc3a0afb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([18, 264, 268, 315, 329, 447, 461, 504, 526, 704, 789], dtype='int64')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intern_missing_index = intern_missing.index\n",
    "intern_missing_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2fd2db46-26a3-4dc2-81a9-b3fec9bfdcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>97032 - 708775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>8000 - 10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>180000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>12000 - 24000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Salary_Range_Standardized Median_Salary_Standardized   avg_sal\n",
       "18             97032 - 708775                        NaN  402903.0\n",
       "264                    120000                        NaN  120000.0\n",
       "268              8000 - 10000                        NaN    9000.0\n",
       "315                    180000                        NaN  180000.0\n",
       "329                    120000                        NaN  120000.0\n",
       "447                    500000                        NaN  500000.0\n",
       "461                    200000                        NaN  200000.0\n",
       "504                    120000                        NaN  120000.0\n",
       "526                    120000                        NaN  120000.0\n",
       "704             12000 - 24000                        NaN   18000.0\n",
       "789                    300000                        NaN  300000.0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[intern_missing_index, ['Salary_Range_Standardized', 'Median_Salary_Standardized', 'avg_sal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "138c0be0-a5bb-4844-8a80-17a2af2b453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values in median_salary_standardized with the average salary \n",
    "\n",
    "df_copy.loc[intern_mask, 'Median_Salary_Standardized'] = df_copy.loc[intern_mask, 'Median_Salary_Standardized'].fillna(\n",
    "                                                            df_copy.loc[intern_mask, 'avg_sal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8e7d3cc2-240d-4988-9d24-a49b45313b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>97032 - 708775</td>\n",
       "      <td>402903.0</td>\n",
       "      <td>402903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>8000 - 10000</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>180000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>500000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>12000 - 24000</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>300000</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Salary_Range_Standardized Median_Salary_Standardized   avg_sal\n",
       "18             97032 - 708775                   402903.0  402903.0\n",
       "264                    120000                   120000.0  120000.0\n",
       "268              8000 - 10000                     9000.0    9000.0\n",
       "315                    180000                   180000.0  180000.0\n",
       "329                    120000                   120000.0  120000.0\n",
       "447                    500000                   500000.0  500000.0\n",
       "461                    200000                   200000.0  200000.0\n",
       "504                    120000                   120000.0  120000.0\n",
       "526                    120000                   120000.0  120000.0\n",
       "704             12000 - 24000                    18000.0   18000.0\n",
       "789                    300000                   300000.0  300000.0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[intern_missing_index, ['Salary_Range_Standardized','Median_Salary_Standardized', 'avg_sal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "99bb9297-d1f6-4a8f-bf3b-ddea52b20690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the values\n",
    "\n",
    "df_copy.loc[intern_missing_index, 'Median_Salary_Standardized'] = (\n",
    "    pd.to_numeric(df_copy.loc[intern_missing_index, 'Median_Salary_Standardized'], errors='coerce')\n",
    "    .round()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2184f363-535f-455f-8e56-828f683ebb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>97032 - 708775</td>\n",
       "      <td>402903.0</td>\n",
       "      <td>402903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>8000 - 10000</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>180000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>500000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>12000 - 24000</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>300000</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Salary_Range_Standardized Median_Salary_Standardized   avg_sal\n",
       "18             97032 - 708775                   402903.0  402903.0\n",
       "264                    120000                   120000.0  120000.0\n",
       "268              8000 - 10000                     9000.0    9000.0\n",
       "315                    180000                   180000.0  180000.0\n",
       "329                    120000                   120000.0  120000.0\n",
       "447                    500000                   500000.0  500000.0\n",
       "461                    200000                   200000.0  200000.0\n",
       "504                    120000                   120000.0  120000.0\n",
       "526                    120000                   120000.0  120000.0\n",
       "704             12000 - 24000                    18000.0   18000.0\n",
       "789                    300000                   300000.0  300000.0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[intern_missing_index, ['Salary_Range_Standardized','Median_Salary_Standardized', 'avg_sal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7788c7ae-39e2-430c-944d-106a91950ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary', 'Salary_Source',\n",
       "       'Salary_Range_Standardized', 'Median_Salary_Standardized', 'avg_sal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1c8c93f8-7dcf-4c63-880a-c1b91a816748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d04427ea-5345-4881-a52a-6c00016a1414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rest of Intern jobs with missing Median_Salary_Standardized\n",
    "\n",
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "334abf21-ee2e-473c-bdca-4961d3509203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>4.6</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>3.2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>4.5</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>4.1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>4.1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>4.4</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>4.5</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3.8</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>3.7</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>4.1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>4.2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3.4</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>4.1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>3.9</td>\n",
       "      <td>96000 – 144000</td>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>3.9</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>3.9</td>\n",
       "      <td>12000 - 24000</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>97032 - 708775</td>\n",
       "      <td>402903.0</td>\n",
       "      <td>402903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>3.9</td>\n",
       "      <td>180000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>3.7</td>\n",
       "      <td>96000 – 120000</td>\n",
       "      <td>108000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>3.9</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>3.4</td>\n",
       "      <td>500000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000 – 1900000</td>\n",
       "      <td>1200000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>3.9</td>\n",
       "      <td>8000 - 10000</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000 – 240000</td>\n",
       "      <td>180000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>3.9</td>\n",
       "      <td>240000 – 480000</td>\n",
       "      <td>360000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company_Rating Salary_Range_Standardized Median_Salary_Standardized  \\\n",
       "8               3.9                      None                        NaN   \n",
       "409             4.6                      None                        NaN   \n",
       "687             3.2                      None                        NaN   \n",
       "640             3.9                      None                        NaN   \n",
       "638             4.5                      None                        NaN   \n",
       "551             4.1                      None                        NaN   \n",
       "547             4.1                      None                        NaN   \n",
       "536             3.9                      None                        NaN   \n",
       "491             3.0                      None                        NaN   \n",
       "446             4.4                      None                        NaN   \n",
       "417             4.5                      None                        NaN   \n",
       "415             3.8                      None                        NaN   \n",
       "425             3.7                      None                        NaN   \n",
       "821             4.1                      None                        NaN   \n",
       "10              3.9                      None                        NaN   \n",
       "253             4.2                      None                        NaN   \n",
       "24              4.8                      None                        NaN   \n",
       "70              3.9                      None                        NaN   \n",
       "81              3.4                      None                        NaN   \n",
       "249             4.1                      None                        NaN   \n",
       "98              4.0                      None                        NaN   \n",
       "514             3.9            96000 – 144000                     120000   \n",
       "789             3.9                    300000                   300000.0   \n",
       "704             3.9             12000 - 24000                    18000.0   \n",
       "18              5.0            97032 - 708775                   402903.0   \n",
       "526             3.9                    120000                   120000.0   \n",
       "315             3.9                    180000                   180000.0   \n",
       "329             3.9                    120000                   120000.0   \n",
       "504             3.9                    120000                   120000.0   \n",
       "469             3.7            96000 – 120000                     108000   \n",
       "461             3.9                    200000                   200000.0   \n",
       "447             3.4                    500000                   500000.0   \n",
       "9               3.9          600000 – 1900000                    1200000   \n",
       "264             3.9                    120000                   120000.0   \n",
       "268             3.9              8000 - 10000                     9000.0   \n",
       "306             3.9           120000 – 240000                     180000   \n",
       "510             3.9           240000 – 480000                     360000   \n",
       "\n",
       "      avg_sal  \n",
       "8         NaN  \n",
       "409       NaN  \n",
       "687       NaN  \n",
       "640       NaN  \n",
       "638       NaN  \n",
       "551       NaN  \n",
       "547       NaN  \n",
       "536       NaN  \n",
       "491       NaN  \n",
       "446       NaN  \n",
       "417       NaN  \n",
       "415       NaN  \n",
       "425       NaN  \n",
       "821       NaN  \n",
       "10        NaN  \n",
       "253       NaN  \n",
       "24        NaN  \n",
       "70        NaN  \n",
       "81        NaN  \n",
       "249       NaN  \n",
       "98        NaN  \n",
       "514       NaN  \n",
       "789  300000.0  \n",
       "704   18000.0  \n",
       "18   402903.0  \n",
       "526  120000.0  \n",
       "315  180000.0  \n",
       "329  120000.0  \n",
       "504  120000.0  \n",
       "469       NaN  \n",
       "461  200000.0  \n",
       "447  500000.0  \n",
       "9         NaN  \n",
       "264  120000.0  \n",
       "268    9000.0  \n",
       "306       NaN  \n",
       "510       NaN  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)] \\\n",
    "        [['Company_Rating', 'Salary_Range_Standardized', 'Median_Salary_Standardized', 'avg_sal']] \\\n",
    "        .sort_values(by='Median_Salary_Standardized', key=lambda x: x.isna(), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "97df51d7-9401-4d64-99c3-6ff2af01bcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name                                                         Optimspace\n",
       "Company_Rating                                                              3.9\n",
       "Job_Title                                               Machine Learning intern\n",
       "Location                                                                 Remote\n",
       "Description                   Machine Learning Intern (Remote) – Optimspace\\...\n",
       "Salary_Range                                                               None\n",
       "Median_Salary                                                               NaN\n",
       "Salary_Source                                                              None\n",
       "Salary_Range_Standardized                                                  None\n",
       "Median_Salary_Standardized                                                  NaN\n",
       "avg_sal                                                                     NaN\n",
       "Name: 22, dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ed98d2cc-0c8c-4973-af4b-b1375d3eb092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Optimspace</td>\n",
       "      <td>Machine Learning intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company_Name                Job_Title  Company_Rating  \\\n",
       "8    Optimspace      Data Analyst Intern             3.9   \n",
       "10   Optimspace      Data Science Intern             3.9   \n",
       "22   Optimspace  Machine Learning intern             3.9   \n",
       "\n",
       "   Salary_Range_Standardized Median_Salary_Standardized  \n",
       "8                       None                        NaN  \n",
       "10                      None                        NaN  \n",
       "22                      None                        NaN  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Optimspace')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Salary_Range_Standardized', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4fd86427-3467-48e9-b992-f3e86cf6298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[22, 'Median_Salary_Standardized'] = 120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "af59b074-ae91-4482-a6cd-3e51a3ff8afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name                                                         Optimspace\n",
       "Company_Rating                                                              3.9\n",
       "Job_Title                                               Machine Learning intern\n",
       "Location                                                                 Remote\n",
       "Description                   Machine Learning Intern (Remote) – Optimspace\\...\n",
       "Salary_Range                                                               None\n",
       "Median_Salary                                                               NaN\n",
       "Salary_Source                                                              None\n",
       "Salary_Range_Standardized                                                  None\n",
       "Median_Salary_Standardized                                               120000\n",
       "avg_sal                                                                     NaN\n",
       "Name: 22, dtype: object"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "36ff81e8-a3df-4e6c-a605-241f454128dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Median_Salary_Standardized    278\n",
       "Salary_Range_Standardized     202\n",
       "dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[['Median_Salary_Standardized', 'Salary_Range_Standardized']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c2db5-411f-4ea6-8410-19287acf22de",
   "metadata": {},
   "source": [
    "## Imputing missing values of Median_Salary_Standardized \n",
    "**Using Company_Rating and Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "735a2ed6-0b0f-4909-979d-8b802768ac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3. , 3.2, 3.4, 3.7, 3.8, 3.9, 4. , 4.1, 4.2, 4.4, 4.5, 4.6, 4.8])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[\n",
    "    df_copy['Salary_Range_Standardized'].isna() & \n",
    "    df_copy['Median_Salary_Standardized'].isna() & \n",
    "    df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)\n",
    "]['Company_Rating'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c6d7c77e-bd50-4b06-865e-7d419d80d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.4, 3.7, 3.9, 5. ])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[\n",
    "    df_copy['Salary_Range_Standardized'].notna() & \n",
    "    df_copy['Median_Salary_Standardized'].notna() & \n",
    "    df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)\n",
    "]['Company_Rating'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c4bc2b61-acb4-4f11-8d55-fc3517b0b763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>AI/ML Engineering Intern – Intern-to-Hire</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>500000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>96000 – 120000</td>\n",
       "      <td>108000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>240000 – 480000</td>\n",
       "      <td>360000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>600000 – 1900000</td>\n",
       "      <td>1200000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Data Science Internship</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>120000 – 240000</td>\n",
       "      <td>180000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Data Analytics Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Data Science Internship (Web Scraping)</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>96000 – 144000</td>\n",
       "      <td>120000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>12000 - 24000</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Pune</td>\n",
       "      <td>180000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>AI &amp; ML Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>8000 - 10000</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Internships in AI &amp; Data Science</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>97032 - 708775</td>\n",
       "      <td>402903.0</td>\n",
       "      <td>402903.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job_Title  Company_Rating    Location  \\\n",
       "447  AI/ML Engineering Intern – Intern-to-Hire             3.4   Bengaluru   \n",
       "469                        Data Science Intern             3.7       Delhi   \n",
       "510                    Machine Learning Intern             3.9   Bengaluru   \n",
       "789                        Data Science Intern             3.9  Chandigarh   \n",
       "9                        Data Scientist Intern             3.9     Chennai   \n",
       "504                        Data Science Intern             3.9      Cochin   \n",
       "526                        Data Science Intern             3.9      Cochin   \n",
       "461                        Data Science Intern             3.9  Coimbatore   \n",
       "264                    Data Science Internship             3.9       India   \n",
       "306                        Data Science Intern             3.9       India   \n",
       "329                      Data Analytics Intern             3.9       India   \n",
       "514     Data Science Internship (Web Scraping)             3.9       India   \n",
       "704                    Machine Learning Intern             3.9       India   \n",
       "315                  Data Scientist Internship             3.9        Pune   \n",
       "268                             AI & ML Intern             3.9      Remote   \n",
       "18            Internships in AI & Data Science             5.0      Cochin   \n",
       "\n",
       "    Salary_Range_Standardized Median_Salary_Standardized   avg_sal  \n",
       "447                    500000                   500000.0  500000.0  \n",
       "469            96000 – 120000                     108000       NaN  \n",
       "510           240000 – 480000                     360000       NaN  \n",
       "789                    300000                   300000.0  300000.0  \n",
       "9            600000 – 1900000                    1200000       NaN  \n",
       "504                    120000                   120000.0  120000.0  \n",
       "526                    120000                   120000.0  120000.0  \n",
       "461                    200000                   200000.0  200000.0  \n",
       "264                    120000                   120000.0  120000.0  \n",
       "306           120000 – 240000                     180000       NaN  \n",
       "329                    120000                   120000.0  120000.0  \n",
       "514            96000 – 144000                     120000       NaN  \n",
       "704             12000 - 24000                    18000.0   18000.0  \n",
       "315                    180000                   180000.0  180000.0  \n",
       "268              8000 - 10000                     9000.0    9000.0  \n",
       "18             97032 - 708775                   402903.0  402903.0  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range_Standardized'].notna() & \n",
    "        df_copy['Median_Salary_Standardized'].notna() & \n",
    "        df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)\n",
    "       ][['Job_Title', 'Company_Rating', 'Location', 'Salary_Range_Standardized', 'Median_Salary_Standardized', 'avg_sal']].sort_values(\n",
    "        by=['Company_Rating', 'Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f37d5369-2746-4e4e-8d8d-aafab334b74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>AI/ML Intern</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>AI/ML/DL Intern</td>\n",
       "      <td>3.2</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>AI/ML &amp; Generative AI Intern (6-Month Internship)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Intern-Data Science</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>AI - Interns</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Intern Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>AI - Interns</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>AI Intern</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Intern - Generative AI</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>AI Engineering Intern</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>AI Engineer Intern</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job_Title  Company_Rating  \\\n",
       "491                                       AI/ML Intern             3.0   \n",
       "687                                    AI/ML/DL Intern             3.2   \n",
       "81                               Data Science - Intern             3.4   \n",
       "425  AI/ML & Generative AI Intern (6-Month Internship)             3.7   \n",
       "415                                Intern-Data Science             3.8   \n",
       "536                                       AI - Interns             3.9   \n",
       "70                               Intern Data Scientist             3.9   \n",
       "640                            Machine Learning Intern             3.9   \n",
       "8                                  Data Analyst Intern             3.9   \n",
       "10                                 Data Science Intern             3.9   \n",
       "98                                 Data Science Intern             4.0   \n",
       "547                                       AI - Interns             4.1   \n",
       "249                                Data Science Intern             4.1   \n",
       "551                                          AI Intern             4.1   \n",
       "821                             Intern - Generative AI             4.1   \n",
       "253                              AI Engineering Intern             4.2   \n",
       "446                              Data Science - Intern             4.4   \n",
       "638                                Data Science Intern             4.5   \n",
       "417                                Data Science Intern             4.5   \n",
       "409                                 AI Engineer Intern             4.6   \n",
       "24                               Data Science - Intern             4.8   \n",
       "\n",
       "       Location Salary_Range_Standardized Median_Salary_Standardized  \n",
       "491   Bengaluru                      None                        NaN  \n",
       "687       India                      None                        NaN  \n",
       "81    Bengaluru                      None                        NaN  \n",
       "425     Gujarat                      None                        NaN  \n",
       "415   Bengaluru                      None                        NaN  \n",
       "536      Cochin                      None                        NaN  \n",
       "70   Coimbatore                      None                        NaN  \n",
       "640       Delhi                      None                        NaN  \n",
       "8        Remote                      None                        NaN  \n",
       "10       Remote                      None                        NaN  \n",
       "98       Mumbai                      None                        NaN  \n",
       "547      Cochin                      None                        NaN  \n",
       "249     Gurgaon                      None                        NaN  \n",
       "551     Gurgaon                      None                        NaN  \n",
       "821     Gurgaon                      None                        NaN  \n",
       "253   Bengaluru                      None                        NaN  \n",
       "446      Remote                      None                        NaN  \n",
       "638   Bengaluru                      None                        NaN  \n",
       "417     Chennai                      None                        NaN  \n",
       "409   Bengaluru                      None                        NaN  \n",
       "24       Remote                      None                        NaN  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[\n",
    "    df_copy['Salary_Range_Standardized'].isna() & \n",
    "    df_copy['Median_Salary_Standardized'].isna() & \n",
    "    df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)\n",
    "][['Job_Title', 'Company_Rating', 'Location', 'Salary_Range_Standardized', 'Median_Salary_Standardized']].sort_values(\n",
    "        by=['Company_Rating', 'Location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042693c-e08d-4f25-9555-981b9cbf9afe",
   "metadata": {},
   "source": [
    "- Rows 504, 526 contains the same rating, location, and salary, we can use that information to impute row 536 which again contains the same rating, location\n",
    "  \n",
    "- The intern job postings (rows: 264, 306, 329, 514, 704) which are located in 'India' contains either 1,20,000 or 1,80,000 as the salary, we can use this information to impute row 687.  \n",
    "- However the rating differs, which for recorded salary values it is 3.9 (on rows 264,.. probably imputed by me using global median) and for missing salary value (on row 687) the rating is 3.2. Lets reduce the salary values of rows with rating 3.9 (rows 264,..) and use that to fill row with rating 3.2 (row 687). Lets use the value 96,000 (8K a month) to impute. \n",
    "\n",
    "- We can use row 461 to impute missing value in row 70 as they have the same company rating, job title, location.\n",
    "\n",
    "- To fill the intern job postings with location bengaluru we only have row 510 to use as row 447 is baised (job title: intern to hire). Row 510 has company rating of 3.9 and salary of 3,60,000 and job title 'Machine Learning Intern', we can use that information to fill row 415 which has the same rating and location. \n",
    "\n",
    "- From our observation rows 268, 704 has very low salary which mighty be in monthly estimation and from further analysis they are indeed yearly salary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6f978717-438d-4dc1-bf2d-100f60faf5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>RP2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Job Title: Data Science Intern\\nLocation: Erna...</td>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employer provided</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>iDataLytics</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Job Title: Data Science Intern\\nLocation: Info...</td>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employer provided</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>ALIGNMINDS TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>3.9</td>\n",
       "      <td>AI - Interns</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Job Title: AI Intern\\nLocation: Kochi, Kerala\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>AlignMinds</td>\n",
       "      <td>4.1</td>\n",
       "      <td>AI - Interns</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Job Title: AI Intern\\nLocation: Kochi, Kerala\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Company_Name  Company_Rating  \\\n",
       "504                                      RP2             3.9   \n",
       "526                              iDataLytics             3.9   \n",
       "536  ALIGNMINDS TECHNOLOGIES PRIVATE LIMITED             3.9   \n",
       "547                               AlignMinds             4.1   \n",
       "\n",
       "               Job_Title Location  \\\n",
       "504  Data Science Intern   Cochin   \n",
       "526  Data Science Intern   Cochin   \n",
       "536         AI - Interns   Cochin   \n",
       "547         AI - Interns   Cochin   \n",
       "\n",
       "                                           Description Salary_Range  \\\n",
       "504  Job Title: Data Science Intern\\nLocation: Erna...      ₹10K/mo   \n",
       "526  Job Title: Data Science Intern\\nLocation: Info...      ₹10K/mo   \n",
       "536  Job Title: AI Intern\\nLocation: Kochi, Kerala\\...         None   \n",
       "547  Job Title: AI Intern\\nLocation: Kochi, Kerala\\...         None   \n",
       "\n",
       "    Median_Salary      Salary_Source Salary_Range_Standardized  \\\n",
       "504           NaN  Employer provided                    120000   \n",
       "526           NaN  Employer provided                    120000   \n",
       "536           NaN               None                      None   \n",
       "547           NaN               None                      None   \n",
       "\n",
       "    Median_Salary_Standardized   avg_sal  \n",
       "504                   120000.0  120000.0  \n",
       "526                   120000.0  120000.0  \n",
       "536                        NaN       NaN  \n",
       "547                        NaN       NaN  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[504, 526, 536, 547]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d9b4c64f-3c9f-4b56-a6af-07343f675064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill row 536 with the value of row 526\n",
    "\n",
    "if pd.isna(df_copy.loc[536, 'Median_Salary_Standardized']):\n",
    "    df_copy.loc[536, 'Median_Salary_Standardized'] = df_copy.loc[526, 'Median_Salary_Standardized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f87c18cf-a284-4966-b407-8ef7117445ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill row 547 with the value of row 526\n",
    "\n",
    "df_copy.loc[547, 'Median_Salary_Standardized'] = 1200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4dc78d0f-3db5-41a8-9658-d5ada445ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute row 687 with salary of 96,000  \n",
    "\n",
    "df_copy.loc[687, 'Median_Salary_Standardized'] = 96000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f8af0d61-0da9-40c8-a6fe-5cab3463d3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Profenaa technologies</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Company Name: profenaa Technologies OMR center...</td>\n",
       "      <td>₹2L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employer provided</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Augusta Hitech Soft Solutions</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Intern Data Scientist</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Industry: IT\\nQualification: PhD\\nRequired Ski...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Company_Name  Company_Rating              Job_Title  \\\n",
       "461          Profenaa technologies             3.9    Data Science Intern   \n",
       "70   Augusta Hitech Soft Solutions             3.9  Intern Data Scientist   \n",
       "\n",
       "       Location                                        Description  \\\n",
       "461  Coimbatore  Company Name: profenaa Technologies OMR center...   \n",
       "70   Coimbatore  Industry: IT\\nQualification: PhD\\nRequired Ski...   \n",
       "\n",
       "    Salary_Range Median_Salary      Salary_Source Salary_Range_Standardized  \\\n",
       "461       ₹2L/yr           NaN  Employer provided                    200000   \n",
       "70          None           NaN               None                      None   \n",
       "\n",
       "    Median_Salary_Standardized   avg_sal  \n",
       "461                   200000.0  200000.0  \n",
       "70                         NaN       NaN  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[461, 70]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ce659b9f-a915-4a58-8994-a858c75b9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill row 70 with value from row 461\n",
    "\n",
    "df_copy.loc[70, 'Median_Salary_Standardized'] = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "fe96fb92-a66c-4809-9c81-db5c7d81e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill row 415 with value from row 510\n",
    "\n",
    "df_copy.loc[415, 'Median_Salary_Standardized'] = 360000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "63729627-fed1-4d11-a4a8-4846616355a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert salaries of row 268, 704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5c0e16ab-73c1-41c5-9bce-48e8a3515cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)][\n",
    "'Median_Salary_Standardized'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ae5bd467-0067-4d27-9181-5a769c6a77f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>AI Engineering Intern</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>AI Engineer Intern</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>AI/ML Intern</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>AI/ML &amp; Generative AI Intern (6-Month Internship)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>AI Intern</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Intern - Generative AI</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job_Title  Company_Rating  \\\n",
       "81                               Data Science - Intern             3.4   \n",
       "253                              AI Engineering Intern             4.2   \n",
       "409                                 AI Engineer Intern             4.6   \n",
       "491                                       AI/ML Intern             3.0   \n",
       "638                                Data Science Intern             4.5   \n",
       "417                                Data Science Intern             4.5   \n",
       "640                            Machine Learning Intern             3.9   \n",
       "425  AI/ML & Generative AI Intern (6-Month Internship)             3.7   \n",
       "249                                Data Science Intern             4.1   \n",
       "551                                          AI Intern             4.1   \n",
       "821                             Intern - Generative AI             4.1   \n",
       "98                                 Data Science Intern             4.0   \n",
       "8                                  Data Analyst Intern             3.9   \n",
       "10                                 Data Science Intern             3.9   \n",
       "24                               Data Science - Intern             4.8   \n",
       "446                              Data Science - Intern             4.4   \n",
       "\n",
       "      Location Salary_Range_Standardized Median_Salary_Standardized  \n",
       "81   Bengaluru                      None                        NaN  \n",
       "253  Bengaluru                      None                        NaN  \n",
       "409  Bengaluru                      None                        NaN  \n",
       "491  Bengaluru                      None                        NaN  \n",
       "638  Bengaluru                      None                        NaN  \n",
       "417    Chennai                      None                        NaN  \n",
       "640      Delhi                      None                        NaN  \n",
       "425    Gujarat                      None                        NaN  \n",
       "249    Gurgaon                      None                        NaN  \n",
       "551    Gurgaon                      None                        NaN  \n",
       "821    Gurgaon                      None                        NaN  \n",
       "98      Mumbai                      None                        NaN  \n",
       "8       Remote                      None                        NaN  \n",
       "10      Remote                      None                        NaN  \n",
       "24      Remote                      None                        NaN  \n",
       "446     Remote                      None                        NaN  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)][[\n",
    "                    'Job_Title', 'Company_Rating', 'Location', 'Salary_Range_Standardized', 'Median_Salary_Standardized'\n",
    "]].sort_values(by='Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522a9d3-0b41-4590-adb4-46e1eeb3b295",
   "metadata": {},
   "source": [
    "- We have used company_rating, location to impute missing values of records which meets our stragtegy, now lets try to use measures of central tendency to impute missing values.\n",
    "- The average salary of intern job posting is between 1,20,000 - 1,80,000, we can use average salary to impute missing values but there are few outlier in the salary values which will skew the average value therefore we can use mode as more than half the records of intern job posting has a salary of 1,20,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "65392d52-3689-430e-a3eb-253be0f0c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the rest of missing value of intern jobs with 1,20,000\n",
    "\n",
    "intern_missing_rest = df_copy['Job_Title'].str.contains(pattern, regex=True, na=False) & \\\n",
    "                      df_copy['Median_Salary_Standardized'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d6c409a6-e3c6-4a30-936e-079a42600c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[intern_missing_rest, 'Median_Salary_Standardized'] = 120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "18e73173-726b-482e-9652-3e12aa4c3340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)]['Median_Salary_Standardized'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "dd0fb892-ab30-41da-9742-4e9a6b6f94eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Analyst Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Collection and Preparation:\\nInterns help...</td>\n",
       "      <td>600000 – 1900000</td>\n",
       "      <td>1200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Science Intern (Remote) – Optimspace\\nAbo...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Internships in AI &amp; Data Science</td>\n",
       "      <td>5.0</td>\n",
       "      <td>An internship in Artificial Intelligence (AI) ...</td>\n",
       "      <td>97032 - 708775</td>\n",
       "      <td>402903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>4.8</td>\n",
       "      <td>About Us\\nJoin Hypersonix, the premier AI-driv...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Intern Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Industry: IT\\nQualification: PhD\\nRequired Ski...</td>\n",
       "      <td>None</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bring more to life.\\nAre you ready to accelera...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Business Unit:\\nFinancial and Valuation Adviso...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.1</td>\n",
       "      <td>About Analytics Vidhya\\nAnalytics Vidhya is on...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>AI Engineering Intern</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AEREO (earlier known as Aarav Unmanned Systems...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Data Science Internship</td>\n",
       "      <td>3.9</td>\n",
       "      <td>We are looking for freshers who are interested...</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>AI &amp; ML Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Final year undergraduate or graduate student i...</td>\n",
       "      <td>8000 - 10000</td>\n",
       "      <td>9000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>About Pivotchain Solutions: https://pivotchain...</td>\n",
       "      <td>120000 – 240000</td>\n",
       "      <td>180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Job description\\nAbout Company:\\nComprinno is ...</td>\n",
       "      <td>180000</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Data Analytics Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>We are looking for talented freshers to join o...</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>AI Engineer Intern</td>\n",
       "      <td>4.6</td>\n",
       "      <td>About the Role:\\nWe are looking for a passiona...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Intern-Data Science</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Job Title: Data Science/Computer Vision Intern...</td>\n",
       "      <td>None</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Job Summary\\nThis internship duration is only ...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>AI/ML &amp; Generative AI Intern (6-Month Internship)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Internship Overview\\nAre you passionate about ...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Data Science - Intern</td>\n",
       "      <td>4.4</td>\n",
       "      <td>About Us\\nEnergize your career with one of Inf...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>AI/ML Engineering Intern – Intern-to-Hire</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Job Title: AI/ML Engineering Intern â€“ Intern...</td>\n",
       "      <td>500000</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Company Name: profenaa Technologies OMR center...</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Job Title: Data Science Intern\\nAbout the Role...</td>\n",
       "      <td>96000 – 120000</td>\n",
       "      <td>108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>AI/ML Intern</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Position: AI/ML Intern\\nAbout the Role\\nAs an ...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Job Title: Data Science Intern\\nLocation: Erna...</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>ML Intern\\nHyperworks Imaging is a cutting-edg...</td>\n",
       "      <td>240000 – 480000</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Data Science Internship (Web Scraping)</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Job Description:\\nConduct in-depth online rese...</td>\n",
       "      <td>96000 – 144000</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Job Title: Data Science Intern\\nLocation: Info...</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>AI - Interns</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Job Title: AI Intern\\nLocation: Kochi, Kerala\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>AI - Interns</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Job Title: AI Intern\\nLocation: Kochi, Kerala\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>1200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>AI Intern</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Job Type: Full Time\\nJob Location: Gurugram\\nE...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>4.5</td>\n",
       "      <td>About SatSure:\\n\\nSatSure is a deep tech, deci...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Role:\\nIntern - Machine Learning\\nLocation:\\nD...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>AI/ML/DL Intern</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Job description\\nWe are seeking a highly motiv...</td>\n",
       "      <td>None</td>\n",
       "      <td>96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>As a Resident in the Machine Learning track at...</td>\n",
       "      <td>12000 - 24000</td>\n",
       "      <td>18000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Please note its NOT work from home job\\nInterv...</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Intern - Generative AI</td>\n",
       "      <td>4.1</td>\n",
       "      <td>We are seeking passionate individuals to join ...</td>\n",
       "      <td>None</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job_Title  Company_Rating  \\\n",
       "8                                  Data Analyst Intern             3.9   \n",
       "9                                Data Scientist Intern             3.9   \n",
       "10                                 Data Science Intern             3.9   \n",
       "18                    Internships in AI & Data Science             5.0   \n",
       "24                               Data Science - Intern             4.8   \n",
       "70                               Intern Data Scientist             3.9   \n",
       "81                               Data Science - Intern             3.4   \n",
       "98                                 Data Science Intern             4.0   \n",
       "249                                Data Science Intern             4.1   \n",
       "253                              AI Engineering Intern             4.2   \n",
       "264                            Data Science Internship             3.9   \n",
       "268                                     AI & ML Intern             3.9   \n",
       "306                                Data Science Intern             3.9   \n",
       "315                          Data Scientist Internship             3.9   \n",
       "329                              Data Analytics Intern             3.9   \n",
       "409                                 AI Engineer Intern             4.6   \n",
       "415                                Intern-Data Science             3.8   \n",
       "417                                Data Science Intern             4.5   \n",
       "425  AI/ML & Generative AI Intern (6-Month Internship)             3.7   \n",
       "446                              Data Science - Intern             4.4   \n",
       "447          AI/ML Engineering Intern – Intern-to-Hire             3.4   \n",
       "461                                Data Science Intern             3.9   \n",
       "469                                Data Science Intern             3.7   \n",
       "491                                       AI/ML Intern             3.0   \n",
       "504                                Data Science Intern             3.9   \n",
       "510                            Machine Learning Intern             3.9   \n",
       "514             Data Science Internship (Web Scraping)             3.9   \n",
       "526                                Data Science Intern             3.9   \n",
       "536                                       AI - Interns             3.9   \n",
       "547                                       AI - Interns             4.1   \n",
       "551                                          AI Intern             4.1   \n",
       "638                                Data Science Intern             4.5   \n",
       "640                            Machine Learning Intern             3.9   \n",
       "687                                    AI/ML/DL Intern             3.2   \n",
       "704                            Machine Learning Intern             3.9   \n",
       "789                                Data Science Intern             3.9   \n",
       "821                             Intern - Generative AI             4.1   \n",
       "\n",
       "                                           Description  \\\n",
       "8    Data Analyst Intern (Remote) – Optimspace\\nAbo...   \n",
       "9    Data Collection and Preparation:\\nInterns help...   \n",
       "10   Data Science Intern (Remote) – Optimspace\\nAbo...   \n",
       "18   An internship in Artificial Intelligence (AI) ...   \n",
       "24   About Us\\nJoin Hypersonix, the premier AI-driv...   \n",
       "70   Industry: IT\\nQualification: PhD\\nRequired Ski...   \n",
       "81   Bring more to life.\\nAre you ready to accelera...   \n",
       "98   Business Unit:\\nFinancial and Valuation Adviso...   \n",
       "249  About Analytics Vidhya\\nAnalytics Vidhya is on...   \n",
       "253  AEREO (earlier known as Aarav Unmanned Systems...   \n",
       "264  We are looking for freshers who are interested...   \n",
       "268  Final year undergraduate or graduate student i...   \n",
       "306  About Pivotchain Solutions: https://pivotchain...   \n",
       "315  Job description\\nAbout Company:\\nComprinno is ...   \n",
       "329  We are looking for talented freshers to join o...   \n",
       "409  About the Role:\\nWe are looking for a passiona...   \n",
       "415  Job Title: Data Science/Computer Vision Intern...   \n",
       "417  Job Summary\\nThis internship duration is only ...   \n",
       "425  Internship Overview\\nAre you passionate about ...   \n",
       "446  About Us\\nEnergize your career with one of Inf...   \n",
       "447  Job Title: AI/ML Engineering Intern â€“ Intern...   \n",
       "461  Company Name: profenaa Technologies OMR center...   \n",
       "469  Job Title: Data Science Intern\\nAbout the Role...   \n",
       "491  Position: AI/ML Intern\\nAbout the Role\\nAs an ...   \n",
       "504  Job Title: Data Science Intern\\nLocation: Erna...   \n",
       "510  ML Intern\\nHyperworks Imaging is a cutting-edg...   \n",
       "514  Job Description:\\nConduct in-depth online rese...   \n",
       "526  Job Title: Data Science Intern\\nLocation: Info...   \n",
       "536  Job Title: AI Intern\\nLocation: Kochi, Kerala\\...   \n",
       "547  Job Title: AI Intern\\nLocation: Kochi, Kerala\\...   \n",
       "551  Job Type: Full Time\\nJob Location: Gurugram\\nE...   \n",
       "638  About SatSure:\\n\\nSatSure is a deep tech, deci...   \n",
       "640  Role:\\nIntern - Machine Learning\\nLocation:\\nD...   \n",
       "687  Job description\\nWe are seeking a highly motiv...   \n",
       "704  As a Resident in the Machine Learning track at...   \n",
       "789  Please note its NOT work from home job\\nInterv...   \n",
       "821  We are seeking passionate individuals to join ...   \n",
       "\n",
       "    Salary_Range_Standardized Median_Salary_Standardized  \n",
       "8                        None                     120000  \n",
       "9            600000 – 1900000                    1200000  \n",
       "10                       None                     120000  \n",
       "18             97032 - 708775                   402903.0  \n",
       "24                       None                     120000  \n",
       "70                       None                     200000  \n",
       "81                       None                     120000  \n",
       "98                       None                     120000  \n",
       "249                      None                     120000  \n",
       "253                      None                     120000  \n",
       "264                    120000                   120000.0  \n",
       "268              8000 - 10000                     9000.0  \n",
       "306           120000 – 240000                     180000  \n",
       "315                    180000                   180000.0  \n",
       "329                    120000                   120000.0  \n",
       "409                      None                     120000  \n",
       "415                      None                     360000  \n",
       "417                      None                     120000  \n",
       "425                      None                     120000  \n",
       "446                      None                     120000  \n",
       "447                    500000                   500000.0  \n",
       "461                    200000                   200000.0  \n",
       "469            96000 – 120000                     108000  \n",
       "491                      None                     120000  \n",
       "504                    120000                   120000.0  \n",
       "510           240000 – 480000                     360000  \n",
       "514            96000 – 144000                     120000  \n",
       "526                    120000                   120000.0  \n",
       "536                      None                   120000.0  \n",
       "547                      None                    1200000  \n",
       "551                      None                     120000  \n",
       "638                      None                     120000  \n",
       "640                      None                     120000  \n",
       "687                      None                      96000  \n",
       "704             12000 - 24000                    18000.0  \n",
       "789                    300000                   300000.0  \n",
       "821                      None                     120000  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)][[\n",
    "        'Job_Title', 'Company_Rating', 'Description', 'Salary_Range_Standardized', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b46532e3-97cf-47c9-97a9-ac673ee0efb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 5)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(pattern, regex=True, na=False)][[\n",
    "        'Job_Title', 'Company_Rating', 'Description', 'Salary_Range_Standardized', 'Median_Salary_Standardized']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4fa59-e0d4-45a5-8689-c47f4e167f62",
   "metadata": {},
   "source": [
    "## Imputing missing values of Median_Salary of all job postings\n",
    "**using average salary from 'Salary_Range_Standardized' column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d93a112f-c5ea-4b0d-b557-bdf99edc55df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name                    0\n",
       "Company_Rating                  0\n",
       "Job_Title                       0\n",
       "Location                        0\n",
       "Description                     1\n",
       "Salary_Range                  202\n",
       "Median_Salary                 290\n",
       "Salary_Source                 208\n",
       "Salary_Range_Standardized     202\n",
       "Median_Salary_Standardized    257\n",
       "avg_sal                       763\n",
       "dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b9b7ccda-1574-4ea8-a232-ce97f577149b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are looking for a skilled Data Scientist to...</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Immersive Infotech Pvt. Ltd</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Data Scientist (2–4 Years Exp) | AI &amp; Optimiza...</td>\n",
       "      <td>₹12L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employer provided</td>\n",
       "      <td>1200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Applied Scientist I, International Machine Lea...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>DESCRIPTION\\nAmazon is looking for a passionat...</td>\n",
       "      <td>₹3L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mastercard</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Our Purpose\\nMastercard powers economies and e...</td>\n",
       "      <td>₹2L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Specialist Data Scientist - TM</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Transport is at the core of modern society. Im...</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Target</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Lead Data Scientist- Operations Research</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About Us:\\nAs a Fortune 50 company with more t...</td>\n",
       "      <td>₹4L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Hilabs</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>The HiLabs Story\\nHiLabs is a leading provider...</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Ideas2IT Technologies</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>In this role, you'll tackle advanced machine l...</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>SeerTech Systems</td>\n",
       "      <td>3.9</td>\n",
       "      <td>AI/ML Engineer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Junior AI Solutions Developer (Remote | Full-T...</td>\n",
       "      <td>₹15K/mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employer provided</td>\n",
       "      <td>180000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>Apple</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Big Data Software Engineer - Manufacturing Sys...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Apple is where individual imaginations gather ...</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  Company_Rating  \\\n",
       "20   LSEG (London Stock Exchange Group)             3.7   \n",
       "23          Immersive Infotech Pvt. Ltd             4.9   \n",
       "42                           Amazon.com             3.6   \n",
       "46                           Mastercard             4.2   \n",
       "47                          Volvo Group             4.1   \n",
       "..                                  ...             ...   \n",
       "758                              Target             4.2   \n",
       "760                              Hilabs             4.3   \n",
       "785               Ideas2IT Technologies             3.8   \n",
       "816                    SeerTech Systems             3.9   \n",
       "825                               Apple             4.1   \n",
       "\n",
       "                                             Job_Title   Location  \\\n",
       "20                               Junior Data Scientist  Bengaluru   \n",
       "23                                      Data Scientist     Remote   \n",
       "42   Applied Scientist I, International Machine Lea...    Gurgaon   \n",
       "46                               Senior Data Scientist    Gurgaon   \n",
       "47                      Specialist Data Scientist - TM  Bengaluru   \n",
       "..                                                 ...        ...   \n",
       "758           Lead Data Scientist- Operations Research  Bengaluru   \n",
       "760                              Senior Data Scientist  Bengaluru   \n",
       "785                                     Data Scientist    Chennai   \n",
       "816                                     AI/ML Engineer     Remote   \n",
       "825  Big Data Software Engineer - Manufacturing Sys...  Bengaluru   \n",
       "\n",
       "                                           Description Salary_Range  \\\n",
       "20   We are looking for a skilled Data Scientist to...      ₹10L/yr   \n",
       "23   Data Scientist (2–4 Years Exp) | AI & Optimiza...      ₹12L/yr   \n",
       "42   DESCRIPTION\\nAmazon is looking for a passionat...       ₹3L/yr   \n",
       "46   Our Purpose\\nMastercard powers economies and e...       ₹2L/yr   \n",
       "47   Transport is at the core of modern society. Im...      ₹10L/yr   \n",
       "..                                                 ...          ...   \n",
       "758  About Us:\\nAs a Fortune 50 company with more t...       ₹4L/yr   \n",
       "760  The HiLabs Story\\nHiLabs is a leading provider...      ₹10L/yr   \n",
       "785  In this role, you'll tackle advanced machine l...      ₹10L/yr   \n",
       "816  Junior AI Solutions Developer (Remote | Full-T...      ₹15K/mo   \n",
       "825  Apple is where individual imaginations gather ...      ₹10L/yr   \n",
       "\n",
       "    Median_Salary      Salary_Source Salary_Range_Standardized  \\\n",
       "20            NaN     Glassdoor Est.                   1000000   \n",
       "23            NaN  Employer provided                   1200000   \n",
       "42            NaN     Glassdoor Est.                    300000   \n",
       "46            NaN     Glassdoor Est.                    200000   \n",
       "47            NaN     Glassdoor Est.                   1000000   \n",
       "..            ...                ...                       ...   \n",
       "758           NaN     Glassdoor Est.                    400000   \n",
       "760           NaN     Glassdoor Est.                   1000000   \n",
       "785           NaN     Glassdoor Est.                   1000000   \n",
       "816           NaN  Employer provided                    180000   \n",
       "825           NaN     Glassdoor Est.                   1000000   \n",
       "\n",
       "    Median_Salary_Standardized  avg_sal  \n",
       "20                         NaN      NaN  \n",
       "23                         NaN      NaN  \n",
       "42                         NaN      NaN  \n",
       "46                         NaN      NaN  \n",
       "47                         NaN      NaN  \n",
       "..                         ...      ...  \n",
       "758                        NaN      NaN  \n",
       "760                        NaN      NaN  \n",
       "785                        NaN      NaN  \n",
       "816                        NaN      NaN  \n",
       "825                        NaN      NaN  \n",
       "\n",
       "[78 rows x 11 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & df_copy['Salary_Range_Standardized'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3c7ae87d-dda6-4e70-a8fb-d2d515e88853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 11)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & df_copy['Salary_Range_Standardized'].notna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7c53f510-5366-44d7-8020-ca1cbafcf8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_ind = df_copy[df_copy['Median_Salary_Standardized'].isna() & df_copy['Salary_Range_Standardized'].notna()].index\n",
    "len(median_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d410e392-baac-4eab-85fc-50cc611b0f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 20,  23,  42,  46,  47,  54,  62,  74,  89, 112, 124, 125, 140, 141,\n",
       "       146, 148, 157, 173, 174, 178, 209, 231, 236, 246, 250, 259, 269, 283,\n",
       "       293, 307, 314, 335, 343, 365, 412, 426, 430, 433, 445, 448, 464, 467,\n",
       "       476, 486, 492, 497, 524, 525, 544, 553, 579, 586, 587, 599, 606, 609,\n",
       "       610, 615, 618, 620, 622, 647, 660, 674, 682, 686, 694, 699, 707, 731,\n",
       "       735, 741, 748, 758, 760, 785, 816, 825],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff19db-ba75-4117-aa08-7a43bf6093f9",
   "metadata": {},
   "source": [
    "- There are 78 rows which has missing values in 'Median_Salary_Standardized' column and recorded values in 'Salary_Range_Standardized' column.\n",
    "\n",
    "- Lets fill those 78 rows with the average salary from 'Salary_Range_Standardized' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a98f9581-f9a0-4464-8ad4-bee7df277fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sal(val):\n",
    "    if not isinstance(val, str) or pd.isna(val):\n",
    "        return np.nan\n",
    "\n",
    "    # Range values\n",
    "    if '-' in val or '–' in val:  \n",
    "        parts = re.split(r'[–-]', val)\n",
    "        try:\n",
    "            return(int(parts[0].strip()) + int(parts[1].strip())) // 2\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # single values \n",
    "    try:\n",
    "        return int(val.strip())\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c9eb45f8-a58e-4033-90f5-0a41751ca3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop('avg_sal', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e4716c7e-a394-40ac-92a2-9bd5b01c740d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary', 'Salary_Source',\n",
       "       'Salary_Range_Standardized', 'Median_Salary_Standardized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a39af34c-44d5-49b7-928c-86e0dba3fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_mask = df_copy['Median_Salary_Standardized'].isna() & df_copy['Salary_Range_Standardized'].notna()\n",
    "\n",
    "df_copy.loc[median_mask, 'avg_sal'] = df_copy.loc[median_mask, 'Salary_Range_Standardized'].apply(avg_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5671187f-4c1b-4e1e-a5ae-86e40c64fdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>720000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>720000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>244623 - 1415106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>829864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Salary_Range_Standardized Median_Salary_Standardized    avg_sal\n",
       "20                    1000000                        NaN  1000000.0\n",
       "23                    1200000                        NaN  1200000.0\n",
       "42                     300000                        NaN   300000.0\n",
       "46                     200000                        NaN   200000.0\n",
       "47                    1000000                        NaN  1000000.0\n",
       "54                    1000000                        NaN  1000000.0\n",
       "62                     500000                        NaN   500000.0\n",
       "74                     720000                        NaN   720000.0\n",
       "89                    2000000                        NaN  2000000.0\n",
       "112                    300000                        NaN   300000.0\n",
       "124                   1000000                        NaN  1000000.0\n",
       "125                    900000                        NaN   900000.0\n",
       "140          244623 - 1415106                        NaN   829864.0\n",
       "141                    800000                        NaN   800000.0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[20,  23,  42,  46,  47,  54,  62,  74,  89, 112, 124, 125, 140, 141], ['Salary_Range_Standardized', 'Median_Salary_Standardized', 'avg_sal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "01e29ab4-fe40-4d7d-8ccd-015e6670f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[median_mask, 'Median_Salary_Standardized'] = df_copy.loc[median_mask, 'Median_Salary_Standardized'].fillna(\n",
    "                                                            df_copy.loc[median_mask, 'avg_sal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3dc2e92f-59b3-48c3-b4ba-0f4d5f168b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>300000</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>500000</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>720000</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>720000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2000000</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>300000</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>900000</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>244623 - 1415106</td>\n",
       "      <td>829864.0</td>\n",
       "      <td>829864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>800000</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>800000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Salary_Range_Standardized Median_Salary_Standardized    avg_sal\n",
       "20                    1000000                  1000000.0  1000000.0\n",
       "23                    1200000                  1200000.0  1200000.0\n",
       "42                     300000                   300000.0   300000.0\n",
       "46                     200000                   200000.0   200000.0\n",
       "47                    1000000                  1000000.0  1000000.0\n",
       "54                    1000000                  1000000.0  1000000.0\n",
       "62                     500000                   500000.0   500000.0\n",
       "74                     720000                   720000.0   720000.0\n",
       "89                    2000000                  2000000.0  2000000.0\n",
       "112                    300000                   300000.0   300000.0\n",
       "124                   1000000                  1000000.0  1000000.0\n",
       "125                    900000                   900000.0   900000.0\n",
       "140          244623 - 1415106                   829864.0   829864.0\n",
       "141                    800000                   800000.0   800000.0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[20,  23,  42,  46,  47,  54,  62,  74,  89, 112, 124, 125, 140, 141], ['Salary_Range_Standardized', 'Median_Salary_Standardized', 'avg_sal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "12f7d2aa-4eb9-4323-90fa-e64d26b28bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name                    0\n",
       "Company_Rating                  0\n",
       "Job_Title                       0\n",
       "Location                        0\n",
       "Description                     1\n",
       "Salary_Range                  202\n",
       "Median_Salary                 290\n",
       "Salary_Source                 208\n",
       "Salary_Range_Standardized     202\n",
       "Median_Salary_Standardized    179\n",
       "avg_sal                       696\n",
       "dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb881ce-75ea-4ccd-b753-e3bc50344554",
   "metadata": {},
   "source": [
    "## Imputing missing values of Median_Salary of 'Junior/Associate' job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3df5c70c-2322-4a4d-9658-0931dd9c7362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains('Junior|Associate', regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7f5fafa6-8d11-4354-a477-22c918875520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains('Junior|Associate', regex=True, na=False) &\\\n",
    "        df_copy['Median_Salary_Standardized'].notna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "33268113-32a7-4ddb-999e-c6bca2f7a932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Associate Consultant - Data Science</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Associate Data Scientist - AI or ML, SQL, Pyth...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Associate Scientist, Data Sourcing &amp; Solutions</td>\n",
       "      <td>3.8</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Junior Data Science Team Member</td>\n",
       "      <td>4.0</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Associate Data Scientists</td>\n",
       "      <td>4.1</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job_Title  Company_Rating  \\\n",
       "709                Associate Consultant - Data Science             3.3   \n",
       "265                              Junior Data Scientist             3.4   \n",
       "549                           Associate Data Scientist             3.4   \n",
       "245                           Associate Data Scientist             3.5   \n",
       "570  Associate Data Scientist - AI or ML, SQL, Pyth...             3.5   \n",
       "50                            Associate Data Scientist             3.7   \n",
       "762     Associate Scientist, Data Sourcing & Solutions             3.8   \n",
       "163                    Junior Data Science Team Member             4.0   \n",
       "19                               Junior Data Scientist             4.1   \n",
       "460                          Associate Data Scientists             4.1   \n",
       "\n",
       "      Location Salary_Range_Standardized Median_Salary_Standardized  \n",
       "709     Remote                      None                        NaN  \n",
       "265      India                      None                        NaN  \n",
       "549     Mumbai                      None                        NaN  \n",
       "245  Bengaluru                      None                        NaN  \n",
       "570    Gurgaon                      None                        NaN  \n",
       "50   Bengaluru                      None                        NaN  \n",
       "762      India                      None                        NaN  \n",
       "163      India                      None                        NaN  \n",
       "19       India                      None                        NaN  \n",
       "460      India                      None                        NaN  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains('Junior|Associate', regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()][[\n",
    "'Job_Title', 'Company_Rating', 'Location', 'Salary_Range_Standardized', 'Median_Salary_Standardized']].sort_values(by='Company_Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "73345882-0ea7-4da8-9620-39e8143b9033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Indore</td>\n",
       "      <td>200000 – 1000000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Junior Data Analyst (F)</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>300000 – 800000</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>600000 – 900000</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>300000 – 600000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Associate Machine Learning Scientist</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Kālkāji Devi</td>\n",
       "      <td>100000 – 600000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Machine Learning Associate</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1080000 – 1200000</td>\n",
       "      <td>1140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Data Scientist Associate Manager</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>900000 – 1000000</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Noida</td>\n",
       "      <td>200000 – 900000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Machine Learning Data Associate II, North Amer...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>300000 – 500000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Associate Data Scientist , Global GBS</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>800000</td>\n",
       "      <td>800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>Associate, Business Intelligence &amp; Analytics</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000 – 1100000</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Associate Data Scientist - AzureML/SageMaker</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>300000 – 800000</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>200000 – 300000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Junior Data Scientist | AGR Knowledge Services...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>300000 – 600000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>Data Scientist Senior Associate</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>IN_Associate_Data Scientist Gen AI_Data &amp; Anal...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Calcutta</td>\n",
       "      <td>40000 – 900000</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Associate, Specialist, Data Scientist, COO</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>500000 – 700000</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Junior Associate - Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Junior Machine Learning Engineer</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>244623 - 1415106</td>\n",
       "      <td>829864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Associate Scientist, Data Sourcing &amp; Solutions</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>800000 – 900000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>720000 – 1200000</td>\n",
       "      <td>960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Research Associate – Data Science</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>300000 – 800000</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Data and AI Associate</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>100000 – 600000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>500000 – 900000</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>500000 – 900000</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Senior Associate Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>500000 – 1000000</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Quant Analytics Associate - SQL, Alteryx and T...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>600000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Data Scientist Associate - AI/ML, Python</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>200000 – 300000</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Payments - Data Scientist Associate</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>300000 – 500000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Associate - Data and Analytics</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>600000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>200000 – 1000000</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>Junior Data science Engineer/Trainer</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Thiruvananthapuram</td>\n",
       "      <td>192000 – 300000</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Associate, Data Analytics &amp; AI</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Pune</td>\n",
       "      <td>500000 – 800000</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>300000 – 500000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Associate Data Scientist - Chennai</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>300000 – 500000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Machine Learning Engineers (Mid-Level &amp; Junior)</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>300000 – 800000</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>Junior AI Engineer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>200000 – 500000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job_Title  Company_Rating  \\\n",
       "189                              Junior Data Scientist             1.0   \n",
       "319                            Junior Data Analyst (F)             2.6   \n",
       "183                              Junior Data Scientist             2.9   \n",
       "217                           Associate Data Scientist             3.1   \n",
       "416               Associate Machine Learning Scientist             3.2   \n",
       "672                         Machine Learning Associate             3.4   \n",
       "711                             Data Science Associate             3.4   \n",
       "671                   Data Scientist Associate Manager             3.4   \n",
       "180                           Associate Data Scientist             3.5   \n",
       "755  Machine Learning Data Associate II, North Amer...             3.6   \n",
       "615              Associate Data Scientist , Global GBS             3.6   \n",
       "706       Associate, Business Intelligence & Analytics             3.7   \n",
       "115       Associate Data Scientist - AzureML/SageMaker             3.7   \n",
       "660                              Junior Data Scientist             3.7   \n",
       "351                           Associate Data Scientist             3.7   \n",
       "352  Junior Data Scientist | AGR Knowledge Services...             3.7   \n",
       "486                    Data Scientist Senior Associate             3.7   \n",
       "678  IN_Associate_Data Scientist Gen AI_Data & Anal...             3.7   \n",
       "20                               Junior Data Scientist             3.7   \n",
       "516         Associate, Specialist, Data Scientist, COO             3.9   \n",
       "307                  Junior Associate - Data Scientist             3.9   \n",
       "140                   Junior Machine Learning Engineer             3.9   \n",
       "714     Associate Scientist, Data Sourcing & Solutions             3.9   \n",
       "58                               Junior Data Scientist             3.9   \n",
       "626                  Research Associate – Data Science             3.9   \n",
       "406                              Data and AI Associate             4.0   \n",
       "195                           Associate Data Scientist             4.0   \n",
       "69                            Associate Data Scientist             4.0   \n",
       "558                    Senior Associate Data Scientist             4.0   \n",
       "596  Quant Analytics Associate - SQL, Alteryx and T...             4.1   \n",
       "328           Data Scientist Associate - AI/ML, Python             4.1   \n",
       "230                Payments - Data Scientist Associate             4.1   \n",
       "199                     Associate - Data and Analytics             4.1   \n",
       "712                           Associate Data Scientist             4.1   \n",
       "770               Junior Data science Engineer/Trainer             4.1   \n",
       "659                     Associate, Data Analytics & AI             4.2   \n",
       "66                               Junior Data Scientist             4.2   \n",
       "527                 Associate Data Scientist - Chennai             4.5   \n",
       "316    Machine Learning Engineers (Mid-Level & Junior)             4.7   \n",
       "458                                 Junior AI Engineer             5.0   \n",
       "\n",
       "               Location Salary_Range_Standardized Median_Salary_Standardized  \n",
       "189              Indore          200000 – 1000000                     400000  \n",
       "319             Gurgaon           300000 – 800000                     500000  \n",
       "183           Hyderābād           600000 – 900000                     700000  \n",
       "217             Gurgaon           300000 – 600000                     400000  \n",
       "416        Kālkāji Devi           100000 – 600000                     300000  \n",
       "672              Remote         1080000 – 1200000                    1140000  \n",
       "711             Gurgaon          700000 – 1000000                     900000  \n",
       "671           Bengaluru          900000 – 1000000                     900000  \n",
       "180               Noida           200000 – 900000                     400000  \n",
       "755           Bengaluru           300000 – 500000                     300000  \n",
       "615           Ahmedabad                    800000                   800000.0  \n",
       "706           Bengaluru         1000000 – 1100000                    1000000  \n",
       "115           Bengaluru           300000 – 800000                     500000  \n",
       "660           Bengaluru                   1000000                  1000000.0  \n",
       "351              Cochin           200000 – 300000                     300000  \n",
       "352              Mumbai           300000 – 600000                     400000  \n",
       "486           Bengaluru                    200000                   200000.0  \n",
       "678            Calcutta            40000 – 900000                     200000  \n",
       "20            Bengaluru                   1000000                  1000000.0  \n",
       "516              Mumbai           500000 – 700000                     600000  \n",
       "307               India                    120000                   120000.0  \n",
       "140               India          244623 - 1415106                   829864.0  \n",
       "714           Bengaluru           800000 – 900000                     800000  \n",
       "58              Gurgaon          720000 – 1200000                     960000  \n",
       "626           Hyderābād           300000 – 800000                     500000  \n",
       "406           Bengaluru           100000 – 600000                     300000  \n",
       "195             Gurgaon           500000 – 900000                     700000  \n",
       "69              Gurgaon           500000 – 900000                     700000  \n",
       "558           Hyderābād          500000 – 1000000                     700000  \n",
       "596           Bengaluru          600000 – 1000000                     800000  \n",
       "328              Mumbai           200000 – 300000                     200000  \n",
       "230              Mumbai           300000 – 500000                     400000  \n",
       "199           Bengaluru          600000 – 1000000                     800000  \n",
       "712             Gurgaon          200000 – 1000000                     500000  \n",
       "770  Thiruvananthapuram           192000 – 300000                     240000  \n",
       "659                Pune           500000 – 800000                     600000  \n",
       "66               Jaipur           300000 – 500000                     400000  \n",
       "527             Chennai           300000 – 500000                     400000  \n",
       "316           Hyderābād           300000 – 800000                     500000  \n",
       "458             Gurgaon           200000 – 500000                     300000  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains('Junior|Associate', regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].notna()][[\n",
    "    'Job_Title', 'Company_Rating', 'Location', 'Salary_Range_Standardized', 'Median_Salary_Standardized']].sort_values(by='Company_Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "40200b29-0bcf-4d9c-b601-bcf8b9c37cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "89708217-6ff8-4f4c-8d27-4abd1d316a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Trinity Life Sciences\n",
       "Company_Rating                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 3.3\n",
       "Job_Title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Associate Consultant - Data Science\n",
       "Location                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Remote\n",
       "Description                   Job Objective:\\nTo work with the team of data scientists in marketing analytics such as marketing mix modelling, price and promotion, forecasting etc. Guide the team in formulation, model development and implementation by liaising with business stakeholders to explain the model outcomes.\\nDesignation: Associate Consultant\\nJob Location: Bangalore/Chennai/Gurgaon\\nType of employment: Permanent\\n\\nJob description:\\n\\nRoles and Responsibilities:\\n\\n Analyse syndicated and non-syndicated data to build Marketing Mix Model and provide insights to support the Marketing Investment\n",
       "Salary_Range                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  None\n",
       "Median_Salary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN\n",
       "Salary_Source                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 None\n",
       "Salary_Range_Standardized                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     None\n",
       "Median_Salary_Standardized                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN\n",
       "avg_sal                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        NaN\n",
       "Name: 709, dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[709]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "70aa817b-bcd4-4398-9a16-d95e5873e276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Kainskep Solutions</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Junior Associate - Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Our Culture &amp; Values:\\nWe’d describe our culture as human, friendly, engaging, supportive, agile, and super collaborative.\\nAt Kainskep Solutions, our five values underpin everything we do, from how we work to how we delight and deliver to our customers.\\nOur values are #TeamMember, #Ownership, #Innovation, #Challenge, and #Collaboration.\\nWhat makes a great team? A Diverse Team!\\nDon’t be put off if you don’t tick all the boxes; we know from research that candidates may not apply if they don’t feel they are 100% there yet; the essential experience we need is the ability to engage clients and build strong, effective relationships. If you don’t tick the rest, we would still love to talk.\\nWe’re committed to creating a diverse and inclusive.\\nWhat you’ll bring:</td>\n",
       "      <td>₹10K/mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employer provided</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Global scientific company</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Junior Machine Learning Engineer</td>\n",
       "      <td>India</td>\n",
       "      <td>Chennai location only, tamil candidates\\nFreshers only immediate joiners\\nA Junior Machine Learning Engineer typically assists in the development, implementation, and maintenance of machine learning models and systems.\\nThis role involves working with data, building and optimizing models, and deploying them for use in applications.\\nCollaboration with other engineers and data scientists is crucial for success.\\nJob Types: Full-time, Permanent, Fresher\\nPay: ₹244,623.13 - ₹1,415,105.56 per year\\nBenefits:\\nHealth insurance\\nPaid time off\\nProvident Fund\\nSchedule:\\nDay shift\\nMorning shift\\nWork Location: In person</td>\n",
       "      <td>₹244,623 - ₹1,415,106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>244623 - 1415106</td>\n",
       "      <td>829864.0</td>\n",
       "      <td>829864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Sri Sathya Sai Sanjeevani Hospital</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Qualification: M.Sc/ MTech in any Biological Sciences\\nExperience: Minimum 2 years’ experience in computational biology post MSc\\nLocation: Kharghar, Navi Mumbai, Interested candidates may send CV to kharghar@ssssrf.org</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  Company_Rating  \\\n",
       "307                  Kainskep Solutions             3.9   \n",
       "140           Global scientific company             3.9   \n",
       "265  Sri Sathya Sai Sanjeevani Hospital             3.4   \n",
       "\n",
       "                             Job_Title Location  \\\n",
       "307  Junior Associate - Data Scientist    India   \n",
       "140   Junior Machine Learning Engineer    India   \n",
       "265              Junior Data Scientist    India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description  \\\n",
       "307  Our Culture & Values:\\nWe’d describe our culture as human, friendly, engaging, supportive, agile, and super collaborative.\\nAt Kainskep Solutions, our five values underpin everything we do, from how we work to how we delight and deliver to our customers.\\nOur values are #TeamMember, #Ownership, #Innovation, #Challenge, and #Collaboration.\\nWhat makes a great team? A Diverse Team!\\nDon’t be put off if you don’t tick all the boxes; we know from research that candidates may not apply if they don’t feel they are 100% there yet; the essential experience we need is the ability to engage clients and build strong, effective relationships. If you don’t tick the rest, we would still love to talk.\\nWe’re committed to creating a diverse and inclusive.\\nWhat you’ll bring:   \n",
       "140                                                                                                                                                      Chennai location only, tamil candidates\\nFreshers only immediate joiners\\nA Junior Machine Learning Engineer typically assists in the development, implementation, and maintenance of machine learning models and systems.\\nThis role involves working with data, building and optimizing models, and deploying them for use in applications.\\nCollaboration with other engineers and data scientists is crucial for success.\\nJob Types: Full-time, Permanent, Fresher\\nPay: ₹244,623.13 - ₹1,415,105.56 per year\\nBenefits:\\nHealth insurance\\nPaid time off\\nProvident Fund\\nSchedule:\\nDay shift\\nMorning shift\\nWork Location: In person   \n",
       "265                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Qualification: M.Sc/ MTech in any Biological Sciences\\nExperience: Minimum 2 years’ experience in computational biology post MSc\\nLocation: Kharghar, Navi Mumbai, Interested candidates may send CV to kharghar@ssssrf.org   \n",
       "\n",
       "              Salary_Range Median_Salary      Salary_Source  \\\n",
       "307                ₹10K/mo           NaN  Employer provided   \n",
       "140  ₹244,623 - ₹1,415,106           NaN                NaN   \n",
       "265                   None           NaN               None   \n",
       "\n",
       "    Salary_Range_Standardized Median_Salary_Standardized   avg_sal  \n",
       "307                    120000                   120000.0  120000.0  \n",
       "140          244623 - 1415106                   829864.0  829864.0  \n",
       "265                      None                        NaN       NaN  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[307, 140, 265]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "dc12d5ee-c884-40ff-9db2-adc95ada994a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Avalon Global Research</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist | AGR Knowledge Services Pvt Ltd</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Responsibilities :\\nManipulate and preprocess structured and unstructured data to prepare datasets for analysis and model training.\\nUtilize Python libraries like PyTorch, Pandas, and NumPy for data analysis, model development, and implementation.\\nFine-tune large language models (LLMs) to meet specific use cases and enterprise requirements.\\nCollaborate with cross-functional teams to experiment with AI/ML models and iterate quickly on prototypes.\\nOptimize workflows to ensure fast experimentation and deployment of models to production environments.</td>\n",
       "      <td>₹3L – ₹6L/yr</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>300000 – 600000</td>\n",
       "      <td>400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Pivotree</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Introduction:\\nOur goal at Pivotree is to help accelerate the future of frictionless commerce. We will help lead this change over the next decade because we believe a future where technology is embedded intimately into all aspects of our everyday lives can benefit everyone and will shape the interactions with the brands we love. We will help shape the future of frictionless commerce by working together with some of the best brands in the world and some of the best people in the industry to leverage converging technologies that will make it possible to accelerate frictionless commerce faster than ever.\\n\\nPivotree provides services focused on the design, implementation, management, and maintenance of complex ecommerce solutions for large enterprises. We provide the technical skills necessary to enable the effective use of technologies combined with the business context to leverage a solution to solve our clients' business challenges. We strive to fill the gaps in available technology with our own IP to reduce the barriers to adoption.\\n\\nWe enable inclusive, immersive and highly personalized experiences for our clients and their customers. We build our products with a view to productizing and scaling technology to lower the costs and reduce the risks of implementing and managing our integrated solutions. Each of our solutions starts with reliable and reputable e-commerce and MDM platforms, which run on enterprise grade infrastructure that are customized to meet a variety of client needs, situations, and budgets. Over the next 10 years we will add new categories and capabilities that will define frictionless commerce ecosystems.\\n\\nThis is a journey of technology acceleration combined with consumer readiness and adoption. We are looking for people capable of adapting relentlessly to the rapidly evolving world around us.\\n\\n\\nThe Junior Data Scientist will be a member of our Data Automation, Machine Learning, and AI Practice, which reports to Pivotree’s Director of Research and Development. The Junior Data Scientist will contribute to:\\n\\n\\n\\nPivotree is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive and accessible workplace.\\n\\nPivotree is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive and accessible workplace.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company_Name  Company_Rating  \\\n",
       "352  Avalon Global Research             3.7   \n",
       "549                Pivotree             3.4   \n",
       "\n",
       "                                                  Job_Title Location  \\\n",
       "352  Junior Data Scientist | AGR Knowledge Services Pvt Ltd   Mumbai   \n",
       "549                                Associate Data Scientist   Mumbai   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description  \\\n",
       "352                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Responsibilities :\\nManipulate and preprocess structured and unstructured data to prepare datasets for analysis and model training.\\nUtilize Python libraries like PyTorch, Pandas, and NumPy for data analysis, model development, and implementation.\\nFine-tune large language models (LLMs) to meet specific use cases and enterprise requirements.\\nCollaborate with cross-functional teams to experiment with AI/ML models and iterate quickly on prototypes.\\nOptimize workflows to ensure fast experimentation and deployment of models to production environments.   \n",
       "549  Introduction:\\nOur goal at Pivotree is to help accelerate the future of frictionless commerce. We will help lead this change over the next decade because we believe a future where technology is embedded intimately into all aspects of our everyday lives can benefit everyone and will shape the interactions with the brands we love. We will help shape the future of frictionless commerce by working together with some of the best brands in the world and some of the best people in the industry to leverage converging technologies that will make it possible to accelerate frictionless commerce faster than ever.\\n\\nPivotree provides services focused on the design, implementation, management, and maintenance of complex ecommerce solutions for large enterprises. We provide the technical skills necessary to enable the effective use of technologies combined with the business context to leverage a solution to solve our clients' business challenges. We strive to fill the gaps in available technology with our own IP to reduce the barriers to adoption.\\n\\nWe enable inclusive, immersive and highly personalized experiences for our clients and their customers. We build our products with a view to productizing and scaling technology to lower the costs and reduce the risks of implementing and managing our integrated solutions. Each of our solutions starts with reliable and reputable e-commerce and MDM platforms, which run on enterprise grade infrastructure that are customized to meet a variety of client needs, situations, and budgets. Over the next 10 years we will add new categories and capabilities that will define frictionless commerce ecosystems.\\n\\nThis is a journey of technology acceleration combined with consumer readiness and adoption. We are looking for people capable of adapting relentlessly to the rapidly evolving world around us.\\n\\n\\nThe Junior Data Scientist will be a member of our Data Automation, Machine Learning, and AI Practice, which reports to Pivotree’s Director of Research and Development. The Junior Data Scientist will contribute to:\\n\\n\\n\\nPivotree is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive and accessible workplace.\\n\\nPivotree is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive and accessible workplace.   \n",
       "\n",
       "     Salary_Range  Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "352  ₹3L – ₹6L/yr  ₹4L/yr Median  Glassdoor Est.           300000 – 600000   \n",
       "549          None            NaN            None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  avg_sal  \n",
       "352                     400000      NaN  \n",
       "549                        NaN      NaN  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[352, 549]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4e086269-d614-41f4-bde2-7300935a57bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Machine Learning Data Associate II, North America Customer Fulfillment (NACF)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>DESCRIPTION\\nAmazon is a global leader in e-commerce and cloud computing, headquartered in Seattle, Washington. Since its inception in 1995, Amazon has strived to be the world's most customer-centric company, catering to a global customer base, which includes not only consumers but also our sellers and vendors (selling partners). Our platform empowers world-class retail brands and individual sellers to increase sales and reach new customers.\\n\\nThe North America Customer Fulfillment (NACF) team is dedicated to effectively network labor planning for optimizing customer experience and enhancing productivity. The successful execution of the network depends on well-defined roles and responsibilities. The AI Ops MLDA (Machine Learning Data Associate) team is dedicated to implementing GenAI solutions to automate and augment tasks across North America Supply Chain (NASC) and Global Services Risk &amp; Compliance (GSRC) teams. The team focuses on expanding use-case portfolios and accelerating the automation lifecycle through internal GenAI products for workflow automation.\\n\\nKey job responsibilities\\nmanaging process recordings and converting them into detailed written documentation\\ngenerative AI tools, while gathering diverse work samples for comprehensive coverage\\noutput validation and issue resolution\\nautomation best practices\\nprocess improvement</td>\n",
       "      <td>₹3L – ₹5L/yr</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>300000 – 500000</td>\n",
       "      <td>300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>BirlaSoft</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Country/Region: IN\\nRequisition ID: 27163\\nWork Model:\\nPosition Type:\\nSalary Range:\\nLocation: INDIA - BENGALURU - BIRLASOFT OFFICE\\nTitle: Associate Data Scientist\\nDescription:\\nArea(s) of responsibility\\nJob Title: Dataiku Developer\\nLocation:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name  Company_Rating  \\\n",
       "755   Amazon.com             3.6   \n",
       "245    BirlaSoft             3.5   \n",
       "\n",
       "                                                                         Job_Title  \\\n",
       "755  Machine Learning Data Associate II, North America Customer Fulfillment (NACF)   \n",
       "245                                                       Associate Data Scientist   \n",
       "\n",
       "      Location  \\\n",
       "755  Bengaluru   \n",
       "245  Bengaluru   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Description  \\\n",
       "755  DESCRIPTION\\nAmazon is a global leader in e-commerce and cloud computing, headquartered in Seattle, Washington. Since its inception in 1995, Amazon has strived to be the world's most customer-centric company, catering to a global customer base, which includes not only consumers but also our sellers and vendors (selling partners). Our platform empowers world-class retail brands and individual sellers to increase sales and reach new customers.\\n\\nThe North America Customer Fulfillment (NACF) team is dedicated to effectively network labor planning for optimizing customer experience and enhancing productivity. The successful execution of the network depends on well-defined roles and responsibilities. The AI Ops MLDA (Machine Learning Data Associate) team is dedicated to implementing GenAI solutions to automate and augment tasks across North America Supply Chain (NASC) and Global Services Risk & Compliance (GSRC) teams. The team focuses on expanding use-case portfolios and accelerating the automation lifecycle through internal GenAI products for workflow automation.\\n\\nKey job responsibilities\\nmanaging process recordings and converting them into detailed written documentation\\ngenerative AI tools, while gathering diverse work samples for comprehensive coverage\\noutput validation and issue resolution\\nautomation best practices\\nprocess improvement   \n",
       "245                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Country/Region: IN\\nRequisition ID: 27163\\nWork Model:\\nPosition Type:\\nSalary Range:\\nLocation: INDIA - BENGALURU - BIRLASOFT OFFICE\\nTitle: Associate Data Scientist\\nDescription:\\nArea(s) of responsibility\\nJob Title: Dataiku Developer\\nLocation:   \n",
       "\n",
       "     Salary_Range  Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "755  ₹3L – ₹5L/yr  ₹3L/yr Median  Glassdoor Est.           300000 – 500000   \n",
       "245          None            NaN            None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  avg_sal  \n",
       "755                     300000      NaN  \n",
       "245                        NaN      NaN  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[755, 245]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f536029d-f45e-4e4b-baf7-1981321d5e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Metyis AG</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Metyis is growing! We are looking for a Data Science Associate with 3+ years of experience to join our Data and Analytics team in Gurgaon, India.\\n\\nWho we are\\nThe next step of your career starts here, where you can bring your own unique mix of skills and perspectives to a fast-growing team.\\nMetyis is a global and forward-thinking firm operating across a wide range of industries, developing and delivering AI &amp; Data, Digital Commerce, Marketing &amp; Design solutions and Advisory services. At Metyis, our long-term partnership model brings long-lasting impact and growth to our business partners and clients through extensive execution capabilities.\\nWith our team, you can experience a collaborative environment with highly skilled multidisciplinary experts, where everyone has room to build bigger and bolder ideas. Being part of Metyis means you can speak your mind and be creative with your knowledge. Imagine the things you can achieve with a team that encourages you to be the best version of yourself.</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹9L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>900000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Circle K</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Job Description\\nAlimentation Couche-Tard Inc., (ACT) is a global Fortune 200 company. A leader in the convenience store and fuel space, it has footprint across 31 countries and territories. The India Data &amp; Analytics Global Capability Centre is an integral part of ACT’s Global Data &amp; Analytics Team and the Associate Data Scientist will be a key player on this team that will help grow analytics globally at ACT.\\nAbout the Role\\nThe hired candidate will partner with multiple departments, including Global Marketing, Merchandising, Global Technology, and Business Units. The incumbent will be responsible for delivering advanced analytics projects that drive business results including interpreting business, selecting the appropriate methodology, data cleaning, exploratory data analysis, model building, and creation of polished deliverables.\\nResponsibilities</td>\n",
       "      <td>₹3L – ₹6L/yr</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>300000 – 600000</td>\n",
       "      <td>400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Associate Data Scientist - AI or ML, SQL, Python, Snowflake</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nPrimary Responsibilities:\\nConducting data analysis using SQL and Python to extract insights from large data sets\\nConducting exploratory data analysis to identify trends, patterns, and insights from data</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name  Company_Rating  \\\n",
       "711    Metyis AG             3.4   \n",
       "217     Circle K             3.1   \n",
       "570        Optum             3.5   \n",
       "\n",
       "                                                       Job_Title Location  \\\n",
       "711                                       Data Science Associate  Gurgaon   \n",
       "217                                     Associate Data Scientist  Gurgaon   \n",
       "570  Associate Data Scientist - AI or ML, SQL, Python, Snowflake  Gurgaon   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Description  \\\n",
       "711  Metyis is growing! We are looking for a Data Science Associate with 3+ years of experience to join our Data and Analytics team in Gurgaon, India.\\n\\nWho we are\\nThe next step of your career starts here, where you can bring your own unique mix of skills and perspectives to a fast-growing team.\\nMetyis is a global and forward-thinking firm operating across a wide range of industries, developing and delivering AI & Data, Digital Commerce, Marketing & Design solutions and Advisory services. At Metyis, our long-term partnership model brings long-lasting impact and growth to our business partners and clients through extensive execution capabilities.\\nWith our team, you can experience a collaborative environment with highly skilled multidisciplinary experts, where everyone has room to build bigger and bolder ideas. Being part of Metyis means you can speak your mind and be creative with your knowledge. Imagine the things you can achieve with a team that encourages you to be the best version of yourself.   \n",
       "217                                                                                                                                                   Job Description\\nAlimentation Couche-Tard Inc., (ACT) is a global Fortune 200 company. A leader in the convenience store and fuel space, it has footprint across 31 countries and territories. The India Data & Analytics Global Capability Centre is an integral part of ACT’s Global Data & Analytics Team and the Associate Data Scientist will be a key player on this team that will help grow analytics globally at ACT.\\nAbout the Role\\nThe hired candidate will partner with multiple departments, including Global Marketing, Merchandising, Global Technology, and Business Units. The incumbent will be responsible for delivering advanced analytics projects that drive business results including interpreting business, selecting the appropriate methodology, data cleaning, exploratory data analysis, model building, and creation of polished deliverables.\\nResponsibilities   \n",
       "570                                                                                                                                                                                                                            Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nPrimary Responsibilities:\\nConducting data analysis using SQL and Python to extract insights from large data sets\\nConducting exploratory data analysis to identify trends, patterns, and insights from data   \n",
       "\n",
       "      Salary_Range  Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "711  ₹7L – ₹10L/yr  ₹9L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "217   ₹3L – ₹6L/yr  ₹4L/yr Median  Glassdoor Est.           300000 – 600000   \n",
       "570           None            NaN            None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  avg_sal  \n",
       "711                     900000      NaN  \n",
       "217                     400000      NaN  \n",
       "570                        NaN      NaN  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[711, 217, 570]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d3b3e56d-c088-4690-b731-6f833381f7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>WeWork India Management</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Associate, Business Intelligence &amp; Analytics</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About us\\nWeWork India is one of India’s leading flexible workspace operators – ‘Great Place To Work’ certified (Nov 2024 – Nov 2025), aimed at creating flexible workspace solutions for company of all sizes.\\nSince its inception in India in 2016, WeWork India has expanded across 68 operational centres in Chennai, New Delhi, Gurugram, Noida, Mumbai, Bengaluru, Pune, and Hyderabad. WeWork India meets distinct workspace needs, for various businesses. WeWork India strives to provide customised and curated solutions for various office space needs through its products and solutions. At WeWork India, we’re driven by collaboration, creativity, and a shared vision to redefine the future of work.\\nIf you're looking to be part of a dynamic, fast-growing organisation that values talent and fosters growth, join us and build your future with WeWork India.\\nFor more information, please visit our website https://wework.co.in/</td>\n",
       "      <td>₹10L – ₹11L/yr</td>\n",
       "      <td>₹10L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000 – 1100000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Rockwell Automation</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Associate Data Scientist - AzureML/SageMaker</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Rockwell Automation is a global technology leader focused on helping the world’s manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility - our people are energized problem solvers that take pride in how the work we do changes the world for the better.\\nWe welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that’s you we would love to have you join us!\\nJob Description\\nSummary:\\nCollaborate with engineers, product managers, and operations leaders to build predictive maintenance models, improve manufacturing throughput, and drive cost savings.</td>\n",
       "      <td>₹3L – ₹8L/yr</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>300000 – 800000</td>\n",
       "      <td>500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description:\\nESG Specialist team are set of skilled and domain knowledge individuals who build and maintain the content currently covered on existing databases and test future database, tools and systems. The Specialist team drives automation and simplification to bring in efficient processes and quality of updates within ESG Operations.\\nThe successful applicant will be working in an agile environment and will work on projects to deliver automation and process simplifications solutions.\\nRoles, Responsibilities &amp; Key Accountabilities:\\nDevelop and deploy machine learning and deep learning models to solve complex problems.\\nConduct statistical analysis to identify trends, patterns, and insights.</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are looking for a skilled Data Scientist to join our dynamic Analytics Centre of Excellence team. This role combines Data Science, Python development, and business analysis to deliver actionable insights and solutions that drive strategic decisions. Knowledge and experience will be put into practice to Quantitative Engineering, financial instrument pricing, and analytics to shape the direction of our technology and tools, impacting both internal and external customers.\\nThis position offers a unique opportunity to work on Data Science projects, Python applications, and requirement analysis, based on your strengths and interests. Whether developing ML models, writing Python code, or collaborating with business partners, playing a key role in the successful delivery of projects.\\nKey responsibilities:\\nData Science: Own development of sophisticated data science and machine learning models, using large datasets to drive business decisions and data-driven strategies across the organization.</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BOEING</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>At Boeing, we innovate and collaborate to make the world a better place. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.\\nOverview\\nAs a leading global aerospace company, Boeing develops, manufactures and services commercial airplanes, defense products and space systems for customers in more than 150 countries. As a top U.S. exporter, the company leverages the talents of a global supplier base to advance economic opportunity, sustainability and community impact. Boeing’s team is committed to innovating for the future, leading with sustainability, and cultivating a culture based on the company’s core values of safety, quality and integrity.\\nTechnology for today and tomorrow\\nThe Boeing India Engineering &amp; Technology Center (BIETC) is a 5500+ engineering workforce that contributes to global aerospace growth. Our engineers deliver cutting-edge R&amp;D, innovation, and high-quality engineering work in global markets, and leverage new-age technologies such as AI/ML, IIoT, Cloud, Model-Based Engineering, and Additive Manufacturing, shaping the future of aerospace.\\n\\n\\nThis is not an Export Control position.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  Company_Rating  \\\n",
       "706             WeWork India Management             3.7   \n",
       "115                 Rockwell Automation             3.7   \n",
       "660  LSEG (London Stock Exchange Group)             3.7   \n",
       "20   LSEG (London Stock Exchange Group)             3.7   \n",
       "50                               BOEING             3.7   \n",
       "\n",
       "                                        Job_Title   Location  \\\n",
       "706  Associate, Business Intelligence & Analytics  Bengaluru   \n",
       "115  Associate Data Scientist - AzureML/SageMaker  Bengaluru   \n",
       "660                         Junior Data Scientist  Bengaluru   \n",
       "20                          Junior Data Scientist  Bengaluru   \n",
       "50                       Associate Data Scientist  Bengaluru   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description  \\\n",
       "706                                                                                                                                                                                                                                                                                                                                        About us\\nWeWork India is one of India’s leading flexible workspace operators – ‘Great Place To Work’ certified (Nov 2024 – Nov 2025), aimed at creating flexible workspace solutions for company of all sizes.\\nSince its inception in India in 2016, WeWork India has expanded across 68 operational centres in Chennai, New Delhi, Gurugram, Noida, Mumbai, Bengaluru, Pune, and Hyderabad. WeWork India meets distinct workspace needs, for various businesses. WeWork India strives to provide customised and curated solutions for various office space needs through its products and solutions. At WeWork India, we’re driven by collaboration, creativity, and a shared vision to redefine the future of work.\\nIf you're looking to be part of a dynamic, fast-growing organisation that values talent and fosters growth, join us and build your future with WeWork India.\\nFor more information, please visit our website https://wework.co.in/   \n",
       "115                                                                                                                                                                                                                                                                                                                                                                                      Rockwell Automation is a global technology leader focused on helping the world’s manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility - our people are energized problem solvers that take pride in how the work we do changes the world for the better.\\nWe welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that’s you we would love to have you join us!\\nJob Description\\nSummary:\\nCollaborate with engineers, product managers, and operations leaders to build predictive maintenance models, improve manufacturing throughput, and drive cost savings.   \n",
       "660                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Job description:\\nESG Specialist team are set of skilled and domain knowledge individuals who build and maintain the content currently covered on existing databases and test future database, tools and systems. The Specialist team drives automation and simplification to bring in efficient processes and quality of updates within ESG Operations.\\nThe successful applicant will be working in an agile environment and will work on projects to deliver automation and process simplifications solutions.\\nRoles, Responsibilities & Key Accountabilities:\\nDevelop and deploy machine learning and deep learning models to solve complex problems.\\nConduct statistical analysis to identify trends, patterns, and insights.   \n",
       "20                                                                                                                                                                                                                                                        We are looking for a skilled Data Scientist to join our dynamic Analytics Centre of Excellence team. This role combines Data Science, Python development, and business analysis to deliver actionable insights and solutions that drive strategic decisions. Knowledge and experience will be put into practice to Quantitative Engineering, financial instrument pricing, and analytics to shape the direction of our technology and tools, impacting both internal and external customers.\\nThis position offers a unique opportunity to work on Data Science projects, Python applications, and requirement analysis, based on your strengths and interests. Whether developing ML models, writing Python code, or collaborating with business partners, playing a key role in the successful delivery of projects.\\nKey responsibilities:\\nData Science: Own development of sophisticated data science and machine learning models, using large datasets to drive business decisions and data-driven strategies across the organization.   \n",
       "50   At Boeing, we innovate and collaborate to make the world a better place. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.\\nOverview\\nAs a leading global aerospace company, Boeing develops, manufactures and services commercial airplanes, defense products and space systems for customers in more than 150 countries. As a top U.S. exporter, the company leverages the talents of a global supplier base to advance economic opportunity, sustainability and community impact. Boeing’s team is committed to innovating for the future, leading with sustainability, and cultivating a culture based on the company’s core values of safety, quality and integrity.\\nTechnology for today and tomorrow\\nThe Boeing India Engineering & Technology Center (BIETC) is a 5500+ engineering workforce that contributes to global aerospace growth. Our engineers deliver cutting-edge R&D, innovation, and high-quality engineering work in global markets, and leverage new-age technologies such as AI/ML, IIoT, Cloud, Model-Based Engineering, and Additive Manufacturing, shaping the future of aerospace.\\n\\n\\nThis is not an Export Control position.   \n",
       "\n",
       "       Salary_Range   Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "706  ₹10L – ₹11L/yr  ₹10L/yr Median  Glassdoor Est.         1000000 – 1100000   \n",
       "115    ₹3L – ₹8L/yr   ₹5L/yr Median  Glassdoor Est.           300000 – 800000   \n",
       "660         ₹10L/yr             NaN  Glassdoor Est.                   1000000   \n",
       "20          ₹10L/yr             NaN  Glassdoor Est.                   1000000   \n",
       "50             None             NaN            None                      None   \n",
       "\n",
       "    Median_Salary_Standardized    avg_sal  \n",
       "706                    1000000        NaN  \n",
       "115                     500000        NaN  \n",
       "660                  1000000.0  1000000.0  \n",
       "20                   1000000.0  1000000.0  \n",
       "50                         NaN        NaN  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[706, 115, 660, 20, 50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "e7bcc95c-28ff-468d-bbbf-969e438f961d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>AXA XL</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Associate Scientist, Data Sourcing &amp; Solutions</td>\n",
       "      <td>India</td>\n",
       "      <td>Outer Ring Road, Devarabisanahalli Vlg Varthur Hobli, Bldg 2A, Twr 3, Phs 1, BANGALORE, IN, 560103\\nDATA AND AI\\n5467\\nBand B\\n\\nJob Description\\nAssociate Scientist - Data Sourcing &amp; Solutions\\nGurgaon/Bangalore, India\\n\\n\\nAXA XL recognises data and information as critical business assets, both in terms of managing risk and enabling new business opportunities. This data should not only be high quality, but also actionable - enabling AXA XL's executive leadership team to maximise benefits and facilitate sustained enterprise advantage. Our Innovation, Data, and Analytics Office (IDA) is focused on driving innovation by optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market. As we develop an enterprise-wide data and digital strategy that moves us toward a greater focus on the use of data and data-driven insights, we are seeking an Associate Scientist for our Data Sourcing &amp; Solutions team. The role sits across the IDA Department to make sure customer requirements are properly captured and transformed into actionable data specifications. Success in the role will require a focus on proactive management of the sourcing and management of data from source through usage.\\n\\nAccountable for documenting data requirements (Business and Function Requirements) and assessing the reusability of Axiom assets.\\nBuild processes to simplify and expedite data sourcing to focus on delivering data to AXA XL business stakeholders frequently.\\n\\n\\n\\n\\nInstill a customer-first attitude, prioritizing service for our business stakeholders above all else.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Imurgence</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Junior Data Science Team Member</td>\n",
       "      <td>India</td>\n",
       "      <td>Duties &amp; Responsibilities:\\n1. Work closely with business analysts, product managers and domain experts to decide on the product road map\\n2. Do extensive primary and secondary research to help enhance the product road map\\n3. Discuss, brainstorm on new modules with the senior team, write business logic with clarity and purpose that helps in reducing turnaround times for new project development\\n4. Co-ordinate with the technology team and assist them to ensure timely execution of new projects\\n5. Lead initiatives like \"automating scoring using machine learning techniques”, \"build asset allocation models\", \"build algorithms for automating financial planning framework\", “build recommendation systems”, “build system for automated fraud detection”, etc\\n6. Analyse data to help in better descision making</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cravita Technologies India</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Strong proficiency in programming languages such as Python and R.\\nExpertise in sentiment analysis, NER, and other natural language processing techniques is a must.\\nExperience in MLOps, Machine Learning, Statistical Modeling, and Data Visualization.\\nExcellent leadership, communication, and interpersonal skills.\\nNumber of Openings : 3</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>DeepTek</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Associate Data Scientists</td>\n",
       "      <td>India</td>\n",
       "      <td>Job Description\\nWe are looking for an entry-level Associate Data Scientist who is passionate about working in the healthcare AI domain. This role will involve collaborating with cross-functional teams, including senior data scientists, application developers, and radiology experts, to develop and refine AI solutions for medical imaging. You will gain hands-on experience working on advanced projects in Computer Vision and LLM finetuning.\\nExperience\\nFresher: (up to 1 year experience can be considered)\\nSkills Required\\nStrong programming skills in Python and familiarity with data science libraries (e.g., NumPy, pandas, scikit-learn).</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Company_Name  Company_Rating  \\\n",
       "762                      AXA XL             3.8   \n",
       "163                   Imurgence             4.0   \n",
       "19   Cravita Technologies India             4.1   \n",
       "460                     DeepTek             4.1   \n",
       "\n",
       "                                          Job_Title Location  \\\n",
       "762  Associate Scientist, Data Sourcing & Solutions    India   \n",
       "163                 Junior Data Science Team Member    India   \n",
       "19                            Junior Data Scientist    India   \n",
       "460                       Associate Data Scientists    India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Description  \\\n",
       "762  Outer Ring Road, Devarabisanahalli Vlg Varthur Hobli, Bldg 2A, Twr 3, Phs 1, BANGALORE, IN, 560103\\nDATA AND AI\\n5467\\nBand B\\n\\nJob Description\\nAssociate Scientist - Data Sourcing & Solutions\\nGurgaon/Bangalore, India\\n\\n\\nAXA XL recognises data and information as critical business assets, both in terms of managing risk and enabling new business opportunities. This data should not only be high quality, but also actionable - enabling AXA XL's executive leadership team to maximise benefits and facilitate sustained enterprise advantage. Our Innovation, Data, and Analytics Office (IDA) is focused on driving innovation by optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market. As we develop an enterprise-wide data and digital strategy that moves us toward a greater focus on the use of data and data-driven insights, we are seeking an Associate Scientist for our Data Sourcing & Solutions team. The role sits across the IDA Department to make sure customer requirements are properly captured and transformed into actionable data specifications. Success in the role will require a focus on proactive management of the sourcing and management of data from source through usage.\\n\\nAccountable for documenting data requirements (Business and Function Requirements) and assessing the reusability of Axiom assets.\\nBuild processes to simplify and expedite data sourcing to focus on delivering data to AXA XL business stakeholders frequently.\\n\\n\\n\\n\\nInstill a customer-first attitude, prioritizing service for our business stakeholders above all else.   \n",
       "163                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Duties & Responsibilities:\\n1. Work closely with business analysts, product managers and domain experts to decide on the product road map\\n2. Do extensive primary and secondary research to help enhance the product road map\\n3. Discuss, brainstorm on new modules with the senior team, write business logic with clarity and purpose that helps in reducing turnaround times for new project development\\n4. Co-ordinate with the technology team and assist them to ensure timely execution of new projects\\n5. Lead initiatives like \"automating scoring using machine learning techniques”, \"build asset allocation models\", \"build algorithms for automating financial planning framework\", “build recommendation systems”, “build system for automated fraud detection”, etc\\n6. Analyse data to help in better descision making   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Strong proficiency in programming languages such as Python and R.\\nExpertise in sentiment analysis, NER, and other natural language processing techniques is a must.\\nExperience in MLOps, Machine Learning, Statistical Modeling, and Data Visualization.\\nExcellent leadership, communication, and interpersonal skills.\\nNumber of Openings : 3   \n",
       "460                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Job Description\\nWe are looking for an entry-level Associate Data Scientist who is passionate about working in the healthcare AI domain. This role will involve collaborating with cross-functional teams, including senior data scientists, application developers, and radiology experts, to develop and refine AI solutions for medical imaging. You will gain hands-on experience working on advanced projects in Computer Vision and LLM finetuning.\\nExperience\\nFresher: (up to 1 year experience can be considered)\\nSkills Required\\nStrong programming skills in Python and familiarity with data science libraries (e.g., NumPy, pandas, scikit-learn).   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "762         None           NaN          None                      None   \n",
       "163         None           NaN          None                      None   \n",
       "19          None           NaN          None                      None   \n",
       "460         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  avg_sal  \n",
       "762                        NaN      NaN  \n",
       "163                        NaN      NaN  \n",
       "19                         NaN      NaN  \n",
       "460                        NaN      NaN  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[762, 163, 19, 460]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dde06c-d298-4da1-85b6-232f3618e738",
   "metadata": {},
   "source": [
    "- The job posting of row 265 require a minimum of 2 years experience in computational biology, junior level jobs that require min of 2 years experience would normally tend to pay more than the market salary of a junior data scientist.\n",
    "- The average salary range for a junior level job is 3,00,000 to 8,00,000 , lets use the maximum salary of 8,00,000 to impute in the missing value of row 265.\n",
    "<br>  \n",
    "- From reading the job description of rows 352 and 549 we can conclude that both the roles are similar to each other, even though the ratings are 3.7 and 3.4 since the job role looks the same we can use row 352 to fill the missing value in 549.  \n",
    "<br>\n",
    "  \n",
    "- We can use row 755 to impute row 245 as the rating, location, job title, role are similar to each other.  \n",
    "<br>\n",
    " - We cannot use row 711 to fill row 570 as row 711 is a manager level job however we can use row 217 to fill rows 570. Row 570 looks like a regular junior level data scientist job which involves performing data analysis, eda etc and also the job does not require prior experience therefore we can use the average salary of 4,00,000 to fill the missing value which again the same salary mentioned in row 217.\n",
    "<br>    \n",
    " - Job postings of rows 706, 115, 660, 20 are all located in Bengaluru with a rating of 3.7 and the salary is either 10,00,000 or 5,00,000 and interestingly the job postings with salary of 10,00,000 is a foriegn based company and the job posting with salary of 5,00,000 is an Indian company.  \n",
    " - Row 50 which we want to fill is a US based company and generally US based companies pay higher and from the above observation, we can finalize to use 10,00,000 to impute the missing value in row 50.  \n",
    "<br>    \n",
    "- Job postings of rows 762, 163, 19, 460 has a rating between 3.8, 4.0, 4.1 and location is India.\n",
    "- From analyzing the job description of row 460 we found that it is an entry level role absolutely for freshers and the required skills are some comman teck stacks of data science, we shall impute the salary with 3,00,000.\n",
    "- From analyzing job posting 19, the role requires experience in MLOps, sentiment analysis, NER and natural language processing , these skills are usually possesed by an experience candidate which tells us that this role requires prior experience. Roles that requires deep and advanced skills such as NLP, MLOps tend to pay a little more than the basic salary of 3,00,000 , we shall impute the salary with 5,00,000.\n",
    "- Job posting of row 163 involves some sophesticated responsibilities such as \"automating scoring using machine learning techniques”, \"build asset allocation models\", \"build algorithms for automating financial planning framework\", “build recommendation systems”, therefore we can assume that even though the role is a Junior level but the responsibilites included can only be gained from prior experience with another company. We can impute the salary with 4,00,000\n",
    "- Finally the job posting of row 762 involves only Data such as data collection, cleaning , data driven insights which tells us the role specifically is all about data which only a part of the responsibility of a data scientist. We can fill the missing value with 3,00,000.\n",
    "<br>\n",
    "- Job posting 709 seems like a regular entry level position therefore we can use 3,00,000 to fill the missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9b9b169c-4724-4b67-8cda-21c31f65b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[265, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[549, 'Median_Salary_Standardized'] = df_copy.loc[352, 'Median_Salary_Standardized']\n",
    "\n",
    "df_copy.loc[245, 'Median_Salary_Standardized'] = df_copy.loc[755, 'Median_Salary_Standardized']\n",
    "\n",
    "df_copy.loc[570, 'Median_Salary_Standardized'] = 400000\n",
    "\n",
    "df_copy.loc[50, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[460, 'Median_Salary_Standardized'] = 300000\n",
    "\n",
    "df_copy.loc[19, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[163, 'Median_Salary_Standardized'] = 400000\n",
    "\n",
    "df_copy.loc[762, 'Median_Salary_Standardized'] = 300000\n",
    "\n",
    "df_copy.loc[709, 'Median_Salary_Standardized'] = 300000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "78b05eea-7a4c-47cc-8c45-30d0ec26c623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains('Junior|Associate', regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "fbf0a189-e5b9-4e02-95ff-02f0f68a8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop('avg_sal', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f0b9b87b-375f-4fec-a395-6468fe8a1951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name                    0\n",
       "Company_Rating                  0\n",
       "Job_Title                       0\n",
       "Location                        0\n",
       "Description                     1\n",
       "Salary_Range                  202\n",
       "Median_Salary                 290\n",
       "Salary_Source                 208\n",
       "Salary_Range_Standardized     202\n",
       "Median_Salary_Standardized    169\n",
       "dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f4942ee3-a3aa-4bcb-add1-e205fe71eabc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Veracity Software</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Jr Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>What makes us special\\nWelcome to Veracity life! Here work is more than just a task; it's a vibrant tapestry woven with passion, collaboration, and endless opportunities. At Veracity, we believe that a fulfilling career is not just about what you do but also about the environment in which you thrive. Dive into a glimpse of life within our dynamic organization as we look forward to hearing from you.\\n\\nExperience Life at Veracity Software Private Limited\\nCultivating Collaboration\\nAt Veracity, collaboration isn't just encouraged; it's ingrained in our DNA. Step into an environment where teamwork is more than just a buzzword; it's the cornerstone of our success. From brainstorming sessions to cross-departmental projects, every interaction fosters connections that fuel innovation</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Sciera</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Jr Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Sciera Inc. is an Atlanta based Data &amp; Technology company with 12 years’ experience of driving business results of Fortune 500 companies with unparalleled computing power and advanced data science capabilities. Sciera is focused on how we deal with petabyte-scale data and our applications' ability to respond to consumers in milliseconds. As a result, our technologies and solutions assist businesses in turning Big Data into actionable insights — and insights into business success.\\nAt Sciera, our employees and their families are important to us. We seek individuals who are self-motivated, dependable, and who are equally productive while working alone or in a group. We expect candidates to contribute to the culture, diversity, and autonomy in which we thrive.\\nSo, if you love challenges, a fast paced environment and being on the cutting edge of technology - this could very well be the opportunity for you.\\nJob Location: Chennai</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Company_Name  Company_Rating          Job_Title Location  \\\n",
       "53   Veracity Software             4.3  Jr Data Scientist    India   \n",
       "171             Sciera             4.4  Jr Data Scientist  Chennai   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Description  \\\n",
       "53                                                                                                                                                          What makes us special\\nWelcome to Veracity life! Here work is more than just a task; it's a vibrant tapestry woven with passion, collaboration, and endless opportunities. At Veracity, we believe that a fulfilling career is not just about what you do but also about the environment in which you thrive. Dive into a glimpse of life within our dynamic organization as we look forward to hearing from you.\\n\\nExperience Life at Veracity Software Private Limited\\nCultivating Collaboration\\nAt Veracity, collaboration isn't just encouraged; it's ingrained in our DNA. Step into an environment where teamwork is more than just a buzzword; it's the cornerstone of our success. From brainstorming sessions to cross-departmental projects, every interaction fosters connections that fuel innovation   \n",
       "171  Sciera Inc. is an Atlanta based Data & Technology company with 12 years’ experience of driving business results of Fortune 500 companies with unparalleled computing power and advanced data science capabilities. Sciera is focused on how we deal with petabyte-scale data and our applications' ability to respond to consumers in milliseconds. As a result, our technologies and solutions assist businesses in turning Big Data into actionable insights — and insights into business success.\\nAt Sciera, our employees and their families are important to us. We seek individuals who are self-motivated, dependable, and who are equally productive while working alone or in a group. We expect candidates to contribute to the culture, diversity, and autonomy in which we thrive.\\nSo, if you love challenges, a fast paced environment and being on the cutting edge of technology - this could very well be the opportunity for you.\\nJob Location: Chennai   \n",
       "\n",
       "      Salary_Range  Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "53            None            NaN            None                      None   \n",
       "171  ₹7L – ₹10L/yr  ₹8L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "53                         NaN  \n",
       "171                     800000  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(r'\\bJr\\b', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b7267ed6-5153-4dea-a41f-f54b7da6b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[53, 'Median_Salary_Standardized'] = 400000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a564373-c03a-4b81-8795-74374f6fb08e",
   "metadata": {},
   "source": [
    "## Imputing missing values of Median_Salary of 'Senior' level job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "003dec86-45e6-4caa-ac1a-663d9d8ddd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3da4a36b-4581-48d2-a7e4-529cc3b5dd34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Kraft Heinz Company</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>o9 Solutions</td>\n",
       "      <td>Data Scientist, Senior</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Nestlé IT</td>\n",
       "      <td>Senior Data Scientist - Supply Chain</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>KPMG</td>\n",
       "      <td>Senior - Data Science</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Rockwell Automation</td>\n",
       "      <td>Senior Data Scientist- AzureML/SageMaker</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>Staff Software Developer, Machine Learning</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>JioStar</td>\n",
       "      <td>Staff Data Scientist- Subs &amp; Pay</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Mico</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>EY</td>\n",
       "      <td>Digital-Staff-Machine Learning Developer</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>Imaging IQ</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Nagarro</td>\n",
       "      <td>Staff Engineer, Machine Learning</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Mastercard</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>EPAM Systems, Inc.</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Novartis</td>\n",
       "      <td>Senior Principal Data Scientist, CADD</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Entain India</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>Senior Software Developer, Machine Learning</td>\n",
       "      <td>4.1</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Grid Dynamics</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>EY</td>\n",
       "      <td>Data Scientist - Senior Manager</td>\n",
       "      <td>3.7</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Lyric</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Motorola Solutions</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>Mahindra &amp; Mahindra Ltd</td>\n",
       "      <td>Sr. Data Scientist, AI Division</td>\n",
       "      <td>4.0</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Lingaro Group</td>\n",
       "      <td>Senior Data Scientist (Generative AI)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>QoreNext</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>Censius</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>4.4</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Crayon Data</td>\n",
       "      <td>Senior Data scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Grid Dynamics</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Helius Technologies</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>FiveExceptions Software Solutions</td>\n",
       "      <td>Data Scientist /Senior Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Indore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Teradata</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data Scientist / Senior Data Scientist, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Axis My India</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Talenzen</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Noida</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Datafortune</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Pune</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Michelin</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>NICE Systems</td>\n",
       "      <td>Senior Data Scientist Engineer</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Pune</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>fifthnote</td>\n",
       "      <td>Senior Data scientist (Remote)</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5x Data</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>RELX</td>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>InApp</td>\n",
       "      <td>AI/ML Engineer (Senior Data Scientist/AI Engineer)</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  \\\n",
       "675                 Kraft Heinz Company   \n",
       "715                        o9 Solutions   \n",
       "705                           Nestlé IT   \n",
       "203                                KPMG   \n",
       "337                 Rockwell Automation   \n",
       "395                        Kinaxis Inc.   \n",
       "523                             JioStar   \n",
       "520                                Mico   \n",
       "535                                  EY   \n",
       "33              Boston Consulting Group   \n",
       "820                          Imaging IQ   \n",
       "700                             Nagarro   \n",
       "401                          Mastercard   \n",
       "438                  EPAM Systems, Inc.   \n",
       "653                            Novartis   \n",
       "829                        Entain India   \n",
       "7                          Kinaxis Inc.   \n",
       "418                       Grid Dynamics   \n",
       "522                                  EY   \n",
       "478                               Lyric   \n",
       "797                  Motorola Solutions   \n",
       "827             Mahindra & Mahindra Ltd   \n",
       "545                       Lingaro Group   \n",
       "548                            QoreNext   \n",
       "684                             Censius   \n",
       "592                         Crayon Data   \n",
       "636                       Grid Dynamics   \n",
       "719                 Helius Technologies   \n",
       "654   FiveExceptions Software Solutions   \n",
       "681                            Teradata   \n",
       "121             Boston Consulting Group   \n",
       "63              Boston Consulting Group   \n",
       "794                       Axis My India   \n",
       "515  LSEG (London Stock Exchange Group)   \n",
       "568                            Talenzen   \n",
       "531                         Datafortune   \n",
       "398                            Michelin   \n",
       "670                        NICE Systems   \n",
       "291                           fifthnote   \n",
       "369                            Elsevier   \n",
       "97                              5x Data   \n",
       "376                                RELX   \n",
       "677                               InApp   \n",
       "\n",
       "                                                 Job_Title  Company_Rating  \\\n",
       "675                                  Senior Data Scientist             3.6   \n",
       "715                                 Data Scientist, Senior             3.8   \n",
       "705                   Senior Data Scientist - Supply Chain             4.1   \n",
       "203                                  Senior - Data Science             3.7   \n",
       "337               Senior Data Scientist- AzureML/SageMaker             3.7   \n",
       "395             Staff Software Developer, Machine Learning             4.1   \n",
       "523                       Staff Data Scientist- Subs & Pay             3.9   \n",
       "520                                  Senior Data Scientist             3.3   \n",
       "535               Digital-Staff-Machine Learning Developer             3.7   \n",
       "33         AI Engineer / Senior AI Engineer, India - BCG X             4.2   \n",
       "820                                  Senior Data Scientist             3.9   \n",
       "700                       Staff Engineer, Machine Learning             3.9   \n",
       "401                                  Senior Data Scientist             4.2   \n",
       "438                                  Senior Data Scientist             4.0   \n",
       "653                  Senior Principal Data Scientist, CADD             4.0   \n",
       "829                                  Senior Data Scientist             3.7   \n",
       "7              Senior Software Developer, Machine Learning             4.1   \n",
       "418                                  Senior Data Scientist             3.9   \n",
       "522                        Data Scientist - Senior Manager             3.7   \n",
       "478                                  Senior Data Scientist             3.9   \n",
       "797                                  Senior Data Scientist             4.3   \n",
       "827                        Sr. Data Scientist, AI Division             4.0   \n",
       "545                  Senior Data Scientist (Generative AI)             4.0   \n",
       "548                                  Senior Data Scientist             3.9   \n",
       "684                                     Sr. Data Scientist             4.4   \n",
       "592                                  Senior Data scientist             3.7   \n",
       "636                                   Staff Data Scientist             3.9   \n",
       "719                                  Senior Data Scientist             4.3   \n",
       "654                  Data Scientist /Senior Data Scientist             4.2   \n",
       "681                                  Senior Data Scientist             3.8   \n",
       "121  Data Scientist / Senior Data Scientist, India - BCG X             4.2   \n",
       "63         AI Engineer / Senior AI Engineer, India - BCG X             4.2   \n",
       "794                                  Senior Data Scientist             4.3   \n",
       "515                                  Senior Data Scientist             3.7   \n",
       "568                                  Senior Data Scientist             3.9   \n",
       "531                                  Senior Data Scientist             4.2   \n",
       "398                                  Senior Data Scientist             4.0   \n",
       "670                         Senior Data Scientist Engineer             4.2   \n",
       "291                         Senior Data scientist (Remote)             4.3   \n",
       "369                                Senior Data Scientist I             4.0   \n",
       "97                                   Senior Data Scientist             4.8   \n",
       "376                                Senior Data Scientist I             4.0   \n",
       "677     AI/ML Engineer (Senior Data Scientist/AI Engineer)             4.4   \n",
       "\n",
       "      Location Salary_Range_Standardized Median_Salary_Standardized  \n",
       "675  Ahmedabad                      None                        NaN  \n",
       "715  Bengaluru                      None                        NaN  \n",
       "705  Bengaluru                      None                        NaN  \n",
       "203  Bengaluru                      None                        NaN  \n",
       "337  Bengaluru                      None                        NaN  \n",
       "395  Bengaluru                      None                        NaN  \n",
       "523  Bengaluru                      None                        NaN  \n",
       "520  Bengaluru                      None                        NaN  \n",
       "535    Chennai                      None                        NaN  \n",
       "33     Gurgaon                      None                        NaN  \n",
       "820    Gurgaon                      None                        NaN  \n",
       "700    Gurgaon                      None                        NaN  \n",
       "401    Gurgaon                      None                        NaN  \n",
       "438    Gurgaon                      None                        NaN  \n",
       "653  Hyderābād                      None                        NaN  \n",
       "829  Hyderābād                      None                        NaN  \n",
       "7        India                      None                        NaN  \n",
       "418      India                      None                        NaN  \n",
       "522      India                      None                        NaN  \n",
       "478      India                      None                        NaN  \n",
       "797      India                      None                        NaN  \n",
       "827      India                      None                        NaN  \n",
       "545      India                      None                        NaN  \n",
       "548      India                      None                        NaN  \n",
       "684      India                      None                        NaN  \n",
       "592      India                      None                        NaN  \n",
       "636      India                      None                        NaN  \n",
       "719      India                      None                        NaN  \n",
       "654     Indore                      None                        NaN  \n",
       "681  Karnataka                      None                        NaN  \n",
       "121     Mumbai                      None                        NaN  \n",
       "63      Mumbai                      None                        NaN  \n",
       "794     Mumbai                      None                        NaN  \n",
       "515     Mumbai                      None                        NaN  \n",
       "568      Noida                      None                        NaN  \n",
       "531       Pune                      None                        NaN  \n",
       "398       Pune                      None                        NaN  \n",
       "670       Pune                      None                        NaN  \n",
       "291     Remote                      None                        NaN  \n",
       "369     Remote                      None                        NaN  \n",
       "97      Remote                      None                        NaN  \n",
       "376     Remote                      None                        NaN  \n",
       "677     Remote                      None                        NaN  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False)][[\n",
    "   'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Salary_Range_Standardized', 'Median_Salary_Standardized'\n",
    "]].sort_values(by='Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3a587ee2-b3b9-4620-b0a0-4067fdc947a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].notna() &\n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a018b428-9d31-42d7-9cc0-7b6f4eed4513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range_Standardized'].notna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3560c15d-1fcd-4201-ad91-1bc124b13338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Hitachi Solutions Ltd</td>\n",
       "      <td>Senior AI Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Sciera</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Hitachi Solutions</td>\n",
       "      <td>Senior AI Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>ZF</td>\n",
       "      <td>Senior Data Scientist - AI/ML</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Global Audience Analytics Senior Manager</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>DIATOZ Solutions</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>1200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>OSRAM India Pvt. Limited</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data Scientist / Senior Data Scientist, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Zinnia</td>\n",
       "      <td>Senior Data Scientist (5+ Years)</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mastercard</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Global Cybersecurity Senior Manager - AI Architect</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Senior Data Scientist - AIML</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Maruti Suzuki India Ltd</td>\n",
       "      <td>Sr. Data Scientist 2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Technovert</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Warner Bros. Discovery</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Blackbaud</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>DataEconomy</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Amgen</td>\n",
       "      <td>Senior Associate Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>tezo</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Bank of America</td>\n",
       "      <td>Senior Data Scientist - GBS IND</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Brillio</td>\n",
       "      <td>Senior Data Scientist – R01551342</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Careers at Tide</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Sanofi</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Clean Harbors</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Jabit Soft</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>1800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Astria Digital</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>5300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Intelligence Node</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Crimson Interactive</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Noida</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>ShyftLabs</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Noida</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Techneplus</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Noida</td>\n",
       "      <td>3700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Infoorigin Inc</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Noida</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Innovaccer Analytics</td>\n",
       "      <td>3124-Senior Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Noida</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Senior Data &amp; Applied Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Noida</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Pattern</td>\n",
       "      <td>Senior Data and Applied Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Pune</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>FullThrottle Labs Pvt Ltd</td>\n",
       "      <td>Senior Data Scientist – Generative AI</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Whitefield Careers</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Pattern</td>\n",
       "      <td>Senior Data and Applied Scientist-Operations</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Pune</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>Data Scientist with Machine Learning/Senior Consultant Specialist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Akhilav Technologies LLP</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1080000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Arch Systems, LLC</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Remote</td>\n",
       "      <td>520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>QuantumBricks</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Sr. Executive Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>1200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Company_Name  \\\n",
       "463      Hitachi Solutions Ltd   \n",
       "769                     Sciera   \n",
       "218          Hitachi Solutions   \n",
       "135                         ZF   \n",
       "392    Boston Consulting Group   \n",
       "775           DIATOZ Solutions   \n",
       "330   OSRAM India Pvt. Limited   \n",
       "271    Boston Consulting Group   \n",
       "817                     Zinnia   \n",
       "46                  Mastercard   \n",
       "6      Boston Consulting Group   \n",
       "1                        Optum   \n",
       "529    Maruti Suzuki India Ltd   \n",
       "746                  Microsoft   \n",
       "792                 Technovert   \n",
       "804     Warner Bros. Discovery   \n",
       "818                  Blackbaud   \n",
       "707                DataEconomy   \n",
       "558                      Amgen   \n",
       "824                       tezo   \n",
       "639            Bank of America   \n",
       "357                    Brillio   \n",
       "616            Careers at Tide   \n",
       "142                  Microsoft   \n",
       "279                     Sanofi   \n",
       "160              Clean Harbors   \n",
       "113                 Jabit Soft   \n",
       "701             Astria Digital   \n",
       "667          Intelligence Node   \n",
       "793        Crimson Interactive   \n",
       "0                        Optum   \n",
       "765                  ShyftLabs   \n",
       "736                 Techneplus   \n",
       "731             Infoorigin Inc   \n",
       "468       Innovaccer Analytics   \n",
       "276                  Microsoft   \n",
       "803                    Pattern   \n",
       "713  FullThrottle Labs Pvt Ltd   \n",
       "747         Whitefield Careers   \n",
       "605                    Pattern   \n",
       "387                       HSBC   \n",
       "259   Akhilav Technologies LLP   \n",
       "476          Arch Systems, LLC   \n",
       "43               QuantumBricks   \n",
       "323                  NielsenIQ   \n",
       "\n",
       "                                                             Job_Title  \\\n",
       "463                                           Senior AI Data Scientist   \n",
       "769                                              Senior Data Scientist   \n",
       "218                                           Senior AI Data Scientist   \n",
       "135                                      Senior Data Scientist - AI/ML   \n",
       "392                           Global Audience Analytics Senior Manager   \n",
       "775                                              Senior Data Scientist   \n",
       "330                                              Senior Data Scientist   \n",
       "271              Data Scientist / Senior Data Scientist, India - BCG X   \n",
       "817                                   Senior Data Scientist (5+ Years)   \n",
       "46                                               Senior Data Scientist   \n",
       "6                   Global Cybersecurity Senior Manager - AI Architect   \n",
       "1                                         Senior Data Scientist - AIML   \n",
       "529                                               Sr. Data Scientist 2   \n",
       "746                                              Senior Data Scientist   \n",
       "792                                              Senior Data Scientist   \n",
       "804                                               Staff Data Scientist   \n",
       "818                                              Senior Data Scientist   \n",
       "707                                              Senior Data Scientist   \n",
       "558                                    Senior Associate Data Scientist   \n",
       "824                                              Senior Data Scientist   \n",
       "639                                    Senior Data Scientist - GBS IND   \n",
       "357                                  Senior Data Scientist – R01551342   \n",
       "616                                               Staff Data Scientist   \n",
       "142                                              Senior Data Scientist   \n",
       "279                                              Senior Data Scientist   \n",
       "160                                              Senior Data Scientist   \n",
       "113                                                 Sr. Data Scientist   \n",
       "701                                                 Sr. Data Scientist   \n",
       "667                                              Senior Data Scientist   \n",
       "793                                              Senior Data Scientist   \n",
       "0                                                Senior Data Scientist   \n",
       "765                                              Senior Data Scientist   \n",
       "736                                              Senior Data Scientist   \n",
       "731                                              Senior Data Scientist   \n",
       "468                                         3124-Senior Data Scientist   \n",
       "276                                    Senior Data & Applied Scientist   \n",
       "803                                  Senior Data and Applied Scientist   \n",
       "713                              Senior Data Scientist – Generative AI   \n",
       "747                                              Senior Data Scientist   \n",
       "605                       Senior Data and Applied Scientist-Operations   \n",
       "387  Data Scientist with Machine Learning/Senior Consultant Specialist   \n",
       "259                                              Senior Data Scientist   \n",
       "476                                              Senior Data Scientist   \n",
       "43                                               Senior Data Scientist   \n",
       "323                                       Sr. Executive Data Scientist   \n",
       "\n",
       "     Company_Rating   Location Median_Salary_Standardized  \n",
       "463             3.8    Chennai                     600000  \n",
       "769             4.4    Chennai                     800000  \n",
       "218             3.4    Chennai                     700000  \n",
       "135             3.8    Chennai                     500000  \n",
       "392             4.2    Gurgaon                     800000  \n",
       "775             3.9    Gurgaon                    1200000  \n",
       "330             3.7    Gurgaon                     500000  \n",
       "271             4.2    Gurgaon                     700000  \n",
       "817             3.6    Gurgaon                     800000  \n",
       "46              4.2    Gurgaon                   200000.0  \n",
       "6               4.2    Gurgaon                     700000  \n",
       "1               3.5    Gurgaon                     400000  \n",
       "529             3.8    Gurgaon                     600000  \n",
       "746             4.1  Hyderābād                     600000  \n",
       "792             3.9  Hyderābād                     600000  \n",
       "804             3.6  Hyderābād                     500000  \n",
       "818             3.5  Hyderābād                     600000  \n",
       "707             4.2  Hyderābād                   300000.0  \n",
       "558             4.0  Hyderābād                     700000  \n",
       "824             3.9  Hyderābād                     600000  \n",
       "639             3.9  Hyderābād                     400000  \n",
       "357             3.9  Hyderābād                     900000  \n",
       "616             4.5  Hyderābād                     600000  \n",
       "142             4.1  Hyderābād                     600000  \n",
       "279             4.0  Hyderābād                     900000  \n",
       "160             3.3  Hyderābād                     800000  \n",
       "113             3.9      India                    1800000  \n",
       "701             3.9      India                    5300000  \n",
       "667             3.9     Mumbai                     800000  \n",
       "793             3.7     Mumbai                     800000  \n",
       "0               3.5      Noida                     400000  \n",
       "765             3.8      Noida                     800000  \n",
       "736             3.9      Noida                    3700000  \n",
       "731             3.9      Noida                  1000000.0  \n",
       "468             3.4      Noida                     500000  \n",
       "276             4.1      Noida                     600000  \n",
       "803             4.5       Pune                     800000  \n",
       "713             3.9       Pune                    1600000  \n",
       "747             3.9       Pune                    2500000  \n",
       "605             4.5       Pune                     800000  \n",
       "387             3.9       Pune                    1000000  \n",
       "259             3.9     Remote                  1080000.0  \n",
       "476             4.2     Remote                   520000.0  \n",
       "43              4.7     Remote                    1600000  \n",
       "323             3.8   Vadodara                    1200000  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].notna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Median_Salary_Standardized'\n",
    "]].sort_values(by='Location')[40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f21bffb-8172-438f-a798-5a6083a0641d",
   "metadata": {},
   "source": [
    "### Imputing missing values of jobs located in 'Bengaluru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8e239246-f5d9-4a67-abb7-3651cd1aae86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Singular Intelligence</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Valuebound</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>John Crane</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Mico</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>New Relic</td>\n",
       "      <td>Senior Data Scientist - Product - Bangalore - FY26|R&amp;D|#7210</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>Sr Specialist Data Scientist (ML/AI &amp; Databricks)</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>First Advantage</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Senior AI or ML Engineer</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Fastenal India</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Verve</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>Senior Data Scientist - AWS Professional Services</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>Sapiens</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Bluevine - India</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Rockwell Automation</td>\n",
       "      <td>Senior Data Scientist- AzureML/SageMaker</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>KPMG</td>\n",
       "      <td>Senior - Data Science</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>EY</td>\n",
       "      <td>TTT-Data Science-Staff</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>Senior Applied Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>Commonwealth Bank</td>\n",
       "      <td>Data Scientist Senior Associate</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Ecolab Inc.</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>KnowBe4</td>\n",
       "      <td>Staff Data Scientist (Position located in Bengaluru, India)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>o9 Solutions</td>\n",
       "      <td>Data Scientist, Senior</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>Data Scientist, Senior</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Senior Advisor, Data Science (I8)</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Truecaller</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>TekIT Solutions</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>JioStar</td>\n",
       "      <td>Staff Data Scientist- Subs &amp; Pay</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Aurc Solutions</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>ABB</td>\n",
       "      <td>Senior Data Scientist Specialist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Senior Data Scientist - Periscope</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Nestlé IT</td>\n",
       "      <td>Senior Data Scientist - Supply Chain</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>S&amp;P Global</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>Staff Software Developer, Machine Learning</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Volvo Group</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>Staff Software Developer, Machine Learning</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Target</td>\n",
       "      <td>Sr Data Scientist - ML/OR</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Senior Data Scientist_Data Scientist_7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Texas Instruments</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>Senior, Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Hilabs</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Google</td>\n",
       "      <td>Senior Data Scientist Product, Google One and Photos</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Shamrock Value Private Limited</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  \\\n",
       "625               Singular Intelligence   \n",
       "188                          Valuebound   \n",
       "764                          John Crane   \n",
       "520                                Mico   \n",
       "411                           New Relic   \n",
       "604                                AT&T   \n",
       "334                     First Advantage   \n",
       "34                                Optum   \n",
       "737                      Fastenal India   \n",
       "227                               Verve   \n",
       "798                          Amazon.com   \n",
       "651                             Sapiens   \n",
       "575                    Bluevine - India   \n",
       "337                 Rockwell Automation   \n",
       "203                                KPMG   \n",
       "734                                  EY   \n",
       "694  LSEG (London Stock Exchange Group)   \n",
       "674  LSEG (London Stock Exchange Group)   \n",
       "486                   Commonwealth Bank   \n",
       "95                               PayPal   \n",
       "813                         Ecolab Inc.   \n",
       "300                             KnowBe4   \n",
       "715                        o9 Solutions   \n",
       "613                  Zebra Technologies   \n",
       "830                                Dell   \n",
       "530                          Truecaller   \n",
       "441                     TekIT Solutions   \n",
       "523                             JioStar   \n",
       "822                            Tredence   \n",
       "496                      Aurc Solutions   \n",
       "427                                 ABB   \n",
       "104                  McKinsey & Company   \n",
       "705                           Nestlé IT   \n",
       "407                          S&P Global   \n",
       "395                        Kinaxis Inc.   \n",
       "250                         Volvo Group   \n",
       "35                         Kinaxis Inc.   \n",
       "647                              Target   \n",
       "800                   Fractal Analytics   \n",
       "433                   Texas Instruments   \n",
       "397                  Schneider Electric   \n",
       "760                              Hilabs   \n",
       "716                              Google   \n",
       "561      Shamrock Value Private Limited   \n",
       "\n",
       "                                                        Job_Title  \\\n",
       "625                                         Senior Data Scientist   \n",
       "188                                         Senior Data Scientist   \n",
       "764                                          Staff Data Scientist   \n",
       "520                                         Senior Data Scientist   \n",
       "411  Senior Data Scientist - Product - Bangalore - FY26|R&D|#7210   \n",
       "604             Sr Specialist Data Scientist (ML/AI & Databricks)   \n",
       "334                                         Senior Data Scientist   \n",
       "34                                       Senior AI or ML Engineer   \n",
       "737                                         Senior Data Scientist   \n",
       "227                                          Staff Data Scientist   \n",
       "798             Senior Data Scientist - AWS Professional Services   \n",
       "651                                         Senior Data Scientist   \n",
       "575                                         Senior Data Scientist   \n",
       "337                      Senior Data Scientist- AzureML/SageMaker   \n",
       "203                                         Senior - Data Science   \n",
       "734                                        TTT-Data Science-Staff   \n",
       "694                                         Senior Data Scientist   \n",
       "674                                 Senior Applied Data Scientist   \n",
       "486                               Data Scientist Senior Associate   \n",
       "95                                              Sr Data Scientist   \n",
       "813                                         Senior Data Scientist   \n",
       "300   Staff Data Scientist (Position located in Bengaluru, India)   \n",
       "715                                        Data Scientist, Senior   \n",
       "613                                        Data Scientist, Senior   \n",
       "830                             Senior Advisor, Data Science (I8)   \n",
       "530                                         Senior Data Scientist   \n",
       "441                                         Senior Data Scientist   \n",
       "523                              Staff Data Scientist- Subs & Pay   \n",
       "822                                         Senior Data Scientist   \n",
       "496                                            Sr. Data Scientist   \n",
       "427                              Senior Data Scientist Specialist   \n",
       "104                             Senior Data Scientist - Periscope   \n",
       "705                          Senior Data Scientist - Supply Chain   \n",
       "407                                         Senior Data Scientist   \n",
       "395                    Staff Software Developer, Machine Learning   \n",
       "250                                         Senior Data Scientist   \n",
       "35                     Staff Software Developer, Machine Learning   \n",
       "647                                     Sr Data Scientist - ML/OR   \n",
       "800                        Senior Data Scientist_Data Scientist_7   \n",
       "433                                             Sr Data Scientist   \n",
       "397                                        Senior, Data Scientist   \n",
       "760                                         Senior Data Scientist   \n",
       "716          Senior Data Scientist Product, Google One and Photos   \n",
       "561                                         Senior Data Scientist   \n",
       "\n",
       "     Company_Rating   Location Median_Salary_Standardized  \n",
       "625             2.1  Bengaluru                     500000  \n",
       "188             2.8  Bengaluru                    5000000  \n",
       "764             3.1  Bengaluru                     800000  \n",
       "520             3.3  Bengaluru                        NaN  \n",
       "411             3.4  Bengaluru                     700000  \n",
       "604             3.4  Bengaluru                     600000  \n",
       "334             3.4  Bengaluru                     600000  \n",
       "34              3.5  Bengaluru                     500000  \n",
       "737             3.5  Bengaluru                     400000  \n",
       "227             3.6  Bengaluru                     500000  \n",
       "798             3.6  Bengaluru                     700000  \n",
       "651             3.6  Bengaluru                     700000  \n",
       "575             3.6  Bengaluru                     700000  \n",
       "337             3.7  Bengaluru                        NaN  \n",
       "203             3.7  Bengaluru                        NaN  \n",
       "734             3.7  Bengaluru                     800000  \n",
       "694             3.7  Bengaluru                  1000000.0  \n",
       "674             3.7  Bengaluru                  1000000.0  \n",
       "486             3.7  Bengaluru                   200000.0  \n",
       "95              3.7  Bengaluru                     300000  \n",
       "813             3.7  Bengaluru                     600000  \n",
       "300             3.7  Bengaluru                     600000  \n",
       "715             3.8  Bengaluru                        NaN  \n",
       "613             3.8  Bengaluru                     600000  \n",
       "830             3.8  Bengaluru                     600000  \n",
       "530             3.8  Bengaluru                     500000  \n",
       "441             3.9  Bengaluru                    1800000  \n",
       "523             3.9  Bengaluru                        NaN  \n",
       "822             3.9  Bengaluru                     900000  \n",
       "496             3.9  Bengaluru                    2400000  \n",
       "427             4.0  Bengaluru                     800000  \n",
       "104             4.0  Bengaluru                     800000  \n",
       "705             4.1  Bengaluru                        NaN  \n",
       "407             4.1  Bengaluru                     700000  \n",
       "395             4.1  Bengaluru                        NaN  \n",
       "250             4.1  Bengaluru                  1000000.0  \n",
       "35              4.1  Bengaluru                     500000  \n",
       "647             4.2  Bengaluru                   400000.0  \n",
       "800             4.2  Bengaluru                     800000  \n",
       "433             4.3  Bengaluru                  1000000.0  \n",
       "397             4.3  Bengaluru                     900000  \n",
       "760             4.3  Bengaluru                  1000000.0  \n",
       "716             4.3  Bengaluru                     400000  \n",
       "561             5.0  Bengaluru                    2400000  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Location'].str.contains('Bengaluru', regex=False, na=False) & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Median_Salary_Standardized'\n",
    "]].sort_values(by='Company_Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "54c1ca74-6f67-4056-b869-cdab30839050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job_Title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Senior Data Scientist\n",
       "Company_Rating                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          3.3\n",
       "Description                   Job Summary\\nThe Senior Data Scientist will work on data-driven initiatives to solve complex business challenges, leveraging advanced analytics, machine learning, and statistical modeling. This role requires expertise in translating data insights into actionable strategies and collaborating with cross-functional teams. Ideal candidates will have a strong background in analytics, or tech-driven industries.Key Responsibilities\\nDevelop and deploy predictive models (e.g., customer lifetime value, media mix modeling, time-series forecasting) using Python/R, TensorFlow, or PyTorch.\\nClean, preprocess, and validate large datasets (structured/unstructured) from multiple sources.\\nPartner with stakeholders (e.g., marketing, finance) to design data-driven solutions (e.g., A/B testing)\\nEnsure adherence to data privacy and ethical AI practices\n",
       "Median_Salary_Standardized                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              NaN\n",
       "Name: 520, dtype: object"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[520, ['Job_Title', 'Company_Rating', 'Description', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "375e4065-c9ad-4f7d-bada-c3751ab82bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Rockwell Automation</td>\n",
       "      <td>Senior Data Scientist- AzureML/SageMaker</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Rockwell Automation is a global technology leader focused on helping the world’s manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility - our people are energized problem solvers that take pride in how the work we do changes the world for the better.\\nWe welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that’s you we would love to have you join us!\\nJob Description\\nSummary:\\nData Scientist at Rockwell Automation, you'll join an analytics team of engineers, product managers, and partners that's driving the next wave of AI-powered features for our platform.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>KPMG</td>\n",
       "      <td>Senior - Data Science</td>\n",
       "      <td>3.7</td>\n",
       "      <td>JOB DESCRIPTION\\n\\nAbout KPMG in India\\nKPMG entities in India are professional services firm(s). These Indian member firms are affiliated with KPMG International Limited. KPMG was established in India in August 1993. Our professionals leverage the global network of firms, and are conversant with local laws, regulations, markets and competition. KPMG has offices across India in Ahmedabad, Bengaluru, Chandigarh, Chennai, Gurugram, Jaipur, Hyderabad, Jaipur, Kochi, Kolkata, Mumbai, Noida, Pune, Vadodara and Vijayawada.\\nKPMG entities in India offer services to national and international clients in India across sectors. We strive to provide rapid, performance-based, industry-focused and technology-enabled services, which reflect a shared knowledge of global and local industries and our experience of the Indian business environment.\\nData Science\\n\\n\\n\\n\\nQUALIFICATIONS\\n\\nB.E</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Company_Name                                 Job_Title  \\\n",
       "337  Rockwell Automation  Senior Data Scientist- AzureML/SageMaker   \n",
       "203                 KPMG                     Senior - Data Science   \n",
       "\n",
       "     Company_Rating  \\\n",
       "337             3.7   \n",
       "203             3.7   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Description  \\\n",
       "337  Rockwell Automation is a global technology leader focused on helping the world’s manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility - our people are energized problem solvers that take pride in how the work we do changes the world for the better.\\nWe welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that’s you we would love to have you join us!\\nJob Description\\nSummary:\\nData Scientist at Rockwell Automation, you'll join an analytics team of engineers, product managers, and partners that's driving the next wave of AI-powered features for our platform.   \n",
       "203           JOB DESCRIPTION\\n\\nAbout KPMG in India\\nKPMG entities in India are professional services firm(s). These Indian member firms are affiliated with KPMG International Limited. KPMG was established in India in August 1993. Our professionals leverage the global network of firms, and are conversant with local laws, regulations, markets and competition. KPMG has offices across India in Ahmedabad, Bengaluru, Chandigarh, Chennai, Gurugram, Jaipur, Hyderabad, Jaipur, Kochi, Kolkata, Mumbai, Noida, Pune, Vadodara and Vijayawada.\\nKPMG entities in India offer services to national and international clients in India across sectors. We strive to provide rapid, performance-based, industry-focused and technology-enabled services, which reflect a shared knowledge of global and local industries and our experience of the Indian business environment.\\nData Science\\n\\n\\n\\n\\nQUALIFICATIONS\\n\\nB.E   \n",
       "\n",
       "      Location Median_Salary_Standardized  \n",
       "337  Bengaluru                        NaN  \n",
       "203  Bengaluru                        NaN  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[337, 203], ['Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4499b111-3993-432e-9ecd-4ecd98400f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>o9 Solutions</td>\n",
       "      <td>Data Scientist, Senior</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Transforming the Future of Enterprise Planning\\nAt o9, our mission is to be the Most Value-Creating Platform for enterprises by transforming decision-making through our AI-first approach. By integrating siloed planning capabilities and capturing millions—even billions—in value leakage, we help businesses plan smarter and faster.\\nThis not only enhances operational efficiency but also reduces waste, leading to better outcomes for both businesses and the planet. Global leaders like Google, PepsiCo, Walmart, T-Mobile, AB InBev, and Starbucks trust o9 to optimize their supply chains.\\nBe part of something revolutionary\\nWe have a vision. Our Digital Brain, o9’s AI-powered platform, is being used by global enterprises to\\ndrive their digital transformations. The integrated planning and operational efficiencies we provide is\\nhelping businesses do more, be more and mean more to the world at large. Because businesses that\\nplan better, reduce waste, creating value for themselves and the planet.\\nBut we also have a vision for our people. We want the most talented, committed anddriven people\\nto power our transformative approach. In return, we’ll provide a nurturing environment where you\\ncan be a part of something special.\\n\\nproblems\\n(Heuristic, LP, GA etc), Anomaly detection, Simulation and stochastic models, Market Intelligence etc.\\nConsultants and Data Engineers to ensure successful delivery of o9 projects\\nheuristic-based hierarchical best-fit models using algorithms like exponential\\nsmoothing, ARIMA, prophet and custom parameter tuning.\\nassortments/pricing/inventory etc.\\nactivities like Social Fridays. If you’re in the office, feel free to join these events in person.\\npolitics).</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>Data Scientist, Senior</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Remote Work: Hybrid\\n\\nOverview:\\nAt Zebra, we are a community of innovators who come together to create new ways of working to make everyday life better. United by curiosity and care, we develop dynamic solutions that anticipate our customer’s and partner’s needs and solve their challenges.\\n\\nBeing a part of Zebra Nation means being seen, heard, valued, and respected. Drawing from our diverse perspectives, we collaborate to deliver on our purpose. Here you are a part of a team pushing boundaries to redefine the work of tomorrow for organizations, their employees, and those they serve.</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Senior Advisor, Data Science (I8)</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods, and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.\\nJoin us as a Senior Advisor on our Data Science team in Bangalore to do the best work of your career and make a profound social impact.\\nWhat you’ll achieve\\nData Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods, and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.\\n\\n\\n\\n\\n\\n\\n\\nR274037</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Truecaller</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Hello, Truecaller is calling you from Bangalore, India! Ready to pick up?\\nOur goal is to make communication smarter, safer, and more efficient, all while building trust everywhere. We're all about bringing you smart services with a big social impact, keeping you safe from fraud, harassment, scam calls or messages, so you can focus on the conversations that matter.\\nTop 20 most downloaded apps globally, and world's #1 caller ID and spam-blocking service for Android and iOS, with extensive AI capabilities, with more than 450 million active users per month.\\nFounded in 2009, listed on Nasdaq OMX Stockholm and is categorized as a Large Cap. Our focus on innovation, operational excellence, sustainable growth, and collaboration has resulted in consistently high profitability and strong EBITDA margins.\\nA team of 400 people from ~35 different nationalities spread across our headquarters in Stockholm and offices in Bangalore, Mumbai, Gurgaon and Tel Aviv .</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company_Name                          Job_Title  Company_Rating  \\\n",
       "715        o9 Solutions             Data Scientist, Senior             3.8   \n",
       "613  Zebra Technologies             Data Scientist, Senior             3.8   \n",
       "830                Dell  Senior Advisor, Data Science (I8)             3.8   \n",
       "530          Truecaller              Senior Data Scientist             3.8   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Description  \\\n",
       "715  Transforming the Future of Enterprise Planning\\nAt o9, our mission is to be the Most Value-Creating Platform for enterprises by transforming decision-making through our AI-first approach. By integrating siloed planning capabilities and capturing millions—even billions—in value leakage, we help businesses plan smarter and faster.\\nThis not only enhances operational efficiency but also reduces waste, leading to better outcomes for both businesses and the planet. Global leaders like Google, PepsiCo, Walmart, T-Mobile, AB InBev, and Starbucks trust o9 to optimize their supply chains.\\nBe part of something revolutionary\\nWe have a vision. Our Digital Brain, o9’s AI-powered platform, is being used by global enterprises to\\ndrive their digital transformations. The integrated planning and operational efficiencies we provide is\\nhelping businesses do more, be more and mean more to the world at large. Because businesses that\\nplan better, reduce waste, creating value for themselves and the planet.\\nBut we also have a vision for our people. We want the most talented, committed anddriven people\\nto power our transformative approach. In return, we’ll provide a nurturing environment where you\\ncan be a part of something special.\\n\\nproblems\\n(Heuristic, LP, GA etc), Anomaly detection, Simulation and stochastic models, Market Intelligence etc.\\nConsultants and Data Engineers to ensure successful delivery of o9 projects\\nheuristic-based hierarchical best-fit models using algorithms like exponential\\nsmoothing, ARIMA, prophet and custom parameter tuning.\\nassortments/pricing/inventory etc.\\nactivities like Social Fridays. If you’re in the office, feel free to join these events in person.\\npolitics).   \n",
       "613                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Remote Work: Hybrid\\n\\nOverview:\\nAt Zebra, we are a community of innovators who come together to create new ways of working to make everyday life better. United by curiosity and care, we develop dynamic solutions that anticipate our customer’s and partner’s needs and solve their challenges.\\n\\nBeing a part of Zebra Nation means being seen, heard, valued, and respected. Drawing from our diverse perspectives, we collaborate to deliver on our purpose. Here you are a part of a team pushing boundaries to redefine the work of tomorrow for organizations, their employees, and those they serve.   \n",
       "830                                                                                                                                                                                                                                                                                                                                                                                                                                      Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods, and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.\\nJoin us as a Senior Advisor on our Data Science team in Bangalore to do the best work of your career and make a profound social impact.\\nWhat you’ll achieve\\nData Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods, and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.\\n\\n\\n\\n\\n\\n\\n\\nR274037   \n",
       "530                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Hello, Truecaller is calling you from Bangalore, India! Ready to pick up?\\nOur goal is to make communication smarter, safer, and more efficient, all while building trust everywhere. We're all about bringing you smart services with a big social impact, keeping you safe from fraud, harassment, scam calls or messages, so you can focus on the conversations that matter.\\nTop 20 most downloaded apps globally, and world's #1 caller ID and spam-blocking service for Android and iOS, with extensive AI capabilities, with more than 450 million active users per month.\\nFounded in 2009, listed on Nasdaq OMX Stockholm and is categorized as a Large Cap. Our focus on innovation, operational excellence, sustainable growth, and collaboration has resulted in consistently high profitability and strong EBITDA margins.\\nA team of 400 people from ~35 different nationalities spread across our headquarters in Stockholm and offices in Bangalore, Mumbai, Gurgaon and Tel Aviv .   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "715                        NaN  \n",
       "613                     600000  \n",
       "830                     600000  \n",
       "530                     500000  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[715, 613, 830, 530], ['Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "657c6626-8fee-405d-aaa8-f13a28ce225a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>JioStar</td>\n",
       "      <td>Staff Data Scientist- Subs &amp; Pay</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Job Summary: With a mission to accelerate user acquisition through data-driven intelligence, as a Staff Data Scientist, you will design and deploy machine learning models and decision systems that drive subscription growth via direct-to-consumer (D2C) and B2B/partner channels. You’ll collaborate closely with Product, Engineering, Growth, and Marketing teams to power personalized user journeys, scale experiments, and shape acquisition, retention strategy through insights and automation. If you thrive at the intersection of data, product, and impact — and want to shape how millions of users subscribe — this is the role for you\\n\\nAbout the team: Subscriptions and Payments Team powers the end-to-end direct monetization engine for India’s largest subscription platform, with over 250M+ subscriptions. We build scalable, multi-tenant systems for acquiring users via D2C and partner channels, reducing churn through intelligent renewal and retry mechanisms, and integrating deeply with global and local payment ecosystems like UPI Autopay and card mandates. Our platform drives seamless onboarding, high retention, and reliable payments at scale—enabling frictionless subscription experiences across geographies and devices.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Nestlé IT</td>\n",
       "      <td>Senior Data Scientist - Supply Chain</td>\n",
       "      <td>4.1</td>\n",
       "      <td>About IT in Nestlé\\nWe are a team of IT professionals from diverse cultures, genders and age groups in the world’s largest food and beverage company. We innovate every day through forward-looking technologies to create opportunities for Nestlé’s digital challenges with our consumers, customers and employees.\\nWe have exciting positions in our new Nestlé global services operations based in Bangalore, which works alongside our Regional IT Hub in Sydney and Global IT hubs to provide technology services. This set up will design, implement and maintain IT solutions and sharpen Nestlé’s focus in the growing areas of digital, analytics and innovation to support changing customer, consumer and shopper focus.\\nWhen you join our IT team, you’ll have the opportunity to collaborate across local and global Nestlé teams and external partners to deliver innovative technologies that create tangible business value and contribute proactively to our sustainability goals. Our diversity brings fresh and innovative thinking to how we approach new and existing challenges while embracing different cultures, genders, sexual orientation, abilities and flexible ways of working.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>Staff Software Developer, Machine Learning</td>\n",
       "      <td>4.1</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>Staff Software Developer, Machine Learning</td>\n",
       "      <td>4.1</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company_Name                                   Job_Title  Company_Rating  \\\n",
       "523       JioStar            Staff Data Scientist- Subs & Pay             3.9   \n",
       "705     Nestlé IT        Senior Data Scientist - Supply Chain             4.1   \n",
       "395  Kinaxis Inc.  Staff Software Developer, Machine Learning             4.1   \n",
       "35   Kinaxis Inc.  Staff Software Developer, Machine Learning             4.1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description  \\\n",
       "523  Job Summary: With a mission to accelerate user acquisition through data-driven intelligence, as a Staff Data Scientist, you will design and deploy machine learning models and decision systems that drive subscription growth via direct-to-consumer (D2C) and B2B/partner channels. You’ll collaborate closely with Product, Engineering, Growth, and Marketing teams to power personalized user journeys, scale experiments, and shape acquisition, retention strategy through insights and automation. If you thrive at the intersection of data, product, and impact — and want to shape how millions of users subscribe — this is the role for you\\n\\nAbout the team: Subscriptions and Payments Team powers the end-to-end direct monetization engine for India’s largest subscription platform, with over 250M+ subscriptions. We build scalable, multi-tenant systems for acquiring users via D2C and partner channels, reducing churn through intelligent renewal and retry mechanisms, and integrating deeply with global and local payment ecosystems like UPI Autopay and card mandates. Our platform drives seamless onboarding, high retention, and reliable payments at scale—enabling frictionless subscription experiences across geographies and devices.   \n",
       "705                                                             About IT in Nestlé\\nWe are a team of IT professionals from diverse cultures, genders and age groups in the world’s largest food and beverage company. We innovate every day through forward-looking technologies to create opportunities for Nestlé’s digital challenges with our consumers, customers and employees.\\nWe have exciting positions in our new Nestlé global services operations based in Bangalore, which works alongside our Regional IT Hub in Sydney and Global IT hubs to provide technology services. This set up will design, implement and maintain IT solutions and sharpen Nestlé’s focus in the growing areas of digital, analytics and innovation to support changing customer, consumer and shopper focus.\\nWhen you join our IT team, you’ll have the opportunity to collaborate across local and global Nestlé teams and external partners to deliver innovative technologies that create tangible business value and contribute proactively to our sustainability goals. Our diversity brings fresh and innovative thinking to how we approach new and existing challenges while embracing different cultures, genders, sexual orientation, abilities and flexible ways of working.   \n",
       "395                                                                                                                                                                                                                                                                                                                                                                                        About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:   \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                         About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "523                        NaN  \n",
       "705                        NaN  \n",
       "395                        NaN  \n",
       "35                      500000  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[523, 705, 395, 35], ['Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf8da8-bf6b-464f-b2b6-0907d2bad8f4",
   "metadata": {},
   "source": [
    "- The salary range for Senior level roles location in bengaluru with company rating of 3 - 3.4 is between 4,00,000 to 8,00,000 and the most common salary is 6,00,000. From anaylzing row 520, the roles and responsibility of the job looks pretty common, a typical Data Science job role therefore we can use 6,00,000 to impute the value\n",
    "<br>\n",
    "  \n",
    "- The salary range of jobs with company ratings between 3.6 - 3.8 is 6,00,000 - 10,00,000. \n",
    "- From analyzing job 337, as the title mentions the roles involves MLOps i.e AzureML/Sagemaker, therefore the salary provided might be around 8,00,000 (avg salary).\n",
    "- From analyzing job 203, we cannot extract any information about the role, we can fill in the missing value with 7,00,000 , to maintain variance (there are a lot of values with 6,00,000 we don't want to skew the values).\n",
    "<br>\n",
    "- Job posting 715 involves Anomaly detection, Simulation and stochastic models, Market Intelligence which are some advanced data science skills therefore the pay will be at higher end of the salary range, lets fill the value with 7,00,000.\n",
    "<br>\n",
    "- The common salary range of job posting with rating of 3.9 - 4.3 are 8,00,000 - 10,00,000\n",
    "- Row 523 involves training, deploying ML models and decision for acurring new users which is a very important job in the company and the job title is staff level therefore the salary must be at the higher end, lets impute the missing value with 10,00,000\n",
    "- Row 705 looks like a regular data science role nothing advanced or fancy, lets impute the missing value with the average salary of 8,00,000.\n",
    "<br>\n",
    "- Drop row 395 as it is the duplicate of row 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "499e70c5-b2ea-4160-b3d2-575db3e34701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[520, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[337, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[203, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[715, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[523, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[705, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.drop(395, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ff26fd57-d3cf-401e-b254-476d0f22e0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('Bengaluru', regex=False, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ca852-8d50-44df-9198-18da74ba20d0",
   "metadata": {},
   "source": [
    "### Imputing missing values of jobs located in 'Chennai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "fc3b105e-08f9-4fcb-9ad5-46fea9e500b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name                                                                                                                                                                                                                                                                                                                                                                                                                                EY\n",
       "Company_Rating                                                                                                                                                                                                                                                                                                                                                                                                                             3.7\n",
       "Job_Title                                                                                                                                                                                                                                                                                                                                                                                             Digital-Staff-Machine Learning Developer\n",
       "Location                                                                                                                                                                                                                                                                                                                                                                                                                               Chennai\n",
       "Description                   At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nPosition Name\\n\\nML Developer\\n\\nTaleo ID\n",
       "Salary_Range                                                                                                                                                                                                                                                                                                                                                                                                                              None\n",
       "Median_Salary                                                                                                                                                                                                                                                                                                                                                                                                                              NaN\n",
       "Salary_Source                                                                                                                                                                                                                                                                                                                                                                                                                             None\n",
       "Salary_Range_Standardized                                                                                                                                                                                                                                                                                                                                                                                                                 None\n",
       "Median_Salary_Standardized                                                                                                                                                                                                                                                                                                                                                                                                                 NaN\n",
       "Name: 535, dtype: object"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[535]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e408ffb1-6c3f-4f68-a276-9089e4d0d8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>ZF</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Senior Data Scientist - AI/ML</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Become our next FutureStarter\\nAre you ready to make an impact? ZF is looking for talented individuals to join our team. As a FutureStarter, you’ll have the opportunity to shape the future of mobility. Join us and be part of something extraordinary!\\nSenior Data Scientist - AI/ML\\nCountry/Region: IN\\nLocation: Chennai, TN, IN, 600116\\nReq ID 79914 | GEC Chennai, India, ZF Commercial Vehicle Control Systems India Limited\\n\\nSenior Data Scientist - AI/ML\\nAbout the Team:\\nZF COE Team is effectively communicate complex technical concepts related to AI, ML, DL, and RL to both technical and non-technical audiences. This might involve presenting research findings at conferences or writing papers for academic journals.</td>\n",
       "      <td>₹3L – ₹8L/yr</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>300000 – 800000</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Pfizer</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Senior Statistical Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>An Individual Contributor role\\nProductive hands on programming, supporting deliverables in the study/project/portfolio/standards team, of medium – high complex statistical programming deliverables to support assets and study teams\\nPerforms tasks with limited supervision early in role and independently later in role.\\nIs capable of handling standards/study programming specific activities independently including collaboration across stakeholders at various timezones\\nEnsures adherence to high quality programming standards in their daily work\\nEnsure the tasks are completed on time with quality and are compliant to the process at Pfizer with needed guidance.\\nWork collaboratively with study teams and stakeholders such as clinicians and statisticians on milestones and deliverables.\\n\\n\\nWork Location Assignment: Flexible\\n\\nWork Location Assignment: Hybrid\\n\\nMedical\\n#LI-PFE</td>\n",
       "      <td>₹5L – ₹7L/yr</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>500000 – 700000</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Hitachi Solutions</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Senior AI Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Company Description\\n\\nAbout Hitachi Solutions India Pvt Ltd:\\nHitachi Solutions, Ltd., headquartered in Tokyo, Japan, is a core member of Information &amp; Telecommunication Systems Company of Hitachi Group and a recognized leader in delivering proven business and IT strategies and solutions to companies across many industries. The company provides value-driven services throughout the IT life cycle from systems planning to systems integration, operation and maintenance. Hitachi Solutions delivers products and services of superior value to customers worldwide through key subsidiaries in the United States, Europe, China and India. The flagship company in the Hitachi Group's information and communication system solutions business, Hitachi Solutions also offers solutions for social innovation such as smart cities.\\nOur Competitive Edge</td>\n",
       "      <td>₹6L – ₹9L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>600000 – 900000</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Hitachi Solutions Ltd</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Senior AI Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Company Description\\n\\nAbout Hitachi Solutions India Pvt Ltd:\\n\\nHitachi Solutions, Ltd., headquartered in Tokyo, Japan, is a core member of Information &amp; Telecommunication Systems Company of Hitachi Group and a recognized leader in delivering proven business and IT strategies and solutions to companies across many industries. The company provides value-driven services throughout the IT life cycle from systems planning to systems integration, operation and maintenance. Hitachi Solutions delivers products and services of superior value to customers worldwide through key subsidiaries in the United States, Europe, China and India. The flagship company in the Hitachi Group's information and communication system solutions business, Hitachi Solutions also offers solutions for social innovation such as smart cities.\\n\\n\\n\\nWe work together in a dynamic and rewarding work environment. We have an experienced leadership team, excellent technology and product expertise, and strong relationships with a broad base of customers and partners.\\n\\nWe offer competitive compensation and benefits package, regular performance review, performance bonuses, and regular trainings.\\n\\n\\n\\nWe pride ourselves on being industry leaders and providing an enjoyable work environment where our people can grow personally and professionally. Hitachi is the place people can develop skills they're excited about. The following are our commitments to employees.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOur recruiting team may communicate with candidates via our @hitachisolutions.com domain email address and/or via our SmartRecruiters (Applicant Tracking System) notification@smartrecruiters.com domain email address regarding your application and interview requests.\\n\\nAll offers will originate from our @hitachisolutions.com domain email address. If you receive an offer or information from someone purporting to be an employee of Hitachi Solutions from any other domain, it may not be legitimate.</td>\n",
       "      <td>₹5L – ₹8L/yr</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>500000 – 800000</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Udemy</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Join Udemy. Help define the future of learning.\\nUdemy is an AI-powered reskilling platform built to help people and teams grow. It's personalized, practical, and focused on real-world impact.\\nOur mission is simple: to transform lives through learning. Your work helps people around the world build skills they can use, whether they're picking up something new or leveling up to stay ahead.\\nOver 80 million learners and 17,000 businesses already learn with Udemy. If you're excited by change, energized by learning, and ready to have a real impact, you'll feel right at home.\\nLearn more about us on our company page.\\nHybrid work\\nUdemy is headquartered in San Francisco with global offices in Australia, India, Ireland, Türkiye, and other US locations. Our robust hybrid work model spans San Francisco, Denver, Ankara, Dublin, and Melbourne. This hybrid position requires two days per week in the office at the nearest hub. Learn more about us on our company page.</td>\n",
       "      <td>₹2L – ₹7L/yr</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>200000 – 700000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Sciera</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Job Location: Chennai\\n\\nJob Description 8+ years of experience\\nWe are looking for a Data Scientist lead to analyze large amounts of raw data to find patterns that will help improve our client’s business processes. We will rely on you to build data products to extract valuable business insights.In this role, you should be highly analytical with a flair for analysis, math/statistics and AIML.Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Your goal will be to help our clients analyze trends to make better decisions and develop new data products to serve our clients better.\\nRoles and responsibilities :</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Mani India Technologies</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Title: Senior Data Scientist\\nYears of Experience: 8+ years\\n*Location: The selected candidate is required to work onsite at our Chennai/Kovilpatti location for the initial Three-month project training and execution period. After the Three months, the candidate will be offered remote opportunities.*\\nThe Senior Data Scientist will lead the development and implementation of advanced analytics and\\nAI/ML models to solve complex business problems. This role requires deep statistical expertise,\\nhands-on model building experience, and the ability to translate raw data into strategic insights. The\\ncandidate will collaborate with business stakeholders, data engineers, and AI engineers to deploy\\nproduction-grade models that drive innovation and value.\\nKey responsibilities</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  Company_Rating  \\\n",
       "135                       ZF             3.8   \n",
       "139                   Pfizer             3.8   \n",
       "218        Hitachi Solutions             3.4   \n",
       "463    Hitachi Solutions Ltd             3.8   \n",
       "696                    Udemy             3.6   \n",
       "769                   Sciera             4.4   \n",
       "791  Mani India Technologies             3.5   \n",
       "\n",
       "                             Job_Title Location  \\\n",
       "135      Senior Data Scientist - AI/ML  Chennai   \n",
       "139  Senior Statistical Data Scientist  Chennai   \n",
       "218           Senior AI Data Scientist  Chennai   \n",
       "463           Senior AI Data Scientist  Chennai   \n",
       "696               Staff Data Scientist  Chennai   \n",
       "769              Senior Data Scientist  Chennai   \n",
       "791              Senior Data Scientist  Chennai   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description  \\\n",
       "135                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Become our next FutureStarter\\nAre you ready to make an impact? ZF is looking for talented individuals to join our team. As a FutureStarter, you’ll have the opportunity to shape the future of mobility. Join us and be part of something extraordinary!\\nSenior Data Scientist - AI/ML\\nCountry/Region: IN\\nLocation: Chennai, TN, IN, 600116\\nReq ID 79914 | GEC Chennai, India, ZF Commercial Vehicle Control Systems India Limited\\n\\nSenior Data Scientist - AI/ML\\nAbout the Team:\\nZF COE Team is effectively communicate complex technical concepts related to AI, ML, DL, and RL to both technical and non-technical audiences. This might involve presenting research findings at conferences or writing papers for academic journals.   \n",
       "139                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        An Individual Contributor role\\nProductive hands on programming, supporting deliverables in the study/project/portfolio/standards team, of medium – high complex statistical programming deliverables to support assets and study teams\\nPerforms tasks with limited supervision early in role and independently later in role.\\nIs capable of handling standards/study programming specific activities independently including collaboration across stakeholders at various timezones\\nEnsures adherence to high quality programming standards in their daily work\\nEnsure the tasks are completed on time with quality and are compliant to the process at Pfizer with needed guidance.\\nWork collaboratively with study teams and stakeholders such as clinicians and statisticians on milestones and deliverables.\\n\\n\\nWork Location Assignment: Flexible\\n\\nWork Location Assignment: Hybrid\\n\\nMedical\\n#LI-PFE   \n",
       "218                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Company Description\\n\\nAbout Hitachi Solutions India Pvt Ltd:\\nHitachi Solutions, Ltd., headquartered in Tokyo, Japan, is a core member of Information & Telecommunication Systems Company of Hitachi Group and a recognized leader in delivering proven business and IT strategies and solutions to companies across many industries. The company provides value-driven services throughout the IT life cycle from systems planning to systems integration, operation and maintenance. Hitachi Solutions delivers products and services of superior value to customers worldwide through key subsidiaries in the United States, Europe, China and India. The flagship company in the Hitachi Group's information and communication system solutions business, Hitachi Solutions also offers solutions for social innovation such as smart cities.\\nOur Competitive Edge   \n",
       "463  Company Description\\n\\nAbout Hitachi Solutions India Pvt Ltd:\\n\\nHitachi Solutions, Ltd., headquartered in Tokyo, Japan, is a core member of Information & Telecommunication Systems Company of Hitachi Group and a recognized leader in delivering proven business and IT strategies and solutions to companies across many industries. The company provides value-driven services throughout the IT life cycle from systems planning to systems integration, operation and maintenance. Hitachi Solutions delivers products and services of superior value to customers worldwide through key subsidiaries in the United States, Europe, China and India. The flagship company in the Hitachi Group's information and communication system solutions business, Hitachi Solutions also offers solutions for social innovation such as smart cities.\\n\\n\\n\\nWe work together in a dynamic and rewarding work environment. We have an experienced leadership team, excellent technology and product expertise, and strong relationships with a broad base of customers and partners.\\n\\nWe offer competitive compensation and benefits package, regular performance review, performance bonuses, and regular trainings.\\n\\n\\n\\nWe pride ourselves on being industry leaders and providing an enjoyable work environment where our people can grow personally and professionally. Hitachi is the place people can develop skills they're excited about. The following are our commitments to employees.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOur recruiting team may communicate with candidates via our @hitachisolutions.com domain email address and/or via our SmartRecruiters (Applicant Tracking System) notification@smartrecruiters.com domain email address regarding your application and interview requests.\\n\\nAll offers will originate from our @hitachisolutions.com domain email address. If you receive an offer or information from someone purporting to be an employee of Hitachi Solutions from any other domain, it may not be legitimate.   \n",
       "696                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Join Udemy. Help define the future of learning.\\nUdemy is an AI-powered reskilling platform built to help people and teams grow. It's personalized, practical, and focused on real-world impact.\\nOur mission is simple: to transform lives through learning. Your work helps people around the world build skills they can use, whether they're picking up something new or leveling up to stay ahead.\\nOver 80 million learners and 17,000 businesses already learn with Udemy. If you're excited by change, energized by learning, and ready to have a real impact, you'll feel right at home.\\nLearn more about us on our company page.\\nHybrid work\\nUdemy is headquartered in San Francisco with global offices in Australia, India, Ireland, Türkiye, and other US locations. Our robust hybrid work model spans San Francisco, Denver, Ankara, Dublin, and Melbourne. This hybrid position requires two days per week in the office at the nearest hub. Learn more about us on our company page.   \n",
       "769                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Job Location: Chennai\\n\\nJob Description 8+ years of experience\\nWe are looking for a Data Scientist lead to analyze large amounts of raw data to find patterns that will help improve our client’s business processes. We will rely on you to build data products to extract valuable business insights.In this role, you should be highly analytical with a flair for analysis, math/statistics and AIML.Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research. Your goal will be to help our clients analyze trends to make better decisions and develop new data products to serve our clients better.\\nRoles and responsibilities :   \n",
       "791                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Title: Senior Data Scientist\\nYears of Experience: 8+ years\\n*Location: The selected candidate is required to work onsite at our Chennai/Kovilpatti location for the initial Three-month project training and execution period. After the Three months, the candidate will be offered remote opportunities.*\\nThe Senior Data Scientist will lead the development and implementation of advanced analytics and\\nAI/ML models to solve complex business problems. This role requires deep statistical expertise,\\nhands-on model building experience, and the ability to translate raw data into strategic insights. The\\ncandidate will collaborate with business stakeholders, data engineers, and AI engineers to deploy\\nproduction-grade models that drive innovation and value.\\nKey responsibilities   \n",
       "\n",
       "      Salary_Range  Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "135   ₹3L – ₹8L/yr  ₹5L/yr Median  Glassdoor Est.           300000 – 800000   \n",
       "139   ₹5L – ₹7L/yr  ₹6L/yr Median  Glassdoor Est.           500000 – 700000   \n",
       "218   ₹6L – ₹9L/yr  ₹7L/yr Median  Glassdoor Est.           600000 – 900000   \n",
       "463   ₹5L – ₹8L/yr  ₹6L/yr Median  Glassdoor Est.           500000 – 800000   \n",
       "696   ₹2L – ₹7L/yr  ₹3L/yr Median  Glassdoor Est.           200000 – 700000   \n",
       "769  ₹7L – ₹10L/yr  ₹8L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "791  ₹7L – ₹10L/yr  ₹8L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "135                     500000  \n",
       "139                     600000  \n",
       "218                     700000  \n",
       "463                     600000  \n",
       "696                     300000  \n",
       "769                     800000  \n",
       "791                     800000  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].notna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('Chennai', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c04dd-132a-4016-8c74-1599558f41e5",
   "metadata": {},
   "source": [
    "- We don't have much details about row 535 except the role looks like a regular ML role and the company EY is one of the big 4 firms, just because its a well known company that doesn't mean the pay will be higher, lets fill the missing value with 6,00,000 (avg sal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f49bb68f-43b1-4602-9251-53c7a44caa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[535, 'Median_Salary_Standardized'] = 600000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364cadef-25b1-4779-bda5-faff76207a29",
   "metadata": {},
   "source": [
    "### Imputing missing values of jobs located in 'Gurgaon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "7ae5d95f-215f-486c-90d2-26255c070a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Nagarro</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Staff Engineer, Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Company Description\\n\\nWe're Nagarro. We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale — across all devices and digital mediums, and our people exist everywhere in the world (18,000+ experts across 33 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in!\\n\\nJob Description\\n\\nBy this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Were you given the tools to go beyond solving for X? Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>Imaging IQ</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Senior Data Scientist (Deep Learning and Artificial Intelligence)\\nJob Description\\nWe aim to bring about a new paradigm in medical image diagnostics; providing intelligent, holistic, ethical, explainable and patient centric care. We are looking for innovative problem solvers who love solving problems. We want people who can empathize with the consumer, understand business problems, and design and deliver intelligent products. People who are looking to extend artificial intelligence into unexplored areas. Your primary focus will be in applying deep learning and artificial intelligence techniques to the domain of medical image analysis.\\nResponsibilities\\nSelecting features, building and optimizing classifier engines using deep learning techniques.\\nUnderstanding the problem and applying the suitable image processing techniques\\nUse techniques from artificial intelligence/deep learning to solve supervised and unsupervised learning problems.\\nUnderstanding and designing solutions for complex problems related to medical image analysis by using Deep Learning/Object Detection/Image Segmentation.\\nRecommend and implement best practices around the application of statistical modeling.\\nCreate, train, test, and deploy various neural networks to solve complex problems.\\nDevelop and implement solutions to fit business problems which may include applying algorithms from a standard statistical tool, deep learning or custom algorithm development.\\nUnderstanding the requirements and designing solutions and architecture in accordance with them is important.\\nParticipate in code reviews, sprint planning, and Agile ceremonies to drive high-quality deliverables.\\nDesign and implement scalable data science architectures for training, inference, and deployment pipelines.\\nEnsure code quality, readability, and maintainability by enforcing software engineering best practices within the data science team.\\nOptimize models for production, including quantization, pruning, and latency reduction for real-time inference.\\nDrive the adoption of versioing strategies for models, datasets, and experiments (e.g., using MLFlow, DVC).\\nContribute to the architectural design of data platforms to support large-scale experimentation and production workloads.\\nSkills and Qualifications\\nStrong software engineering skills in Python (or other languages used in data science) with emphasis on clean code, modularity, and testability.\\nExcellent understanding and hands-on of Deep Learning techniques such as ANN, CNN, RNN, LSTM, Transformers, VAEs etc.\\nMust have experience with Tensorflow or PyTorch framework in building, training, testing, and deploying neural networks.\\nExperience in solving problems in the domain of Computer Vision.\\nKnowledge of data, data augmentation, data curation, and synthetic data generation.\\nAbility to understand the complete problem and design the solutions that best fit all the constraints.\\nKnowledge of the common data science and deep learning libraries and toolkits such as Keras, Pandas, Scikit-learn, Numpy, Scipy, OpenCV etc.\\nGood applied statistical skills, such as distributions, statistical testing, regression, etc.\\nExposure to Agile/Scrum methodologies and collaborative development practices.\\nExperience with the development of RESTful APIs.\\nThe knowledge of libraries like FastAPI and the ability to apply it to deep learning architectures is essential.\\nExcellent analytical and problem-solving skills with a good attitude and keen to adapt to evolving technologies.\\nExperience with medical image analysis will be an advantage.\\nExperience designing and building ML architecture components (e.g., feature stores, model registries, inference servers).\\nSolid understanding of software design patterns, microservices, and cloud-native architectures.\\nExpertise in model optimization techniques (e.g., ONNX conversion, TensorRT, model distillation)\\nEducation: BE/B Tech MS/M Tech (will be a bonus)\\nExperience: 3+ Years\\nJob Type: Full-time\\nAbility to commute/relocate:\\nGurugram, Haryana: Reliably commute or planning to relocate before starting work (Required)\\nApplication Question(s):\\nDo you have experience leading teams in AI Development?\\nDo you have experience creating software architecture for production environment in AI applications?\\nExperience:\\nDeep learning: 3 years (Required)\\nComputer vision: 3 years (Required)\\nPyTorch: 3 years (Required)\\nWork Location: In person</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Mastercard</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Our Purpose\\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we’re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\\nTitle and Summary\\nSenior Data Scientist\\nWe are the global technology company behind the world’s fastest payments processing network. We are a vehicle for commerce, a connection to financial systems for the previously excluded, a technology innovation lab, and the home of Priceless®. We ensure every employee has the opportunity to be a part of something bigger and to change lives. We believe as our company grows, so should you. We believe in connecting everyone to endless, priceless possibilities.\\n\\nThe Mastercard Launch program is aimed at early career talent, to help you develop skills and gain cross-functional work experience. Over a period of 18 months, Launch participants will be assigned to a business unit, learn and develop skills, and gain valuable on the job experience.\\n\\nMastercard has over 2 billion payment cards issued by 25,000+ banks across 190+ countries and territories, amassing over 10 petabytes of data. Millions of transactions are flowing to Mastercard in real-time providing an ideal environment to apply and leverage AI at scale. The AI team is responsible for building and deploying innovative AI solutions for all divisions within Mastercard securing a competitive advantage. Our objectives include achieving operational efficiency, improving customer experience, and ensuring robust value propositions of our core products (Credit, Debit, Prepaid) and services (recommendation engine, anti-money laundering, fraud risk management, cybersecurity)\\n\\nRole:\\n\\nAll About You:\\n:• Demonstrated passion for AI competing in sponsored challenges such as Kaggle\\n• •Big Data platforms such as Hadoop, Hive, Spark, GPU Clusters for deep learning\\n•Hierarchical and Self-organizing Maps), TSNE, PCA, Bayesian models, Time Series ARIMA/ARMA, •Recommender Systems - Collaborative Filtering, FPMC, FISM, Fossil\\n•Deep Learning algorithm techniques like Random Forest, GBM, KNN, SVM, Bayesian, Text Mining techniques, Multilayer Perceptron, Neural Networks – Feedforward, CNN, LSTM’s GRU’s is a plus. •Optimization techniques – Activity regularization (L1 and L2), Adam, Adagrad, Adadelta concepts; Cost •Functions in Neural Nets – Contrastive Loss, Hinge Loss, Binary Cross entropy, Categorical Cross entropy; developed applications in KRR, NLP, Speech and Image processing</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>EPAM Systems, Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.\\nWe are seeking a Senior Data Scientist to join our team and drive innovation by leveraging your expertise in statistical data analysis, machine learning, and NLP to create and deliver impactful AI solutions.\\nAs a Senior Data Scientist, you will work on challenging projects that require end-to-end involvement, from data preparation to model deployment, all while working collaboratively with cross-functional teams and delivering production-ready solutions.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  Company_Rating  \\\n",
       "33   Boston Consulting Group             4.2   \n",
       "700                  Nagarro             3.9   \n",
       "820               Imaging IQ             3.9   \n",
       "401               Mastercard             4.2   \n",
       "438       EPAM Systems, Inc.             4.0   \n",
       "\n",
       "                                           Job_Title Location  \\\n",
       "33   AI Engineer / Senior AI Engineer, India - BCG X  Gurgaon   \n",
       "700                 Staff Engineer, Machine Learning  Gurgaon   \n",
       "820                            Senior Data Scientist  Gurgaon   \n",
       "401                            Senior Data Scientist  Gurgaon   \n",
       "438                            Senior Data Scientist  Gurgaon   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description  \\\n",
       "33                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "700                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Company Description\\n\\nWe're Nagarro. We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale — across all devices and digital mediums, and our people exist everywhere in the world (18,000+ experts across 33 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in!\\n\\nJob Description\\n\\nBy this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Were you given the tools to go beyond solving for X? Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us.   \n",
       "820  Senior Data Scientist (Deep Learning and Artificial Intelligence)\\nJob Description\\nWe aim to bring about a new paradigm in medical image diagnostics; providing intelligent, holistic, ethical, explainable and patient centric care. We are looking for innovative problem solvers who love solving problems. We want people who can empathize with the consumer, understand business problems, and design and deliver intelligent products. People who are looking to extend artificial intelligence into unexplored areas. Your primary focus will be in applying deep learning and artificial intelligence techniques to the domain of medical image analysis.\\nResponsibilities\\nSelecting features, building and optimizing classifier engines using deep learning techniques.\\nUnderstanding the problem and applying the suitable image processing techniques\\nUse techniques from artificial intelligence/deep learning to solve supervised and unsupervised learning problems.\\nUnderstanding and designing solutions for complex problems related to medical image analysis by using Deep Learning/Object Detection/Image Segmentation.\\nRecommend and implement best practices around the application of statistical modeling.\\nCreate, train, test, and deploy various neural networks to solve complex problems.\\nDevelop and implement solutions to fit business problems which may include applying algorithms from a standard statistical tool, deep learning or custom algorithm development.\\nUnderstanding the requirements and designing solutions and architecture in accordance with them is important.\\nParticipate in code reviews, sprint planning, and Agile ceremonies to drive high-quality deliverables.\\nDesign and implement scalable data science architectures for training, inference, and deployment pipelines.\\nEnsure code quality, readability, and maintainability by enforcing software engineering best practices within the data science team.\\nOptimize models for production, including quantization, pruning, and latency reduction for real-time inference.\\nDrive the adoption of versioing strategies for models, datasets, and experiments (e.g., using MLFlow, DVC).\\nContribute to the architectural design of data platforms to support large-scale experimentation and production workloads.\\nSkills and Qualifications\\nStrong software engineering skills in Python (or other languages used in data science) with emphasis on clean code, modularity, and testability.\\nExcellent understanding and hands-on of Deep Learning techniques such as ANN, CNN, RNN, LSTM, Transformers, VAEs etc.\\nMust have experience with Tensorflow or PyTorch framework in building, training, testing, and deploying neural networks.\\nExperience in solving problems in the domain of Computer Vision.\\nKnowledge of data, data augmentation, data curation, and synthetic data generation.\\nAbility to understand the complete problem and design the solutions that best fit all the constraints.\\nKnowledge of the common data science and deep learning libraries and toolkits such as Keras, Pandas, Scikit-learn, Numpy, Scipy, OpenCV etc.\\nGood applied statistical skills, such as distributions, statistical testing, regression, etc.\\nExposure to Agile/Scrum methodologies and collaborative development practices.\\nExperience with the development of RESTful APIs.\\nThe knowledge of libraries like FastAPI and the ability to apply it to deep learning architectures is essential.\\nExcellent analytical and problem-solving skills with a good attitude and keen to adapt to evolving technologies.\\nExperience with medical image analysis will be an advantage.\\nExperience designing and building ML architecture components (e.g., feature stores, model registries, inference servers).\\nSolid understanding of software design patterns, microservices, and cloud-native architectures.\\nExpertise in model optimization techniques (e.g., ONNX conversion, TensorRT, model distillation)\\nEducation: BE/B Tech MS/M Tech (will be a bonus)\\nExperience: 3+ Years\\nJob Type: Full-time\\nAbility to commute/relocate:\\nGurugram, Haryana: Reliably commute or planning to relocate before starting work (Required)\\nApplication Question(s):\\nDo you have experience leading teams in AI Development?\\nDo you have experience creating software architecture for production environment in AI applications?\\nExperience:\\nDeep learning: 3 years (Required)\\nComputer vision: 3 years (Required)\\nPyTorch: 3 years (Required)\\nWork Location: In person   \n",
       "401                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Our Purpose\\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we’re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\\nTitle and Summary\\nSenior Data Scientist\\nWe are the global technology company behind the world’s fastest payments processing network. We are a vehicle for commerce, a connection to financial systems for the previously excluded, a technology innovation lab, and the home of Priceless®. We ensure every employee has the opportunity to be a part of something bigger and to change lives. We believe as our company grows, so should you. We believe in connecting everyone to endless, priceless possibilities.\\n\\nThe Mastercard Launch program is aimed at early career talent, to help you develop skills and gain cross-functional work experience. Over a period of 18 months, Launch participants will be assigned to a business unit, learn and develop skills, and gain valuable on the job experience.\\n\\nMastercard has over 2 billion payment cards issued by 25,000+ banks across 190+ countries and territories, amassing over 10 petabytes of data. Millions of transactions are flowing to Mastercard in real-time providing an ideal environment to apply and leverage AI at scale. The AI team is responsible for building and deploying innovative AI solutions for all divisions within Mastercard securing a competitive advantage. Our objectives include achieving operational efficiency, improving customer experience, and ensuring robust value propositions of our core products (Credit, Debit, Prepaid) and services (recommendation engine, anti-money laundering, fraud risk management, cybersecurity)\\n\\nRole:\\n\\nAll About You:\\n:• Demonstrated passion for AI competing in sponsored challenges such as Kaggle\\n• •Big Data platforms such as Hadoop, Hive, Spark, GPU Clusters for deep learning\\n•Hierarchical and Self-organizing Maps), TSNE, PCA, Bayesian models, Time Series ARIMA/ARMA, •Recommender Systems - Collaborative Filtering, FPMC, FISM, Fossil\\n•Deep Learning algorithm techniques like Random Forest, GBM, KNN, SVM, Bayesian, Text Mining techniques, Multilayer Perceptron, Neural Networks – Feedforward, CNN, LSTM’s GRU’s is a plus. •Optimization techniques – Activity regularization (L1 and L2), Adam, Adagrad, Adadelta concepts; Cost •Functions in Neural Nets – Contrastive Loss, Hinge Loss, Binary Cross entropy, Categorical Cross entropy; developed applications in KRR, NLP, Speech and Image processing   \n",
       "438                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.\\nWe are seeking a Senior Data Scientist to join our team and drive innovation by leveraging your expertise in statistical data analysis, machine learning, and NLP to create and deliver impactful AI solutions.\\nAs a Senior Data Scientist, you will work on challenging projects that require end-to-end involvement, from data preparation to model deployment, all while working collaboratively with cross-functional teams and delivering production-ready solutions.   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "33          None           NaN          None                      None   \n",
       "700         None           NaN          None                      None   \n",
       "820         None           NaN          None                      None   \n",
       "401         None           NaN          None                      None   \n",
       "438         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "33                         NaN  \n",
       "700                        NaN  \n",
       "820                        NaN  \n",
       "401                        NaN  \n",
       "438                        NaN  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[33, 700, 820, 401, 438]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "9362bc1e-8954-4e3d-a184-75ad55463f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist - AIML</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nApply advanced statistical techniques, data science methodologies, and AI practices, including generative AI using GPT models\\nDesign, develop, and implement cutting-edge generative AI models and systems</td>\n",
       "      <td>₹2L – ₹9L/yr</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>200000 – 900000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Global Cybersecurity Senior Manager - AI Architect</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>₹6L – ₹8L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>600000 – 800000</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mastercard</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Our Purpose\\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we’re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\\nTitle and Summary\\nSenior Data Scientist\\nJob Title - Senior Data Scientist – Data &amp; Analytics\\n\\nOur Purpose\\nWe work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.\\n\\nWho is Mastercard?\\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships, and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\\n\\nOur Team\\nAs consumer preference for digital payments continues to grow, ensuring a seamless and secure consumer experience is top of mind. Optimization Solutions team focuses on tracking of digital performance across all products and regions, understanding the factors influencing performance and the broader industry landscape. This includes delivering data-driven insights and business recommendations, engaging directly with key external stakeholders on implementing optimization solutions (new and existing), and partnering across the organization to drive alignment and ensure action is taken.\\n\\nThe Role\\nYou will be part of AI Centre of Excellence, in Core Products Mastercard working hands on ML and AI projects.\\nThe candidate, will be the technical lead on solving and identifying Merchant Localization across various global markets. In this role, you will be required to build new ML models to catch merchant localization and scale existing models for recurring inference.\\nYou will be required to work closely in collaboration with multiple internal business groups across Mastercard. You are also responsible for creating design documents, including data models, data flow diagrams, and system architecture diagrams.\\n\\nAll about You\\n\\nAdditional Competencies</td>\n",
       "      <td>₹2L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist / Senior Data Scientist, India - BCG X</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>₹6L – ₹8L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>600000 – 800000</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>OSRAM India Pvt. Limited</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Central Functions support the board as well as the business in achieving its strategic objectives. These are, for example, Information Technology, Human Resources, Logistics, Compliance, Finance and many more.\\nDesign, implement, and optimize machine learning models across various domains (e.g., SCM, Manufacturing, Product Management) following the Cross-Industry Standard Process for Data Mining (CRISP-DM) process.\\nTrain, fine-tune, and optimize deep learning models for diverse applications while handling large-scale datasets for preprocessing and transformation.\\nBuild and maintain robust data pipelines for AI applications, collaborating with data engineers to optimize infrastructure for efficient ML processing and deployment.\\nDeploy, monitor, and optimize machine learning models in production environments, ensuring scalability and performance.</td>\n",
       "      <td>₹2L – ₹10L/yr</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>200000 – 1000000</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Global Audience Analytics Senior Manager</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Maruti Suzuki India Ltd</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Sr. Data Scientist 2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Ability to design and implement workflows of Linear and Logistic Regression, Ensemble Models (Random Forest, Boosting) using R/Python\\nDemonstrable competency in Probability and Statistics, ability to use ideas of Data Distributions, Hypothesis Testing and other Statistical Tests.\\nMust have experience in dealing with outliers, denoising data and handling the impact of pandemic like situations.\\nShould be able to perform EDA of raw data &amp; feature engineering wherever applicable\\nDemonstrable competency in Data Visualisation using the Python/R Data Science Stack.\\nShould be able to leverage cloud platforms for training and deploying large scale solutions.\\nShould be able to train and evaluate ML model using various machine learning and deep learning algorithm.</td>\n",
       "      <td>₹3L – ₹10L/yr</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>300000 – 1000000</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>DIATOZ Solutions</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>We’re looking for an experienced and strategic Senior Data Scientist who can drive high-impact business outcomes by deploying advanced real-time statistical and AI models. This role requires full ownership of projects—from business requirement gathering to production deployment—while working cross-functionally with teams such as marketing, sales, and service.\\nExperience: 7-9 yrs , Hybrid\\nJob Type: Contractual (min 6 months)\\nJoining: Immediate joiners\\nKey Responsibilities:\\nOwn end-to-end development and deployment of statistical and AI models.\\nCollaborate with business teams to gather requirements and deliver data-driven solutions.</td>\n",
       "      <td>₹1L – ₹2L/mo</td>\n",
       "      <td>₹1L/mo Median</td>\n",
       "      <td>Employer provided</td>\n",
       "      <td>1200000 – 2400000</td>\n",
       "      <td>1200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Zinnia</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Senior Data Scientist (5+ Years)</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>WHO WE ARE:\\nZinnia is the leading technology platform for accelerating life and annuities growth. With innovative enterprise solutions and data insights, Zinnia simplifies the experience of buying, selling, and administering insurance products. All of which enables more people to protect their financial futures. Our success is driven by a commitment to three core values: be bold, team up, deliver value – and that we do. Zinnia has over $180 billion in assets under administration, serves 100+ carrier clients, 2500 distributors and partners, and over 2 million policyholders.\\nWHO YOU ARE:\\nWe are seeking a highly motivated Senior Data Scientist with strong technical expertise, business acumen, and strategic problem-solving abilities. In this role, you will independently own and build forecasting models. You will work closely with stakeholders across Product, Data Engineering &amp; Analytics, and Business Strategy to identify opportunities to resolve business problems. This is a</td>\n",
       "      <td>₹6L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>600000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company_Name  Company_Rating  \\\n",
       "1                       Optum             3.5   \n",
       "6     Boston Consulting Group             4.2   \n",
       "46                 Mastercard             4.2   \n",
       "271   Boston Consulting Group             4.2   \n",
       "330  OSRAM India Pvt. Limited             3.7   \n",
       "392   Boston Consulting Group             4.2   \n",
       "529   Maruti Suzuki India Ltd             3.8   \n",
       "775          DIATOZ Solutions             3.9   \n",
       "817                    Zinnia             3.6   \n",
       "\n",
       "                                                 Job_Title Location  \\\n",
       "1                             Senior Data Scientist - AIML  Gurgaon   \n",
       "6       Global Cybersecurity Senior Manager - AI Architect  Gurgaon   \n",
       "46                                   Senior Data Scientist  Gurgaon   \n",
       "271  Data Scientist / Senior Data Scientist, India - BCG X  Gurgaon   \n",
       "330                                  Senior Data Scientist  Gurgaon   \n",
       "392               Global Audience Analytics Senior Manager  Gurgaon   \n",
       "529                                   Sr. Data Scientist 2  Gurgaon   \n",
       "775                                  Senior Data Scientist  Gurgaon   \n",
       "817                       Senior Data Scientist (5+ Years)  Gurgaon   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Description  \\\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nApply advanced statistical techniques, data science methodologies, and AI practices, including generative AI using GPT models\\nDesign, develop, and implement cutting-edge generative AI models and systems   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "46                                                                                                                                                                                                                             Our Purpose\\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we’re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\\nTitle and Summary\\nSenior Data Scientist\\nJob Title - Senior Data Scientist – Data & Analytics\\n\\nOur Purpose\\nWe work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.\\n\\nWho is Mastercard?\\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships, and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\\n\\nOur Team\\nAs consumer preference for digital payments continues to grow, ensuring a seamless and secure consumer experience is top of mind. Optimization Solutions team focuses on tracking of digital performance across all products and regions, understanding the factors influencing performance and the broader industry landscape. This includes delivering data-driven insights and business recommendations, engaging directly with key external stakeholders on implementing optimization solutions (new and existing), and partnering across the organization to drive alignment and ensure action is taken.\\n\\nThe Role\\nYou will be part of AI Centre of Excellence, in Core Products Mastercard working hands on ML and AI projects.\\nThe candidate, will be the technical lead on solving and identifying Merchant Localization across various global markets. In this role, you will be required to build new ML models to catch merchant localization and scale existing models for recurring inference.\\nYou will be required to work closely in collaboration with multiple internal business groups across Mastercard. You are also responsible for creating design documents, including data models, data flow diagrams, and system architecture diagrams.\\n\\nAll about You\\n\\nAdditional Competencies   \n",
       "271  Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "330                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Central Functions support the board as well as the business in achieving its strategic objectives. These are, for example, Information Technology, Human Resources, Logistics, Compliance, Finance and many more.\\nDesign, implement, and optimize machine learning models across various domains (e.g., SCM, Manufacturing, Product Management) following the Cross-Industry Standard Process for Data Mining (CRISP-DM) process.\\nTrain, fine-tune, and optimize deep learning models for diverse applications while handling large-scale datasets for preprocessing and transformation.\\nBuild and maintain robust data pipelines for AI applications, collaborating with data engineers to optimize infrastructure for efficient ML processing and deployment.\\nDeploy, monitor, and optimize machine learning models in production environments, ensuring scalability and performance.   \n",
       "392                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "529                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Ability to design and implement workflows of Linear and Logistic Regression, Ensemble Models (Random Forest, Boosting) using R/Python\\nDemonstrable competency in Probability and Statistics, ability to use ideas of Data Distributions, Hypothesis Testing and other Statistical Tests.\\nMust have experience in dealing with outliers, denoising data and handling the impact of pandemic like situations.\\nShould be able to perform EDA of raw data & feature engineering wherever applicable\\nDemonstrable competency in Data Visualisation using the Python/R Data Science Stack.\\nShould be able to leverage cloud platforms for training and deploying large scale solutions.\\nShould be able to train and evaluate ML model using various machine learning and deep learning algorithm.   \n",
       "775                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             We’re looking for an experienced and strategic Senior Data Scientist who can drive high-impact business outcomes by deploying advanced real-time statistical and AI models. This role requires full ownership of projects—from business requirement gathering to production deployment—while working cross-functionally with teams such as marketing, sales, and service.\\nExperience: 7-9 yrs , Hybrid\\nJob Type: Contractual (min 6 months)\\nJoining: Immediate joiners\\nKey Responsibilities:\\nOwn end-to-end development and deployment of statistical and AI models.\\nCollaborate with business teams to gather requirements and deliver data-driven solutions.   \n",
       "817                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      WHO WE ARE:\\nZinnia is the leading technology platform for accelerating life and annuities growth. With innovative enterprise solutions and data insights, Zinnia simplifies the experience of buying, selling, and administering insurance products. All of which enables more people to protect their financial futures. Our success is driven by a commitment to three core values: be bold, team up, deliver value – and that we do. Zinnia has over $180 billion in assets under administration, serves 100+ carrier clients, 2500 distributors and partners, and over 2 million policyholders.\\nWHO YOU ARE:\\nWe are seeking a highly motivated Senior Data Scientist with strong technical expertise, business acumen, and strategic problem-solving abilities. In this role, you will independently own and build forecasting models. You will work closely with stakeholders across Product, Data Engineering & Analytics, and Business Strategy to identify opportunities to resolve business problems. This is a   \n",
       "\n",
       "      Salary_Range  Median_Salary      Salary_Source  \\\n",
       "1     ₹2L – ₹9L/yr  ₹4L/yr Median     Glassdoor Est.   \n",
       "6     ₹6L – ₹8L/yr  ₹7L/yr Median     Glassdoor Est.   \n",
       "46          ₹2L/yr            NaN     Glassdoor Est.   \n",
       "271   ₹6L – ₹8L/yr  ₹7L/yr Median     Glassdoor Est.   \n",
       "330  ₹2L – ₹10L/yr  ₹5L/yr Median     Glassdoor Est.   \n",
       "392  ₹7L – ₹10L/yr  ₹8L/yr Median     Glassdoor Est.   \n",
       "529  ₹3L – ₹10L/yr  ₹6L/yr Median     Glassdoor Est.   \n",
       "775   ₹1L – ₹2L/mo  ₹1L/mo Median  Employer provided   \n",
       "817  ₹6L – ₹10L/yr  ₹8L/yr Median     Glassdoor Est.   \n",
       "\n",
       "    Salary_Range_Standardized Median_Salary_Standardized  \n",
       "1             200000 – 900000                     400000  \n",
       "6             600000 – 800000                     700000  \n",
       "46                     200000                   200000.0  \n",
       "271           600000 – 800000                     700000  \n",
       "330          200000 – 1000000                     500000  \n",
       "392          700000 – 1000000                     800000  \n",
       "529          300000 – 1000000                     600000  \n",
       "775         1200000 – 2400000                    1200000  \n",
       "817          600000 – 1000000                     800000  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].notna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('Gurgaon', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230446b4-c28b-43fb-8219-c946730d3e35",
   "metadata": {},
   "source": [
    "- Row 33's company name is boston consulting group and we can use the salary 700000 from row 271 which is again the same company to fill the missing value in row 33.\n",
    "- Row 401 and 46 are replicas of each other, we can remove row 401.\n",
    "- From analyzing row 438 we found that the role involves statistical data analysis, machine learning, and NLP and end to end projects from data collection to model deployment. This is a typical data science role with typical skill sets, a logical thinking would involve to fill the missing value with the avg salary of a senior level role i.e 6,00,000.\n",
    "- To fill row 700 which is again a typical ML role and since the company is globally located its better to assume that the pay is a higher than average, lets impute the salary with 9,00,000.\n",
    "- Row 820 involves a variety of data science skills such as Deep Learning/Object Detection/Image Segmentation/MLOps (DVC/MLFlow)/Tensor flow/ pytorch, the domain of the role is medical, location is hybrid and the role seems to be advanced which is suitable for a highly experience candidate, we shall impute the salary with a value of 15,00,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "6b81326a-b7aa-4e08-80c1-43e46cc44b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('Gurgaon', regex=False, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ba410b56-2069-4ff8-b622-87d2e185cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[33, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.drop(401, axis=0, inplace=True)\n",
    "\n",
    "df_copy.loc[438, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[700, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[820, 'Median_Salary_Standardized'] = 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "263647d0-f31d-4167-8b01-e9dc1930d557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('Gurgaon', regex=False, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71548c-fe69-41e2-9e7a-27b8389bf490",
   "metadata": {},
   "source": [
    "### Imputing missing values of jobs located in 'Hyderābād'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "884dca37-8671-47ea-9a9f-612fdd784198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Novartis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Senior Principal Data Scientist, CADD</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Summary\\nJoin our dynamic and innovative global Computer-Aided Drug Discovery (CADD) group, now expanding to India! Be a part of our Hyderabad team, where we unite diverse talents to revolutionize the validation and development of new targets in Biomedical Research. As a driving force behind drug discovery, we are excited to find an exceptional computational scientist like you to join our global ranks.\\nImagine the opportunity to unlock hidden knowledge and disruptive insights from the vast and invaluable data collected by one of the world's most renowned pharmaceutical companies. We need your expertise, experience, and unwavering passion to help us extract this wealth of information. Collaborating with a multidisciplinary group of scientists, you will be at the forefront of crafting inventive solutions to the most pressing drug discovery challenges, forging new paths toward groundbreaking medicines.\\nAre you ready to seize this extraordinary chance to make a significant impact in the field of drug discovery? We invite you to embark on this thrilling journey with us, as we push the boundaries of what's possible in scientific exploration. Join our team and be part of a revolution that will shape the future of medicine.\\nTogether, we will transform the landscape of drug discovery, accelerate breakthroughs, and change lives. Apply now and let your expertise shine in our dynamic and forward-thinking environment.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Entain India</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Company Description\\n\\nEntain India is the engineering and delivery powerhouse for Entain, one of the world’s leading global sports and gaming groups. Established in Hyderabad in 2001, we’ve grown from a small tech hub into a dynamic force, delivering cutting-edge software solutions and support services that power billions of transactions for millions of users worldwide.\\nOur focus on quality at scale drives us to create innovative technology that supports Entain’s mission to lead the change in global sports and gaming sector. At Entain India, we make the impossible possible, together.\\n\\nJob Description\\n\\nAs our Senior Data Scientist you will be building high quality (normally deployed to a production environment) systems that align with our strategic goals, and are fully integrated with our products and processes. You will work with stakeholders around the globe to scope our solutions, help them understand, test and adopt our solutions.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company_Name  Company_Rating                              Job_Title  \\\n",
       "653      Novartis             4.0  Senior Principal Data Scientist, CADD   \n",
       "829  Entain India             3.7                  Senior Data Scientist   \n",
       "\n",
       "      Location  \\\n",
       "653  Hyderābād   \n",
       "829  Hyderābād   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Description  \\\n",
       "653  Summary\\nJoin our dynamic and innovative global Computer-Aided Drug Discovery (CADD) group, now expanding to India! Be a part of our Hyderabad team, where we unite diverse talents to revolutionize the validation and development of new targets in Biomedical Research. As a driving force behind drug discovery, we are excited to find an exceptional computational scientist like you to join our global ranks.\\nImagine the opportunity to unlock hidden knowledge and disruptive insights from the vast and invaluable data collected by one of the world's most renowned pharmaceutical companies. We need your expertise, experience, and unwavering passion to help us extract this wealth of information. Collaborating with a multidisciplinary group of scientists, you will be at the forefront of crafting inventive solutions to the most pressing drug discovery challenges, forging new paths toward groundbreaking medicines.\\nAre you ready to seize this extraordinary chance to make a significant impact in the field of drug discovery? We invite you to embark on this thrilling journey with us, as we push the boundaries of what's possible in scientific exploration. Join our team and be part of a revolution that will shape the future of medicine.\\nTogether, we will transform the landscape of drug discovery, accelerate breakthroughs, and change lives. Apply now and let your expertise shine in our dynamic and forward-thinking environment.   \n",
       "829                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Company Description\\n\\nEntain India is the engineering and delivery powerhouse for Entain, one of the world’s leading global sports and gaming groups. Established in Hyderabad in 2001, we’ve grown from a small tech hub into a dynamic force, delivering cutting-edge software solutions and support services that power billions of transactions for millions of users worldwide.\\nOur focus on quality at scale drives us to create innovative technology that supports Entain’s mission to lead the change in global sports and gaming sector. At Entain India, we make the impossible possible, together.\\n\\nJob Description\\n\\nAs our Senior Data Scientist you will be building high quality (normally deployed to a production environment) systems that align with our strategic goals, and are fully integrated with our products and processes. You will work with stakeholders around the globe to scope our solutions, help them understand, test and adopt our solutions.   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "653         None           NaN          None                      None   \n",
       "829         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "653                        NaN  \n",
       "829                        NaN  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) &\n",
    "        df_copy['Location'].str.contains('Hyderābād')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "cba021d4-af9e-4a77-af0d-e5f310bf7719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Novartis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Summary\\nWe are seeking a talented and motivated Data Scientist to join our dynamic team. The ideal candidate will possess strong technical skills in machine learning, natural language processing (NLP), generative AI, graph neural networks, and topic modeling. You will also be adept at designing experiments to validate hypotheses and drive decision-making.\\nAbout the Role\\nKey Responsibilities:\\nDevelop and deploy scalable machine learning models to address business challenges.\\nUtilize NLP techniques to extract insights from unstructured text data.\\nImplement graph neural networks to analyze relational data and uncover complex patterns.</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Novartis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist - Real World Data - Data42</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Summary\\nAre you passionate about the intersection of data, technology and science, and excited by the potential of Real-World Data (RWD) and AI? Do you thrive in collaborative environments and aspire to contribute to the discovery of groundbreaking medical insights? If so, join the data42 team at Novartis!\\nAt Novartis, we reimagine medicine by leveraging state-of-the-art analytics and our extensive internal and external data resources. Our data42 platform grants access to high-quality, multi-modal preclinical and clinical data, along with RWD, creating the optimal environment for developing advanced AI/ML models and generating health insights. Our global team of data scientists and engineers utilizes this platform to uncover novel insights and guide drug development decisions.\\nAs an RWD SME / RWE Execution Data Scientist, you will focus on executing innovative methodologies and AI models to mine RWD on the data42 platform. You will be the go-to authority for leveraging diverse RWD modalities patterns crucial to understanding patient populations, biomarkers, and drug targets, accelerating the development of life-changing medicines.</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Novartis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Senior Principal Data Scientist, CADD</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Summary\\nJoin our dynamic and innovative global Computer-Aided Drug Discovery (CADD) group, now expanding to India! Be a part of our Hyderabad team, where we unite diverse talents to revolutionize the validation and development of new targets in Biomedical Research. As a driving force behind drug discovery, we are excited to find an exceptional computational scientist like you to join our global ranks.\\nImagine the opportunity to unlock hidden knowledge and disruptive insights from the vast and invaluable data collected by one of the world's most renowned pharmaceutical companies. We need your expertise, experience, and unwavering passion to help us extract this wealth of information. Collaborating with a multidisciplinary group of scientists, you will be at the forefront of crafting inventive solutions to the most pressing drug discovery challenges, forging new paths toward groundbreaking medicines.\\nAre you ready to seize this extraordinary chance to make a significant impact in the field of drug discovery? We invite you to embark on this thrilling journey with us, as we push the boundaries of what's possible in scientific exploration. Join our team and be part of a revolution that will shape the future of medicine.\\nTogether, we will transform the landscape of drug discovery, accelerate breakthroughs, and change lives. Apply now and let your expertise shine in our dynamic and forward-thinking environment.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name  Company_Rating                                  Job_Title  \\\n",
       "431     Novartis             4.0                             Data Scientist   \n",
       "543     Novartis             4.0  Data Scientist - Real World Data - Data42   \n",
       "653     Novartis             4.0      Senior Principal Data Scientist, CADD   \n",
       "\n",
       "      Location  \\\n",
       "431  Hyderābād   \n",
       "543  Hyderābād   \n",
       "653  Hyderābād   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Description  \\\n",
       "431                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Summary\\nWe are seeking a talented and motivated Data Scientist to join our dynamic team. The ideal candidate will possess strong technical skills in machine learning, natural language processing (NLP), generative AI, graph neural networks, and topic modeling. You will also be adept at designing experiments to validate hypotheses and drive decision-making.\\nAbout the Role\\nKey Responsibilities:\\nDevelop and deploy scalable machine learning models to address business challenges.\\nUtilize NLP techniques to extract insights from unstructured text data.\\nImplement graph neural networks to analyze relational data and uncover complex patterns.   \n",
       "543                                                                                                                                                                                                                                                                                          Summary\\nAre you passionate about the intersection of data, technology and science, and excited by the potential of Real-World Data (RWD) and AI? Do you thrive in collaborative environments and aspire to contribute to the discovery of groundbreaking medical insights? If so, join the data42 team at Novartis!\\nAt Novartis, we reimagine medicine by leveraging state-of-the-art analytics and our extensive internal and external data resources. Our data42 platform grants access to high-quality, multi-modal preclinical and clinical data, along with RWD, creating the optimal environment for developing advanced AI/ML models and generating health insights. Our global team of data scientists and engineers utilizes this platform to uncover novel insights and guide drug development decisions.\\nAs an RWD SME / RWE Execution Data Scientist, you will focus on executing innovative methodologies and AI models to mine RWD on the data42 platform. You will be the go-to authority for leveraging diverse RWD modalities patterns crucial to understanding patient populations, biomarkers, and drug targets, accelerating the development of life-changing medicines.   \n",
       "653  Summary\\nJoin our dynamic and innovative global Computer-Aided Drug Discovery (CADD) group, now expanding to India! Be a part of our Hyderabad team, where we unite diverse talents to revolutionize the validation and development of new targets in Biomedical Research. As a driving force behind drug discovery, we are excited to find an exceptional computational scientist like you to join our global ranks.\\nImagine the opportunity to unlock hidden knowledge and disruptive insights from the vast and invaluable data collected by one of the world's most renowned pharmaceutical companies. We need your expertise, experience, and unwavering passion to help us extract this wealth of information. Collaborating with a multidisciplinary group of scientists, you will be at the forefront of crafting inventive solutions to the most pressing drug discovery challenges, forging new paths toward groundbreaking medicines.\\nAre you ready to seize this extraordinary chance to make a significant impact in the field of drug discovery? We invite you to embark on this thrilling journey with us, as we push the boundaries of what's possible in scientific exploration. Join our team and be part of a revolution that will shape the future of medicine.\\nTogether, we will transform the landscape of drug discovery, accelerate breakthroughs, and change lives. Apply now and let your expertise shine in our dynamic and forward-thinking environment.   \n",
       "\n",
       "      Salary_Range  Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "431  ₹7L – ₹10L/yr  ₹8L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "543  ₹7L – ₹10L/yr  ₹8L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "653           None            NaN            None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "431                     800000  \n",
       "543                     800000  \n",
       "653                        NaN  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Novartis', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb8421-7c20-4b34-9cf9-46598ffaa8e0",
   "metadata": {},
   "source": [
    "- We can fill the missing value of row 653 with the values from rows 543 and 431 which are the same job postings with just different roles.\n",
    "- Impute the salary with 8,00,000.\n",
    "\n",
    "- The most common salary provided in 'Hyderābād' is 6,00,000 and we don't have enough information to assume the salary of row 829 therefore we can use 6,00,000 to impute the salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7c99b139-adcf-4041-9c88-63f1b8d00a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[653, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[829, 'Median_Salary_Standardized'] = 600000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86db1c-38c9-488e-8498-49acd68915b3",
   "metadata": {},
   "source": [
    "### Imputing missing values of jobs located in 'India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "487c7aa1-5fe4-48c4-b3a3-b0eaaf188699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Senior Software Developer, Machine Learning</td>\n",
       "      <td>India</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Grid Dynamics</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>6+ years of experience as a Data Scientist\\n3-4 years of very good Python, PySpark development experience\\n1-2 years of software development experience - preferred\\n1-2 years of experience as a data scientist with preference in Time Series\\nExperience of ML Ops / DevOps\\nExposure to ML models such as random forest, XGboost, LightGBM, and some other ensemble modeling algorithms\\n4 years experience on Azure Cloud Platforms (databricks, Azure ML studio, etc)\\nNo Phd’s. BS or MS degree is Software Engineering, Computer Science or Statistics related\\nAbility to learn fast and handle multiple priorities</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Lyric</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>About the Company\\nWhy We Built Lyric: Supply chains are more critical and complex than ever. Every day, large enterprises navigate trillions of possible decisions that could impact the bottom line. Powerful algorithms and AI can address these problems, yet most organizations struggle to leverage supply chain AI at scale. The current SCM technologies are either rigid, limited-scope point solutions or custom solutions built in-house, which demand immense expertise and investment.\\nThat is…until now.\\nEnter Lyric: Lyric is an enterprise AI platform built specifically for supply chains, offering the best of both worlds:\\nOut-of-the-box AI solutions for optimizing networks, allocating inventory, scheduling routes, planning fulfillment capacity, promising orders, propagating demand, building predictions, analyzing scenarios, and more,</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>EY</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist - Senior Manager</td>\n",
       "      <td>India</td>\n",
       "      <td>At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nRole: Senior Manager - Data Scientist\\nDesignation: Senior Manager\\nPreferred Experience: 12+ years\\n\\nKey Responsibilities:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Lingaro Group</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Senior Data Scientist (Generative AI)</td>\n",
       "      <td>India</td>\n",
       "      <td>Growth through diversity, equity, and inclusion. As an ethical business, we do what is right — including ensuring equal opportunities and fostering a safe, respectful workplace for each of us. We believe diversity fuels both personal and business growth. We're committed to building an inclusive community where all our people thrive regardless of their backgrounds, identities, or other personal characteristics.\\n\\nTasks:\\n\\nRunning end-to-end initiatives (Business understanding, Data understanding/preparation, Modeling, Evaluation and Deployment).\\nAnalyzing and interpreting the findings.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>QoreNext</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>About Us\\nQoreNext is a tech startup that is the first of it kind cloud-based platform for the enterprise foundational data content powering Artificial Intelligence and Business Intelligence. Businesses need data to operate, from health to finance. Instead of manually extracting data from across the web, we provide a one-stop service meeting all data needs. QORE is created to be a virtual gigafactory where our clients can experience our integrated library with our seamless ease of integration, always updated and current. We provide our clients with reliable high-quality data with a flexible pricing model where they only pay for what is consumed, resulting in a value subscription that allows future major savings.\\nWith a remote-first, office agnostic approach, the QoreNext team is distributed across North America, APAC and India.\\nWhat's the opportunity?</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Crayon Data</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Senior Data scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Job Description\\nRole: Sr Data Scientist\\n\\nExperience level: 5 to 8 years\\n\\nLocation: Chennai\\n\\nWho are we?\\n\\nCrayon Data is a leading provider of AI-led revenue acceleration solutions, headquartered in Singapore with a local presence in India and the UAE. The company was founded in 2012 with the vision of simplifying the world’s choices. Our flagship platform, maya.ai, helps enterprises across the Banking, Fin-tech, and Travel industries create and capture sustainable revenue streams by unlocking the value of data.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Grid Dynamics</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>8+ years into ML Model implementation, experimentation &amp; related software engineering focused\\nExperience as a data scientist with Demand forecasting algorithms\\nPython, PySpark development experience a must\\n1-2 years of software development experience - preferred\\nExposure to ML models such as random forest, XGboost, LightGBM, and some other ensemble modeling algorithms\\nExperience on Azure Cloud Platforms (\"Databricks, Azure ML studio, etc)\\nAbility to learn fast and handle multiple priorities\\n\\nResponsibilities</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>Censius</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>About Us\\nCensius is a US-based product company that is enabling AI at scale for enterprises. We are unlocking MLOps scalability by building the world's fastest way to deploy models and are amongst the earliest companies to tackle Model Performance Management. At Censius, you will get to solve difficult problems in a very nascent, but rapidly growing, area.\\n\\nAbout the role\\nIn this role, you will design and implement a generic ML platform that helps monitor models across modalities in production. You will collaborate with the research and development teams to build robust ML and big data monitoring platforms.\\n\\n\\n\\nCompetitive Salary</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Helius Technologies</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Our goal is to transform the entire hiring process by making it simple, efficient, and enjoyable for recruiters, hiring managers, and candidates alike\\nOur mission is to offer the best-in-class AI-powered technologies to empower small, medium, and large businesses in their staffing &amp; recruitment transformation.\\nResponsibilities\\nSet, define, and own the data science roadmap\\nBuild, maintain, and enhance Manatal core features focusing on:\\nCV/Resume parsing in multiple languages\\nCandidate recommendation engine\\nCandidate for social media enrichment</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Motorola Solutions</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Company Overview\\nAt Motorola Solutions, we believe that everything starts with our people. We’re a global close-knit community, united by the relentless pursuit to help keep people safer everywhere. Our critical communications, video security and command center technologies support public safety agencies and enterprises alike, enabling the coordination that’s critical for safer communities, safer schools, safer hospitals and safer businesses. Connect with a career that matters, and help us build a safer future.\\n\\nDepartment Overview\\nThe Design &amp; Tools (D&amp;T) team is a strategic component of Centralized Managed Support Operations (CMSO), responsible for providing exceptional Service Design &amp; innovative technology solutions to enable and empower MSI Centralized Managed Support Operations to meet and exceed customer's expectations. In this role, you will fit in the AI &amp; Architecture team within D&amp;T.\\n\\n\\n\\n\\nNone\\n\\nNone\\n\\nExperienced\\nNo</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>Mahindra &amp; Mahindra Ltd</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sr. Data Scientist, AI Division</td>\n",
       "      <td>India</td>\n",
       "      <td>Sr. Data Scientist, AI Division\\nDate: 17 Jul 2025\\nLocation: Mumbai - Worli, Mumbai - Worli, IN\\nCompany: Mahindra &amp; Mahindra Ltd\\nRoles &amp; Responsibilities:\\nDesign and implement scalable, cloud-based data solutions using AWS, Azure, or GCP (mandatory).\\nBuild, optimize, and maintain ETL/ELT pipelines for efficient data processing.\\nManage and design cloud-based data storage systems such as data warehouses and data lakes.\\nEnsure data quality, security, and compliance in cloud environments.\\nImplement real-time and batch data processing frameworks.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  Company_Rating  \\\n",
       "7               Kinaxis Inc.             4.1   \n",
       "418            Grid Dynamics             3.9   \n",
       "478                    Lyric             3.9   \n",
       "522                       EY             3.7   \n",
       "545            Lingaro Group             4.0   \n",
       "548                 QoreNext             3.9   \n",
       "592              Crayon Data             3.7   \n",
       "636            Grid Dynamics             3.9   \n",
       "684                  Censius             4.4   \n",
       "719      Helius Technologies             4.3   \n",
       "797       Motorola Solutions             4.3   \n",
       "827  Mahindra & Mahindra Ltd             4.0   \n",
       "\n",
       "                                       Job_Title Location  \\\n",
       "7    Senior Software Developer, Machine Learning    India   \n",
       "418                        Senior Data Scientist    India   \n",
       "478                        Senior Data Scientist    India   \n",
       "522              Data Scientist - Senior Manager    India   \n",
       "545        Senior Data Scientist (Generative AI)    India   \n",
       "548                        Senior Data Scientist    India   \n",
       "592                        Senior Data scientist    India   \n",
       "636                         Staff Data Scientist    India   \n",
       "684                           Sr. Data Scientist    India   \n",
       "719                        Senior Data Scientist    India   \n",
       "797                        Senior Data Scientist    India   \n",
       "827              Sr. Data Scientist, AI Division    India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Description  \\\n",
       "7                                                                                                      About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:   \n",
       "418                                                                                                                                                                                                                                                                                                                                                              6+ years of experience as a Data Scientist\\n3-4 years of very good Python, PySpark development experience\\n1-2 years of software development experience - preferred\\n1-2 years of experience as a data scientist with preference in Time Series\\nExperience of ML Ops / DevOps\\nExposure to ML models such as random forest, XGboost, LightGBM, and some other ensemble modeling algorithms\\n4 years experience on Azure Cloud Platforms (databricks, Azure ML studio, etc)\\nNo Phd’s. BS or MS degree is Software Engineering, Computer Science or Statistics related\\nAbility to learn fast and handle multiple priorities   \n",
       "478                                                                                                                 About the Company\\nWhy We Built Lyric: Supply chains are more critical and complex than ever. Every day, large enterprises navigate trillions of possible decisions that could impact the bottom line. Powerful algorithms and AI can address these problems, yet most organizations struggle to leverage supply chain AI at scale. The current SCM technologies are either rigid, limited-scope point solutions or custom solutions built in-house, which demand immense expertise and investment.\\nThat is…until now.\\nEnter Lyric: Lyric is an enterprise AI platform built specifically for supply chains, offering the best of both worlds:\\nOut-of-the-box AI solutions for optimizing networks, allocating inventory, scheduling routes, planning fulfillment capacity, promising orders, propagating demand, building predictions, analyzing scenarios, and more,   \n",
       "522                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nRole: Senior Manager - Data Scientist\\nDesignation: Senior Manager\\nPreferred Experience: 12+ years\\n\\nKey Responsibilities:   \n",
       "545                                                                                                                                                                                                                                                                                                                                                                        Growth through diversity, equity, and inclusion. As an ethical business, we do what is right — including ensuring equal opportunities and fostering a safe, respectful workplace for each of us. We believe diversity fuels both personal and business growth. We're committed to building an inclusive community where all our people thrive regardless of their backgrounds, identities, or other personal characteristics.\\n\\nTasks:\\n\\nRunning end-to-end initiatives (Business understanding, Data understanding/preparation, Modeling, Evaluation and Deployment).\\nAnalyzing and interpreting the findings.   \n",
       "548                                                                                         About Us\\nQoreNext is a tech startup that is the first of it kind cloud-based platform for the enterprise foundational data content powering Artificial Intelligence and Business Intelligence. Businesses need data to operate, from health to finance. Instead of manually extracting data from across the web, we provide a one-stop service meeting all data needs. QORE is created to be a virtual gigafactory where our clients can experience our integrated library with our seamless ease of integration, always updated and current. We provide our clients with reliable high-quality data with a flexible pricing model where they only pay for what is consumed, resulting in a value subscription that allows future major savings.\\nWith a remote-first, office agnostic approach, the QoreNext team is distributed across North America, APAC and India.\\nWhat's the opportunity?   \n",
       "592                                                                                                                                                                                                                                                                                                                                                                                                                                             Job Description\\nRole: Sr Data Scientist\\n\\nExperience level: 5 to 8 years\\n\\nLocation: Chennai\\n\\nWho are we?\\n\\nCrayon Data is a leading provider of AI-led revenue acceleration solutions, headquartered in Singapore with a local presence in India and the UAE. The company was founded in 2012 with the vision of simplifying the world’s choices. Our flagship platform, maya.ai, helps enterprises across the Banking, Fin-tech, and Travel industries create and capture sustainable revenue streams by unlocking the value of data.   \n",
       "636                                                                                                                                                                                                                                                                                                                                                                                                                                                 8+ years into ML Model implementation, experimentation & related software engineering focused\\nExperience as a data scientist with Demand forecasting algorithms\\nPython, PySpark development experience a must\\n1-2 years of software development experience - preferred\\nExposure to ML models such as random forest, XGboost, LightGBM, and some other ensemble modeling algorithms\\nExperience on Azure Cloud Platforms (\"Databricks, Azure ML studio, etc)\\nAbility to learn fast and handle multiple priorities\\n\\nResponsibilities   \n",
       "684                                                                                                                                                                                                                                                                                                                      About Us\\nCensius is a US-based product company that is enabling AI at scale for enterprises. We are unlocking MLOps scalability by building the world's fastest way to deploy models and are amongst the earliest companies to tackle Model Performance Management. At Censius, you will get to solve difficult problems in a very nascent, but rapidly growing, area.\\n\\nAbout the role\\nIn this role, you will design and implement a generic ML platform that helps monitor models across modalities in production. You will collaborate with the research and development teams to build robust ML and big data monitoring platforms.\\n\\n\\n\\nCompetitive Salary   \n",
       "719                                                                                                                                                                                                                                                                                                                                                                                                               Our goal is to transform the entire hiring process by making it simple, efficient, and enjoyable for recruiters, hiring managers, and candidates alike\\nOur mission is to offer the best-in-class AI-powered technologies to empower small, medium, and large businesses in their staffing & recruitment transformation.\\nResponsibilities\\nSet, define, and own the data science roadmap\\nBuild, maintain, and enhance Manatal core features focusing on:\\nCV/Resume parsing in multiple languages\\nCandidate recommendation engine\\nCandidate for social media enrichment   \n",
       "797  Company Overview\\nAt Motorola Solutions, we believe that everything starts with our people. We’re a global close-knit community, united by the relentless pursuit to help keep people safer everywhere. Our critical communications, video security and command center technologies support public safety agencies and enterprises alike, enabling the coordination that’s critical for safer communities, safer schools, safer hospitals and safer businesses. Connect with a career that matters, and help us build a safer future.\\n\\nDepartment Overview\\nThe Design & Tools (D&T) team is a strategic component of Centralized Managed Support Operations (CMSO), responsible for providing exceptional Service Design & innovative technology solutions to enable and empower MSI Centralized Managed Support Operations to meet and exceed customer's expectations. In this role, you will fit in the AI & Architecture team within D&T.\\n\\n\\n\\n\\nNone\\n\\nNone\\n\\nExperienced\\nNo   \n",
       "827                                                                                                                                                                                                                                                                                                                                                                                                               Sr. Data Scientist, AI Division\\nDate: 17 Jul 2025\\nLocation: Mumbai - Worli, Mumbai - Worli, IN\\nCompany: Mahindra & Mahindra Ltd\\nRoles & Responsibilities:\\nDesign and implement scalable, cloud-based data solutions using AWS, Azure, or GCP (mandatory).\\nBuild, optimize, and maintain ETL/ELT pipelines for efficient data processing.\\nManage and design cloud-based data storage systems such as data warehouses and data lakes.\\nEnsure data quality, security, and compliance in cloud environments.\\nImplement real-time and batch data processing frameworks.   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "7           None           NaN          None                      None   \n",
       "418         None           NaN          None                      None   \n",
       "478         None           NaN          None                      None   \n",
       "522         None           NaN          None                      None   \n",
       "545         None           NaN          None                      None   \n",
       "548         None           NaN          None                      None   \n",
       "592         None           NaN          None                      None   \n",
       "636         None           NaN          None                      None   \n",
       "684         None           NaN          None                      None   \n",
       "719         None           NaN          None                      None   \n",
       "797         None           NaN          None                      None   \n",
       "827         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "7                          NaN  \n",
       "418                        NaN  \n",
       "478                        NaN  \n",
       "522                        NaN  \n",
       "545                        NaN  \n",
       "548                        NaN  \n",
       "592                        NaN  \n",
       "636                        NaN  \n",
       "684                        NaN  \n",
       "719                        NaN  \n",
       "797                        NaN  \n",
       "827                        NaN  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() &\n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('India', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c39e4-c471-4c66-86cd-c2c7cbc2095b",
   "metadata": {},
   "source": [
    "### Imputing values in rows with company name - 'Kinaxis Inc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3b06da9e-893f-4125-b919-3ab9c9085f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Senior Software Developer, Machine Learning</td>\n",
       "      <td>India</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Staff Software Developer, Machine Learning</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:</td>\n",
       "      <td>₹3L – ₹8L/yr</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>300000 – 800000</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Kinaxis Inc.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Software Developer 2, Machine Learning</td>\n",
       "      <td>India</td>\n",
       "      <td>About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\nWhy join Kinaxis?:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name  Company_Rating                                    Job_Title  \\\n",
       "7   Kinaxis Inc.             4.1  Senior Software Developer, Machine Learning   \n",
       "35  Kinaxis Inc.             4.1   Staff Software Developer, Machine Learning   \n",
       "64  Kinaxis Inc.             4.1       Software Developer 2, Machine Learning   \n",
       "\n",
       "     Location  \\\n",
       "7       India   \n",
       "35  Bengaluru   \n",
       "64      India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Description  \\\n",
       "7   About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:   \n",
       "35  About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\n\\nWhy join Kinaxis?:   \n",
       "64    About Kinaxis:\\nAbout Kinaxis\\nElevate your career journey by embracing a new challenge with Kinaxis. We are experts in tech, but it’s really our people who give us passion to always seek ways to do things better. As such, we’re serious about your career growth and professional development, because People matter at Kinaxis.\\n\\nIn 1984, we started out as a team of three engineers based in Ottawa, Canada. Today, we have grown to become a global organization with over 2000 employees around the world, and support 40,000+ users in over 100 countries. As a global leader in end-to-end supply chain management, we enable supply chain excellence for all industries. We are expanding our team in Chennai and around the world as we continue to innovate and revolutionize how we support our customers.\\n\\nAbout the team:\\nAbout the role:\\nWhy join Kinaxis?:   \n",
       "\n",
       "    Salary_Range  Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "7           None            NaN            None                      None   \n",
       "35  ₹3L – ₹8L/yr  ₹5L/yr Median  Glassdoor Est.           300000 – 800000   \n",
       "64          None            NaN            None                      None   \n",
       "\n",
       "   Median_Salary_Standardized  \n",
       "7                         NaN  \n",
       "35                     500000  \n",
       "64                        NaN  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Kinaxis Inc.', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a81a98-67b6-44be-9eac-a98ac8796700",
   "metadata": {},
   "source": [
    "- Row 7's company name is 'Kinaxis Inc.' and there are other job postings with the same company, we can use this info to impute the missing value in row 7 and 64. The recorded value of 5L on row 35 is pretty low that's because most job's salary is estimated by glassdoor itself and glassdoor typically estimates salary lower than the actual market salary, so lets impute our own value using average and basic analysis. \n",
    "    - Row 7 - Senior software developer, machine learning  - 8,00,000\n",
    "    - Row 64 - Software developer 2, machine learning      - 5,00,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "854a2778-0ad4-4054-99af-5962ce33cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[7, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[64, 'Median_Salary_Standardized'] = 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d6c7a-f4cd-4aa5-b8e6-d1b947a260c6",
   "metadata": {},
   "source": [
    "### Imputing values in rows with company name - 'Grid Dynamics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "9c392db1-544a-4e8d-9bc1-7f3d5ef88e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Grid Dynamics</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>1. ML Model implementation, experimentation &amp; related software engineering focused\\n2. Experience as a data scientist with preference in forecasting algorithms\\n3. Python, PySpark development experience a must with 3-4 years of experience\\n\\nResponsibilities\\n\\nMachine Learning model implementations\\n\\nRequirements\\n\\nAbility to learn fast and handle multiple priorities</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Grid Dynamics</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>6+ years of experience as a Data Scientist\\n3-4 years of very good Python, PySpark development experience\\n1-2 years of software development experience - preferred\\n1-2 years of experience as a data scientist with preference in Time Series\\nExperience of ML Ops / DevOps\\nExposure to ML models such as random forest, XGboost, LightGBM, and some other ensemble modeling algorithms\\n4 years experience on Azure Cloud Platforms (databricks, Azure ML studio, etc)\\nNo Phd’s. BS or MS degree is Software Engineering, Computer Science or Statistics related\\nAbility to learn fast and handle multiple priorities</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Grid Dynamics</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>8+ years into ML Model implementation, experimentation &amp; related software engineering focused\\nExperience as a data scientist with Demand forecasting algorithms\\nPython, PySpark development experience a must\\n1-2 years of software development experience - preferred\\nExposure to ML models such as random forest, XGboost, LightGBM, and some other ensemble modeling algorithms\\nExperience on Azure Cloud Platforms (\"Databricks, Azure ML studio, etc)\\nAbility to learn fast and handle multiple priorities\\n\\nResponsibilities</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company_Name  Company_Rating              Job_Title Location  \\\n",
       "170  Grid Dynamics             3.9         Data Scientist    India   \n",
       "418  Grid Dynamics             3.9  Senior Data Scientist    India   \n",
       "636  Grid Dynamics             3.9   Staff Data Scientist    India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description  \\\n",
       "170                                                                                                                                                                                                                                          1. ML Model implementation, experimentation & related software engineering focused\\n2. Experience as a data scientist with preference in forecasting algorithms\\n3. Python, PySpark development experience a must with 3-4 years of experience\\n\\nResponsibilities\\n\\nMachine Learning model implementations\\n\\nRequirements\\n\\nAbility to learn fast and handle multiple priorities   \n",
       "418  6+ years of experience as a Data Scientist\\n3-4 years of very good Python, PySpark development experience\\n1-2 years of software development experience - preferred\\n1-2 years of experience as a data scientist with preference in Time Series\\nExperience of ML Ops / DevOps\\nExposure to ML models such as random forest, XGboost, LightGBM, and some other ensemble modeling algorithms\\n4 years experience on Azure Cloud Platforms (databricks, Azure ML studio, etc)\\nNo Phd’s. BS or MS degree is Software Engineering, Computer Science or Statistics related\\nAbility to learn fast and handle multiple priorities   \n",
       "636                                                                                     8+ years into ML Model implementation, experimentation & related software engineering focused\\nExperience as a data scientist with Demand forecasting algorithms\\nPython, PySpark development experience a must\\n1-2 years of software development experience - preferred\\nExposure to ML models such as random forest, XGboost, LightGBM, and some other ensemble modeling algorithms\\nExperience on Azure Cloud Platforms (\"Databricks, Azure ML studio, etc)\\nAbility to learn fast and handle multiple priorities\\n\\nResponsibilities   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "170         None           NaN          None                      None   \n",
       "418         None           NaN          None                      None   \n",
       "636         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "170                        NaN  \n",
       "418                        NaN  \n",
       "636                        NaN  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Grid Dynamics', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca536c1-6619-4e40-b4ad-1f99992aa497",
   "metadata": {},
   "source": [
    "- Imputing rows 170, 418, 636  \n",
    "      - 170 - Data Scientist       : 3-4 years of experience, python, pyspark, ML models   \n",
    "      - 418 - Senior Data Scientist: 6+ years of experienc, 3-4 years in python, 1-2 years in software development, MLOps  \n",
    "      - 636 - Staff Data Scientist : 8+ years of experience in Data science, 1-2 years of experience in Software development, MLops  \n",
    "- The job description is very detailed which means the role requires a talented/experienced data scientist, and there is a clear difference between the roles as the rank increases the roles, responsibilities, skills required are also increases. Its better to assume that each role offers the salary that equals the market rate.\n",
    "      - Row 170 - 9,00,000  \n",
    "      - Row 418 - 15,00,000  \n",
    "      - Row 636 - 24,00,000  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "2246720e-4672-4f40-9b9c-5720ecf1253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[170, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[418, 'Median_Salary_Standardized'] = 1500000\n",
    "\n",
    "df_copy.loc[636, 'Median_Salary_Standardized'] = 2400000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85e30a-4ca5-4efa-b8e1-232616de8c6f",
   "metadata": {},
   "source": [
    "### Imputing values in rows with company name - 'EY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "300983ae-3b39-489d-b651-3b65a4ecd32a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EY</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Management - Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nData Management - Data Scientist\\nAt EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nEY is a global leader in assurance, tax, transaction and advisory services. Technology is at the heart of what we do and deliver at EY. Technology solutions are integrated in the client services we deliver and are key to our innovation as an organization. Fuelled by a US$1.5+B investment in technology and innovation, EY is primed to guide clients in their efforts to drive sustainable growth, create new value, and build new and better ways of working. As part of Enterprise Technology, you’ll be at the forefront of integrating technology into what we do at EY. That means more growth for you, exciting learning opportunities, career choices and the chance to make a real impact.</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>EY</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Management - Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nData Management (Data Scientist)\\n\\nThe opportunity\\nEY’s global enterprise technology group provides various enabling services (ERP, infrastructure, platforms, service desk) to assist over 300K employees in creating and delivering solutions and services to Fortune 500, privately held and government-like entities.</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>EY</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist - Senior Manager</td>\n",
       "      <td>India</td>\n",
       "      <td>At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nRole: Senior Manager - Data Scientist\\nDesignation: Senior Manager\\nPreferred Experience: 12+ years\\n\\nKey Responsibilities:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>EY</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Digital-Staff-Machine Learning Developer</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nPosition Name\\n\\nML Developer\\n\\nTaleo ID</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>EY</td>\n",
       "      <td>3.7</td>\n",
       "      <td>TTT-Data Science-Staff</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nTAX TECHNOLOGY TRANSFORMATION – Data Science -Senior\\nEY GDS’s Tax Innovation, Solutions and Technology (IST) group as well as the Tax Tech Transformation (TTT) team’s mission is to develop, implement and integrate technology solutions that better serve our clients and engagement teams. As a member of EY’s core Tax practice, you’ll develop a deep tax technical knowledge and outstanding database, data analytics and programming skills.\\n\\nEver-increasing regulations require tax departments to gather, organize and analyse more data than ever before. Often the data necessary to satisfy these ever-increasing and complex regulations must be collected from a variety of systems and departments throughout an organization. Effectively and efficiently handling the variety and volume of data is often extremely challenging and time consuming for a company.</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>700000 – 1000000</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name  Company_Rating                                 Job_Title  \\\n",
       "92            EY             3.7          Data Management - Data Scientist   \n",
       "119           EY             3.7          Data Management - Data Scientist   \n",
       "522           EY             3.7           Data Scientist - Senior Manager   \n",
       "535           EY             3.7  Digital-Staff-Machine Learning Developer   \n",
       "734           EY             3.7                    TTT-Data Science-Staff   \n",
       "\n",
       "      Location  \\\n",
       "92   Bengaluru   \n",
       "119  Bengaluru   \n",
       "522      India   \n",
       "535    Chennai   \n",
       "734  Bengaluru   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Description  \\\n",
       "92   At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nData Management - Data Scientist\\nAt EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nEY is a global leader in assurance, tax, transaction and advisory services. Technology is at the heart of what we do and deliver at EY. Technology solutions are integrated in the client services we deliver and are key to our innovation as an organization. Fuelled by a US$1.5+B investment in technology and innovation, EY is primed to guide clients in their efforts to drive sustainable growth, create new value, and build new and better ways of working. As part of Enterprise Technology, you’ll be at the forefront of integrating technology into what we do at EY. That means more growth for you, exciting learning opportunities, career choices and the chance to make a real impact.   \n",
       "119                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nData Management (Data Scientist)\\n\\nThe opportunity\\nEY’s global enterprise technology group provides various enabling services (ERP, infrastructure, platforms, service desk) to assist over 300K employees in creating and delivering solutions and services to Fortune 500, privately held and government-like entities.   \n",
       "522                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nRole: Senior Manager - Data Scientist\\nDesignation: Senior Manager\\nPreferred Experience: 12+ years\\n\\nKey Responsibilities:   \n",
       "535                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nPosition Name\\n\\nML Developer\\n\\nTaleo ID   \n",
       "734                                                                                                                                                                                                                              At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\\n\\nTAX TECHNOLOGY TRANSFORMATION – Data Science -Senior\\nEY GDS’s Tax Innovation, Solutions and Technology (IST) group as well as the Tax Tech Transformation (TTT) team’s mission is to develop, implement and integrate technology solutions that better serve our clients and engagement teams. As a member of EY’s core Tax practice, you’ll develop a deep tax technical knowledge and outstanding database, data analytics and programming skills.\\n\\nEver-increasing regulations require tax departments to gather, organize and analyse more data than ever before. Often the data necessary to satisfy these ever-increasing and complex regulations must be collected from a variety of systems and departments throughout an organization. Effectively and efficiently handling the variety and volume of data is often extremely challenging and time consuming for a company.   \n",
       "\n",
       "      Salary_Range  Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "92   ₹7L – ₹10L/yr  ₹8L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "119  ₹7L – ₹10L/yr  ₹8L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "522           None            NaN            None                      None   \n",
       "535           None            NaN            None                      None   \n",
       "734  ₹7L – ₹10L/yr  ₹8L/yr Median  Glassdoor Est.          700000 – 1000000   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "92                      800000  \n",
       "119                     800000  \n",
       "522                        NaN  \n",
       "535                     600000  \n",
       "734                     800000  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('EY', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "b63f4bee-78ee-4b23-ad8c-d48ec0bc4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[[522, 535], 'Median_Salary_Standardized'] = 800000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557c743-59ef-49e3-a0ac-1781d77d3bcb",
   "metadata": {},
   "source": [
    "### Imputing values in rows with company name - 'Helius Technologies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "1e45254c-8813-4042-a2cd-e2fbe5b4d581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Helius Technologies</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Data Scientist (Machine Learning)</td>\n",
       "      <td>India</td>\n",
       "      <td>As a Machine Learning Scientist, you will work collaboratively with our Data Scientists and Data Analysts to develop analytical frameworks and reliable measurement strategies for eCommerce.\\nIn this role, you will be responsible for working on models to optimize customer experience, enhance the ROI of marketing campaigns, detect abuse in marketing campaigns, and solve interesting problems related to ranking and recommendations. You will also be tasked with devising and evaluating models to identify growth opportunities, estimate the impact of new features on our platforms, and personalize the user experience.\\nAdditionally, you will be responsible for identifying the most impactful opportunities for business development based on user needs, scoping and independently solving moderately complex problems, and taking ownership of projects with minimal guidance. You will partner with other data scientists, data analysts, and data engineers to test and build hypotheses, deliver actionable insights that fuel business decisions, and define the metrics used to measure the performance of initiatives and track them through dashboards.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Helius Technologies</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Job Scope:\\nResponsible for developing POCs/projects for customers to demonstrate power of company product(s) &amp; capabilities to customer stakeholders and data scientists.\\nResponsible for ensuring that POCs/projects are delivered on time, scope and quality\\nResponsible for understanding customer requirements from POC and translating them into solutions using the human-first approach\\nTake primary responsibility for answering technical, data and related questions from the customer, related to the POC/project\\nProvide regular progress updates to the customer and other stakeholders\\nPerform activities like data analysis, solution formulation, model development, testing/evaluation, field testing (representative POC related activities)\\nQualification Requirements\\n\\n\\nExperience with Apache Spark and/or Hadoop development Programming language: scripting languages, Scala, Java</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Helius Technologies</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Our goal is to transform the entire hiring process by making it simple, efficient, and enjoyable for recruiters, hiring managers, and candidates alike\\nOur mission is to offer the best-in-class AI-powered technologies to empower small, medium, and large businesses in their staffing &amp; recruitment transformation.\\nResponsibilities\\nSet, define, and own the data science roadmap\\nBuild, maintain, and enhance Manatal core features focusing on:\\nCV/Resume parsing in multiple languages\\nCandidate recommendation engine\\nCandidate for social media enrichment</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Company_Name  Company_Rating                          Job_Title  \\\n",
       "127  Helius Technologies             4.3  Data Scientist (Machine Learning)   \n",
       "225  Helius Technologies             4.3                     Data Scientist   \n",
       "719  Helius Technologies             4.3              Senior Data Scientist   \n",
       "\n",
       "    Location  \\\n",
       "127    India   \n",
       "225    India   \n",
       "719    India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Description  \\\n",
       "127  As a Machine Learning Scientist, you will work collaboratively with our Data Scientists and Data Analysts to develop analytical frameworks and reliable measurement strategies for eCommerce.\\nIn this role, you will be responsible for working on models to optimize customer experience, enhance the ROI of marketing campaigns, detect abuse in marketing campaigns, and solve interesting problems related to ranking and recommendations. You will also be tasked with devising and evaluating models to identify growth opportunities, estimate the impact of new features on our platforms, and personalize the user experience.\\nAdditionally, you will be responsible for identifying the most impactful opportunities for business development based on user needs, scoping and independently solving moderately complex problems, and taking ownership of projects with minimal guidance. You will partner with other data scientists, data analysts, and data engineers to test and build hypotheses, deliver actionable insights that fuel business decisions, and define the metrics used to measure the performance of initiatives and track them through dashboards.   \n",
       "225                                                                                                                                                                                                                                                                    Job Scope:\\nResponsible for developing POCs/projects for customers to demonstrate power of company product(s) & capabilities to customer stakeholders and data scientists.\\nResponsible for ensuring that POCs/projects are delivered on time, scope and quality\\nResponsible for understanding customer requirements from POC and translating them into solutions using the human-first approach\\nTake primary responsibility for answering technical, data and related questions from the customer, related to the POC/project\\nProvide regular progress updates to the customer and other stakeholders\\nPerform activities like data analysis, solution formulation, model development, testing/evaluation, field testing (representative POC related activities)\\nQualification Requirements\\n\\n\\nExperience with Apache Spark and/or Hadoop development Programming language: scripting languages, Scala, Java   \n",
       "719                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Our goal is to transform the entire hiring process by making it simple, efficient, and enjoyable for recruiters, hiring managers, and candidates alike\\nOur mission is to offer the best-in-class AI-powered technologies to empower small, medium, and large businesses in their staffing & recruitment transformation.\\nResponsibilities\\nSet, define, and own the data science roadmap\\nBuild, maintain, and enhance Manatal core features focusing on:\\nCV/Resume parsing in multiple languages\\nCandidate recommendation engine\\nCandidate for social media enrichment   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "127         None           NaN          None                      None   \n",
       "225         None           NaN          None                      None   \n",
       "719         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "127                        NaN  \n",
       "225                        NaN  \n",
       "719                        NaN  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Helius Technologies', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6daf7e4-5419-4824-bdcf-4f929b1a828f",
   "metadata": {},
   "source": [
    "- Imputing rows 127, 225, 719:\n",
    "    - Row 127 - Data Scientist(machine learning) - 800000\n",
    "    - Row 225 - Data Scientist                   - 800000\n",
    "    - Row 719 - Senior Data Scientist            - 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d0ba1968-07c0-446b-873d-5d80ffdbdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[[127, 225, 719], 'Median_Salary_Standardized'] = 800000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86601f59-9139-40cd-8f9c-9aac117eaf32",
   "metadata": {},
   "source": [
    "### Imputing rest of the job postings located in India"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a722f-bce3-45e8-a377-914a983582a7",
   "metadata": {},
   "source": [
    "- Rows to impute:  \n",
    "478 - involves AI - 900000    \n",
    "545 - basic DS role - 700000   \n",
    "548 - tech startup - 900000  \n",
    "592 - 5-8 years of experience - 800000  \n",
    "684 - Competitive salary - 1000000  \n",
    "797 - not enough info - 600000  \n",
    "827 - AI division - 1200000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "fbb25af6-ed92-4771-8c10-2db4797a7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[478, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[545, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[548, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[592, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[684, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[797, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[827, 'Median_Salary_Standardized'] = 1200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "3ec2d8df-1c18-4f00-bca3-09bac15993ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company_Name, Company_Rating, Job_Title, Location, Description, Salary_Range, Median_Salary, Salary_Source, Salary_Range_Standardized, Median_Salary_Standardized]\n",
       "Index: []"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() &\n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('India', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "de4bc274-eb4e-4909-a024-d4c29f3f611a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Talenzen</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Senior Data Scientist – Reporting &amp; Data Validation (7–9 Years)\\nLocation: Noida Sec-62\\nExperience: 7–9 Years\\nIndustry: IT Services / Software\\nJob Type: Full-Time\\nRole Summary:\\nWe are hiring a Senior Data Scientist with strong experience in reporting, data validation, and analysis. The candidate will be responsible for ensuring data accuracy, preparing automated reports, identifying anomalies, and supporting business teams with actionable insights.\\nKey Responsibilities:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Teradata</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Our Company\\n\\nAt Teradata, we believe that people thrive when empowered with better information. That’s why we built the most complete cloud analytics and data platform for AI. By delivering harmonized data, trusted AI, and faster innovation, we uplift and empower our customers—and our customers’ customers—to make better, more confident decisions. The world’s top companies across every major industry trust Teradata to improve business performance, enrich customer experiences, and fully integrate data across the enterprise.\\n\\nWhat you will do ?\\n\\nBe one of the Individual Contributor and a part of our Data Science practice in GSIH India/Pakistan\\n\\nBe proactive and a SME in his/her skills and a great team member, specializing in AI/ML.\\n\\nProduce packaged solutions, AaaS offerings, in addition to supporting Analytics projects and PoCs/PoVs.\\n\\nWork in a team to define and execute data science solutions that address client use cases and business requirements\\n\\nDefine activities, scope, and timelines on data science projects\\n\\nDeliver projects following our internal frameworks and best practices\\n\\nBe AI/ML expert to advice customers in defining Analytics Roadmap, Ecosystem and Architecture for Complex Enterprise Systems.\\n\\nExperienced in implementing AI/ML solutions in Agile environment.\\n\\nDiscover, interpret and document unique insights in large-scale distributed datasets through exploratory analysis and the application of advanced analytical methodologies\\n\\nCreate statistical, machine learning and deep learning models in multiple technologies using best-in-class data science approaches\\n\\nPrepare and conduct presentations and client workshops, communicating past experiences in sales and speaking opportunities\\n\\nGuide junior members of the delivery team during projects\\n\\nTeradata Vantage as a skill that needs to be acquired after joining Teradata\\n\\nCandidate will work on Teradata ClearScape Analytics Offerings\\n\\nWho You’ll Work With\\n\\nWork as an individual contributor to define and execute Advanced Analytics solutions that address client use cases and business requirements.\\n\\nWork in close coordination with Data Science teams in other GSIH centers as well International Data Science teams to serve global customers.\\n\\nWill need to be a quick learner with the desire to improve skill sets\\n\\nAs this is a project-oriented position in either onsite or offsite situations having accountability for managing client expectations while delivering the services and solutions associated with the Teradata database\\n\\nThis position will combine direct client consulting engagement activities, new solution development and analytics positioning responsibilities\\n\\nWhat Makes You a Qualified Candidate\\n\\nBachelor’s, Master’s or PhD degree in a related discipline (Mathematics, Statistics, Computer Science, or Data Science)\\n5+ years of related work and/or research experience in quantitative roles\\nIn-depth knowledge in at least 2 of the following data science domains\\n\\nText Mining / NLP\\nGraph and Network Analysis\\nDeep Learning/Gen AI\\nGeospatial Analysis\\nSignal Processing, Image, Video\\nPredictive Modeling and Recommender Systems\\n\\nExtensive knowledge of at least one open-source scientific language such as Python\\nKnowledge of working with AI/ML modules of cloud providers is a plus\\nFluency in SQL and good knowledge of relational databases\\nPassionate about asking and answering questions in large, distributed datasets\\n\\nExperience with at least one general purpose, high level programming language such as C/C++, Java, PHP, or Python\\n\\nWhat You’ll Bring\\n\\nExperience implementing end-to-end large scale Machine Learning/AI project\\n\\nExperience in Python, SQL\\nBe a clear and confident communicator with excellent presentation skills and with the ability to translate technology concepts into concise business focused messages in both technical and sales presentations\\nPossess strong interpersonal and communication skills\\nBe proficient in the use of both written and spoken business English\\nProven skills in creative-problem-solving of complex and advanced technical subject matter\\nPossess a solid understanding of the value of data and how technology enables companies to compete better in the market place\\nBe able to consult in a client facing environment, linking analytical solutions to the value and competitive advantage that technology can help a client deliver.\\nWill have prior experience of working in a multi-country organization\\nHave the ability to collaborate with an interdisciplinary team to solve problems\\nBe self-starter with a positive attitude, intellectual curiosity and a passion for analytics and solving real world problems\\nBe willing to travel up to 40-70%\\n\\n#LI-NM1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>FiveExceptions Software Solutions</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist /Senior Data Scientist</td>\n",
       "      <td>Indore</td>\n",
       "      <td>We are seeking an experienced Data Scientist to join our team. The ideal candidate will have a strong background in developing and deploying advanced AI/ML models, with a focus on solving complex business problems.\\nLocation: Hyderabad\\nKey Responsibilities\\nDevelop Models: Design, build, and optimize machine learning models.\\nData Analysis: Collect, preprocess, and analyse large datasets.\\nData Representation: Create data visualizations and dashboards to communicate findings\\nCollaborate: Work with cross-functional teams to define project requirements and deliverables.\\nDeploy &amp; Maintain: Deploy AI/ML models into production and ensure their performance, accuracy and efficiency.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company_Name  Company_Rating  \\\n",
       "568                           Talenzen             3.9   \n",
       "681                           Teradata             3.8   \n",
       "654  FiveExceptions Software Solutions             4.2   \n",
       "\n",
       "                                 Job_Title   Location  \\\n",
       "568                  Senior Data Scientist      Noida   \n",
       "681                  Senior Data Scientist  Karnataka   \n",
       "654  Data Scientist /Senior Data Scientist     Indore   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Description  \\\n",
       "568                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Senior Data Scientist – Reporting & Data Validation (7–9 Years)\\nLocation: Noida Sec-62\\nExperience: 7–9 Years\\nIndustry: IT Services / Software\\nJob Type: Full-Time\\nRole Summary:\\nWe are hiring a Senior Data Scientist with strong experience in reporting, data validation, and analysis. The candidate will be responsible for ensuring data accuracy, preparing automated reports, identifying anomalies, and supporting business teams with actionable insights.\\nKey Responsibilities:   \n",
       "681  Our Company\\n\\nAt Teradata, we believe that people thrive when empowered with better information. That’s why we built the most complete cloud analytics and data platform for AI. By delivering harmonized data, trusted AI, and faster innovation, we uplift and empower our customers—and our customers’ customers—to make better, more confident decisions. The world’s top companies across every major industry trust Teradata to improve business performance, enrich customer experiences, and fully integrate data across the enterprise.\\n\\nWhat you will do ?\\n\\nBe one of the Individual Contributor and a part of our Data Science practice in GSIH India/Pakistan\\n\\nBe proactive and a SME in his/her skills and a great team member, specializing in AI/ML.\\n\\nProduce packaged solutions, AaaS offerings, in addition to supporting Analytics projects and PoCs/PoVs.\\n\\nWork in a team to define and execute data science solutions that address client use cases and business requirements\\n\\nDefine activities, scope, and timelines on data science projects\\n\\nDeliver projects following our internal frameworks and best practices\\n\\nBe AI/ML expert to advice customers in defining Analytics Roadmap, Ecosystem and Architecture for Complex Enterprise Systems.\\n\\nExperienced in implementing AI/ML solutions in Agile environment.\\n\\nDiscover, interpret and document unique insights in large-scale distributed datasets through exploratory analysis and the application of advanced analytical methodologies\\n\\nCreate statistical, machine learning and deep learning models in multiple technologies using best-in-class data science approaches\\n\\nPrepare and conduct presentations and client workshops, communicating past experiences in sales and speaking opportunities\\n\\nGuide junior members of the delivery team during projects\\n\\nTeradata Vantage as a skill that needs to be acquired after joining Teradata\\n\\nCandidate will work on Teradata ClearScape Analytics Offerings\\n\\nWho You’ll Work With\\n\\nWork as an individual contributor to define and execute Advanced Analytics solutions that address client use cases and business requirements.\\n\\nWork in close coordination with Data Science teams in other GSIH centers as well International Data Science teams to serve global customers.\\n\\nWill need to be a quick learner with the desire to improve skill sets\\n\\nAs this is a project-oriented position in either onsite or offsite situations having accountability for managing client expectations while delivering the services and solutions associated with the Teradata database\\n\\nThis position will combine direct client consulting engagement activities, new solution development and analytics positioning responsibilities\\n\\nWhat Makes You a Qualified Candidate\\n\\nBachelor’s, Master’s or PhD degree in a related discipline (Mathematics, Statistics, Computer Science, or Data Science)\\n5+ years of related work and/or research experience in quantitative roles\\nIn-depth knowledge in at least 2 of the following data science domains\\n\\nText Mining / NLP\\nGraph and Network Analysis\\nDeep Learning/Gen AI\\nGeospatial Analysis\\nSignal Processing, Image, Video\\nPredictive Modeling and Recommender Systems\\n\\nExtensive knowledge of at least one open-source scientific language such as Python\\nKnowledge of working with AI/ML modules of cloud providers is a plus\\nFluency in SQL and good knowledge of relational databases\\nPassionate about asking and answering questions in large, distributed datasets\\n\\nExperience with at least one general purpose, high level programming language such as C/C++, Java, PHP, or Python\\n\\nWhat You’ll Bring\\n\\nExperience implementing end-to-end large scale Machine Learning/AI project\\n\\nExperience in Python, SQL\\nBe a clear and confident communicator with excellent presentation skills and with the ability to translate technology concepts into concise business focused messages in both technical and sales presentations\\nPossess strong interpersonal and communication skills\\nBe proficient in the use of both written and spoken business English\\nProven skills in creative-problem-solving of complex and advanced technical subject matter\\nPossess a solid understanding of the value of data and how technology enables companies to compete better in the market place\\nBe able to consult in a client facing environment, linking analytical solutions to the value and competitive advantage that technology can help a client deliver.\\nWill have prior experience of working in a multi-country organization\\nHave the ability to collaborate with an interdisciplinary team to solve problems\\nBe self-starter with a positive attitude, intellectual curiosity and a passion for analytics and solving real world problems\\nBe willing to travel up to 40-70%\\n\\n#LI-NM1   \n",
       "654                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              We are seeking an experienced Data Scientist to join our team. The ideal candidate will have a strong background in developing and deploying advanced AI/ML models, with a focus on solving complex business problems.\\nLocation: Hyderabad\\nKey Responsibilities\\nDevelop Models: Design, build, and optimize machine learning models.\\nData Analysis: Collect, preprocess, and analyse large datasets.\\nData Representation: Create data visualizations and dashboards to communicate findings\\nCollaborate: Work with cross-functional teams to define project requirements and deliverables.\\nDeploy & Maintain: Deploy AI/ML models into production and ensure their performance, accuracy and efficiency.   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "568         None           NaN          None                      None   \n",
       "681         None           NaN          None                      None   \n",
       "654         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "568                        NaN  \n",
       "681                        NaN  \n",
       "654                        NaN  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[568, 681, 654]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593d6d7-416f-41ba-a6a6-905c177e90f4",
   "metadata": {},
   "source": [
    "- Row 568 - 7-9 years of experience, expertise in reporting, data validation - 900000\n",
    "- Row 681 - 5+ years of experience, master's or phD, Deep learning, GenAI, Image analysis etc - 2000000\n",
    "- Row 654 - Typical data science role with expertise in developing ML/AI models - 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "944daa48-7bcc-4bd0-8999-fd3dc940cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[568, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[681, 'Median_Salary_Standardized'] = 2000000\n",
    "\n",
    "df_copy.loc[654, 'Median_Salary_Standardized'] = 1500000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4321cc-2a41-49fa-b17c-70af68f1ee4f",
   "metadata": {},
   "source": [
    "### Imputing missing values of jobs located in 'Mumbai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "fd70241c-d3f1-44a9-ae53-8a135982f229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>JOIN OUR DIVERSE TEAM! Are you eager to drive your career forward? LSEG is seeking a dedicated Data Scientist to enhance our Oil Research.\\nLSEG Oil Research is a part of global Research team of 130+ analysts committed to delivering insight and intelligence on the physical and paper commodities markets. Combining deep domain expertise, vast data resources, and the LSEG's Workspace platform, LSEG Commodities Research is a trusted partner of commodities professionals worldwide. A career with the Oil Research team presents a unique opportunity to apply existing analytical skills and develop new knowledge to better understand the production, flow, consumption and pricing of the world's crude and oil products.\\nThe Data Scientist role requires developing and analyzing market models, identifying key factors driving market trends, and using data analytics to provide strategic insights. While industry-specific experience, particularly in oil and gas, is helpful, it is not required. The ideal candidate will have a strong background in data analytic techniques, proficiency in Python, familiarity with data management and storage solutions such as Databricks or Snowflake, and a passion for using data to tackle complex business challenges.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Axis My India</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>6 to 8 years in the same/similar field\\n\\nDate Opened\\n07/09/2025\\nIndustry\\nResearch\\nJob Type\\nFull time\\nCity\\nMumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist / Senior Data Scientist, India - BCG X</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  Company_Rating  \\\n",
       "515  LSEG (London Stock Exchange Group)             3.7   \n",
       "794                       Axis My India             4.3   \n",
       "63              Boston Consulting Group             4.2   \n",
       "121             Boston Consulting Group             4.2   \n",
       "\n",
       "                                                 Job_Title Location  \\\n",
       "515                                  Senior Data Scientist   Mumbai   \n",
       "794                                  Senior Data Scientist   Mumbai   \n",
       "63         AI Engineer / Senior AI Engineer, India - BCG X   Mumbai   \n",
       "121  Data Scientist / Senior Data Scientist, India - BCG X   Mumbai   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Description  \\\n",
       "515                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           JOIN OUR DIVERSE TEAM! Are you eager to drive your career forward? LSEG is seeking a dedicated Data Scientist to enhance our Oil Research.\\nLSEG Oil Research is a part of global Research team of 130+ analysts committed to delivering insight and intelligence on the physical and paper commodities markets. Combining deep domain expertise, vast data resources, and the LSEG's Workspace platform, LSEG Commodities Research is a trusted partner of commodities professionals worldwide. A career with the Oil Research team presents a unique opportunity to apply existing analytical skills and develop new knowledge to better understand the production, flow, consumption and pricing of the world's crude and oil products.\\nThe Data Scientist role requires developing and analyzing market models, identifying key factors driving market trends, and using data analytics to provide strategic insights. While industry-specific experience, particularly in oil and gas, is helpful, it is not required. The ideal candidate will have a strong background in data analytic techniques, proficiency in Python, familiarity with data management and storage solutions such as Databricks or Snowflake, and a passion for using data to tackle complex business challenges.   \n",
       "794                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 6 to 8 years in the same/similar field\\n\\nDate Opened\\n07/09/2025\\nIndustry\\nResearch\\nJob Type\\nFull time\\nCity\\nMumbai   \n",
       "63   Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "121                                                                                                                          Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "515         None           NaN          None                      None   \n",
       "794         None           NaN          None                      None   \n",
       "63          None           NaN          None                      None   \n",
       "121         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "515                        NaN  \n",
       "794                        NaN  \n",
       "63                         NaN  \n",
       "121                        NaN  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[515, 794, 63, 121]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "11d18528-e4ec-4bcc-95fe-26d9d263314e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are looking for a skilled Data Scientist to join our dynamic Analytics Centre of Excellence team. This role combines Data Science, Python development, and business analysis to deliver actionable insights and solutions that drive strategic decisions. Knowledge and experience will be put into practice to Quantitative Engineering, financial instrument pricing, and analytics to shape the direction of our technology and tools, impacting both internal and external customers.\\nThis position offers a unique opportunity to work on Data Science projects, Python applications, and requirement analysis, based on your strengths and interests. Whether developing ML models, writing Python code, or collaborating with business partners, playing a key role in the successful delivery of projects.\\nKey responsibilities:\\nData Science: Own development of sophisticated data science and machine learning models, using large datasets to drive business decisions and data-driven strategies across the organization.</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Proud to share LSEG in the India is Great Place to Work certified (Jun ’25 – Jun ’26).\\nLearn more about life and purpose of our company directly from India colleagues’ video:\\nBengaluru, India | Where We Work | LSEG\\nThe Emerging Tech Standard Delivery Team will orchestrate adoption of new technologies and build Enterprise Solutions for D&amp;A Operations. The individual will work closely with Specialists, Operations &amp; Technology delivery teams to devise documentation of Enterprise solutions that deliver business and customer value. The individual in the role will handle partners and coordinate with teams highly proficient in machine learning, database development and front-end application engineering.\\nThe individual will be crafting and maintaining high-quality requirements documentation for various projects. This role requires a deep understanding of both the technical and business aspects of projects and communication effectively with partners at all levels.\\nRoles, Responsibilities &amp; Key Accountabilities\\nBuild clear, concise, and comprehensive requirements documents that outline project objectives, scope, functional requirements, technical specifications, and user requirements.\\nWork with business analysts, product managers, developers, and other partners to capture detailed information and understand project needs.\\nConvert requirements into functional specifications that can be understood and implemented by technical teams.\\nWrite acceptance criteria to capture specific functionalities and user interactions.\\nEnsure all requirements documents adhere to established standards and apply industry standard practices for transparency, accuracy, and consistency.\\nRegularly review and update documentation to reflect changes in project scope, requirements, or feedback from partners.\\nAssist in conducting workshops and meetings to capture requirements, resolve ambiguities, and gain consensus on project work.\\nBuild traceability matrices to trace back the requirements throughout the project lifecycle, ensuring that all requirements are met.\\nProvide support to project teams during development, testing, and implementation phases, ensuring that requirements are understood and accurately implemented.\\nParticipate in quality assurance activities to validate that the final product meets detailed requirements.</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>JOIN OUR DIVERSE TEAM! Are you eager to drive your career forward? LSEG is seeking a dedicated Data Scientist to enhance our Oil Research.\\nLSEG Oil Research is a part of global Research team of 130+ analysts committed to delivering insight and intelligence on the physical and paper commodities markets. Combining deep domain expertise, vast data resources, and the LSEG's Workspace platform, LSEG Commodities Research is a trusted partner of commodities professionals worldwide. A career with the Oil Research team presents a unique opportunity to apply existing analytical skills and develop new knowledge to better understand the production, flow, consumption and pricing of the world's crude and oil products.\\nThe Data Scientist role requires developing and analyzing market models, identifying key factors driving market trends, and using data analytics to provide strategic insights. While industry-specific experience, particularly in oil and gas, is helpful, it is not required. The ideal candidate will have a strong background in data analytic techniques, proficiency in Python, familiarity with data management and storage solutions such as Databricks or Snowflake, and a passion for using data to tackle complex business challenges.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description:\\nESG Specialist team are set of skilled and domain knowledge individuals who build and maintain the content currently covered on existing databases and test future database, tools and systems. The Specialist team drives automation and simplification to bring in efficient processes and quality of updates within ESG Operations.\\nThe successful applicant will be working in an agile environment and will work on projects to deliver automation and process simplifications solutions.\\nRoles, Responsibilities &amp; Key Accountabilities:\\nDevelop and deploy machine learning and deep learning models to solve complex problems.\\nConduct statistical analysis to identify trends, patterns, and insights.</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Senior Applied Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Role profile:\\nAre you an experienced data scientist with a passion for productionising AI solutions? Do you want to build innovative solutions for financial markets and professionals by co-developing with teams of brilliant, collaborative data scientists? If so, we’d love to talk to you!\\nRole summary:\\nAs a Senior Data Scientist, you will drive the development of high-impact, scalable AI solutions, moving beyond prototypes to production systems.\\nWe are looking for an experienced data scientist with the proven ability to manage project timelines and deliver high-quality code that aligns with business goals.\\nThe successful candidate will combine strong problem-solving skills with a collaborative approach to ensure team success.</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>LSEG (London Stock Exchange Group)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>The Emerging Tech Standard Delivery Team will orchestrate adoption of emerging technologies and build Enterprise Solutions for D&amp;A Operations. The individual will work closely with Specialists, Operations &amp; Technology delivery teams to devise Enterprise solutions that deliver business and customer value. The individual in the role will handle partners and co-ordinate with teams highly proficient in machine learning, database development and front-end application engineering. The individual needs to self-learn in areas including emerging technology, industry methods of working, financial content, and business processes used across D&amp;A teams. Beyond this, they should have a good sense of numbers, data analysis, be articulate and able to connect to the technical and non-technical people.\\nRole, Responsibilities &amp; Key Accountabilities:\\nBe responsible for the product vision for industry leading data management framework (data acquisition, cleaning, transformations, etc).</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glassdoor Est.</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  Company_Rating  \\\n",
       "20   LSEG (London Stock Exchange Group)             3.7   \n",
       "231  LSEG (London Stock Exchange Group)             3.7   \n",
       "515  LSEG (London Stock Exchange Group)             3.7   \n",
       "660  LSEG (London Stock Exchange Group)             3.7   \n",
       "674  LSEG (London Stock Exchange Group)             3.7   \n",
       "694  LSEG (London Stock Exchange Group)             3.7   \n",
       "\n",
       "                         Job_Title   Location  \\\n",
       "20           Junior Data Scientist  Bengaluru   \n",
       "231                 Data Scientist  Bengaluru   \n",
       "515          Senior Data Scientist     Mumbai   \n",
       "660          Junior Data Scientist  Bengaluru   \n",
       "674  Senior Applied Data Scientist  Bengaluru   \n",
       "694          Senior Data Scientist  Bengaluru   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Description  \\\n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          We are looking for a skilled Data Scientist to join our dynamic Analytics Centre of Excellence team. This role combines Data Science, Python development, and business analysis to deliver actionable insights and solutions that drive strategic decisions. Knowledge and experience will be put into practice to Quantitative Engineering, financial instrument pricing, and analytics to shape the direction of our technology and tools, impacting both internal and external customers.\\nThis position offers a unique opportunity to work on Data Science projects, Python applications, and requirement analysis, based on your strengths and interests. Whether developing ML models, writing Python code, or collaborating with business partners, playing a key role in the successful delivery of projects.\\nKey responsibilities:\\nData Science: Own development of sophisticated data science and machine learning models, using large datasets to drive business decisions and data-driven strategies across the organization.   \n",
       "231  Proud to share LSEG in the India is Great Place to Work certified (Jun ’25 – Jun ’26).\\nLearn more about life and purpose of our company directly from India colleagues’ video:\\nBengaluru, India | Where We Work | LSEG\\nThe Emerging Tech Standard Delivery Team will orchestrate adoption of new technologies and build Enterprise Solutions for D&A Operations. The individual will work closely with Specialists, Operations & Technology delivery teams to devise documentation of Enterprise solutions that deliver business and customer value. The individual in the role will handle partners and coordinate with teams highly proficient in machine learning, database development and front-end application engineering.\\nThe individual will be crafting and maintaining high-quality requirements documentation for various projects. This role requires a deep understanding of both the technical and business aspects of projects and communication effectively with partners at all levels.\\nRoles, Responsibilities & Key Accountabilities\\nBuild clear, concise, and comprehensive requirements documents that outline project objectives, scope, functional requirements, technical specifications, and user requirements.\\nWork with business analysts, product managers, developers, and other partners to capture detailed information and understand project needs.\\nConvert requirements into functional specifications that can be understood and implemented by technical teams.\\nWrite acceptance criteria to capture specific functionalities and user interactions.\\nEnsure all requirements documents adhere to established standards and apply industry standard practices for transparency, accuracy, and consistency.\\nRegularly review and update documentation to reflect changes in project scope, requirements, or feedback from partners.\\nAssist in conducting workshops and meetings to capture requirements, resolve ambiguities, and gain consensus on project work.\\nBuild traceability matrices to trace back the requirements throughout the project lifecycle, ensuring that all requirements are met.\\nProvide support to project teams during development, testing, and implementation phases, ensuring that requirements are understood and accurately implemented.\\nParticipate in quality assurance activities to validate that the final product meets detailed requirements.   \n",
       "515                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       JOIN OUR DIVERSE TEAM! Are you eager to drive your career forward? LSEG is seeking a dedicated Data Scientist to enhance our Oil Research.\\nLSEG Oil Research is a part of global Research team of 130+ analysts committed to delivering insight and intelligence on the physical and paper commodities markets. Combining deep domain expertise, vast data resources, and the LSEG's Workspace platform, LSEG Commodities Research is a trusted partner of commodities professionals worldwide. A career with the Oil Research team presents a unique opportunity to apply existing analytical skills and develop new knowledge to better understand the production, flow, consumption and pricing of the world's crude and oil products.\\nThe Data Scientist role requires developing and analyzing market models, identifying key factors driving market trends, and using data analytics to provide strategic insights. While industry-specific experience, particularly in oil and gas, is helpful, it is not required. The ideal candidate will have a strong background in data analytic techniques, proficiency in Python, familiarity with data management and storage solutions such as Databricks or Snowflake, and a passion for using data to tackle complex business challenges.   \n",
       "660                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Job description:\\nESG Specialist team are set of skilled and domain knowledge individuals who build and maintain the content currently covered on existing databases and test future database, tools and systems. The Specialist team drives automation and simplification to bring in efficient processes and quality of updates within ESG Operations.\\nThe successful applicant will be working in an agile environment and will work on projects to deliver automation and process simplifications solutions.\\nRoles, Responsibilities & Key Accountabilities:\\nDevelop and deploy machine learning and deep learning models to solve complex problems.\\nConduct statistical analysis to identify trends, patterns, and insights.   \n",
       "674                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Role profile:\\nAre you an experienced data scientist with a passion for productionising AI solutions? Do you want to build innovative solutions for financial markets and professionals by co-developing with teams of brilliant, collaborative data scientists? If so, we’d love to talk to you!\\nRole summary:\\nAs a Senior Data Scientist, you will drive the development of high-impact, scalable AI solutions, moving beyond prototypes to production systems.\\nWe are looking for an experienced data scientist with the proven ability to manage project timelines and deliver high-quality code that aligns with business goals.\\nThe successful candidate will combine strong problem-solving skills with a collaborative approach to ensure team success.   \n",
       "694                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The Emerging Tech Standard Delivery Team will orchestrate adoption of emerging technologies and build Enterprise Solutions for D&A Operations. The individual will work closely with Specialists, Operations & Technology delivery teams to devise Enterprise solutions that deliver business and customer value. The individual in the role will handle partners and co-ordinate with teams highly proficient in machine learning, database development and front-end application engineering. The individual needs to self-learn in areas including emerging technology, industry methods of working, financial content, and business processes used across D&A teams. Beyond this, they should have a good sense of numbers, data analysis, be articulate and able to connect to the technical and non-technical people.\\nRole, Responsibilities & Key Accountabilities:\\nBe responsible for the product vision for industry leading data management framework (data acquisition, cleaning, transformations, etc).   \n",
       "\n",
       "    Salary_Range Median_Salary   Salary_Source Salary_Range_Standardized  \\\n",
       "20       ₹10L/yr           NaN  Glassdoor Est.                   1000000   \n",
       "231      ₹10L/yr           NaN  Glassdoor Est.                   1000000   \n",
       "515         None           NaN            None                      None   \n",
       "660      ₹10L/yr           NaN  Glassdoor Est.                   1000000   \n",
       "674      ₹10L/yr           NaN  Glassdoor Est.                   1000000   \n",
       "694      ₹10L/yr           NaN  Glassdoor Est.                   1000000   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "20                   1000000.0  \n",
       "231                  1000000.0  \n",
       "515                        NaN  \n",
       "660                  1000000.0  \n",
       "674                  1000000.0  \n",
       "694                  1000000.0  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('LSEG (London Stock Exchange Group)', regex=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1b389b48-c683-40c8-8cfb-0685ddad02bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Global Cybersecurity Senior Manager - AI Architect</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Analyst, Geo Analytics, India - X Delivery</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Locations: Gurgaon | Bengaluru\\nWho We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data Engineer - Global People Analytics</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data Scientist / Senior Data Scientist, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Analyst, Geo Analytics, India - X Delivery</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Locations: Gurgaon | Bengaluru\\nWho We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data Scientist / Senior Data Scientist, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Global Audience Analytics Senior Manager</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  \\\n",
       "6    Boston Consulting Group   \n",
       "33   Boston Consulting Group   \n",
       "61   Boston Consulting Group   \n",
       "62   Boston Consulting Group   \n",
       "63   Boston Consulting Group   \n",
       "121  Boston Consulting Group   \n",
       "211  Boston Consulting Group   \n",
       "271  Boston Consulting Group   \n",
       "392  Boston Consulting Group   \n",
       "\n",
       "                                                 Job_Title  Company_Rating  \\\n",
       "6       Global Cybersecurity Senior Manager - AI Architect             4.2   \n",
       "33         AI Engineer / Senior AI Engineer, India - BCG X             4.2   \n",
       "61              Analyst, Geo Analytics, India - X Delivery             4.2   \n",
       "62                 Data Engineer - Global People Analytics             4.2   \n",
       "63         AI Engineer / Senior AI Engineer, India - BCG X             4.2   \n",
       "121  Data Scientist / Senior Data Scientist, India - BCG X             4.2   \n",
       "211             Analyst, Geo Analytics, India - X Delivery             4.2   \n",
       "271  Data Scientist / Senior Data Scientist, India - BCG X             4.2   \n",
       "392               Global Audience Analytics Senior Manager             4.2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Description  \\\n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "33   Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Locations: Gurgaon | Bengaluru\\nWho We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "63   Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "121                                                                                                                          Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "211                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Locations: Gurgaon | Bengaluru\\nWho We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "271                                                                                                                          Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "392                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "\n",
       "      Location Median_Salary_Standardized  \n",
       "6      Gurgaon                     700000  \n",
       "33     Gurgaon                     700000  \n",
       "61     Gurgaon                     700000  \n",
       "62     Gurgaon                   500000.0  \n",
       "63      Mumbai                        NaN  \n",
       "121     Mumbai                        NaN  \n",
       "211  Bengaluru                        NaN  \n",
       "271    Gurgaon                     700000  \n",
       "392    Gurgaon                     800000  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Boston Consulting Group', regex=False, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location',  'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a861b-05ff-4101-ad18-fa01736c0735",
   "metadata": {},
   "source": [
    "- Row 515 - Every job posting from the company 'LSEG' has salary estimated by glassdoor and the estimation is the same across all the roles, its better that we avoid the estimation value by glassdoor.\n",
    "- The role is a senior level role involves all the responsibilites of a ideal data scientist, lets impute the salary with 12,00,000\n",
    "<br>\n",
    "  \n",
    "- There isn't enough information in row 794, no details on skills, experience, role, responsibilites, lets drop the row.\n",
    "<br>\n",
    "- Row's 63 and 33 are excatly the same except the location, the salary can be similar for both these job postings, impute the salary of row 63 with value of 7,00,000.\n",
    "<br>\n",
    "- Again row's 121, 271 are the same job postings but in different location, lets impute the salary of row 121 with value from row 271 i.e 7,00,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c32359ed-35f3-4329-9bf5-cd745916eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[515, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.drop(794, axis=0, inplace=True)\n",
    "\n",
    "df_copy.loc[63, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[121, 'Median_Salary_Standardized'] = 700000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5de1b-61fa-48e7-a28c-829fe8c680e4",
   "metadata": {},
   "source": [
    "### Imputing missing values of jobs located in 'Pune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "6ec1b764-99af-497d-989a-7daf03d05fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>NICE Systems</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Senior Data Scientist Engineer</td>\n",
       "      <td>Pune</td>\n",
       "      <td>At NiCE, we don’t limit our challenges. We challenge our limits. Always. We’re ambitious. We’re game changers. And we play to win. We set the highest standards and execute beyond them. And if you’re like us, we can offer you the ultimate career opportunity that will light a fire within you.\\nSo, what’s the role all about?\\nThe Prompt Engineer optimizes prompts to generative AI models across NiCE's Illuminate applications. As part of the Illuminate Research team, the Prompt Engineer works with several groups in the business to help our applications deliver the highest quality customer experience.\\nThe Prompt Engineer partners with global development teams to help diagnose and resolve prompt-based issues. This includes helping to define and execute tests for LLM-based systems that are difficult to evaluate with traditional test automation tools. The Prompt Engineer also helps educate the development teams on advances in prompt engineering and helps update production prompts to evolving industry best practices.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Michelin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Senior Data Scientist\\n- - - - - - - - - - - -\\nWe are seeking a talented Senior Data Scientist of Dynamic Pricing with a passion for solving business problems through the creation and management of dynamic pricing models. In this role, you will lead the innovation and support of our dynamic pricing program, directly impacting growth, profitability, and overall efficiency. You may have the opportunity to navigate the complexities of dynamic pricing in a constantly changing market, using our rich database of millions of data points to build and maintain effective pricing strategies. The position will also be expected to mentor 1-2 data scientists.\\n\\nKey Responsibilities:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Datafortune</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Experience: 5+ Years\\nEmployment Type: Full-Time\\n\\nAbout the Role:\\nWe are looking for a highly skilled Data Scientist with a strong background in Machine Learning, Statistical Modeling, and hands-on experience working with Generative AI technologies. The ideal candidate will have deep technical expertise in agentic AI systems, RAG (Retrieval-Augmented Generation) architectures, and the ability to implement, fine-tune, and evaluate large language models such as OpenAI, LLaMA, or Cortex. This is a high-impact role where you'll be building intelligent, scalable, and context-aware AI solutions that solve real-world business problems.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company_Name  Company_Rating                       Job_Title Location  \\\n",
       "670  NICE Systems             4.2  Senior Data Scientist Engineer     Pune   \n",
       "398      Michelin             4.0           Senior Data Scientist     Pune   \n",
       "531   Datafortune             4.2           Senior Data Scientist     Pune   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Description  \\\n",
       "670  At NiCE, we don’t limit our challenges. We challenge our limits. Always. We’re ambitious. We’re game changers. And we play to win. We set the highest standards and execute beyond them. And if you’re like us, we can offer you the ultimate career opportunity that will light a fire within you.\\nSo, what’s the role all about?\\nThe Prompt Engineer optimizes prompts to generative AI models across NiCE's Illuminate applications. As part of the Illuminate Research team, the Prompt Engineer works with several groups in the business to help our applications deliver the highest quality customer experience.\\nThe Prompt Engineer partners with global development teams to help diagnose and resolve prompt-based issues. This includes helping to define and execute tests for LLM-based systems that are difficult to evaluate with traditional test automation tools. The Prompt Engineer also helps educate the development teams on advances in prompt engineering and helps update production prompts to evolving industry best practices.   \n",
       "398                                                                                                                                                                                                                                                                                                                                                          Senior Data Scientist\\n- - - - - - - - - - - -\\nWe are seeking a talented Senior Data Scientist of Dynamic Pricing with a passion for solving business problems through the creation and management of dynamic pricing models. In this role, you will lead the innovation and support of our dynamic pricing program, directly impacting growth, profitability, and overall efficiency. You may have the opportunity to navigate the complexities of dynamic pricing in a constantly changing market, using our rich database of millions of data points to build and maintain effective pricing strategies. The position will also be expected to mentor 1-2 data scientists.\\n\\nKey Responsibilities:   \n",
       "531                                                                                                                                                                                                                                                                                                                                                                                                  Experience: 5+ Years\\nEmployment Type: Full-Time\\n\\nAbout the Role:\\nWe are looking for a highly skilled Data Scientist with a strong background in Machine Learning, Statistical Modeling, and hands-on experience working with Generative AI technologies. The ideal candidate will have deep technical expertise in agentic AI systems, RAG (Retrieval-Augmented Generation) architectures, and the ability to implement, fine-tune, and evaluate large language models such as OpenAI, LLaMA, or Cortex. This is a high-impact role where you'll be building intelligent, scalable, and context-aware AI solutions that solve real-world business problems.   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "670         None           NaN          None                      None   \n",
       "398         None           NaN          None                      None   \n",
       "531         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "670                        NaN  \n",
       "398                        NaN  \n",
       "531                        NaN  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[670, 398, 531]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f79338b0-04cc-458e-b453-76bf760434a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Michelin</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist\\n- - - - - - - - - - - -\\nKEY EXPECTED ACHIEVEMENTS\\nThe business need is understood and formalized in a descriptive datasheet or specifications\\nThe methods are clearly selected by their theoretical bases, advantages and drawbacks\\nThe data, its relevance and its source are described and prioritized\\nThe data are prepared (cleaned, enriched, mapped, agregated, …) and the approach is documented\\nThe data analysis is implemented and documented\\nMachine Learning pipeline are built, tested and automatized for deployment\\nThe algorithms and models (descriptive and/or predictive) are developed and the approach is documented</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Michelin</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Senior Data Scientist\\n- - - - - - - - - - - -\\nWe are seeking a talented Senior Data Scientist of Dynamic Pricing with a passion for solving business problems through the creation and management of dynamic pricing models. In this role, you will lead the innovation and support of our dynamic pricing program, directly impacting growth, profitability, and overall efficiency. You may have the opportunity to navigate the complexities of dynamic pricing in a constantly changing market, using our rich database of millions of data points to build and maintain effective pricing strategies. The position will also be expected to mentor 1-2 data scientists.\\n\\nKey Responsibilities:</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Michelin</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Principal Data Scientist\\n- - - - - - - - - - - -\\nKEY EXPECTED ACHIEVEMENTS\\nThe need is understood and formalized in a descriptive datasheet or Cahier des Charges\\nthe methods are clearly selected by their theoretical bases, advantages and disadvantages\\nthe data, its relevance and its source are described and prioritized\\nthe data are aggregated and the approach is documented. (Key or parameter allowing to link the different sources )\\nthe analysis is implemented and documented\\nthe results of the analysis or the model are presented to the customers in the form of presentation (Pt or other) indicating the performances and the limits. The source code is delivered and explained if necessary.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Michelin</td>\n",
       "      <td>Manager - Data Scientist</td>\n",
       "      <td>Manager - Data Scientist\\n- - - - - - - - - - - -\\nRequired Skills:\\n6+ years of overall NLP/GenAI/Recommender Systems experience with considerable time spent in building enterprise grade solutions.\\nProficiency in working with large datasets and performing data preprocessing on cloud platforms.\\nPractical experience in developing generative AI applications, including prompt engineering, Retrieval-Augmented Generation (RAG) applications.\\nGood understanding of LLM concepts and fundamental. Hands-on experience in leveraging LLMs for POCs and applied problem solving and integrating it into overall solution workflow.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                 Job_Title  \\\n",
       "79      Michelin            Data Scientist   \n",
       "398     Michelin     Senior Data Scientist   \n",
       "619     Michelin  Principal Data Scientist   \n",
       "643     Michelin  Manager - Data Scientist   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Description  \\\n",
       "79                                                               Data Scientist\\n- - - - - - - - - - - -\\nKEY EXPECTED ACHIEVEMENTS\\nThe business need is understood and formalized in a descriptive datasheet or specifications\\nThe methods are clearly selected by their theoretical bases, advantages and drawbacks\\nThe data, its relevance and its source are described and prioritized\\nThe data are prepared (cleaned, enriched, mapped, agregated, …) and the approach is documented\\nThe data analysis is implemented and documented\\nMachine Learning pipeline are built, tested and automatized for deployment\\nThe algorithms and models (descriptive and/or predictive) are developed and the approach is documented   \n",
       "398                        Senior Data Scientist\\n- - - - - - - - - - - -\\nWe are seeking a talented Senior Data Scientist of Dynamic Pricing with a passion for solving business problems through the creation and management of dynamic pricing models. In this role, you will lead the innovation and support of our dynamic pricing program, directly impacting growth, profitability, and overall efficiency. You may have the opportunity to navigate the complexities of dynamic pricing in a constantly changing market, using our rich database of millions of data points to build and maintain effective pricing strategies. The position will also be expected to mentor 1-2 data scientists.\\n\\nKey Responsibilities:   \n",
       "619  Principal Data Scientist\\n- - - - - - - - - - - -\\nKEY EXPECTED ACHIEVEMENTS\\nThe need is understood and formalized in a descriptive datasheet or Cahier des Charges\\nthe methods are clearly selected by their theoretical bases, advantages and disadvantages\\nthe data, its relevance and its source are described and prioritized\\nthe data are aggregated and the approach is documented. (Key or parameter allowing to link the different sources )\\nthe analysis is implemented and documented\\nthe results of the analysis or the model are presented to the customers in the form of presentation (Pt or other) indicating the performances and the limits. The source code is delivered and explained if necessary.   \n",
       "643                                                                                  Manager - Data Scientist\\n- - - - - - - - - - - -\\nRequired Skills:\\n6+ years of overall NLP/GenAI/Recommender Systems experience with considerable time spent in building enterprise grade solutions.\\nProficiency in working with large datasets and performing data preprocessing on cloud platforms.\\nPractical experience in developing generative AI applications, including prompt engineering, Retrieval-Augmented Generation (RAG) applications.\\nGood understanding of LLM concepts and fundamental. Hands-on experience in leveraging LLMs for POCs and applied problem solving and integrating it into overall solution workflow.   \n",
       "\n",
       "     Company_Rating Median_Salary_Standardized  \n",
       "79              4.0                        NaN  \n",
       "398             4.0                        NaN  \n",
       "619             4.0                     900000  \n",
       "643             4.0                     900000  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Michelin', regex=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Description', 'Company_Rating', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e151f7e5-02ee-4a72-9e26-b2125020e75c",
   "metadata": {},
   "source": [
    "- Row 670's job title is Senior Data Scientist Engineer but the actual job is about Prompt Engineering which involves optimizing the responses, results of generative AI/LLMs, it is an on demand role and also it is in senior level, so the pay should be higher, lets impute the salary with value of 8,00,000.\n",
    "<br>\n",
    "\n",
    "- Row 398 can be imputed by using the informations from other job postings from the same company 'Michelin'. The salary for manager and principal level roles is 900000, obviously the salary for Senior Data Scientist and Data Scientist will be lower than that, we can impute the salary of row 398 with 900000 and for row 79 we can impute with 700000.\n",
    "<br>\n",
    "\n",
    "- Row 531 requires a candidate with 5+ years of experience and skills in Machine Learning, Statistical Modeling, and hands-on experience working with Generative AI technologies and expertise in agentic AI systems, RAG, this role involves both generaic ML skills as well as on demand AI skills therefore the pay has to be higher as the role involves AI agents. Lets impute the salary with 1200000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "a36ef551-7291-4640-8344-a7a45a7fa74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[670, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[398, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[79,  'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[531, 'Median_Salary_Standardized'] = 1200000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4809520-94e1-4bdd-b51e-658fb321c41e",
   "metadata": {},
   "source": [
    "### Imputing missing values of jobs located in 'Remote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "18e85c94-23cd-4db5-ba9a-e2d13a25a6d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>QuantumBricks</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Job Summary:\\nWe are seeking a highly motivated and analytical Data Scientist to join our team. In this role, you will be responsible for transforming raw data into actionable insights that drive strategic decisions and innovation. You will work closely with cross-functional teams to develop data-driven solutions, predictive models, and visualizations that inform business operations and strategy.\\nKey Responsibilities:\\nAnalyze large, complex datasets to identify trends, patterns, and actionable insights.\\nBuild, validate, and deploy predictive models and machine learning algorithms.\\nCommunicate findings clearly through visualizations, dashboards, and reports.\\nCollaborate with product, engineering, and business teams to integrate models into products or workflows.</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Akhilav Technologies LLP</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Senior Data Scientist\\nExperience: 7 Years | Location: Remote\\nAn experienced Data Scientist with a strong focus on AI/ML pipeline design, LLM integration, and cloud-based data systems, ready to contribute to cutting-edge projects.\\nKey Skills &amp; Expertise:\\nData Ingestion &amp; Transformation using Azure Data Lake and Cosmos DB\\nVector Embeddings &amp; Semantic Search with Azure AI Search, LangChain, and FAISS\\nImplementation of RAG Pipelines to enhance domain-specific LLM responses\\nDocument Chunking &amp; Metadata Tagging for efficient knowledge structuring\\nSeamless Knowledge Base Integration for dynamic LLM interaction</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1080000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Arch Systems, LLC</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Job Title: AI Data Scientist (Full-Time)\\nWork Hours: 6:30 PM to 3:30 AM IST\\nLocation: Remote (India)\\nStart Date: Immediate Joiners Preferred\\nAbout the Role:\\nWe are looking for a highly skilled and experienced AI Data Scientist to join our team full-time. This is a senior-level position requiring hands-on expertise in building AI/ML models, data analytics, and deploying data-driven solutions. The role operates during US business hours (India time: 6:30 PM IST – 3:30 AM IST).\\nKey Responsibilities:\\nDesign, develop, and deploy machine learning and AI models to solve complex business problems</td>\n",
       "      <td>Remote</td>\n",
       "      <td>520000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company_Name              Job_Title  Company_Rating  \\\n",
       "43              QuantumBricks  Senior Data Scientist             4.7   \n",
       "259  Akhilav Technologies LLP  Senior Data Scientist             3.9   \n",
       "476         Arch Systems, LLC  Senior Data Scientist             4.2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Description  \\\n",
       "43   Job Summary:\\nWe are seeking a highly motivated and analytical Data Scientist to join our team. In this role, you will be responsible for transforming raw data into actionable insights that drive strategic decisions and innovation. You will work closely with cross-functional teams to develop data-driven solutions, predictive models, and visualizations that inform business operations and strategy.\\nKey Responsibilities:\\nAnalyze large, complex datasets to identify trends, patterns, and actionable insights.\\nBuild, validate, and deploy predictive models and machine learning algorithms.\\nCommunicate findings clearly through visualizations, dashboards, and reports.\\nCollaborate with product, engineering, and business teams to integrate models into products or workflows.   \n",
       "259                                                                                                                                                                Senior Data Scientist\\nExperience: 7 Years | Location: Remote\\nAn experienced Data Scientist with a strong focus on AI/ML pipeline design, LLM integration, and cloud-based data systems, ready to contribute to cutting-edge projects.\\nKey Skills & Expertise:\\nData Ingestion & Transformation using Azure Data Lake and Cosmos DB\\nVector Embeddings & Semantic Search with Azure AI Search, LangChain, and FAISS\\nImplementation of RAG Pipelines to enhance domain-specific LLM responses\\nDocument Chunking & Metadata Tagging for efficient knowledge structuring\\nSeamless Knowledge Base Integration for dynamic LLM interaction   \n",
       "476                                                                                                                                                                                 Job Title: AI Data Scientist (Full-Time)\\nWork Hours: 6:30 PM to 3:30 AM IST\\nLocation: Remote (India)\\nStart Date: Immediate Joiners Preferred\\nAbout the Role:\\nWe are looking for a highly skilled and experienced AI Data Scientist to join our team full-time. This is a senior-level position requiring hands-on expertise in building AI/ML models, data analytics, and deploying data-driven solutions. The role operates during US business hours (India time: 6:30 PM IST – 3:30 AM IST).\\nKey Responsibilities:\\nDesign, develop, and deploy machine learning and AI models to solve complex business problems   \n",
       "\n",
       "    Location Median_Salary_Standardized  \n",
       "43    Remote                    1600000  \n",
       "259   Remote                  1080000.0  \n",
       "476   Remote                   520000.0  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].notna() &\n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('Remote', regex=False, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9170cad0-6d47-4bc9-a8da-d3d9d6d407aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5x Data</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.8</td>\n",
       "      <td>At 5X, we help companies organize their data and make it actionable. Founded by engineers who built data platforms at hypergrowth companies, we saw first-hand the complexity and fragmentation plaguing modern data stacks. That’s why we created 5X — an end-to-end data and AI platform that unifies data tooling, streamlines operations, and empowers teams to build with data without drowning in integrations and vendor sprawl.\\nResponsibilities\\nUnderstand and analyse client's business requirements to design and implement effective data solutions.\\nCreate and optimize data models to support client reporting and analytics needs.\\nProactively communicate with clients to provide project updates and address any issues or concerns.\\nComfortable to travel to meet customers in the US and go deeper on projects</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>fifthnote</td>\n",
       "      <td>Senior Data scientist (Remote)</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Position Summary\\nResponsible for designing, developing, and implementing advanced AI/ML models to solve business problems related to Revenue Cycle operations for US based healthcare Systems.\\n\\nExperience 2-5 years of relevant experience building AI/ML models and rich experience in python, R and SAS, NLP experience is preferred\\n\\nReports To Director- Analytics\\n\\nQualification Holds degree in Computer Science, Math or other Science, Preferred-Master's Degree</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Senior Data Scientist I\\nAre you interested in working with data and analytics to solve problems?\\n\\nAre you interested in bringing your Gen AI, Machine Learning and NLP expertise to projects?\\n\\nAbout our Team:\\nData Science Health Content Operations team works with a focus on Generative AI, Machine Learning, Natural Language Processing, and Statistical techniques. It helps in building state of the art applications for the health sciences domain.\\n\\nAbout the Role:</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>RELX</td>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Senior Data Scientist I\\nAre you interested in working with data and analytics to solve problems?\\n\\nAre you interested in bringing your Gen AI, Machine Learning and NLP expertise to projects?\\n\\nAbout our Team:\\nData Science Health Content Operations team works with a focus on Generative AI, Machine Learning, Natural Language Processing, and Statistical techniques. It helps in building state of the art applications for the health sciences domain.\\n\\nAbout the Role:</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>InApp</td>\n",
       "      <td>AI/ML Engineer (Senior Data Scientist/AI Engineer)</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Experience: 7-10 years\\n\\nJob Responsibilities\\nDevelop, train, optimize, and deploy ML/Deep Learning/Generative AI models.\\nBuild end-to-end pipelines for model development, training, and deployment.\\nOptimize model inference for production usage, ensuring scalability and efficiency.\\nCollaborate with stakeholders to define business problems and design AI solutions.\\nWrite high-quality, maintainable code following best engineering practices. Required Qualifications, Capabilities, And Skills\\nBachelors or Master’s degree in Data Science, ML, or AI.\\n7+ years of experience working as a Data Scientist or AI/ML Engineer.\\nExpertise in NLP, Transformers, Large Language Models (LLMs), and the Hugging\\nFace library.\\nExperience optimizing LLM training and inference performance.\\nProficiency in at least one deep learning framework (PyTorch, TensorFlow, Keras).\\nStrong programming skills in Python, with experience in ML frameworks such as\\nscikit-learn.\\nExperience with deploying ML models in production and working with cloud-based AI\\nsolutions (AWS, GCP, Azure).\\nStrong understanding of ML operations (MLOps), including CI/CD for ML workflows.\\nAbility to document technical solutions and communicate effectively with stakeholders.</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                                           Job_Title  \\\n",
       "97       5x Data                               Senior Data Scientist   \n",
       "291    fifthnote                      Senior Data scientist (Remote)   \n",
       "369     Elsevier                             Senior Data Scientist I   \n",
       "376         RELX                             Senior Data Scientist I   \n",
       "677        InApp  AI/ML Engineer (Senior Data Scientist/AI Engineer)   \n",
       "\n",
       "     Company_Rating  \\\n",
       "97              4.8   \n",
       "291             4.3   \n",
       "369             4.0   \n",
       "376             4.0   \n",
       "677             4.4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Description  \\\n",
       "97                                                                                                                                                                                                                                                                                                                                                                                                                                                       At 5X, we help companies organize their data and make it actionable. Founded by engineers who built data platforms at hypergrowth companies, we saw first-hand the complexity and fragmentation plaguing modern data stacks. That’s why we created 5X — an end-to-end data and AI platform that unifies data tooling, streamlines operations, and empowers teams to build with data without drowning in integrations and vendor sprawl.\\nResponsibilities\\nUnderstand and analyse client's business requirements to design and implement effective data solutions.\\nCreate and optimize data models to support client reporting and analytics needs.\\nProactively communicate with clients to provide project updates and address any issues or concerns.\\nComfortable to travel to meet customers in the US and go deeper on projects   \n",
       "291                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Position Summary\\nResponsible for designing, developing, and implementing advanced AI/ML models to solve business problems related to Revenue Cycle operations for US based healthcare Systems.\\n\\nExperience 2-5 years of relevant experience building AI/ML models and rich experience in python, R and SAS, NLP experience is preferred\\n\\nReports To Director- Analytics\\n\\nQualification Holds degree in Computer Science, Math or other Science, Preferred-Master's Degree   \n",
       "369                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Senior Data Scientist I\\nAre you interested in working with data and analytics to solve problems?\\n\\nAre you interested in bringing your Gen AI, Machine Learning and NLP expertise to projects?\\n\\nAbout our Team:\\nData Science Health Content Operations team works with a focus on Generative AI, Machine Learning, Natural Language Processing, and Statistical techniques. It helps in building state of the art applications for the health sciences domain.\\n\\nAbout the Role:   \n",
       "376                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Senior Data Scientist I\\nAre you interested in working with data and analytics to solve problems?\\n\\nAre you interested in bringing your Gen AI, Machine Learning and NLP expertise to projects?\\n\\nAbout our Team:\\nData Science Health Content Operations team works with a focus on Generative AI, Machine Learning, Natural Language Processing, and Statistical techniques. It helps in building state of the art applications for the health sciences domain.\\n\\nAbout the Role:   \n",
       "677  Experience: 7-10 years\\n\\nJob Responsibilities\\nDevelop, train, optimize, and deploy ML/Deep Learning/Generative AI models.\\nBuild end-to-end pipelines for model development, training, and deployment.\\nOptimize model inference for production usage, ensuring scalability and efficiency.\\nCollaborate with stakeholders to define business problems and design AI solutions.\\nWrite high-quality, maintainable code following best engineering practices. Required Qualifications, Capabilities, And Skills\\nBachelors or Master’s degree in Data Science, ML, or AI.\\n7+ years of experience working as a Data Scientist or AI/ML Engineer.\\nExpertise in NLP, Transformers, Large Language Models (LLMs), and the Hugging\\nFace library.\\nExperience optimizing LLM training and inference performance.\\nProficiency in at least one deep learning framework (PyTorch, TensorFlow, Keras).\\nStrong programming skills in Python, with experience in ML frameworks such as\\nscikit-learn.\\nExperience with deploying ML models in production and working with cloud-based AI\\nsolutions (AWS, GCP, Azure).\\nStrong understanding of ML operations (MLOps), including CI/CD for ML workflows.\\nAbility to document technical solutions and communicate effectively with stakeholders.   \n",
       "\n",
       "    Location Median_Salary_Standardized  \n",
       "97    Remote                        NaN  \n",
       "291   Remote                        NaN  \n",
       "369   Remote                        NaN  \n",
       "376   Remote                        NaN  \n",
       "677   Remote                        NaN  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna() &\n",
    "        df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Location'].str.contains('Remote', regex=False, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "26655518-f30b-4864-a0e5-1f0c5aeb7334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Data Scientist III</td>\n",
       "      <td>Data Scientist III\\nAre you interested in working with data Engineers and analytics to solve problems?\\nAre you interested in bringing and building up your NLP and (gen) AI expertise to projects?\\nAbout our team:\\nIn RDP, we are describing the world of scientific research as accurately as possible by profiling a wide range of entities, from People and Organizations to research artefacts such as Publications and Grants all the way to topics and concepts that characterize what research is about. Our entity-linking and disambiguation systems integrate data from a diverse set of sources that include millions of research articles to demonstrate market leading performance. The RDP team is large, full of talented people, and highly cross-functional and collaborative: As a data scientist, you will be working together with software engineers, analysts, product managers, and architects on selected areas of focus, and be part of the wider RDP Data Science team.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Senior Data Scientist I\\nAre you interested in working with data and analytics to solve problems?\\n\\nAre you interested in bringing your Gen AI, Machine Learning and NLP expertise to projects?\\n\\nAbout our Team:\\nData Science Health Content Operations team works with a focus on Generative AI, Machine Learning, Natural Language Processing, and Statistical techniques. It helps in building state of the art applications for the health sciences domain.\\n\\nAbout the Role:</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                Job_Title  \\\n",
       "173     Elsevier       Data Scientist III   \n",
       "369     Elsevier  Senior Data Scientist I   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Description  \\\n",
       "173  Data Scientist III\\nAre you interested in working with data Engineers and analytics to solve problems?\\nAre you interested in bringing and building up your NLP and (gen) AI expertise to projects?\\nAbout our team:\\nIn RDP, we are describing the world of scientific research as accurately as possible by profiling a wide range of entities, from People and Organizations to research artefacts such as Publications and Grants all the way to topics and concepts that characterize what research is about. Our entity-linking and disambiguation systems integrate data from a diverse set of sources that include millions of research articles to demonstrate market leading performance. The RDP team is large, full of talented people, and highly cross-functional and collaborative: As a data scientist, you will be working together with software engineers, analysts, product managers, and architects on selected areas of focus, and be part of the wider RDP Data Science team.   \n",
       "369                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Senior Data Scientist I\\nAre you interested in working with data and analytics to solve problems?\\n\\nAre you interested in bringing your Gen AI, Machine Learning and NLP expertise to projects?\\n\\nAbout our Team:\\nData Science Health Content Operations team works with a focus on Generative AI, Machine Learning, Natural Language Processing, and Statistical techniques. It helps in building state of the art applications for the health sciences domain.\\n\\nAbout the Role:   \n",
       "\n",
       "     Company_Rating Median_Salary_Standardized  \n",
       "173             4.0                   700000.0  \n",
       "369             4.0                        NaN  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Elsevier', regex=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Description', 'Company_Rating', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e433de68-0e41-4086-a01b-4ec8b2f3a708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>InApp</td>\n",
       "      <td>AI/ML Engineer (Senior Data Scientist/AI Engineer)</td>\n",
       "      <td>Experience: 7-10 years\\n\\nJob Responsibilities\\nDevelop, train, optimize, and deploy ML/Deep Learning/Generative AI models.\\nBuild end-to-end pipelines for model development, training, and deployment.\\nOptimize model inference for production usage, ensuring scalability and efficiency.\\nCollaborate with stakeholders to define business problems and design AI solutions.\\nWrite high-quality, maintainable code following best engineering practices. Required Qualifications, Capabilities, And Skills\\nBachelors or Master’s degree in Data Science, ML, or AI.\\n7+ years of experience working as a Data Scientist or AI/ML Engineer.\\nExpertise in NLP, Transformers, Large Language Models (LLMs), and the Hugging\\nFace library.\\nExperience optimizing LLM training and inference performance.\\nProficiency in at least one deep learning framework (PyTorch, TensorFlow, Keras).\\nStrong programming skills in Python, with experience in ML frameworks such as\\nscikit-learn.\\nExperience with deploying ML models in production and working with cloud-based AI\\nsolutions (AWS, GCP, Azure).\\nStrong understanding of ML operations (MLOps), including CI/CD for ML workflows.\\nAbility to document technical solutions and communicate effectively with stakeholders.</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>InApp</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Experience: 4-7 years\\n\\nJob Responsibilities\\nBuild and maintain data pipelines for data acquisition, cleaning, and augmentation.\\nDevelop and implement data visualization tools to track model performance and key business metrics.\\nAnalyze large-scale datasets to extract insights and provide recommendations for model improvements.\\nWork with stakeholders to understand business requirements and translate them into data-driven solutions.\\nSupport the model evaluation process by generating reports and dashboards.\\nAssist in data preparation and exploration to improve the quality of training datasets. Required Qualifications, Capabilities, And Skills\\nBachelor’s or Master’s degree in Data Science, Statistics, or a related field.\\n3+ years of experience in data analysis, reporting, and visualization.\\nProficiency in Python or R, with experience using pandas, NumPy, and other data manipulation libraries.\\nStrong understanding of statistical concepts and experience with ML libraries such as scikit-learn and statsmodels.\\nExperience with SQL for data extraction and manipulation.\\nFamiliarity with business intelligence tools (e.g., Tableau, Power BI).\\nStrong problem-solving and analytical skills.\\nAbility to communicate technical insights effectively to non-technical stakeholders. Preferred Qualifications\\nExperience with cloud platforms such as AWS, GCP, or Azure\\nKnowledge of data engineering concepts and ETL pipelines. Note\\nMarked in Bold are must-have skills.\\nAnything more than a 60% match can be considered.\\nPreferred qualifications are just good to have. Will be a great value add.</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                                           Job_Title  \\\n",
       "677        InApp  AI/ML Engineer (Senior Data Scientist/AI Engineer)   \n",
       "753        InApp                                        Data Analyst   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Description  \\\n",
       "677                                                                                                                                                                                                                                                                                                                                                                                Experience: 7-10 years\\n\\nJob Responsibilities\\nDevelop, train, optimize, and deploy ML/Deep Learning/Generative AI models.\\nBuild end-to-end pipelines for model development, training, and deployment.\\nOptimize model inference for production usage, ensuring scalability and efficiency.\\nCollaborate with stakeholders to define business problems and design AI solutions.\\nWrite high-quality, maintainable code following best engineering practices. Required Qualifications, Capabilities, And Skills\\nBachelors or Master’s degree in Data Science, ML, or AI.\\n7+ years of experience working as a Data Scientist or AI/ML Engineer.\\nExpertise in NLP, Transformers, Large Language Models (LLMs), and the Hugging\\nFace library.\\nExperience optimizing LLM training and inference performance.\\nProficiency in at least one deep learning framework (PyTorch, TensorFlow, Keras).\\nStrong programming skills in Python, with experience in ML frameworks such as\\nscikit-learn.\\nExperience with deploying ML models in production and working with cloud-based AI\\nsolutions (AWS, GCP, Azure).\\nStrong understanding of ML operations (MLOps), including CI/CD for ML workflows.\\nAbility to document technical solutions and communicate effectively with stakeholders.   \n",
       "753  Experience: 4-7 years\\n\\nJob Responsibilities\\nBuild and maintain data pipelines for data acquisition, cleaning, and augmentation.\\nDevelop and implement data visualization tools to track model performance and key business metrics.\\nAnalyze large-scale datasets to extract insights and provide recommendations for model improvements.\\nWork with stakeholders to understand business requirements and translate them into data-driven solutions.\\nSupport the model evaluation process by generating reports and dashboards.\\nAssist in data preparation and exploration to improve the quality of training datasets. Required Qualifications, Capabilities, And Skills\\nBachelor’s or Master’s degree in Data Science, Statistics, or a related field.\\n3+ years of experience in data analysis, reporting, and visualization.\\nProficiency in Python or R, with experience using pandas, NumPy, and other data manipulation libraries.\\nStrong understanding of statistical concepts and experience with ML libraries such as scikit-learn and statsmodels.\\nExperience with SQL for data extraction and manipulation.\\nFamiliarity with business intelligence tools (e.g., Tableau, Power BI).\\nStrong problem-solving and analytical skills.\\nAbility to communicate technical insights effectively to non-technical stakeholders. Preferred Qualifications\\nExperience with cloud platforms such as AWS, GCP, or Azure\\nKnowledge of data engineering concepts and ETL pipelines. Note\\nMarked in Bold are must-have skills.\\nAnything more than a 60% match can be considered.\\nPreferred qualifications are just good to have. Will be a great value add.   \n",
       "\n",
       "     Company_Rating Location Median_Salary_Standardized  \n",
       "677             4.4   Remote                        NaN  \n",
       "753             4.4   Remote                        NaN  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('InApp', regex=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Description', 'Company_Rating', 'Location', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccd91d-3d61-4dc6-81cd-01132750e99b",
   "metadata": {},
   "source": [
    "- Row 97's job posting involves understanding client's requirements and creating data solutions to meet their needs, the role also involved travelling to US to meet with clients and solve their problems/needs, remote jobs mostly tend to pay higher plus this role involves travelling to US so the pay mush be real good, lets impute the salary with 2000000\n",
    "<br>\n",
    "\n",
    "- Row 291 this role requires 2-5 years of experience, expertise in building AI/ML models and rich experience in python, R and SAS, NLP and the candidate will be reporting To Director- Analytics, lets impute the salary with 1200000\n",
    "<br>\n",
    "\n",
    "- Row 369, using information from similar job posting, lets impute the salary with 1000000\n",
    "<br>\n",
    "\n",
    "- Row 376, the job posting is in health care domain and no experience is mentioned, skills required as advanced level data science skills, lets impute the salary with value of 800000\n",
    "<br>\n",
    "\n",
    "- Row 677 seems like an advanced AI/ML role which requires skills in ML and AI/LLM models, MLOps, cloud platforms and requires 7+ years of experience, the pay has to be around 3000000.\n",
    "- Row 753, impute the missing value with 900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "12424ddc-6d9d-4066-9643-3680142ef1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[97, 'Median_Salary_Standardized'] = 2000000\n",
    "\n",
    "df_copy.loc[291, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[369, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[376, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[677, 'Median_Salary_Standardized'] = 3000000\n",
    "\n",
    "df_copy.loc[753, 'Median_Salary_Standardized'] = 900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "c06648db-a8ed-4590-98ec-5e225c72262b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Kraft Heinz Company</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>All Posting Locations: Ahmedabad, Gujarat, IN\\nJob Functions: Global Business Services\\nDate Published: April 29, 2025\\nRef#: R-89849\\n\\nABOUT THE ROLE\\nJob Description\\nThe Data Scientist – Operations will play a key role in transforming operational processes through advanced analytics and data-driven decision-making. This role focuses on optimizing supply chain, manufacturing, and overall operations by developing predictive models, streamlining workflows, and uncovering insights to enhance efficiency and reduce costs.</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Company_Name              Job_Title  \\\n",
       "675  Kraft Heinz Company  Senior Data Scientist   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Description  \\\n",
       "675  All Posting Locations: Ahmedabad, Gujarat, IN\\nJob Functions: Global Business Services\\nDate Published: April 29, 2025\\nRef#: R-89849\\n\\nABOUT THE ROLE\\nJob Description\\nThe Data Scientist – Operations will play a key role in transforming operational processes through advanced analytics and data-driven decision-making. This role focuses on optimizing supply chain, manufacturing, and overall operations by developing predictive models, streamlining workflows, and uncovering insights to enhance efficiency and reduce costs.   \n",
       "\n",
       "     Company_Rating Median_Salary_Standardized  \n",
       "675             3.6                        NaN  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()][[\n",
    "    'Company_Name', 'Job_Title', 'Description', 'Company_Rating', 'Median_Salary_Standardized'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "e663f185-1eff-44db-86ea-eda653c482c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[675, 'Median_Salary_Standardized'] = 600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7773401c-7e0b-4e55-883a-311f9a7dda59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company_Name, Job_Title, Description, Company_Rating, Median_Salary_Standardized]\n",
       "Index: []"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains('Senior|Sr|Staff', regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()][[\n",
    "    'Company_Name', 'Job_Title', 'Description', 'Company_Rating', 'Median_Salary_Standardized'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a88e0da-74e5-4e8d-9c32-63e9904a05ca",
   "metadata": {},
   "source": [
    "## Imputing missing values of Median_Salary of 'Manager+' level job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "1f247251-694f-4488-b0e0-7aaed65e04a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains('Manager|Principal|Lead', regex=True, na=False)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "15281e38-db79-4ce3-a9df-91493ff954d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Enabling Areas - DEC - Manager - Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Texas Instruments</td>\n",
       "      <td>Principal Data Scientist (Demand Forecasting)</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Citi</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Careers at Tide</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>WPP Media</td>\n",
       "      <td>Manager - Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Tracxn Technologies</td>\n",
       "      <td>Leadership - Head of Data &amp; AI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Lead AI or ML Engineer</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Novartis</td>\n",
       "      <td>Senior Principal Data Scientist, CADD</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>EY</td>\n",
       "      <td>Data Scientist - Senior Manager</td>\n",
       "      <td>3.7</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>AI Lead - L1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Innovaccer Analytics</td>\n",
       "      <td>2885-Lead Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Noida</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Branch International</td>\n",
       "      <td>Data and Reporting Lead</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company_Name                                        Job_Title  \\\n",
       "26               Deloitte  Enabling Areas - DEC - Manager - Data Scientist   \n",
       "375     Texas Instruments    Principal Data Scientist (Demand Forecasting)   \n",
       "462                  Citi                              Lead Data Scientist   \n",
       "466       Careers at Tide                              Lead Data Scientist   \n",
       "664             WPP Media                         Manager - Data Scientist   \n",
       "742   Tracxn Technologies                   Leadership - Head of Data & AI   \n",
       "32                  Optum                           Lead AI or ML Engineer   \n",
       "653              Novartis            Senior Principal Data Scientist, CADD   \n",
       "522                    EY                  Data Scientist - Senior Manager   \n",
       "708         Wipro Limited                                     AI Lead - L1   \n",
       "423  Innovaccer Analytics                         2885-Lead Data Scientist   \n",
       "442  Branch International                          Data and Reporting Lead   \n",
       "\n",
       "     Company_Rating   Location Salary_Range Median_Salary  \\\n",
       "26              3.8  Bengaluru         None           NaN   \n",
       "375             4.3  Bengaluru         None           NaN   \n",
       "462             3.7  Bengaluru         None           NaN   \n",
       "466             4.5  Bengaluru         None           NaN   \n",
       "664             3.4  Bengaluru         None           NaN   \n",
       "742             3.0  Bengaluru         None           NaN   \n",
       "32              3.5    Gurgaon         None           NaN   \n",
       "653             4.0  Hyderābād         None           NaN   \n",
       "522             3.7      India         None           NaN   \n",
       "708             3.6      India         None           NaN   \n",
       "423             3.4      Noida         None           NaN   \n",
       "442             4.0     Remote         None           NaN   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "26                         NaN  \n",
       "375                        NaN  \n",
       "462                        NaN  \n",
       "466                        NaN  \n",
       "664                        NaN  \n",
       "742                        NaN  \n",
       "32                         NaN  \n",
       "653                     800000  \n",
       "522                     800000  \n",
       "708                        NaN  \n",
       "423                        NaN  \n",
       "442                        NaN  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range_Standardized'].isna() & \n",
    "        df_copy['Job_Title'].str.contains('Manager|Principal|Lead', regex=True, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "        ]].sort_values(by='Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a7802c9a-43d4-42f9-9fae-4da9b0712c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Enabling Areas - DEC - Manager - Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Job requisition ID :: 77946\\nDate: Jul 13, 2025\\nLocation: Bengaluru\\nDesignation: Manager\\nEntity: Deloitte Touche Tohmatsu India LLP\\nYour potential, unleashed.\\n\\nIndia’s impact on the global economy has increased at an exponential rate and Deloitte presents an opportunity to unleash and realise your potential amongst cutting edge leaders, and organisations shaping the future of the region, and indeed, the world beyond.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>GENERATIVE AI – DATA SCIENTIST (Machine Learning Scientist) - HYD</td>\n",
       "      <td>3.8</td>\n",
       "      <td>GENERATIVE AI – DATA SCIENTIST (Machine Learning Scientist)\\nDo you want to make an impact with generative AI, fun and challenges included? Join the Tax and Legal\\nDigit@l Asset Factory!\\nThe vision of the Digit@l Asset Factory is to enable the Tax &amp; Legal practice to become the undisputed digital leader in Belgium, regionally and globally.\\nThe team supports this vision by leveraging (GEN AI &amp; cloud) technology to create innovative solutions that differentiate us from competition through increased efficiency and an end-to-end globally consistent digital experience.\\nYour Profile\\nDegree in Computer Science, Data Science, Machine Learning, or related field.</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company_Name  \\\n",
       "26     Deloitte   \n",
       "41     Deloitte   \n",
       "\n",
       "                                                            Job_Title  \\\n",
       "26                    Enabling Areas - DEC - Manager - Data Scientist   \n",
       "41  GENERATIVE AI – DATA SCIENTIST (Machine Learning Scientist) - HYD   \n",
       "\n",
       "    Company_Rating  \\\n",
       "26             3.8   \n",
       "41             3.8   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Description  \\\n",
       "26                                                                                                                                                                                                                                                 Job requisition ID :: 77946\\nDate: Jul 13, 2025\\nLocation: Bengaluru\\nDesignation: Manager\\nEntity: Deloitte Touche Tohmatsu India LLP\\nYour potential, unleashed.\\n\\nIndia’s impact on the global economy has increased at an exponential rate and Deloitte presents an opportunity to unleash and realise your potential amongst cutting edge leaders, and organisations shaping the future of the region, and indeed, the world beyond.   \n",
       "41  GENERATIVE AI – DATA SCIENTIST (Machine Learning Scientist)\\nDo you want to make an impact with generative AI, fun and challenges included? Join the Tax and Legal\\nDigit@l Asset Factory!\\nThe vision of the Digit@l Asset Factory is to enable the Tax & Legal practice to become the undisputed digital leader in Belgium, regionally and globally.\\nThe team supports this vision by leveraging (GEN AI & cloud) technology to create innovative solutions that differentiate us from competition through increased efficiency and an end-to-end globally consistent digital experience.\\nYour Profile\\nDegree in Computer Science, Data Science, Machine Learning, or related field.   \n",
       "\n",
       "     Location Median_Salary_Standardized  \n",
       "26  Bengaluru                        NaN  \n",
       "41  Hyderābād                     800000  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Deloitte')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "0323dfe1-3686-482b-9af6-c087b2a11497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Texas Instruments</td>\n",
       "      <td>Principal Data Scientist (Demand Forecasting)</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Change the world. Love your job.\\nTexas Instruments is seeking experienced Data Scientist to join our team. As the Data Scientist in TI's Demand Analytics team, you will play a pivotal role in shaping and executing our demand planning and inventory buffer strategies for the company. You will be working side by side with a team of highly technical professionals that will consists of application developers, system architects, data scientists and data engineers. This role will be responsible for solving complex business problems through innovative solutions that deliver tangible business value. This position requires a technical leader with a strong technical background in AI/ML, simulation solutions, strategic thinking, and a passion for innovation through data. This team is responsible for: portfolio management for demand forecasting algorithms, generation of inventory buffer targets, segmentation of TI's products and simulation/validation frameworks, defining specs/reference architectures to best achieve business outcomes and ensuring security and interoperability between capabilities.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Texas Instruments</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Change the world. Love your job.\\nTexas Instruments (TI) is out front and ready for the next big challenge. Our innovations are at the core of nearly every electronics product in use today. And it doesn't stop there. We're developing breakthrough technology to power the world's future innovations as well. TI is committed to building a better future — from the responsible manufacturing of our semiconductors, to caring for our employees, to giving back inside our communities. Put your talent to work with us.\\n\\nThis is a great opportunity to be part of an established team that's continuing to look for growth opportunities, working with worldwide leading customers and developing cutting edge solutions in the areas of consumer electronics, mobile computing and communications.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Company_Name                                      Job_Title  \\\n",
       "375  Texas Instruments  Principal Data Scientist (Demand Forecasting)   \n",
       "433  Texas Instruments                              Sr Data Scientist   \n",
       "\n",
       "     Company_Rating  \\\n",
       "375             4.3   \n",
       "433             4.3   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Description  \\\n",
       "375  Change the world. Love your job.\\nTexas Instruments is seeking experienced Data Scientist to join our team. As the Data Scientist in TI's Demand Analytics team, you will play a pivotal role in shaping and executing our demand planning and inventory buffer strategies for the company. You will be working side by side with a team of highly technical professionals that will consists of application developers, system architects, data scientists and data engineers. This role will be responsible for solving complex business problems through innovative solutions that deliver tangible business value. This position requires a technical leader with a strong technical background in AI/ML, simulation solutions, strategic thinking, and a passion for innovation through data. This team is responsible for: portfolio management for demand forecasting algorithms, generation of inventory buffer targets, segmentation of TI's products and simulation/validation frameworks, defining specs/reference architectures to best achieve business outcomes and ensuring security and interoperability between capabilities.   \n",
       "433                                                                                                                                                                                                                                                                                                                                  Change the world. Love your job.\\nTexas Instruments (TI) is out front and ready for the next big challenge. Our innovations are at the core of nearly every electronics product in use today. And it doesn't stop there. We're developing breakthrough technology to power the world's future innovations as well. TI is committed to building a better future — from the responsible manufacturing of our semiconductors, to caring for our employees, to giving back inside our communities. Put your talent to work with us.\\n\\nThis is a great opportunity to be part of an established team that's continuing to look for growth opportunities, working with worldwide leading customers and developing cutting edge solutions in the areas of consumer electronics, mobile computing and communications.   \n",
       "\n",
       "      Location Salary_Range_Standardized Median_Salary_Standardized  \n",
       "375  Bengaluru                      None                        NaN  \n",
       "433  Bengaluru                   1000000                  1000000.0  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Texas Instruments')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Salary_Range_Standardized', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "4ea166b1-566b-40ad-8ddd-f8d2497166de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Citi</td>\n",
       "      <td>Data Scientist/Machine Learning Engineer (AVP)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\\nJob Description:\\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\\nTechnology\\nApplications Development\\nFull time\\nPlease see the requirements listed above.\\nData Science, Machine Learning.</td>\n",
       "      <td>Pune</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Citi</td>\n",
       "      <td>Data Science Analyst 2 - C10 - CHENNAI</td>\n",
       "      <td>3.7</td>\n",
       "      <td>The Data Science Analyst 2 is a developing professional role. Applies specialty area knowledge in monitoring, assessing, analyzing and/or evaluating processes and data. Identifies policy gaps and formulates policies. Interprets data and makes recommendations. Researches and interprets factual information. Identifies inconsistencies in data or results, defines business issues and formulates recommendations on policies, procedures or practices. Integrates established disciplinary knowledge within own specialty area with basic understanding of related industry practices. Good understanding of how the team interacts with others in accomplishing the objectives of the area. Develops working knowledge of industry practices and standards. Limited but direct impact on the business through the quality of the tasks/services provided. Impact of the job holder is restricted to own team.\\n\\nResponsibilities:\\n\\n\\n\\nTechnology\\nData Science\\nFull time\\nPlease see the requirements listed above.\\nFor complementary skills, please see above and/or contact the recruiter.</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Citi</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>The Spec Analytics Intmd Analyst is a developing professional role. Deals with most problems independently and has some latitude to solve complex problems. Integrates in-depth specialty area knowledge with a solid understanding of industry standards and practices. Good understanding of how the team and area integrate with others in accomplishing the objectives of the sub function/ job family. Applies analytical thinking and knowledge of data analysis tools and methodologies. Requires attention to detail when making judgments and recommendations based on the analysis of factual information. Typically deals with variable issues with potentially broader business impact. Applies professional judgment when interpreting data and results. Breaks down information in a systematic and communicable manner. Developed communication and diplomacy skills are required in order to exchange potentially complex/sensitive information. Moderate but direct impact through close contact with the businesses' core activities. Quality and timeliness of service provided will affect the effectiveness of own team and other closely related teams.\\n\\n\\n\\n\\nDecision Management\\nSpecialized Analytics (Data Science/Computational Statistics)\\nFull time\\nPlease see the requirements listed above.\\nFor complementary skills, please see above and/or contact the recruiter.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Citi</td>\n",
       "      <td>C12 - AVP Data Scientist - PUNE</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Job Description\\nCiti Analytics &amp; Information Management (AIM) team is a global community that objectively connects and analyzes information to create actionable intelligence for our business leaders. It identifies fact-based opportunities for revenue growth and expense reduction in partnership with the businesses. The role of C12 (Individual Contributor) AVP is within Fraud Analytics team in Citi AIM. The primary area of focus for this position is to analyze transaction data, understand fraud pattern , develop fraud loss mitigation strategies with the objective of overall business goal of minimizing fraud losses as well as minimizing customer impact. The person will also be responsible for monitoring strategy performance, collaborate with strategy implementation team for strategy implementation, proactively come up with fraud loss mitigation measure leveraging new data sources, advanced analytics techniques wherever applicable.\\nJob Description Summary:\\n\\n\\nDecision Management\\nSpecialized Analytics (Data Science/Computational Statistics)\\nFull time\\nPlease see the requirements listed above.\\nFor complementary skills, please see above and/or contact the recruiter.</td>\n",
       "      <td>Pune</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                                       Job_Title  \\\n",
       "60          Citi  Data Scientist/Machine Learning Engineer (AVP)   \n",
       "367         Citi          Data Science Analyst 2 - C10 - CHENNAI   \n",
       "462         Citi                             Lead Data Scientist   \n",
       "584         Citi                 C12 - AVP Data Scientist - PUNE   \n",
       "\n",
       "     Company_Rating  \\\n",
       "60              3.7   \n",
       "367             3.7   \n",
       "462             3.7   \n",
       "584             3.7   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description  \\\n",
       "60   ML Solutions team within Markets OPS Technology is dedicated to developing solutions using Artificial Intelligence, Machine Learning and Generative AI. This team is a leader in creating new ideas, innovative technology solutions, and ground-breaking solutions for Markets Operations and Other Line of Businesses. We work closely with our clients and business partners to progress solutions from ideation to production by leveraging the entrepreneurial spirit and technological excellence.\\nJob Description:\\nThe ML Solutions team is seeking a Data Scientist/Machine Learning Engineer to drive the design, development, and deployment of innovative AI/ML and GenAI-based solutions. In this hands-on role, you will leverage your expertise to create a variety of AI models, guiding a team from initial concept to successful production. A key aspect involves mentoring team members and fostering their growth. You will collaborate closely with business partners and stakeholders, championing the adoption of these advanced technologies to enhance client experiences, deliver tangible value to our customers, and ensure adherence to regulatory requirements through cutting-edge technical solutions. This position offers a unique opportunity to shape the future of our AI initiatives and make a significant impact on the organization.\\nTechnology\\nApplications Development\\nFull time\\nPlease see the requirements listed above.\\nData Science, Machine Learning.   \n",
       "367                                                                                                                                                                                                                                                                                                                                                                                                   The Data Science Analyst 2 is a developing professional role. Applies specialty area knowledge in monitoring, assessing, analyzing and/or evaluating processes and data. Identifies policy gaps and formulates policies. Interprets data and makes recommendations. Researches and interprets factual information. Identifies inconsistencies in data or results, defines business issues and formulates recommendations on policies, procedures or practices. Integrates established disciplinary knowledge within own specialty area with basic understanding of related industry practices. Good understanding of how the team interacts with others in accomplishing the objectives of the area. Develops working knowledge of industry practices and standards. Limited but direct impact on the business through the quality of the tasks/services provided. Impact of the job holder is restricted to own team.\\n\\nResponsibilities:\\n\\n\\n\\nTechnology\\nData Science\\nFull time\\nPlease see the requirements listed above.\\nFor complementary skills, please see above and/or contact the recruiter.   \n",
       "462                                                                                                     The Spec Analytics Intmd Analyst is a developing professional role. Deals with most problems independently and has some latitude to solve complex problems. Integrates in-depth specialty area knowledge with a solid understanding of industry standards and practices. Good understanding of how the team and area integrate with others in accomplishing the objectives of the sub function/ job family. Applies analytical thinking and knowledge of data analysis tools and methodologies. Requires attention to detail when making judgments and recommendations based on the analysis of factual information. Typically deals with variable issues with potentially broader business impact. Applies professional judgment when interpreting data and results. Breaks down information in a systematic and communicable manner. Developed communication and diplomacy skills are required in order to exchange potentially complex/sensitive information. Moderate but direct impact through close contact with the businesses' core activities. Quality and timeliness of service provided will affect the effectiveness of own team and other closely related teams.\\n\\n\\n\\n\\nDecision Management\\nSpecialized Analytics (Data Science/Computational Statistics)\\nFull time\\nPlease see the requirements listed above.\\nFor complementary skills, please see above and/or contact the recruiter.   \n",
       "584                                                                                                                                                                                                                                                                              Job Description\\nCiti Analytics & Information Management (AIM) team is a global community that objectively connects and analyzes information to create actionable intelligence for our business leaders. It identifies fact-based opportunities for revenue growth and expense reduction in partnership with the businesses. The role of C12 (Individual Contributor) AVP is within Fraud Analytics team in Citi AIM. The primary area of focus for this position is to analyze transaction data, understand fraud pattern , develop fraud loss mitigation strategies with the objective of overall business goal of minimizing fraud losses as well as minimizing customer impact. The person will also be responsible for monitoring strategy performance, collaborate with strategy implementation team for strategy implementation, proactively come up with fraud loss mitigation measure leveraging new data sources, advanced analytics techniques wherever applicable.\\nJob Description Summary:\\n\\n\\nDecision Management\\nSpecialized Analytics (Data Science/Computational Statistics)\\nFull time\\nPlease see the requirements listed above.\\nFor complementary skills, please see above and/or contact the recruiter.   \n",
       "\n",
       "      Location Median_Salary_Standardized  \n",
       "60        Pune                     400000  \n",
       "367    Chennai                     600000  \n",
       "462  Bengaluru                        NaN  \n",
       "584       Pune                        NaN  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Citi')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "efe30786-701d-44f1-acae-4c862830e15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Careers at Tide</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ABOUT TIDE\\nAt Tide, we are building a business management platform designed to save small businesses time and money. We provide our members with business accounts and related banking services, but also a comprehensive set of connected administrative solutions from invoicing to accounting.\\n\\nLaunched in 2017, Tide is now used by over 1 million small businesses across the world and is available to UK, Indian and German SMEs. Headquartered in central London, with offices in Sofia, Hyderabad, Delhi, Berlin and Belgrade, Tide employs over 2,000 employees.\\n\\nTide is rapidly growing, expanding into new products and markets and always looking for passionate and driven people. Join us in our mission to empower small businesses and help them save time and money.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Careers at Tide</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>ABOUT TIDE\\nAt Tide, we are building a business management platform designed to save small businesses time and money. We provide our members with business accounts and related banking services, but also a comprehensive set of connected administrative solutions from invoicing to accounting.\\n\\nLaunched in 2017, Tide is now used by over 1 million small businesses across the world and is available to UK, Indian and German SMEs. Headquartered in central London, with offices in Sofia, Hyderabad, Delhi, Berlin and Belgrade, Tide employs over 2,000 employees.\\n\\nTide is rapidly growing, expanding into new products and markets and always looking for passionate and driven people. Join us in our mission to empower small businesses and help them save time and money.</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Company_Name             Job_Title  Company_Rating  \\\n",
       "466  Careers at Tide   Lead Data Scientist             4.5   \n",
       "616  Careers at Tide  Staff Data Scientist             4.5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Description  \\\n",
       "466  ABOUT TIDE\\nAt Tide, we are building a business management platform designed to save small businesses time and money. We provide our members with business accounts and related banking services, but also a comprehensive set of connected administrative solutions from invoicing to accounting.\\n\\nLaunched in 2017, Tide is now used by over 1 million small businesses across the world and is available to UK, Indian and German SMEs. Headquartered in central London, with offices in Sofia, Hyderabad, Delhi, Berlin and Belgrade, Tide employs over 2,000 employees.\\n\\nTide is rapidly growing, expanding into new products and markets and always looking for passionate and driven people. Join us in our mission to empower small businesses and help them save time and money.   \n",
       "616  ABOUT TIDE\\nAt Tide, we are building a business management platform designed to save small businesses time and money. We provide our members with business accounts and related banking services, but also a comprehensive set of connected administrative solutions from invoicing to accounting.\\n\\nLaunched in 2017, Tide is now used by over 1 million small businesses across the world and is available to UK, Indian and German SMEs. Headquartered in central London, with offices in Sofia, Hyderabad, Delhi, Berlin and Belgrade, Tide employs over 2,000 employees.\\n\\nTide is rapidly growing, expanding into new products and markets and always looking for passionate and driven people. Join us in our mission to empower small businesses and help them save time and money.   \n",
       "\n",
       "      Location Median_Salary_Standardized  \n",
       "466  Bengaluru                        NaN  \n",
       "616  Hyderābād                     600000  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Careers at Tide')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "916e5b0e-95f1-4039-9581-ab9b97575edb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.</td>\n",
       "      <td>Noida</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Senior Data Scientist - AIML</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nApply advanced statistical techniques, data science methodologies, and AI practices, including generative AI using GPT models\\nDesign, develop, and implement cutting-edge generative AI models and systems</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Director AI/ML Engineer</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together\\nOptum is seeking a highly skilled Director of Software Engineering to join our dynamic team. You will work on cutting-edge Generative AI technology projects to solve complex business problems across the company. You are a strong leader with skills and a foundation in software engineering, cloud infrastructure, and cloud-native system design.\\nPrimary Responsibilities:</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.</td>\n",
       "      <td>Noida</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Lead AI or ML Engineer</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nWe are seeking a highly skilled and experienced Data Scientist to join our team based in Bangalore. As a Data Scientist, you will play a critical role in developing and implementing AI/ML solutions. You will be responsible for utilizing your expertise in Python, SQL, and various frameworks like Scikit Learn, TensorFlow, and PyTorch to deliver production-grade AI/ML projects. The ideal candidate will have 2+ years of experience in Data Science, AI/ML, and a solid understanding of mathematical and statistical concepts. Experience in the US Healthcare domain and knowledge of Big Data and data streaming technologies are desirable.</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Senior AI or ML Engineer</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nDevelop and Deploy ML Models: Code and develop software that deploys machine learning models and algorithms into production environments, with a focus on healthcare applications\\nCommunication: Present complex analytics results and concepts to leadership and internal stakeholders in a clear and concise manner</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nDeveloping end-to-end pipeline for different document processing use cases\\nConnecting with business for requirement gathering and status updates\\nMaintaining accuracy of the work delivered</td>\n",
       "      <td>Noida</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Optum</td>\n",
       "      <td>Associate Data Scientist - AI or ML, SQL, Python, Snowflake</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nPrimary Responsibilities:\\nConducting data analysis using SQL and Python to extract insights from large data sets\\nConducting exploratory data analysis to identify trends, patterns, and insights from data</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                                                    Job_Title  \\\n",
       "0          Optum                                        Senior Data Scientist   \n",
       "1          Optum                                 Senior Data Scientist - AIML   \n",
       "2          Optum                                      Director AI/ML Engineer   \n",
       "30         Optum                                               Data Scientist   \n",
       "32         Optum                                       Lead AI or ML Engineer   \n",
       "34         Optum                                     Senior AI or ML Engineer   \n",
       "180        Optum                                     Associate Data Scientist   \n",
       "570        Optum  Associate Data Scientist - AI or ML, SQL, Python, Snowflake   \n",
       "\n",
       "     Company_Rating  \\\n",
       "0               3.5   \n",
       "1               3.5   \n",
       "2               3.5   \n",
       "30              3.5   \n",
       "32              3.5   \n",
       "34              3.5   \n",
       "180             3.5   \n",
       "570             3.5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Description  \\\n",
       "0                                                                                                                                        Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                          Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nApply advanced statistical techniques, data science methodologies, and AI practices, including generative AI using GPT models\\nDesign, develop, and implement cutting-edge generative AI models and systems   \n",
       "2                                                                                                                                                                                                                                                                       Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together\\nOptum is seeking a highly skilled Director of Software Engineering to join our dynamic team. You will work on cutting-edge Generative AI technology projects to solve complex business problems across the company. You are a strong leader with skills and a foundation in software engineering, cloud infrastructure, and cloud-native system design.\\nPrimary Responsibilities:   \n",
       "30                                                                                                                                       Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.   \n",
       "32   Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nWe are seeking a highly skilled and experienced Data Scientist to join our team based in Bangalore. As a Data Scientist, you will play a critical role in developing and implementing AI/ML solutions. You will be responsible for utilizing your expertise in Python, SQL, and various frameworks like Scikit Learn, TensorFlow, and PyTorch to deliver production-grade AI/ML projects. The ideal candidate will have 2+ years of experience in Data Science, AI/ML, and a solid understanding of mathematical and statistical concepts. Experience in the US Healthcare domain and knowledge of Big Data and data streaming technologies are desirable.   \n",
       "34                                                                                                                                                                                                                                                                                                              Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nDevelop and Deploy ML Models: Code and develop software that deploys machine learning models and algorithms into production environments, with a focus on healthcare applications\\nCommunication: Present complex analytics results and concepts to leadership and internal stakeholders in a clear and concise manner   \n",
       "180                                                                                                                                                                                                                                                                                                                                                                                                                                      Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nDeveloping end-to-end pipeline for different document processing use cases\\nConnecting with business for requirement gathering and status updates\\nMaintaining accuracy of the work delivered   \n",
       "570                                                                                                                                                                                                                                                                                                                                                                                                                                                Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nPrimary Responsibilities:\\nConducting data analysis using SQL and Python to extract insights from large data sets\\nConducting exploratory data analysis to identify trends, patterns, and insights from data   \n",
       "\n",
       "      Location Median_Salary_Standardized  \n",
       "0        Noida                     400000  \n",
       "1      Gurgaon                     400000  \n",
       "2    Bengaluru                     500000  \n",
       "30       Noida                     400000  \n",
       "32     Gurgaon                        NaN  \n",
       "34   Bengaluru                     500000  \n",
       "180      Noida                     400000  \n",
       "570    Gurgaon                     400000  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Optum')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "8b3d690e-48c7-419d-be74-dc61867733bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>Data Scientist - L3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\\nJob Description\\nRole Purpose\\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions.\\n͏\\nDo\\n\\n\\n\\n\\nMandatory Skills: Data Science.\\nExperience: 3-5 Years.\\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹2L – ₹8L/yr</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>AI Lead - L1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\\nJob Description\\nRole Purpose\\nThe purpose of this role is to develop minimum viable product (MVP) and comprehensive AI solutions that meet and exceed client’s expectations and add value to business.\\n\\n\\n\\n\\n\\n\\n\\nMandatory Skills: Data Science.\\nExperience: 5-8 Years.\\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>Data Scientist Lead - L1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\\nJob Description\\nRole Purpose\\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions\\n͏\\nDo\\n\\n\\n\\n\\nMandatory Skills: Data Science.\\nExperience: 5-8 Years.\\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹2L – ₹8L/yr</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company_Name                 Job_Title  Company_Rating  \\\n",
       "267  Wipro Limited       Data Scientist - L3             3.6   \n",
       "708  Wipro Limited              AI Lead - L1             3.6   \n",
       "826  Wipro Limited  Data Scientist Lead - L1             3.6   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description  \\\n",
       "267                                                                  Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\\nJob Description\\nRole Purpose\\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions.\\n͏\\nDo\\n\\n\\n\\n\\nMandatory Skills: Data Science.\\nExperience: 3-5 Years.\\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.   \n",
       "708  Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\\nJob Description\\nRole Purpose\\nThe purpose of this role is to develop minimum viable product (MVP) and comprehensive AI solutions that meet and exceed client’s expectations and add value to business.\\n\\n\\n\\n\\n\\n\\n\\nMandatory Skills: Data Science.\\nExperience: 5-8 Years.\\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.   \n",
       "826                                                                   Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\\nJob Description\\nRole Purpose\\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions\\n͏\\nDo\\n\\n\\n\\n\\nMandatory Skills: Data Science.\\nExperience: 5-8 Years.\\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.   \n",
       "\n",
       "      Location  Salary_Range  Median_Salary Median_Salary_Standardized  \n",
       "267  Bengaluru  ₹2L – ₹8L/yr  ₹4L/yr Median                     400000  \n",
       "708      India          None            NaN                        NaN  \n",
       "826  Bengaluru  ₹2L – ₹8L/yr  ₹4L/yr Median                     400000  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Wipro Limited')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "edac3384-15b6-489e-8c06-4cd1fac1f4f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Innovaccer Analytics</td>\n",
       "      <td>2885-Lead Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Your Role\\nThe technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.\\nData is our bread and butter for innovation. We are looking for a Staff Data Scientist who understands healthcare data and can leverage the data to build algorithms to personalize treatments based on the clinical and behavioral history of patients. We are looking for a superstar who will define and build the next generation of predictive analytics tools in healthcare.\\nAnalytics at Innovaccer\\nOur analytics team is dedicated to weaving analytics and data science magics across our products. They are the owners and custodians of intelligence behind our products. With their expertise and innovative approach, they play a crucial role in building various analytical models (including descriptive, predictive, and prescriptive) to help our end-users make smart decisions. Their focus on continuous improvement and cutting-edge methodologies ensures that they're always creating market leading solutions that propel our products to new heights of success</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Innovaccer Analytics</td>\n",
       "      <td>3124-Senior Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Analytics at Innovaccer\\n\\nOur analytics team is dedicated to weaving analytics and data science magics across our products. They are the owners and custodians of intelligence behind our products. With their expertise and innovative approach, they play a crucial role in building various analytical models (including descriptive, predictive, and prescriptive) to help our end-users make smart decisions. Their focus on continuous improvement and cutting-edge methodologies ensures that they're always creating market leading solutions that propel our products to new heights of success. If analytics is your game, then this team is just the right place for you.\\nThe technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.</td>\n",
       "      <td>Noida</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Innovaccer Analytics</td>\n",
       "      <td>3123-Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Analytics at Innovaccer\\n\\nOur analytics team is dedicated to weaving analytics and data science magics across our products. They are the owners and custodians of intelligence behind our products. With their expertise and innovative approach, they play a crucial role in building various analytical models (including descriptive, predictive, and prescriptive) to help our end-users make smart decisions. Their focus on continuous improvement and cutting-edge methodologies ensures that they're always creating market leading solutions that propel our products to new heights of success. If analytics is your game, then this team is just the right place for you.\\nThe technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.</td>\n",
       "      <td>Noida</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company_Name                   Job_Title  Company_Rating  \\\n",
       "423  Innovaccer Analytics    2885-Lead Data Scientist             3.4   \n",
       "468  Innovaccer Analytics  3124-Senior Data Scientist             3.4   \n",
       "796  Innovaccer Analytics         3123-Data Scientist             3.4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Description  \\\n",
       "423  Your Role\\nThe technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.\\nData is our bread and butter for innovation. We are looking for a Staff Data Scientist who understands healthcare data and can leverage the data to build algorithms to personalize treatments based on the clinical and behavioral history of patients. We are looking for a superstar who will define and build the next generation of predictive analytics tools in healthcare.\\nAnalytics at Innovaccer\\nOur analytics team is dedicated to weaving analytics and data science magics across our products. They are the owners and custodians of intelligence behind our products. With their expertise and innovative approach, they play a crucial role in building various analytical models (including descriptive, predictive, and prescriptive) to help our end-users make smart decisions. Their focus on continuous improvement and cutting-edge methodologies ensures that they're always creating market leading solutions that propel our products to new heights of success   \n",
       "468                                                                                                                                                                                                                                                                                                                   Analytics at Innovaccer\\n\\nOur analytics team is dedicated to weaving analytics and data science magics across our products. They are the owners and custodians of intelligence behind our products. With their expertise and innovative approach, they play a crucial role in building various analytical models (including descriptive, predictive, and prescriptive) to help our end-users make smart decisions. Their focus on continuous improvement and cutting-edge methodologies ensures that they're always creating market leading solutions that propel our products to new heights of success. If analytics is your game, then this team is just the right place for you.\\nThe technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.   \n",
       "796                                                                                                                                                                                                                                                                                                                   Analytics at Innovaccer\\n\\nOur analytics team is dedicated to weaving analytics and data science magics across our products. They are the owners and custodians of intelligence behind our products. With their expertise and innovative approach, they play a crucial role in building various analytical models (including descriptive, predictive, and prescriptive) to help our end-users make smart decisions. Their focus on continuous improvement and cutting-edge methodologies ensures that they're always creating market leading solutions that propel our products to new heights of success. If analytics is your game, then this team is just the right place for you.\\nThe technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.   \n",
       "\n",
       "    Location Median_Salary_Standardized  \n",
       "423    Noida                        NaN  \n",
       "468    Noida                     500000  \n",
       "796    Noida                     500000  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Innovaccer Analytics')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "bf9e343a-1bb3-4957-8b4f-213abcefa877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Branch International</td>\n",
       "      <td>Data and Reporting Lead</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Branch Overview\\nBranch delivers world-class financial services to the mobile generation. With offices in the United States, Nigeria, Kenya, and India, Branch is a for-profit socially conscious company that uses the power of data science to reduce the cost of delivering financial services in emerging markets. We believe that everyone everywhere deserves fair financial access. The rapid spread of smartphones presents an opportunity for the world’s emerging middle class to access banking options and achieve financial flexibility.\\nBranch’s mission-driven team is led by the founder and former CEO of Kiva.org. The company presents a rich opportunity for our team members to drive meaningful growth in rapidly evolving and changing markets. In 2019, Branch announced its Series C and has garnered more than $100M in funding with investments from leading Silicon Valley firms including Andreessen Horowitz, Trinity Capital, Foundation Capital, Visa, and the International Finance Corporation (IFC).</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company_Name                Job_Title  Company_Rating  \\\n",
       "442  Branch International  Data and Reporting Lead             4.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Description  \\\n",
       "442  Branch Overview\\nBranch delivers world-class financial services to the mobile generation. With offices in the United States, Nigeria, Kenya, and India, Branch is a for-profit socially conscious company that uses the power of data science to reduce the cost of delivering financial services in emerging markets. We believe that everyone everywhere deserves fair financial access. The rapid spread of smartphones presents an opportunity for the world’s emerging middle class to access banking options and achieve financial flexibility.\\nBranch’s mission-driven team is led by the founder and former CEO of Kiva.org. The company presents a rich opportunity for our team members to drive meaningful growth in rapidly evolving and changing markets. In 2019, Branch announced its Series C and has garnered more than $100M in funding with investments from leading Silicon Valley firms including Andreessen Horowitz, Trinity Capital, Foundation Capital, Visa, and the International Finance Corporation (IFC).   \n",
       "\n",
       "    Location Median_Salary_Standardized  \n",
       "442   Remote                        NaN  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Branch International')][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "460870ce-f191-40fe-9f4f-10a64ba2885f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>WPP Media</td>\n",
       "      <td>Manager - Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Our UK team aspires to build an offshore hub in India to work alongside the UK team. We need an experienced professional to build and lead the practice, with a focus on the modelling elements of MMM. Reporting the Director of the Data Science &amp; Modelling in the India Hub this is an exciting opportunity to set up and shape a market leading MMM unit.\\nWe envisage the initial months will be focused on establishing a cohesive team that are set up to work together as a unit, and smoothly with the UK team. There will be a big focus on training and processes to make the partnership work. Over this period, as the team grows, we will start to transition MMM projects across to the India hub, but with dual responsibilities for delivery across both the India hub and UK team.\\nOnce established, our ambition is to run a significant proportion of our MMM work out of the India hub, notably for the Data and Modelling elements of the MMM project cycles. The India hub Account Lead (Modelling) will focus on providing best practice modelling to support the delivery of MMM analytics.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Tracxn Technologies</td>\n",
       "      <td>Leadership - Head of Data &amp; AI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Job Description\\nScale AI-Driven Operations | Build Intelligent Data Systems | Lead with Innovation\\nAre you a forward-thinking leader passionate about harnessing AI to transform data operations at scale? Do you excel at building structured, high-quality data pipelines that power real-world business decisions? If you're looking to take end-to-end ownership of AI-first data workflows in a global SaaS platform, Tracxn is where your vision becomes impact.\\nLocation: Bangalore, India (Work from Office)\\nJob Type: Full-time\\nAbout Tracxn\\nTracxn is a leading market intelligence platform tracking over millions of private companies globally across industries. Our clients include Venture Capital firms, Private Equity funds, Investment Banks, and Corporates who rely on us for actionable insights and data. As a tech-first company, we are constantly evolving our capabilities in AI and automation to redefine data quality, scale, and delivery.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Innovaccer Analytics</td>\n",
       "      <td>2885-Lead Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Your Role\\nThe technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.\\nData is our bread and butter for innovation. We are looking for a Staff Data Scientist who understands healthcare data and can leverage the data to build algorithms to personalize treatments based on the clinical and behavioral history of patients. We are looking for a superstar who will define and build the next generation of predictive analytics tools in healthcare.\\nAnalytics at Innovaccer\\nOur analytics team is dedicated to weaving analytics and data science magics across our products. They are the owners and custodians of intelligence behind our products. With their expertise and innovative approach, they play a crucial role in building various analytical models (including descriptive, predictive, and prescriptive) to help our end-users make smart decisions. Their focus on continuous improvement and cutting-edge methodologies ensures that they're always creating market leading solutions that propel our products to new heights of success</td>\n",
       "      <td>Noida</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Branch International</td>\n",
       "      <td>Data and Reporting Lead</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Branch Overview\\nBranch delivers world-class financial services to the mobile generation. With offices in the United States, Nigeria, Kenya, and India, Branch is a for-profit socially conscious company that uses the power of data science to reduce the cost of delivering financial services in emerging markets. We believe that everyone everywhere deserves fair financial access. The rapid spread of smartphones presents an opportunity for the world’s emerging middle class to access banking options and achieve financial flexibility.\\nBranch’s mission-driven team is led by the founder and former CEO of Kiva.org. The company presents a rich opportunity for our team members to drive meaningful growth in rapidly evolving and changing markets. In 2019, Branch announced its Series C and has garnered more than $100M in funding with investments from leading Silicon Valley firms including Andreessen Horowitz, Trinity Capital, Foundation Capital, Visa, and the International Finance Corporation (IFC).</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company_Name                       Job_Title  Company_Rating  \\\n",
       "664             WPP Media        Manager - Data Scientist             3.4   \n",
       "742   Tracxn Technologies  Leadership - Head of Data & AI             3.0   \n",
       "423  Innovaccer Analytics        2885-Lead Data Scientist             3.4   \n",
       "442  Branch International         Data and Reporting Lead             4.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Description  \\\n",
       "664                                                                                                                                                                                Our UK team aspires to build an offshore hub in India to work alongside the UK team. We need an experienced professional to build and lead the practice, with a focus on the modelling elements of MMM. Reporting the Director of the Data Science & Modelling in the India Hub this is an exciting opportunity to set up and shape a market leading MMM unit.\\nWe envisage the initial months will be focused on establishing a cohesive team that are set up to work together as a unit, and smoothly with the UK team. There will be a big focus on training and processes to make the partnership work. Over this period, as the team grows, we will start to transition MMM projects across to the India hub, but with dual responsibilities for delivery across both the India hub and UK team.\\nOnce established, our ambition is to run a significant proportion of our MMM work out of the India hub, notably for the Data and Modelling elements of the MMM project cycles. The India hub Account Lead (Modelling) will focus on providing best practice modelling to support the delivery of MMM analytics.   \n",
       "742                                                                                                                                                                                                                                                                                                                      Job Description\\nScale AI-Driven Operations | Build Intelligent Data Systems | Lead with Innovation\\nAre you a forward-thinking leader passionate about harnessing AI to transform data operations at scale? Do you excel at building structured, high-quality data pipelines that power real-world business decisions? If you're looking to take end-to-end ownership of AI-first data workflows in a global SaaS platform, Tracxn is where your vision becomes impact.\\nLocation: Bangalore, India (Work from Office)\\nJob Type: Full-time\\nAbout Tracxn\\nTracxn is a leading market intelligence platform tracking over millions of private companies globally across industries. Our clients include Venture Capital firms, Private Equity funds, Investment Banks, and Corporates who rely on us for actionable insights and data. As a tech-first company, we are constantly evolving our capabilities in AI and automation to redefine data quality, scale, and delivery.   \n",
       "423  Your Role\\nThe technology that once promised to simplify patient care has brought more issues than anyone ever anticipated. At Innovaccer, we defeat this beast by making full use of all the data Healthcare has worked so hard to collect, and replacing long-standing problems with ideal solutions.\\nData is our bread and butter for innovation. We are looking for a Staff Data Scientist who understands healthcare data and can leverage the data to build algorithms to personalize treatments based on the clinical and behavioral history of patients. We are looking for a superstar who will define and build the next generation of predictive analytics tools in healthcare.\\nAnalytics at Innovaccer\\nOur analytics team is dedicated to weaving analytics and data science magics across our products. They are the owners and custodians of intelligence behind our products. With their expertise and innovative approach, they play a crucial role in building various analytical models (including descriptive, predictive, and prescriptive) to help our end-users make smart decisions. Their focus on continuous improvement and cutting-edge methodologies ensures that they're always creating market leading solutions that propel our products to new heights of success   \n",
       "442                                                                                                                                                                                                                                                              Branch Overview\\nBranch delivers world-class financial services to the mobile generation. With offices in the United States, Nigeria, Kenya, and India, Branch is a for-profit socially conscious company that uses the power of data science to reduce the cost of delivering financial services in emerging markets. We believe that everyone everywhere deserves fair financial access. The rapid spread of smartphones presents an opportunity for the world’s emerging middle class to access banking options and achieve financial flexibility.\\nBranch’s mission-driven team is led by the founder and former CEO of Kiva.org. The company presents a rich opportunity for our team members to drive meaningful growth in rapidly evolving and changing markets. In 2019, Branch announced its Series C and has garnered more than $100M in funding with investments from leading Silicon Valley firms including Andreessen Horowitz, Trinity Capital, Foundation Capital, Visa, and the International Finance Corporation (IFC).   \n",
       "\n",
       "      Location Salary_Range Median_Salary Median_Salary_Standardized  \n",
       "664  Bengaluru         None           NaN                        NaN  \n",
       "742  Bengaluru         None           NaN                        NaN  \n",
       "423      Noida         None           NaN                        NaN  \n",
       "442     Remote         None           NaN                        NaN  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[664, 742, 423, 442], [\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ee77d609-50d6-43c7-ba8d-c551ada398f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>Infineon Technologies</td>\n",
       "      <td>Manager Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>₹3L – ₹4L/yr</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Allstate</td>\n",
       "      <td>Data Scientist Associate Manager</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹9L – ₹10L/yr</td>\n",
       "      <td>₹9L/yr Median</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Lead Data Scientist- ML</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹6L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>XO Health Inc.</td>\n",
       "      <td>Lead AI Scientist</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹35L – ₹40L/yr</td>\n",
       "      <td>₹38L/yr Median</td>\n",
       "      <td>3800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Target</td>\n",
       "      <td>Lead Data Scientist- Operations Research</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹4L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Axcess Tech Systems</td>\n",
       "      <td>Data Science Lead</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹22L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>Data Scientist Lead - L1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹2L – ₹8L/yr</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Onity Group Inc.</td>\n",
       "      <td>Manager, Data Scientist and Machine Learning Engineer</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>₹1L – ₹3L/yr</td>\n",
       "      <td>₹2L/yr Median</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>Ideas2IT Technologies</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>₹10L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Zuora</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>₹5L – ₹8L/yr</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>TVS Motor Company</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>₹6L – ₹9L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>RECPRO TECHNOLOGIES</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>₹20L – ₹30L/yr</td>\n",
       "      <td>₹25L/yr Median</td>\n",
       "      <td>2500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Global Audience Analytics Senior Manager</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Klook</td>\n",
       "      <td>Manager, Data Scientist, Pricing Strategy</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>₹5L – ₹10L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>KPMG</td>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>₹5L – ₹9L/yr</td>\n",
       "      <td>₹6L/yr Median</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Global Cybersecurity Senior Manager - AI Architect</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>₹6L – ₹8L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Reckitt</td>\n",
       "      <td>IT&amp;D Data Scientist &amp; Analytics Manager</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>₹9L – ₹10L/yr</td>\n",
       "      <td>₹9L/yr Median</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Anblicks</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>₹6L – ₹8L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BP Energy</td>\n",
       "      <td>Data Scientist Manager</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Pune</td>\n",
       "      <td>₹7L – ₹9L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Michelin</td>\n",
       "      <td>Manager - Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>₹9L – ₹10L/yr</td>\n",
       "      <td>₹9L/yr Median</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Michelin</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>₹9L – ₹10L/yr</td>\n",
       "      <td>₹9L/yr Median</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>₹7L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  \\\n",
       "685    Infineon Technologies   \n",
       "671                 Allstate   \n",
       "648        Fractal Analytics   \n",
       "646           XO Health Inc.   \n",
       "758                   Target   \n",
       "618      Axcess Tech Systems   \n",
       "826            Wipro Limited   \n",
       "457         Onity Group Inc.   \n",
       "525    Ideas2IT Technologies   \n",
       "744                    Zuora   \n",
       "93         TVS Motor Company   \n",
       "650      RECPRO TECHNOLOGIES   \n",
       "392  Boston Consulting Group   \n",
       "292                    Klook   \n",
       "149                     KPMG   \n",
       "6    Boston Consulting Group   \n",
       "532                  Reckitt   \n",
       "673                 Anblicks   \n",
       "3                  BP Energy   \n",
       "643                 Michelin   \n",
       "619                 Michelin   \n",
       "699                NielsenIQ   \n",
       "\n",
       "                                                 Job_Title  Company_Rating  \\\n",
       "685                                 Manager Data Scientist             4.0   \n",
       "671                       Data Scientist Associate Manager             3.4   \n",
       "648                                Lead Data Scientist- ML             4.2   \n",
       "646                                      Lead AI Scientist             1.0   \n",
       "758               Lead Data Scientist- Operations Research             4.2   \n",
       "618                                      Data Science Lead             4.2   \n",
       "826                               Data Scientist Lead - L1             3.6   \n",
       "457  Manager, Data Scientist and Machine Learning Engineer             3.8   \n",
       "525                                    Lead Data Scientist             3.8   \n",
       "744                               Principal Data Scientist             3.6   \n",
       "93                                Principal Data Scientist             3.6   \n",
       "650                                    Lead Data Scientist             3.9   \n",
       "392               Global Audience Analytics Senior Manager             4.2   \n",
       "292              Manager, Data Scientist, Pricing Strategy             3.4   \n",
       "149                       Assistant Manager - Data Science             3.7   \n",
       "6       Global Cybersecurity Senior Manager - AI Architect             4.2   \n",
       "532                IT&D Data Scientist & Analytics Manager             3.8   \n",
       "673                                    Lead Data Scientist             4.4   \n",
       "3                                   Data Scientist Manager             3.9   \n",
       "643                               Manager - Data Scientist             4.0   \n",
       "619                               Principal Data Scientist             4.0   \n",
       "699                                    Lead Data Scientist             3.8   \n",
       "\n",
       "      Location    Salary_Range   Median_Salary Median_Salary_Standardized  \n",
       "685  Ahmedabad    ₹3L – ₹4L/yr   ₹3L/yr Median                     300000  \n",
       "671  Bengaluru   ₹9L – ₹10L/yr   ₹9L/yr Median                     900000  \n",
       "648  Bengaluru   ₹6L – ₹10L/yr   ₹8L/yr Median                     800000  \n",
       "646  Bengaluru  ₹35L – ₹40L/yr  ₹38L/yr Median                    3800000  \n",
       "758  Bengaluru          ₹4L/yr             NaN                   400000.0  \n",
       "618  Bengaluru         ₹22L/yr             NaN                  2200000.0  \n",
       "826  Bengaluru    ₹2L – ₹8L/yr   ₹4L/yr Median                     400000  \n",
       "457  Bengaluru    ₹1L – ₹3L/yr   ₹2L/yr Median                     200000  \n",
       "525    Chennai         ₹10L/yr             NaN                  1000000.0  \n",
       "744    Chennai    ₹5L – ₹8L/yr   ₹6L/yr Median                     600000  \n",
       "93     Chennai    ₹6L – ₹9L/yr   ₹7L/yr Median                     700000  \n",
       "650    Chennai  ₹20L – ₹30L/yr  ₹25L/yr Median                    2500000  \n",
       "392    Gurgaon   ₹7L – ₹10L/yr   ₹8L/yr Median                     800000  \n",
       "292    Gurgaon   ₹5L – ₹10L/yr   ₹7L/yr Median                     700000  \n",
       "149    Gurgaon    ₹5L – ₹9L/yr   ₹6L/yr Median                     600000  \n",
       "6      Gurgaon    ₹6L – ₹8L/yr   ₹7L/yr Median                     700000  \n",
       "532    Gurgaon   ₹9L – ₹10L/yr   ₹9L/yr Median                     900000  \n",
       "673  Hyderābād    ₹6L – ₹8L/yr   ₹7L/yr Median                     700000  \n",
       "3         Pune    ₹7L – ₹9L/yr   ₹8L/yr Median                     800000  \n",
       "643       Pune   ₹9L – ₹10L/yr   ₹9L/yr Median                     900000  \n",
       "619       Pune   ₹9L – ₹10L/yr   ₹9L/yr Median                     900000  \n",
       "699   Vadodara          ₹7L/yr             NaN                   700000.0  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Salary_Range_Standardized'].notna() & \n",
    "        df_copy['Job_Title'].str.contains('Manager|Principal|Lead', regex=True, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "        ]].sort_values(by='Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54d182-ddf5-43c5-b373-b8a3a9721157",
   "metadata": {},
   "source": [
    "- Row 26, impute the missing value with 8,00,000, using information from similar job postings.\n",
    "\n",
    "- Row 375, from analyzing similar job posting which has a salary of 10,00,000 for 'Sr Data Scientist', we can impute the missing value for the current job posting 'Principal Data Scientist' with a value of 20,00,000.\n",
    "\n",
    "- Row 462, from analysis of similar job posting 10,00,000 would be the ideal salary for this job posting\n",
    "- Row 584, this job posting seems a little different from the others as the role is a individual contributor and involves analyzing  transaction data, understand fraud pattern , develop fraud loss mitigation strategies with the objective of overall business goal of minimizing fraud losses as well as minimizing customer impact, the pay must be really good for kind of role, lets impute the salary with 15,00,000.\n",
    "\n",
    "- Row 466, the role is a Lead Data Scientist and location is Bengaluru, similar job posting has a salary of 6,00,000 for staff level, lets impute the salary with 10,00,000.\n",
    "\n",
    "- Row 32, using information from job posting from the same company we can impute the salary with 8,00,000.\n",
    "\n",
    "- Row 708, the role requires 5-8 years of experience, lets impute the salary with 8,00,000\n",
    "\n",
    "- Row 664, lets impute the missing salary with 7,00,000.\n",
    "\n",
    "- Row 742, this role involves AI and data plus it is a leadership role therefore the pay must be higher, lets impute the salary with 15,00,000.\n",
    "\n",
    "- Row 423, lets impute the missing salary with 8,00,000.\n",
    "\n",
    "- Row 442, this is a global company which currenlty raised funding of 100M and location of the role in remote, job title is 'Data and Reporting Lead', lets impute the missing salary with 20,00,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "2738b8c6-1ad0-4539-b2cc-b5e0760ee140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[26, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[375, 'Median_Salary_Standardized'] = 2000000\n",
    "\n",
    "df_copy.loc[462, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[584, 'Median_Salary_Standardized'] = 1500000\n",
    "\n",
    "df_copy.loc[466, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[32, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[708, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[664, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[742, 'Median_Salary_Standardized'] = 1500000\n",
    "\n",
    "df_copy.loc[423, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[442, 'Median_Salary_Standardized'] = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "5f4954b9-9a8d-4c4c-b3ca-c88807775f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f2f0d-b733-489e-8a0c-1df0b40d3dde",
   "metadata": {},
   "source": [
    "## Imputing missing values as per of role types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b1160f74-a30a-4607-8637-2fa1ebdc1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category 1: ML Engineer, Machine Learning Engineer, Engineer\n",
    "pattern_1 = r'\\b(?:ml engineer|machine learning engineer|engineer)\\b'\n",
    "\n",
    "# Category 2: Data Scientist, Data Science\n",
    "pattern_2 = r'\\b(?:data scientist|data science)\\b'\n",
    "\n",
    "# Category 3: Data Analyst, Analyst, Analytics\n",
    "pattern_3 = r'\\b(?:data analyst|analyst|analytics)\\b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba0dc1-e0be-4261-acd8-e53a5eeb6363",
   "metadata": {},
   "source": [
    "### Imputing missing values of 'Engineer' roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1834022d-6ecd-4ef3-b9b7-4abca9dc09d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Giniminds Solutions Private Limited</td>\n",
       "      <td>Data Scientist/ LLM Engineer</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Aidaptive</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Smart Data Solutions LLC</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>2.8</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Artius Solutions</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>4.6</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name                     Job_Title  \\\n",
       "294  Giniminds Solutions Private Limited  Data Scientist/ LLM Engineer   \n",
       "754                            Aidaptive     Machine Learning Engineer   \n",
       "772                            Accenture              AI / ML Engineer   \n",
       "795             Smart Data Solutions LLC     Machine Learning Engineer   \n",
       "809                     Artius Solutions     Machine Learning Engineer   \n",
       "831                                Adobe     Machine Learning Engineer   \n",
       "\n",
       "     Company_Rating   Location Salary_Range Median_Salary  \\\n",
       "294             3.9  Bengaluru         None           NaN   \n",
       "754             4.8     Remote         None           NaN   \n",
       "772             3.8  Bengaluru         None           NaN   \n",
       "795             2.8      India         None           NaN   \n",
       "809             4.6      India         None           NaN   \n",
       "831             4.2  Bengaluru         None           NaN   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "294                        NaN  \n",
       "754                        NaN  \n",
       "772                        NaN  \n",
       "795                        NaN  \n",
       "809                        NaN  \n",
       "831                        NaN  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(pattern_1, case=False, regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "5f672456-5796-4d34-8437-312027e752d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Giniminds Solutions Private Limited</td>\n",
       "      <td>Data Scientist/ LLM Engineer</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Designation: Data Scientist (LLMs &amp; GenAI)\\nJob Overview:\\nWe are looking for an experienced Python developer with a strong background in Large Language Models (LLMs), Generative AI (GenAI), excellent knowledge prompt engineering, tools for RAG development. The ideal candidate will have hands-on experience in prompt engineering, working with advanced AI frameworks such as LlamaIndex, LangChain, LangGraph, and AutoGen.\\nThis role involves building scalable applications and solutions that leverage the latest advancements in AI to solve complex business problems like intelligent chatbots, assistants and digital twins.\\nKey Responsibilities:\\nDevelop and implement AI-driven solutions using Python and state-of-the-art LLMs like Azure OpenAI, Lama, Gemini.\\nDesign and optimize prompt engineering strategies to improve model responses and performance.\\nWork with tools like LlamaIndex, LangChain, and LangGraph to integrate AI into business workflows.\\nUse LangGraph and AutoGen to design and manage multi-step reasoning workflows for complex applications by using poly LLMs.\\nDevelop APIs and interfaces for integrating LLM-based models into existing systems on Flask.\\nPerform performance testing, debugging, and continuous improvement of APIs.\\nResearch on developing conversational agents, personalized recommendations, and other GenAI-powered products like intelligent chatbots, assistants and digital twins.\\nKeep up with the latest developments in AI/ML and apply new techniques to improve our models and tools.\\nRequired Skills &amp; Qualifications:\\nExperience: 2-4 years of Python development experience with a focus on AI/ML.\\nKnowledge: In-depth understanding of LLMs, GenAI, and prompt engineering.\\nFrameworks: Proficiency in LlamaIndex, LangChain, LangGraph, and AutoGen.\\nMachine Learning: Experience with deploying and scaling machine learning models in production environments.\\nSpeech processing : Proficiency with speech-to-text or voice recognition systems such as Azure cognitive services and Google Speech API.\\nNLP: Solid understanding of natural language processing, tokenization, and semantic analysis.\\nAPIs: Strong experience in developing and integrating RESTful APIs on Flask for AI/ML systems.\\nProblem Solving: Ability to create scalable solutions for multi-modal, poly LLM and generative AI applications.\\nCollaboration: Excellent communication and teamwork skills to collaborate with cross-functional teams.\\nPreferred Qualifications:\\nKnowledge on Speech synthesis and Sentience simulation\\nExperience with cloud platforms (Azure and GCP) for deploying and scaling AI/ML models.\\nFamiliarity with containerization (Docker) and orchestration tools (Kubernetes) for deploying microservices.\\nExperience with reinforcement learning, transformers, or other cutting-edge techniques.\\nUnderstanding of ethical AI, data privacy, and responsible AI practices.\\nJob Type: Full-time\\nAbility to commute/relocate:\\nBangalore, Karnataka: Reliably commute or planning to relocate before starting work (Preferred)\\nEducation:\\nBachelor's (Required)\\nExperience:\\nLLM: 2 years (Preferred)\\nLangChain or LangGraph: 2 years (Preferred)\\nDocker: 2 years (Preferred)\\nSTT / ASR: 2 years (Preferred)\\nAPI Development: 2 years (Preferred)\\nWork Location: In person</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Giniminds Solutions Private Limited</td>\n",
       "      <td>Data Scientist- Industrial AI</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>Job Title: Data Scientist Industrial AI\\nLocation: Bengaluru, India (On-site/Hybrid)\\nDepartment: AI &amp; Digital Twins\\nAbout\\nGiniminds Virtual AI Factory\\nGiniminds is pioneering the future of manufacturing with its Virtual AI Factory— a cutting-edge, photorealistic digital twin of real-world production environments. Built on NVIDIA Omniverse, it integrates simulation, AI, and real time sensor data to enable predictive analytics, process optimization, and accelerated production cycles. This platform serves as a risk-free innovation hub to develop, validate, and deploy AI solutions.\\nPosition Summary\\nWe are seeking a Digital Twin Developer specializing in NVIDIA Omniverse and Industrial AI. You will design, build, and simulate digital replicas of manufacturing operations, integrating real-world data, 3D visualization, and AI driven insights to solve complex industrial challenges such as predictive maintenance, process efficiency, and defect detection.\\nKey Responsibilities\\nDevelop advanced digital twin environments using Omniverse USD Composer and Universal Scene Description (USD)workflows.\\nImport, optimize, and manage complex 3D CAD assets from tools such as Siemens NX, SolidWorks, and AutoCAD for real-time factory simulations.\\nImplement physics-based simulations for robotic systems, material flow, and machinery using PhysX and Isaac Sim.\\nIntegrate AI/ML models for predictive maintenance (RNN, LSTM) and visual defect detection (CNN, Transformers).\\nGenerate synthetic datasets for AI training using Omniverse Replicator and other tools, including artificial sensor and image data.\\nCollaborate with data engineering teams to connect the digital twin to live factory data via MQTT, Kafka, OPC-UA, and industrial systems (MES, ERP, PLM).\\nDevelop custom dashboards and visualization tools within Omniverse for monitoring KPIs, alerts, and simulation outputs.\\nRequired Skills &amp; Qualifications\\nStrong hands-on experience with NVIDIA Omniverse (USD Composer, Nucleus).\\nProficiency in 3D asset management using Blender, Maya, or 3ds Max. Experience with NVIDIA PhysX and/or Isaac Sim for industrial robotics and process simulations.\\nPractical experience in industrial AI model development, including vision based inspection or predictive analytics.\\nAdvanced programming skills in Python for Omniverse scripting, simulation automation, and tool development.\\nSolid understanding of manufacturing processes, MES/ERP systems, and factory operations.\\nPreferred Qualifications\\nExperience with synthetic data generation tools (Omniverse Replicator, GANs, Diffusion Models).\\nIn-depth knowledge of USD workflows, including layering and composition arcs.\\nFamiliarity with industrial data streaming tools (Kafka, MQTT).\\nCloud computing and DevOps exposure AWS, Azure, GCP, Docker).\\nExperience in developing Omniverse extensions or custom applications.\\nWhat We Offer\\nOpportunity to work on groundbreaking AI + industrial automation projects.\\nCompetitive salary and comprehensive benefits.\\nAccess to advanced tools, NVIDIA technology, and high-performance hardware.\\nDynamic, collaborative work culture with a strong focus on innovation and career growth\\nJob Type: Full-time\\nAbility to commute/relocate:\\nJP Nagar, Bengaluru, Karnataka: Reliably commute or planning to relocate before starting work (Required)\\nApplication Question(s):\\nDo you have experience working with Digital Twins?\\nDo you have experience with 3D CAD Tools like Blender, Maya etc ?\\nDo you have experience with tools like Kafka?\\nDo you have experience with Industrial AI Model Development?\\nEducation:\\nBachelor's (Required)\\nWork Location: In person</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name                      Job_Title  \\\n",
       "294  Giniminds Solutions Private Limited   Data Scientist/ LLM Engineer   \n",
       "309  Giniminds Solutions Private Limited  Data Scientist- Industrial AI   \n",
       "\n",
       "     Company_Rating   Location  \\\n",
       "294             3.9  Bengaluru   \n",
       "309             3.9      India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Description  \\\n",
       "294                                                                                                                                                                                                                                                                                                                                                                                     Job Designation: Data Scientist (LLMs & GenAI)\\nJob Overview:\\nWe are looking for an experienced Python developer with a strong background in Large Language Models (LLMs), Generative AI (GenAI), excellent knowledge prompt engineering, tools for RAG development. The ideal candidate will have hands-on experience in prompt engineering, working with advanced AI frameworks such as LlamaIndex, LangChain, LangGraph, and AutoGen.\\nThis role involves building scalable applications and solutions that leverage the latest advancements in AI to solve complex business problems like intelligent chatbots, assistants and digital twins.\\nKey Responsibilities:\\nDevelop and implement AI-driven solutions using Python and state-of-the-art LLMs like Azure OpenAI, Lama, Gemini.\\nDesign and optimize prompt engineering strategies to improve model responses and performance.\\nWork with tools like LlamaIndex, LangChain, and LangGraph to integrate AI into business workflows.\\nUse LangGraph and AutoGen to design and manage multi-step reasoning workflows for complex applications by using poly LLMs.\\nDevelop APIs and interfaces for integrating LLM-based models into existing systems on Flask.\\nPerform performance testing, debugging, and continuous improvement of APIs.\\nResearch on developing conversational agents, personalized recommendations, and other GenAI-powered products like intelligent chatbots, assistants and digital twins.\\nKeep up with the latest developments in AI/ML and apply new techniques to improve our models and tools.\\nRequired Skills & Qualifications:\\nExperience: 2-4 years of Python development experience with a focus on AI/ML.\\nKnowledge: In-depth understanding of LLMs, GenAI, and prompt engineering.\\nFrameworks: Proficiency in LlamaIndex, LangChain, LangGraph, and AutoGen.\\nMachine Learning: Experience with deploying and scaling machine learning models in production environments.\\nSpeech processing : Proficiency with speech-to-text or voice recognition systems such as Azure cognitive services and Google Speech API.\\nNLP: Solid understanding of natural language processing, tokenization, and semantic analysis.\\nAPIs: Strong experience in developing and integrating RESTful APIs on Flask for AI/ML systems.\\nProblem Solving: Ability to create scalable solutions for multi-modal, poly LLM and generative AI applications.\\nCollaboration: Excellent communication and teamwork skills to collaborate with cross-functional teams.\\nPreferred Qualifications:\\nKnowledge on Speech synthesis and Sentience simulation\\nExperience with cloud platforms (Azure and GCP) for deploying and scaling AI/ML models.\\nFamiliarity with containerization (Docker) and orchestration tools (Kubernetes) for deploying microservices.\\nExperience with reinforcement learning, transformers, or other cutting-edge techniques.\\nUnderstanding of ethical AI, data privacy, and responsible AI practices.\\nJob Type: Full-time\\nAbility to commute/relocate:\\nBangalore, Karnataka: Reliably commute or planning to relocate before starting work (Preferred)\\nEducation:\\nBachelor's (Required)\\nExperience:\\nLLM: 2 years (Preferred)\\nLangChain or LangGraph: 2 years (Preferred)\\nDocker: 2 years (Preferred)\\nSTT / ASR: 2 years (Preferred)\\nAPI Development: 2 years (Preferred)\\nWork Location: In person   \n",
       "309  Job Title: Data Scientist Industrial AI\\nLocation: Bengaluru, India (On-site/Hybrid)\\nDepartment: AI & Digital Twins\\nAbout\\nGiniminds Virtual AI Factory\\nGiniminds is pioneering the future of manufacturing with its Virtual AI Factory— a cutting-edge, photorealistic digital twin of real-world production environments. Built on NVIDIA Omniverse, it integrates simulation, AI, and real time sensor data to enable predictive analytics, process optimization, and accelerated production cycles. This platform serves as a risk-free innovation hub to develop, validate, and deploy AI solutions.\\nPosition Summary\\nWe are seeking a Digital Twin Developer specializing in NVIDIA Omniverse and Industrial AI. You will design, build, and simulate digital replicas of manufacturing operations, integrating real-world data, 3D visualization, and AI driven insights to solve complex industrial challenges such as predictive maintenance, process efficiency, and defect detection.\\nKey Responsibilities\\nDevelop advanced digital twin environments using Omniverse USD Composer and Universal Scene Description (USD)workflows.\\nImport, optimize, and manage complex 3D CAD assets from tools such as Siemens NX, SolidWorks, and AutoCAD for real-time factory simulations.\\nImplement physics-based simulations for robotic systems, material flow, and machinery using PhysX and Isaac Sim.\\nIntegrate AI/ML models for predictive maintenance (RNN, LSTM) and visual defect detection (CNN, Transformers).\\nGenerate synthetic datasets for AI training using Omniverse Replicator and other tools, including artificial sensor and image data.\\nCollaborate with data engineering teams to connect the digital twin to live factory data via MQTT, Kafka, OPC-UA, and industrial systems (MES, ERP, PLM).\\nDevelop custom dashboards and visualization tools within Omniverse for monitoring KPIs, alerts, and simulation outputs.\\nRequired Skills & Qualifications\\nStrong hands-on experience with NVIDIA Omniverse (USD Composer, Nucleus).\\nProficiency in 3D asset management using Blender, Maya, or 3ds Max. Experience with NVIDIA PhysX and/or Isaac Sim for industrial robotics and process simulations.\\nPractical experience in industrial AI model development, including vision based inspection or predictive analytics.\\nAdvanced programming skills in Python for Omniverse scripting, simulation automation, and tool development.\\nSolid understanding of manufacturing processes, MES/ERP systems, and factory operations.\\nPreferred Qualifications\\nExperience with synthetic data generation tools (Omniverse Replicator, GANs, Diffusion Models).\\nIn-depth knowledge of USD workflows, including layering and composition arcs.\\nFamiliarity with industrial data streaming tools (Kafka, MQTT).\\nCloud computing and DevOps exposure AWS, Azure, GCP, Docker).\\nExperience in developing Omniverse extensions or custom applications.\\nWhat We Offer\\nOpportunity to work on groundbreaking AI + industrial automation projects.\\nCompetitive salary and comprehensive benefits.\\nAccess to advanced tools, NVIDIA technology, and high-performance hardware.\\nDynamic, collaborative work culture with a strong focus on innovation and career growth\\nJob Type: Full-time\\nAbility to commute/relocate:\\nJP Nagar, Bengaluru, Karnataka: Reliably commute or planning to relocate before starting work (Required)\\nApplication Question(s):\\nDo you have experience working with Digital Twins?\\nDo you have experience with 3D CAD Tools like Blender, Maya etc ?\\nDo you have experience with tools like Kafka?\\nDo you have experience with Industrial AI Model Development?\\nEducation:\\nBachelor's (Required)\\nWork Location: In person   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "294                        NaN  \n",
       "309                        NaN  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Giniminds Solutions Private Limited', regex=False, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Description', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "6ceccb67-fdcb-4672-aef8-21bd3b41671b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Scientist Specialist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Job Title - &lt;Data Scientist&gt; + &lt;Level Specialist&gt; + &lt;Entity ACS/Accenture Song&gt;\\nManagement Level: &lt;Level 9- Specialist &gt;\\nLocation: Kochi, Coimbatore, Trivandrum\\nMust have skills: Big Data, Python or R\\nGood to have skills: Scala, SQL\\nJob Summary\\nA Data Scientist is expected to be hands-on to deliver end to end vis a vis projects undertaken in the Analytics space. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Science Practitioner</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Project Role : Data Science Practitioner\\nProject Role Description : Formulating, design and deliver AI/ML-based decision-making frameworks and models for business outcomes. Measure and justify AI/ML based solution values.\\nMust have skills : Machine Learning\\nGood to have skills : NA\\nMinimum 15 year(s) of experience is required\\nEducational Qualification : 15 years full time education\\n\\nSummary: As a Data Science Practitioner, you will be engaged in formulating, designing, and delivering AI and machine learning-based decision-making frameworks and models that drive business outcomes. Your typical day will involve collaborating with various teams to measure and justify the value of AI and machine learning solutions, ensuring that they align with organizational goals and deliver tangible results. You will also be responsible for analyzing complex data sets, deriving insights, and presenting findings to stakeholders to support informed decision-making processes. Roles &amp; Responsibilities: - Expected to be a Subject Matter Expert with deep knowledge and experience. - Should have influencing and advisory skills. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Expected to provide solutions to problems that apply across multiple teams. - Facilitate workshops and training sessions to enhance team capabilities in AI and machine learning. - Continuously evaluate and improve existing AI and machine learning models to ensure optimal performance. Professional &amp; Technical Skills: - Must To Have Skills: Proficiency in Machine Learning. - Strong understanding of data preprocessing techniques and feature engineering. - Experience with various machine learning frameworks such as TensorFlow and PyTorch. - Ability to implement and optimize algorithms for predictive modeling. - Familiarity with cloud platforms for deploying machine learning models. Additional Information: - The candidate should have minimum 15 years of experience in Machine Learning. - This position is based at our Bengaluru office. - A 15 years full time education is required.\\n\\n15 years full time education</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Insights &amp; Visualization Practition</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>Project Role : Data Insights &amp; Visualization Practition\\nProject Role Description : Create interactive interfaces that enable humans to understand, interpret, and communicate complex data and insights. Wrangle, analyze, and prepare data to ensure delivery of relevant, consistent, timely, and actionable insights. Leverage modern business intelligence, storytelling, and web-based visualization tools to create interactive dashboards, reports and emerging VIS/BI artifacts. Use and customize (Gen)AI and AI-powered VIS/BI capabilities to enable a dialog with data.\\nMust have skills : Data Analytics\\nGood to have skills : NA\\nMinimum 2 year(s) of experience is required\\nEducational Qualification : 15 years full time education\\n\\nJob Description: **Position Summary:** The Data Visualization Specialist will transform complex datasets into clear, actionable visualizations that support decision-making. **Key Responsibilities:** - Design and develop interactive dashboards and reports. - Collaborate with analysts and stakeholders to gather visualization requirements. - Ensure data visualizations are accurate, intuitive, and impactful. - Stay updated on best practices in data visualization. - Create visually compelling dashboards and reports to communicate insights. - Work closely with stakeholders to understand visualization requirements. - Ensure consistency in visual design and adherence to branding guidelines. - Optimize visualizations for performance and scalability. - Train end-users on interpreting and utilizing visual analytics tools. **Qualifications:** - Bachelor's degree in Data Science, Computer Science, or a related field. - 3-5 years of experience in data visualization. - Proficiency in Power BI, Tableau, or similar tools. - Strong design sense and attention to detail. - Excellent communication and collaboration skills. Additional Information: - The candidate should have minimum 2 years of experience in Data Analytics. - This position is based at our Hyderabad office. - A 15 years full time education is required.\\n\\n15 years full time education</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>AI / ML Engineer</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Project Role : AI / ML Engineer\\nProject Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing.\\nMust have skills : Computer Vision\\nGood to have skills : Hana\\nMinimum 12 year(s) of experience is required\\nEducational Qualification : 15 years full time education\\n\\nSummary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, deep learning, and neural networks, while also exploring innovative applications such as chatbots and image processing. Collaboration with cross-functional teams will be essential to integrate these advanced technologies into existing systems and workflows, driving efficiency and enhancing user experiences. Roles &amp; Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Expected to provide solutions to problems that apply across multiple teams. - Facilitate knowledge sharing and mentorship within the team to foster professional growth. - Continuously evaluate and improve existing processes and systems to enhance performance and reliability. Professional &amp; Technical Skills: - Must To Have Skills: Proficiency in Machine Learning. - Strong understanding of various machine learning algorithms and their applications. - Experience with cloud-based AI services and deployment strategies. - Familiarity with programming languages such as Python or R for model development. - Knowledge of data preprocessing techniques and data pipeline construction. Additional Information: - The candidate should have minimum 12 years of experience in Machine Learning. - This position is based at our Bengaluru office. - A 15 years full time education is required.\\n\\n15 years full time education</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                                 Job_Title  Company_Rating  \\\n",
       "282    Accenture                 Data Scientist Specialist             3.8   \n",
       "389    Accenture                 Data Science Practitioner             3.8   \n",
       "437    Accenture  Data Insights & Visualization Practition             3.8   \n",
       "772    Accenture                          AI / ML Engineer             3.8   \n",
       "\n",
       "      Location  \\\n",
       "282     Cochin   \n",
       "389  Bengaluru   \n",
       "437  Hyderābād   \n",
       "772  Bengaluru   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Description  \\\n",
       "282                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Job Title - <Data Scientist> + <Level Specialist> + <Entity ACS/Accenture Song>\\nManagement Level: <Level 9- Specialist >\\nLocation: Kochi, Coimbatore, Trivandrum\\nMust have skills: Big Data, Python or R\\nGood to have skills: Scala, SQL\\nJob Summary\\nA Data Scientist is expected to be hands-on to deliver end to end vis a vis projects undertaken in the Analytics space. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.   \n",
       "389                                                                                                                                                                          Project Role : Data Science Practitioner\\nProject Role Description : Formulating, design and deliver AI/ML-based decision-making frameworks and models for business outcomes. Measure and justify AI/ML based solution values.\\nMust have skills : Machine Learning\\nGood to have skills : NA\\nMinimum 15 year(s) of experience is required\\nEducational Qualification : 15 years full time education\\n\\nSummary: As a Data Science Practitioner, you will be engaged in formulating, designing, and delivering AI and machine learning-based decision-making frameworks and models that drive business outcomes. Your typical day will involve collaborating with various teams to measure and justify the value of AI and machine learning solutions, ensuring that they align with organizational goals and deliver tangible results. You will also be responsible for analyzing complex data sets, deriving insights, and presenting findings to stakeholders to support informed decision-making processes. Roles & Responsibilities: - Expected to be a Subject Matter Expert with deep knowledge and experience. - Should have influencing and advisory skills. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Expected to provide solutions to problems that apply across multiple teams. - Facilitate workshops and training sessions to enhance team capabilities in AI and machine learning. - Continuously evaluate and improve existing AI and machine learning models to ensure optimal performance. Professional & Technical Skills: - Must To Have Skills: Proficiency in Machine Learning. - Strong understanding of data preprocessing techniques and feature engineering. - Experience with various machine learning frameworks such as TensorFlow and PyTorch. - Ability to implement and optimize algorithms for predictive modeling. - Familiarity with cloud platforms for deploying machine learning models. Additional Information: - The candidate should have minimum 15 years of experience in Machine Learning. - This position is based at our Bengaluru office. - A 15 years full time education is required.\\n\\n15 years full time education   \n",
       "437                                                                                                                                                                                                                                         Project Role : Data Insights & Visualization Practition\\nProject Role Description : Create interactive interfaces that enable humans to understand, interpret, and communicate complex data and insights. Wrangle, analyze, and prepare data to ensure delivery of relevant, consistent, timely, and actionable insights. Leverage modern business intelligence, storytelling, and web-based visualization tools to create interactive dashboards, reports and emerging VIS/BI artifacts. Use and customize (Gen)AI and AI-powered VIS/BI capabilities to enable a dialog with data.\\nMust have skills : Data Analytics\\nGood to have skills : NA\\nMinimum 2 year(s) of experience is required\\nEducational Qualification : 15 years full time education\\n\\nJob Description: **Position Summary:** The Data Visualization Specialist will transform complex datasets into clear, actionable visualizations that support decision-making. **Key Responsibilities:** - Design and develop interactive dashboards and reports. - Collaborate with analysts and stakeholders to gather visualization requirements. - Ensure data visualizations are accurate, intuitive, and impactful. - Stay updated on best practices in data visualization. - Create visually compelling dashboards and reports to communicate insights. - Work closely with stakeholders to understand visualization requirements. - Ensure consistency in visual design and adherence to branding guidelines. - Optimize visualizations for performance and scalability. - Train end-users on interpreting and utilizing visual analytics tools. **Qualifications:** - Bachelor's degree in Data Science, Computer Science, or a related field. - 3-5 years of experience in data visualization. - Proficiency in Power BI, Tableau, or similar tools. - Strong design sense and attention to detail. - Excellent communication and collaboration skills. Additional Information: - The candidate should have minimum 2 years of experience in Data Analytics. - This position is based at our Hyderabad office. - A 15 years full time education is required.\\n\\n15 years full time education   \n",
       "772  Project Role : AI / ML Engineer\\nProject Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing.\\nMust have skills : Computer Vision\\nGood to have skills : Hana\\nMinimum 12 year(s) of experience is required\\nEducational Qualification : 15 years full time education\\n\\nSummary: As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve designing and implementing production-ready solutions, ensuring that they meet quality standards. You will work with various AI models, including generative AI, deep learning, and neural networks, while also exploring innovative applications such as chatbots and image processing. Collaboration with cross-functional teams will be essential to integrate these advanced technologies into existing systems and workflows, driving efficiency and enhancing user experiences. Roles & Responsibilities: - Expected to be an SME. - Collaborate and manage the team to perform. - Responsible for team decisions. - Engage with multiple teams and contribute on key decisions. - Expected to provide solutions to problems that apply across multiple teams. - Facilitate knowledge sharing and mentorship within the team to foster professional growth. - Continuously evaluate and improve existing processes and systems to enhance performance and reliability. Professional & Technical Skills: - Must To Have Skills: Proficiency in Machine Learning. - Strong understanding of various machine learning algorithms and their applications. - Experience with cloud-based AI services and deployment strategies. - Familiarity with programming languages such as Python or R for model development. - Knowledge of data preprocessing techniques and data pipeline construction. Additional Information: - The candidate should have minimum 12 years of experience in Machine Learning. - This position is based at our Bengaluru office. - A 15 years full time education is required.\\n\\n15 years full time education   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "282                        NaN  \n",
       "389                        NaN  \n",
       "437                        NaN  \n",
       "772                        NaN  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Accenture', regex=False, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Description', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "c62ab759-1a5b-41c0-8f25-88ff5796d626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Aidaptive</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Role:\\nWe're a global team with a track record of building world class enterprise products and are seeking talented Machine Learning Engineers to develop and optimize ML models.\\nMinimum qualifications:\\nBachelor's degree in Computer Science, Mathematics, or equivalent practical experience.\\nPython development experience for modeling.\\nExperience with deep learning frameworks including TensorFlow and other machine learning libraries\\nPreferred qualifications:\\nMaster's or PhD degree in Computer Science, Artificial Intelligence, Machine Learning, or related technical field.</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Smart Data Solutions LLC</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>2.8</td>\n",
       "      <td>About us:\\n\\nFor over 20 years, Smart Data Solutions has been partnering with leading payer organizations to provide automation and technology solutions enabling data standardization and workflow automation. The company brings a comprehensive set of turn-key services to handle all claims and claims-related information regardless of format (paper, fax, electronic), digitizing and normalizing for seamless use by payer clients. Solutions include intelligent data capture, conversion and digitization, mailroom management, comprehensive clearinghouse services and proprietary workflow offerings. SDS’ headquarters are just outside of St. Paul, MN and leverages dedicated onshore and offshore resources as part of its service delivery model. The company counts over 420 healthcare organizations as clients, including multiple Blue Cross Blue Shield state plans, large regional health plans and leading independent TPAs, handling over 500 million transactions of varying types annually with a 98%+ customer retention rate. SDS has also invested meaningfully in automation and machine learning capabilities across its tech-enabled processes to drive scalability and greater internal operating efficiency while also improving client results.</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Artius Solutions</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Job Title: Machine Learning Engineer\\nJob Type: Contract (2 Months)\\nLocation: Remote (Preferred: India, Pakistan, Nigeria, Kenya, Egypt, Ghana, Bangladesh, Turkey, Mexico)\\nWork Hours: Minimum 20 hours per week, with at least 4 hours/day overlapping with PST\\nEmployment Type: Contractor (No medical benefits or paid leave)\\nJob Overview:\\nWe are seeking an experienced Machine Learning Engineer with strong expertise in JAX and solid knowledge of TensorFlow. You will lead the migration of TensorFlow models and training pipelines to JAX, ensuring model accuracy and optimal performance. This role requires deep involvement in model internals, benchmarking, and cross-framework compatibility.\\nKey Responsibilities:\\nRequired Skills:\\nPreferred Skills (Bonus):\\nAdditional Details:</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Our Company\\n\\nChanging the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.\\n\\nWe’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!\\n\\nAdobe Advertising Cloud\\nAdobe Advertising is a combination of a ‘Demand Side Platform (DSP)’ and a ‘Spend Optimizer’ that helps customers plan, buy, measure, and optimize their digital media (across CTV, Online Video, Display, Search, Social, and Retail Media Networks). We help the largest global advertisers maximize the impact of their paid media budgets by delivering connected and personalized experiences to their consumers. The Opportunity\\nThis opportunity is with the Spend Optimizer group. In collaboration with a team of highly motivated data scientists and engineers, you will apply reinforcement learning, time series analysis, bayesian modeling, Gen AI frameworks to optimize ad spends and drive the best user experiences.\\nWhat you'll Do\\nTechnically lead and guide team of skilled machine learning engineers to design and implement ML algorithms/models\\nCollaborate with multi-functional teams to determine technical requirements\\nDevelop and deploy scalable machine learning solutions that optimize Adobe’s products and services, deliver value to clients and drive customer adoption\\nDrive innovation through research and experimentation, encouraging an environment where new ideas can thrive\\nMonitor and evaluate the performance of ML models, making vital adjustments to compete at the highest level What you need to succeed\\nOutstanding knowledge of machine learning frameworks and tools such as PyTorch, Tensorflow, Scikit-learn, with strong programming skills in Python\\nSolid understanding of core machine learning and statistics, including Bayesian Modeling, Time Series Analysis, Reinforcement Learning, and Optimization\\nExperience in developing, deploying and maintaining ML models in a production environment\\nAbility to thrive in a collaborative, inclusive, and diverse workplace, embracing different perspectives and ideas Ideal Candidate Profile:\\nAbout 10 years of experience in an applied Machine Learning setting, delivering cloud-scale, data-driven products, and services\\nPhD or Master’s in Computer Science/ Applied Math/Statistics/ related field.\\nExperience and domain expertise in Digital ad technologies is desirable.\\nComfort with ambiguity, adaptability to evolving priorities, and an ability to influence technical and non-technical collaborators\\nA very strong problem solving and execution ability, ability to innovate, and focus on delivering value to Adobe customers, can compensate for any of the above requirements.\\n\\nAdobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.\\n\\nAdobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company_Name                  Job_Title  Company_Rating  \\\n",
       "754                 Aidaptive  Machine Learning Engineer             4.8   \n",
       "795  Smart Data Solutions LLC  Machine Learning Engineer             2.8   \n",
       "809          Artius Solutions  Machine Learning Engineer             4.6   \n",
       "831                     Adobe  Machine Learning Engineer             4.2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Description  \\\n",
       "754                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Role:\\nWe're a global team with a track record of building world class enterprise products and are seeking talented Machine Learning Engineers to develop and optimize ML models.\\nMinimum qualifications:\\nBachelor's degree in Computer Science, Mathematics, or equivalent practical experience.\\nPython development experience for modeling.\\nExperience with deep learning frameworks including TensorFlow and other machine learning libraries\\nPreferred qualifications:\\nMaster's or PhD degree in Computer Science, Artificial Intelligence, Machine Learning, or related technical field.   \n",
       "795                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   About us:\\n\\nFor over 20 years, Smart Data Solutions has been partnering with leading payer organizations to provide automation and technology solutions enabling data standardization and workflow automation. The company brings a comprehensive set of turn-key services to handle all claims and claims-related information regardless of format (paper, fax, electronic), digitizing and normalizing for seamless use by payer clients. Solutions include intelligent data capture, conversion and digitization, mailroom management, comprehensive clearinghouse services and proprietary workflow offerings. SDS’ headquarters are just outside of St. Paul, MN and leverages dedicated onshore and offshore resources as part of its service delivery model. The company counts over 420 healthcare organizations as clients, including multiple Blue Cross Blue Shield state plans, large regional health plans and leading independent TPAs, handling over 500 million transactions of varying types annually with a 98%+ customer retention rate. SDS has also invested meaningfully in automation and machine learning capabilities across its tech-enabled processes to drive scalability and greater internal operating efficiency while also improving client results.   \n",
       "809                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Job Title: Machine Learning Engineer\\nJob Type: Contract (2 Months)\\nLocation: Remote (Preferred: India, Pakistan, Nigeria, Kenya, Egypt, Ghana, Bangladesh, Turkey, Mexico)\\nWork Hours: Minimum 20 hours per week, with at least 4 hours/day overlapping with PST\\nEmployment Type: Contractor (No medical benefits or paid leave)\\nJob Overview:\\nWe are seeking an experienced Machine Learning Engineer with strong expertise in JAX and solid knowledge of TensorFlow. You will lead the migration of TensorFlow models and training pipelines to JAX, ensuring model accuracy and optimal performance. This role requires deep involvement in model internals, benchmarking, and cross-framework compatibility.\\nKey Responsibilities:\\nRequired Skills:\\nPreferred Skills (Bonus):\\nAdditional Details:   \n",
       "831  Our Company\\n\\nChanging the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.\\n\\nWe’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!\\n\\nAdobe Advertising Cloud\\nAdobe Advertising is a combination of a ‘Demand Side Platform (DSP)’ and a ‘Spend Optimizer’ that helps customers plan, buy, measure, and optimize their digital media (across CTV, Online Video, Display, Search, Social, and Retail Media Networks). We help the largest global advertisers maximize the impact of their paid media budgets by delivering connected and personalized experiences to their consumers. The Opportunity\\nThis opportunity is with the Spend Optimizer group. In collaboration with a team of highly motivated data scientists and engineers, you will apply reinforcement learning, time series analysis, bayesian modeling, Gen AI frameworks to optimize ad spends and drive the best user experiences.\\nWhat you'll Do\\nTechnically lead and guide team of skilled machine learning engineers to design and implement ML algorithms/models\\nCollaborate with multi-functional teams to determine technical requirements\\nDevelop and deploy scalable machine learning solutions that optimize Adobe’s products and services, deliver value to clients and drive customer adoption\\nDrive innovation through research and experimentation, encouraging an environment where new ideas can thrive\\nMonitor and evaluate the performance of ML models, making vital adjustments to compete at the highest level What you need to succeed\\nOutstanding knowledge of machine learning frameworks and tools such as PyTorch, Tensorflow, Scikit-learn, with strong programming skills in Python\\nSolid understanding of core machine learning and statistics, including Bayesian Modeling, Time Series Analysis, Reinforcement Learning, and Optimization\\nExperience in developing, deploying and maintaining ML models in a production environment\\nAbility to thrive in a collaborative, inclusive, and diverse workplace, embracing different perspectives and ideas Ideal Candidate Profile:\\nAbout 10 years of experience in an applied Machine Learning setting, delivering cloud-scale, data-driven products, and services\\nPhD or Master’s in Computer Science/ Applied Math/Statistics/ related field.\\nExperience and domain expertise in Digital ad technologies is desirable.\\nComfort with ambiguity, adaptability to evolving priorities, and an ability to influence technical and non-technical collaborators\\nA very strong problem solving and execution ability, ability to innovate, and focus on delivering value to Adobe customers, can compensate for any of the above requirements.\\n\\nAdobe is proud to be an Equal Employment Opportunity employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.\\n\\nAdobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.   \n",
       "\n",
       "      Location  \n",
       "754     Remote  \n",
       "795      India  \n",
       "809      India  \n",
       "831  Bengaluru  "
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[754, 795, 809, 831], ['Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008cd2fa-665b-4e5a-8c4f-9bea26b08673",
   "metadata": {},
   "source": [
    "- Row 294, the job posting is a Data Science/LLM role, it also requires experience in Data science techs, LLMs/GenAI, frame works such as LlamaIndex, LangChain, LangGraph, Autogen, the location of the job is Bengaluru, required experience is 2-4 years, the pay range would be 10,00,000.\n",
    "- Row 309, thr job posting is a advanced AI role which requires experience in Omniverse USD Composer and Universal Scene Description (USD)workflows, DevOps(AWS, Azure, GCP, Docker), the role involes building advanced digital twin environments, location is Bengaluru, it is an AI role which requires experience in a list of tools & technologies, the pay has to be higher, lets impute the salary with 12,00,000.\n",
    "<br>\n",
    "\n",
    "- Row 282, lets impute the salary with 7,00,000.\n",
    "- Row 389, which requires 15 years of experience in ML and related skills, lets impute the salary with 80,00,000.\n",
    "- Row 437, the job posting is data insights & visualization role, requires 3-5 years of experience in data visualization, let impute the salary with 8,00,000.\n",
    "- Row 772, the role is a AI/ML engineer which requires experience, knowledge in deep ML techs, AI, requires 12 years of experience, the pay range of AI/ML engineer is usually higher, lets impute the salary with 70,00,000.\n",
    "<br>\n",
    "\n",
    "- Row 754, requires a master's or phD, experience with deep learning frameworks including TensorFlow and other machine learning libraries, lets impute the salary with 12,00,000.\n",
    "- Row 795, not enough information about the role, lets impute the salary with 6,00,000.\n",
    "- Row 809, is a 2 month contract role(intern), location is remote, requires experience in tensorflow, JAX, lets impute the salary with 50,000.\n",
    "- Row 831, is a machine learning engineer role which requires knowledge of machine learning frameworks and tools such as PyTorch, Tensorflow, Scikit-learn, with strong programming skills in Python, Solid understanding of core machine learning and statistics, including Bayesian Modeling, Time Series Analysis, Reinforcement Learning, and Optimization, Experience in developing, deploying and maintaining ML models in a production environment, the role is senior or higher level role and adobe is a global company, lets impute the salary with 20,00,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "4b12cfba-0455-4e9d-8c46-847cb60203c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[294, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[309, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[282, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[389, 'Median_Salary_Standardized'] = 8000000\n",
    "\n",
    "df_copy.loc[437, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[772, 'Median_Salary_Standardized'] = 7000000\n",
    "\n",
    "df_copy.loc[754, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[795, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[809, 'Median_Salary_Standardized'] = 50000\n",
    "df_copy.loc[809, 'Intern'] = 1\n",
    "\n",
    "df_copy.loc[831, 'Median_Salary_Standardized'] = 2000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf4e19-d9ec-4db7-b213-5135665f4be1",
   "metadata": {},
   "source": [
    "### Imputing missing values of 'Analyst' roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "2fab130d-8911-45d8-a26e-0e80e8c57553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sumeru</td>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Tecvesten Consulting</td>\n",
       "      <td>Data Scientist / Data Analyst / BI</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Teramind</td>\n",
       "      <td>Data Scientist - Online Behavioral Analytics &amp; Generative AI</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Analyst, Geo Analytics, India - X Delivery</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Splashgain</td>\n",
       "      <td>Data Scientist/ Data Analyst</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Sentient</td>\n",
       "      <td>AI Data Analyst</td>\n",
       "      <td>5.0</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>BlazingCoders</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.5</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Kone</td>\n",
       "      <td>Data and Analytics</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>iTDAY India</td>\n",
       "      <td>Data Scientist &amp; Analyst</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  \\\n",
       "21                    Sumeru   \n",
       "67      Tecvesten Consulting   \n",
       "145                 Teramind   \n",
       "211  Boston Consulting Group   \n",
       "226               Splashgain   \n",
       "465                 Sentient   \n",
       "552            BlazingCoders   \n",
       "555                     Kone   \n",
       "577              iTDAY India   \n",
       "\n",
       "                                                        Job_Title  \\\n",
       "21                                         Data Scientist/Analyst   \n",
       "67                             Data Scientist / Data Analyst / BI   \n",
       "145  Data Scientist - Online Behavioral Analytics & Generative AI   \n",
       "211                    Analyst, Geo Analytics, India - X Delivery   \n",
       "226                                  Data Scientist/ Data Analyst   \n",
       "465                                               AI Data Analyst   \n",
       "552                                                  Data Analyst   \n",
       "555                                            Data and Analytics   \n",
       "577                                      Data Scientist & Analyst   \n",
       "\n",
       "     Company_Rating   Location Salary_Range Median_Salary  \\\n",
       "21              3.3     Remote         None           NaN   \n",
       "67              3.9      India         None           NaN   \n",
       "145             3.6    Haryana         None           NaN   \n",
       "211             4.2  Bengaluru         None           NaN   \n",
       "226             3.7    Gujarat         None           NaN   \n",
       "465             5.0      India         None           NaN   \n",
       "552             4.5      India         None           NaN   \n",
       "555             4.0       Pune         None           NaN   \n",
       "577             4.5  Bengaluru         None           NaN   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "21                         NaN  \n",
       "67                         NaN  \n",
       "145                        NaN  \n",
       "211                        NaN  \n",
       "226                        NaN  \n",
       "465                        NaN  \n",
       "552                        NaN  \n",
       "555                        NaN  \n",
       "577                        NaN  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(pattern_3, case=False, regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "9cfbdf11-ffbb-498e-9149-556dda4e5152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Global Cybersecurity Senior Manager - AI Architect</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>₹6L – ₹8L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Analyst, Geo Analytics, India - X Delivery</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Gurgaon | Bengaluru\\nWho We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>₹4L – ₹10L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data Engineer - Global People Analytics</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>₹5L/yr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>AI Engineer / Senior AI Engineer, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data Scientist / Senior Data Scientist, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Analyst, Geo Analytics, India - X Delivery</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Locations: Gurgaon | Bengaluru\\nWho We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data Scientist / Senior Data Scientist, India - BCG X</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.</td>\n",
       "      <td>₹6L – ₹8L/yr</td>\n",
       "      <td>₹7L/yr Median</td>\n",
       "      <td>700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Global Audience Analytics Senior Manager</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</td>\n",
       "      <td>₹7L – ₹10L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name  \\\n",
       "6    Boston Consulting Group   \n",
       "33   Boston Consulting Group   \n",
       "61   Boston Consulting Group   \n",
       "62   Boston Consulting Group   \n",
       "63   Boston Consulting Group   \n",
       "121  Boston Consulting Group   \n",
       "211  Boston Consulting Group   \n",
       "271  Boston Consulting Group   \n",
       "392  Boston Consulting Group   \n",
       "\n",
       "                                                 Job_Title  Company_Rating  \\\n",
       "6       Global Cybersecurity Senior Manager - AI Architect             4.2   \n",
       "33         AI Engineer / Senior AI Engineer, India - BCG X             4.2   \n",
       "61              Analyst, Geo Analytics, India - X Delivery             4.2   \n",
       "62                 Data Engineer - Global People Analytics             4.2   \n",
       "63         AI Engineer / Senior AI Engineer, India - BCG X             4.2   \n",
       "121  Data Scientist / Senior Data Scientist, India - BCG X             4.2   \n",
       "211             Analyst, Geo Analytics, India - X Delivery             4.2   \n",
       "271  Data Scientist / Senior Data Scientist, India - BCG X             4.2   \n",
       "392               Global Audience Analytics Senior Manager             4.2   \n",
       "\n",
       "      Location  \\\n",
       "6      Gurgaon   \n",
       "33     Gurgaon   \n",
       "61     Gurgaon   \n",
       "62     Gurgaon   \n",
       "63      Mumbai   \n",
       "121     Mumbai   \n",
       "211  Bengaluru   \n",
       "271    Gurgaon   \n",
       "392    Gurgaon   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Description  \\\n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "33   Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Locations: Gurgaon | Bengaluru\\nWho We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "63   Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nBuild AI/ML technology stacks from concept to production, including data pipelines, model training, and deployment.\\nDevelop and optimize Generative AI workflows, including prompt engineering, fine-tuning (LoRA, QLoRA), retrieval-augmented generation (RAG), and LLM-based applications.\\nWork with Large Language Models (LLMs) such as Llama, Mistral, and GPT, ensuring efficient adaptation for various use cases.\\nDesign and implement AI-driven automation using agentic AI systems and orchestration frameworks like Autogen, LangGraph, and CrewAI.\\nLeverage cloud AI infrastructure (AWS, Azure, GCP) for scalable deployment and performance tuning.\\nCollaborate with cross-functional teams to deliver AI-driven solutions.\\n\\nWhat You'll Bring\\n\\nBachelor’s, Master’s, or PhD in Computer Science, Data Science, Mathematics, Statistics, Engineering or a related field.\\n2+ years of experience in AI/ML, with expertise in Generative AI and LLMs.\\nStrong proficiency in Python and experience with AI/ML frameworks like PyTorch and TensorFlow.\\nKnowledge of advanced prompt engineering techniques (Chain of Thought, Few-Shot, Self-Consistency).\\nExperience in AI workflow automation and model orchestration.\\nHands-on experience with API development using Flask or Django.\\nFamiliarity with data processing frameworks like Databricks and Airflow.\\nStrong analytical skills and the ability to work in a collaborative environment\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "121                                                                                                                          Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "211                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Locations: Gurgaon | Bengaluru\\nWho We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "271                                                                                                                          Locations: Mumbai | Gurgaon\\n\\nWho We Are\\n\\nWe are BCG X. Our global team of 3,000 tech experts are united by a drive to make a difference. Working across industries and disciplines, we go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. BCG X provides a unique ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWe Are BCG X\\n\\nWe’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.\\n\\nWhat You'll Do\\n\\nAs a Data Scientist at BCG, you will collaborate on challenging projects to increasing your understanding of complex business problems from diverse perspectives and developing new skills and experience to help you at every stage of your career. You will use data and advanced analytics to uncover innovative insights that create lasting impact for BCG and its clients.\\n\\nKey Competencies\\n\\nApplying advanced analytics and AI/ML techniques to solve complex business problems and create value for BCG clients.\\n\\nConceptualizing business problems and drive frameworks.\\n\\nManaging engagements, client relationships, and display initiative to effectively drive solutions to client problems.\\n\\nCommunicating effectively and professionally with clients, delivering impactful solutions and presenting insights coherently.\\n\\nCollaborating to work in cross-functional teams with diverse backgrounds and perspectives\\n\\nWhat You'll Bring\\n\\nA master’s degree or PhD in computer science, data science, mathematics, statistics, engineering, or a related field\\n\\n2+ years of relevant work experience in data science, machine learning, artificial intelligence, or big data\\n\\nProficiency in Python, R, SQL, and other programming languages and tools for data analysis and machine learning\\n\\nExperience in designing, developing, and deploying scalable and robust data products using cloud platforms such as AWS, Azure, or Google Cloud\\n\\nExperience in using machine learning techniques such as regression, classification, clustering, natural language processing, computer vision, etc.\\n\\nFamiliarity with industry-specific skills such as retail analytics, healthcare analytics, financial analytics, etc.\\n\\nBoston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.\\nBCG is an E - Verify Employer. Click here for more information on E-Verify.   \n",
       "392                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Who We Are\\nBoston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.\\n\\nTo succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures—and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.   \n",
       "\n",
       "      Salary_Range  Median_Salary Median_Salary_Standardized  \n",
       "6     ₹6L – ₹8L/yr  ₹7L/yr Median                     700000  \n",
       "33            None            NaN                     700000  \n",
       "61   ₹4L – ₹10L/yr  ₹7L/yr Median                     700000  \n",
       "62          ₹5L/yr            NaN                   500000.0  \n",
       "63            None            NaN                     700000  \n",
       "121           None            NaN                     700000  \n",
       "211           None            NaN                        NaN  \n",
       "271   ₹6L – ₹8L/yr  ₹7L/yr Median                     700000  \n",
       "392  ₹7L – ₹10L/yr  ₹8L/yr Median                     800000  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Boston Consulting Group', regex=False, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Description', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "e6154f33-15e7-4b8e-a774-ed2452a41040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Splashgain</td>\n",
       "      <td>Data Scientist/ Data Analyst</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Working Experience: 0 to 5 Years\\nAny candidate with Data Science Certifications or hands-on experience in Data Science/ Stat domain would be preferred.\\nSupport our product, sales, leadership, and marketing teams with insights gained from analyzing company data.\\nThe ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.\\nExperience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms, and creating/running simulations.\\nAbility to drive business results with their data-based insights, comfortable working with a wide range of stakeholders and functional teams.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Splashgain</td>\n",
       "      <td>AI/ML &amp; Generative AI Intern (6-Month Internship)</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Internship Overview\\nAre you passionate about AI, Machine Learning, and Generative AI?\\nWe are offering an exciting 6-month internship opportunity for students and recent graduates to gain hands-on experience working on real-world projects involving large language models (LLMs), prompt engineering, and AI agent development.\\nThis internship is ideal for candidates who want to explore careers in AI/ML and enhance their portfolios through impactful project work, mentorship, and practical exposure.\\nKey Learning Opportunities &amp; Responsibilities\\nAs an intern, you will:\\nAssist in developing and testing ML models using Python and frameworks like Scikit-learn, PyTorch, or</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                                          Job_Title  \\\n",
       "226   Splashgain                       Data Scientist/ Data Analyst   \n",
       "425   Splashgain  AI/ML & Generative AI Intern (6-Month Internship)   \n",
       "\n",
       "     Company_Rating Location  \\\n",
       "226             3.7  Gujarat   \n",
       "425             3.7  Gujarat   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Description  \\\n",
       "226  Working Experience: 0 to 5 Years\\nAny candidate with Data Science Certifications or hands-on experience in Data Science/ Stat domain would be preferred.\\nSupport our product, sales, leadership, and marketing teams with insights gained from analyzing company data.\\nThe ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.\\nExperience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms, and creating/running simulations.\\nAbility to drive business results with their data-based insights, comfortable working with a wide range of stakeholders and functional teams.   \n",
       "425                                                                                                                  Internship Overview\\nAre you passionate about AI, Machine Learning, and Generative AI?\\nWe are offering an exciting 6-month internship opportunity for students and recent graduates to gain hands-on experience working on real-world projects involving large language models (LLMs), prompt engineering, and AI agent development.\\nThis internship is ideal for candidates who want to explore careers in AI/ML and enhance their portfolios through impactful project work, mentorship, and practical exposure.\\nKey Learning Opportunities & Responsibilities\\nAs an intern, you will:\\nAssist in developing and testing ML models using Python and frameworks like Scikit-learn, PyTorch, or   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "226                        NaN  \n",
       "425                     120000  "
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('Splashgain', regex=False, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Description', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "cf60ba26-702b-45ce-bfd8-72adbaa876a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sumeru</td>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Job Title:- Data Scientist/Data Analyst\\nJob Location:- Remote\\nJob Type: Full-Time Position\\n\\nPosition Summary\\nWe are looking for a Data Scientist or Analyst who will be working closely with other Data Scientists and Data analysts on performing detailed requirements analysis given by clients. Identifying objectives, executing complex analytical projects, and defining processes to deliver robust analytical solutions for clients.\\n\\nKey Responsibilities</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Tecvesten Consulting</td>\n",
       "      <td>Data Scientist / Data Analyst / BI</td>\n",
       "      <td>3.9</td>\n",
       "      <td>About Us\\nTecvesten Consulting, a collective young minds with energetic vision of consulting through different perspective.\\n\\nJob Description\\nThe candidate will primarily be responsible for extracting and analysing data from various sources, structuring and organizing it and presenting key insights through dashboards and reports to support management decision-making.\\n\\nWorking Days: 6 days work week</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Teramind</td>\n",
       "      <td>Data Scientist - Online Behavioral Analytics &amp; Generative AI</td>\n",
       "      <td>3.6</td>\n",
       "      <td>About Teramind\\n\\nTeramind is the leading platform for user behavior analytics, serving multiple use cases from insider risk mitigation to business process optimization. With our comprehensive suite of solutions, organizations gain unprecedented visibility into user activities while enhancing security, optimizing productivity, and ensuring compliance. Trusted by Fortune 500 companies and businesses of all sizes across industries, our innovative platform helps organizations protect sensitive data, maximize workforce performance, and create safer, more efficient digital workplaces. Through real-time monitoring and advanced analytics, we enable businesses to safeguard their most sensitive information while optimizing employee productivity in both in-office and remote work environments.</td>\n",
       "      <td>Haryana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Sentient</td>\n",
       "      <td>AI Data Analyst</td>\n",
       "      <td>5.0</td>\n",
       "      <td>At Sentient, we’re pioneering the open artificial general intelligence (AGI) frontier, enabling loyalty and monetization of open-source models through cutting-edge research. Our platform is designed to democratize AI development, empowering communities to collaboratively train, control, monetize, and build on top of AI models in a truly open and accessible ecosystem, ensuring fair value distribution to AI builders.\\nSentient is backed by leading Silicon Valley venture capital firms including Founders’ Fund and founded by top AI academics and protocol founders.\\nJob Summary\\nWe're seeking an exceptional AI Product Data Analyst to join our team in building Sentient Chat, a multi-agent product aiming to compete with leading consumer AI competitors. This role is a unique opportunity to work on end-to-end AI system development, from data analysis to executing on tangible AI feature improvements. The ideal candidate will have a strong focus on data analysis, natural language processing, and understanding of consumer AI performance expectations.</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>BlazingCoders</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Overview:\\nWe are looking for a skilled Data Analyst to join our growing team. The ideal candidate will be passionate about data, capable of translating numbers into actionable insights, and confident in presenting findings to stakeholders. If you love solving problems with data and driving smart business decisions, we want to hear from you.\\nRoles and Responsibilities:\\nCollect, clean, and analyze large datasets from various sources\\nDevelop and maintain dashboards and reports for different departments\\nIdentify trends, patterns, and correlations in complex data sets\\nWork closely with teams to understand business goals and provide data-driven insights</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Kone</td>\n",
       "      <td>Data and Analytics</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A Data and Machine Learning Specialist is responsible for managing, analyzing, and leveraging data to drive business insights and develop predictive models. This role combines elements of data science, data engineering, data management, and machine learning to ensure data-driven decision-making and innovation.\\nResponsibilities:\\nData Collection &amp; Management: Gather, clean, and organize data from various sources to ensure its accuracy and accessibility.\\nData Analysis: Utilize statistical methods and machine learning tools to analyze data and uncover trends and patterns.\\nPipeline Development: Design and maintain efficient data pipelines and architectures to facilitate seamless data flow.</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>iTDAY India</td>\n",
       "      <td>Data Scientist &amp; Analyst</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Employment Type:\\nFull Time\\nJob Description:\\nJob Overview\\n\\nWe are looking for a Data Scientist who will support our product, sales, leadership and\\nmarketing teams with insights gained from analyzing company data. The ideal candidate is\\nadept at using large data sets to find opportunities for product and process optimization and\\nusing models to test the effectiveness of different courses of action. They must have strong\\nexperience using a variety of data mining/data analysis methods, using a variety of data\\ntools, building and implementing models, using/creating algorithms and creating/running\\nsimulations. They must have a proven ability to drive business results with their data-based\\ninsights. They must be comfortable working with a wide range of stakeholders and functional\\nteams. The right candidate will have a passion for discovering solutions hidden in large data\\nsets and working with stakeholders to improve business outcomes.</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company_Name  \\\n",
       "21                 Sumeru   \n",
       "67   Tecvesten Consulting   \n",
       "145              Teramind   \n",
       "465              Sentient   \n",
       "552         BlazingCoders   \n",
       "555                  Kone   \n",
       "577           iTDAY India   \n",
       "\n",
       "                                                        Job_Title  \\\n",
       "21                                         Data Scientist/Analyst   \n",
       "67                             Data Scientist / Data Analyst / BI   \n",
       "145  Data Scientist - Online Behavioral Analytics & Generative AI   \n",
       "465                                               AI Data Analyst   \n",
       "552                                                  Data Analyst   \n",
       "555                                            Data and Analytics   \n",
       "577                                      Data Scientist & Analyst   \n",
       "\n",
       "     Company_Rating  \\\n",
       "21              3.3   \n",
       "67              3.9   \n",
       "145             3.6   \n",
       "465             5.0   \n",
       "552             4.5   \n",
       "555             4.0   \n",
       "577             4.5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Description  \\\n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Job Title:- Data Scientist/Data Analyst\\nJob Location:- Remote\\nJob Type: Full-Time Position\\n\\nPosition Summary\\nWe are looking for a Data Scientist or Analyst who will be working closely with other Data Scientists and Data analysts on performing detailed requirements analysis given by clients. Identifying objectives, executing complex analytical projects, and defining processes to deliver robust analytical solutions for clients.\\n\\nKey Responsibilities   \n",
       "67                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            About Us\\nTecvesten Consulting, a collective young minds with energetic vision of consulting through different perspective.\\n\\nJob Description\\nThe candidate will primarily be responsible for extracting and analysing data from various sources, structuring and organizing it and presenting key insights through dashboards and reports to support management decision-making.\\n\\nWorking Days: 6 days work week   \n",
       "145                                                                                                                                                                                                                                                                       About Teramind\\n\\nTeramind is the leading platform for user behavior analytics, serving multiple use cases from insider risk mitigation to business process optimization. With our comprehensive suite of solutions, organizations gain unprecedented visibility into user activities while enhancing security, optimizing productivity, and ensuring compliance. Trusted by Fortune 500 companies and businesses of all sizes across industries, our innovative platform helps organizations protect sensitive data, maximize workforce performance, and create safer, more efficient digital workplaces. Through real-time monitoring and advanced analytics, we enable businesses to safeguard their most sensitive information while optimizing employee productivity in both in-office and remote work environments.   \n",
       "465  At Sentient, we’re pioneering the open artificial general intelligence (AGI) frontier, enabling loyalty and monetization of open-source models through cutting-edge research. Our platform is designed to democratize AI development, empowering communities to collaboratively train, control, monetize, and build on top of AI models in a truly open and accessible ecosystem, ensuring fair value distribution to AI builders.\\nSentient is backed by leading Silicon Valley venture capital firms including Founders’ Fund and founded by top AI academics and protocol founders.\\nJob Summary\\nWe're seeking an exceptional AI Product Data Analyst to join our team in building Sentient Chat, a multi-agent product aiming to compete with leading consumer AI competitors. This role is a unique opportunity to work on end-to-end AI system development, from data analysis to executing on tangible AI feature improvements. The ideal candidate will have a strong focus on data analysis, natural language processing, and understanding of consumer AI performance expectations.   \n",
       "552                                                                                                                                                                                                                                                                                                                                                                                                           Overview:\\nWe are looking for a skilled Data Analyst to join our growing team. The ideal candidate will be passionate about data, capable of translating numbers into actionable insights, and confident in presenting findings to stakeholders. If you love solving problems with data and driving smart business decisions, we want to hear from you.\\nRoles and Responsibilities:\\nCollect, clean, and analyze large datasets from various sources\\nDevelop and maintain dashboards and reports for different departments\\nIdentify trends, patterns, and correlations in complex data sets\\nWork closely with teams to understand business goals and provide data-driven insights   \n",
       "555                                                                                                                                                                                                                                                                                                                                                                       A Data and Machine Learning Specialist is responsible for managing, analyzing, and leveraging data to drive business insights and develop predictive models. This role combines elements of data science, data engineering, data management, and machine learning to ensure data-driven decision-making and innovation.\\nResponsibilities:\\nData Collection & Management: Gather, clean, and organize data from various sources to ensure its accuracy and accessibility.\\nData Analysis: Utilize statistical methods and machine learning tools to analyze data and uncover trends and patterns.\\nPipeline Development: Design and maintain efficient data pipelines and architectures to facilitate seamless data flow.   \n",
       "577                                                                                                    Employment Type:\\nFull Time\\nJob Description:\\nJob Overview\\n\\nWe are looking for a Data Scientist who will support our product, sales, leadership and\\nmarketing teams with insights gained from analyzing company data. The ideal candidate is\\nadept at using large data sets to find opportunities for product and process optimization and\\nusing models to test the effectiveness of different courses of action. They must have strong\\nexperience using a variety of data mining/data analysis methods, using a variety of data\\ntools, building and implementing models, using/creating algorithms and creating/running\\nsimulations. They must have a proven ability to drive business results with their data-based\\ninsights. They must be comfortable working with a wide range of stakeholders and functional\\nteams. The right candidate will have a passion for discovering solutions hidden in large data\\nsets and working with stakeholders to improve business outcomes.   \n",
       "\n",
       "      Location  \n",
       "21      Remote  \n",
       "67       India  \n",
       "145    Haryana  \n",
       "465      India  \n",
       "552      India  \n",
       "555       Pune  \n",
       "577  Bengaluru  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[21, 67, 145, 465, 552, 555, 577], ['Company_Name', 'Job_Title', 'Company_Rating', 'Description', 'Location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad4ea5-012a-410a-985b-3867845f0d61",
   "metadata": {},
   "source": [
    "- Row 211, using information from 61, lets impute the salary with 700000.\n",
    "- Row 226, lets impute the salary with 6,00,000.\n",
    "<br>\n",
    "\n",
    "- Row 21, lets impute the salary with 10,00,000.\n",
    "- Row 67, lets impute the salary with 7,00,000.\n",
    "- Row 145, lets impute the salary with 6,00,000.\n",
    "- Row 465, the rating of the company is 5.0 and backed by VC's, the role involves AI cum data analyst, lets impute the salary with 8,00,000.\n",
    "- Row 552, the pay would be around 5,00,000.\n",
    "- Row 555, the salary range of this role would be round 6,00,000.\n",
    "- Row 577, the rating of the company is 4.5 and location is bengaluru which is filled with companies competiting again each other, therefore the pay has be competitive, lets impute the salary with 8,00,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "48d007ea-9d17-4aec-9107-87fa380b20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[211, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[226, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[21, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[67, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[145, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[465, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[552, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[555, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[577, 'Median_Salary_Standardized'] = 800000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf025bb-8963-4673-94d1-0a5812f962c0",
   "metadata": {},
   "source": [
    "### Imputing missing values of 'Data Scientist' roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "b5c9b7bf-2a5e-461b-bb74-c9672d323d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "36a07007-3658-461c-84c3-176b3c6438b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Procter &amp; Gamble</td>\n",
       "      <td>Data Scientist - Product Supply</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Goa</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Numerator</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Akamai</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MOLECULAR CONNECTIONS</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>SkillCircle</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>4.7</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>Pisoft Informatics</td>\n",
       "      <td>Data Science Developer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Liases Foras</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>MNJ Software</td>\n",
       "      <td>Data Science (AI &amp; Python Program Developers)</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>ChicMic Studios</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Company_Name                                      Job_Title  \\\n",
       "12                  PayPal                                 Data Scientist   \n",
       "37        Procter & Gamble                Data Scientist - Product Supply   \n",
       "51               Numerator                                 Data Scientist   \n",
       "68                  Akamai                                 Data Scientist   \n",
       "73   MOLECULAR CONNECTIONS                                 Data Scientist   \n",
       "..                     ...                                            ...   \n",
       "761            SkillCircle                                   Data Science   \n",
       "768     Pisoft Informatics                         Data Science Developer   \n",
       "776           Liases Foras                                 DATA SCIENTIST   \n",
       "801           MNJ Software  Data Science (AI & Python Program Developers)   \n",
       "807        ChicMic Studios                                 Data Scientist   \n",
       "\n",
       "     Company_Rating Location Salary_Range Median_Salary  \\\n",
       "12              3.7  Chennai         None           NaN   \n",
       "37              4.1      Goa         None           NaN   \n",
       "51              4.3    India         None           NaN   \n",
       "68              4.5    India         None           NaN   \n",
       "73              3.5   Remote         None           NaN   \n",
       "..              ...      ...          ...           ...   \n",
       "761             4.7    India         None           NaN   \n",
       "768             4.0   Mohali         None           NaN   \n",
       "776             3.1   Mumbai         None           NaN   \n",
       "801             4.4   Remote         None           NaN   \n",
       "807             3.9   Mohali         None           NaN   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "12                         NaN  \n",
       "37                         NaN  \n",
       "51                         NaN  \n",
       "68                         NaN  \n",
       "73                         NaN  \n",
       "..                         ...  \n",
       "761                        NaN  \n",
       "768                        NaN  \n",
       "776                        NaN  \n",
       "801                        NaN  \n",
       "807                        NaN  \n",
       "\n",
       "[82 rows x 7 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(pattern_2, case=False, regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "c94f4fd7-b488-450b-b4ad-3fd714103e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Job_Title'].str.contains(pattern_2, case=False, regex=True, na=False) & \n",
    "        df_copy['Median_Salary_Standardized'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "f3680792-1d97-406e-9f34-81ae68aab923",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mask = df_copy['Job_Title'].str.contains(pattern_2, case=False, regex=True, na=False) & \\\n",
    "        df_copy['Median_Salary_Standardized'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "16bb1fc7-d865-4b69-b278-d7908bb83103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Source</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>Intern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>The Company\\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\\n\\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\\n\\nWe offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Procter &amp; Gamble</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist - Product Supply</td>\n",
       "      <td>Goa</td>\n",
       "      <td>P&amp;G was founded over 180 years ago as a simple soap and candle company. Today, we're the world’s largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but significant ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship. The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and clear, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.\\n\\nDedication from Us:\\nYou will be at core of Ground- breaking innovations, be given exciting opportunities, lead initiatives, and take charge and responsibility, in creative workspaces where new insights thrive. All the while, you'll receive outstanding training to help you become a leader in your field. What we Offer: Continuous mentorship – work with peers and receive both formal training as well as day-to-day mentoring from your manager multifaceted and encouraging work environment– employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Numerator</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>We’re reinventing the market research industry. Let’s reinvent it together.\\nAt Numerator, we believe tomorrow’s success starts with today’s market intelligence. We empower the world’s leading brands and retailers with unmatched insights into consumer behavior and the influencers that drive it.\\nResponsibilities:\\nDeliver complex analytics projects, providing data-driven insights to address critical business challenges by analyzing disaggregated data utilizing modeling, statistics, and machine learning.\\nWork with diverse data sets to clean, manipulate, and analyze data using tools such as R, Python, and SQL\\nApply a range of statistical techniques and modeling processes to transactional and attitudinal data to help answer our clients’ business questions\\nDevelop expertise in all our analytical solutions, understanding their technical intricacies and their value to clients</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Akamai</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Do you want to see your data insights directly strengthen the defenses of critical security products?\\nDo you thrive on dissecting complex data to outsmart sophisticated attackers?\\nJoin our Global Web Security group\\nOur team is part of the Application Security organization, responsible for the technologies powering Akamai's security products and protecting some of the world's major internet brands. Working in partnership with Global Services, Engineering, and Product teams we help our customers get the best protection against threat actors.\\nShape internet security\\nIn this role, you'll play a key part in strengthening security products by analyzing data, addressing customer challenges, and driving product improvements. You'll collaborate across teams to implement solutions, enhance detection accuracy, and provide insights that shape strategy and performance.\\nAs a Data Scientist, you will be responsible for:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MOLECULAR CONNECTIONS</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Requirement Details.\\nJob Description:\\nJob Designation: Data Scientist\\nRequired Education and experience:\\nBA/ BS in biostatistics, math, statistics, public health, or biological sciences with a minimum of 2 year of experience/ Masters in statistics\\n[Plus] real-world data, clinical trial data or Oncology experience\\n[Plus] Advanced degree in the aforementioned fields\\nRequired knowledge, skills and abilities:\\nStrong knowledge of the R programming language with a minimum of 2 year of experience</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Halo Media</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Data Scientist - India, Fully Remote</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Halo believes in innovation by inclusion to solve digital problems. As an international agency of over 200 people specializing in interactive media strategy and development, we embrace equity and empowerment in a serious way. Our interdisciplinary teams of unique designers, developers and entrepreneurial minds with a variety of backgrounds, viewpoints, and skills connect to solve business challenges of every shape and size. We empathize to form deep, meaningful relationships with our clients so they can do the same with their audience. Working at Halo feels like belonging. Learn more about our philosophy, benefits, and team at https://halopowered.com/As an AI Architect, you will lead the design of scalable, secure, and modern technology solutions, leveraging artificial intelligence, cloud platforms, and microservices—while ensuring alignment with AI governance principles, agile delivery, and platform modernization strategies\\nAs a Data Scientist, you’ll be part of a multidisciplinary team applying advanced analytics, machine learning, and generative AI to solve real-world problems across our consulting, health, wealth, and career businesses. You will collaborate closely with engineering, product, and business stakeholders to develop scalable models, design intelligent pipelines, and influence data-driven decision-making across the enterprise.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>WTW</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>202504116\\nIndia\\nMumbai, Maharashtra, India\\nBevorzugt\\nDescription\\nGain a comprehensive understanding of the process and data flow.\\nAcquire in-depth knowledge of the reports provided by GB Outsourcing.\\nCreate analytics and reports for insurers to enable strategic decision-making based on various facts, figures, and trends.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Nestlé IT</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About You\\nYou are an expert in applying advanced analytics to solve marketing and sales business problems. You are equally comfortable applying your knowledge to optimize marketing spend or working with sales to optimize trade spend.\\nYou are hands-on in your ability to build models, but you are also comfortable coaching less experienced team members in how to solve problems, or managing agencies to deliver where needed.\\nYou know that having a great model isn’t enough, you love to derive the “so what” from your models and tell compelling stories which inspire action and drive growth.\\n\\nA day in the life of...\\nYou’ll be responsible for using advanced analytics to provide robust measurements of marketing &amp;amp; trade investment across different business models, product categories and\\nvaried geographies.\\nYou will work closely with your stakeholders to provide guidance on how best to optimize and allocate marketing &amp;amp; trade investments in order to support the delivery of our commercial strategy.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Rolling Arrays</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>(Location: India/Remote)\\nWe are seeking an experienced Data Scientist with experience in data analytics, machine learning, and statistical modeling. The ideal candidate will be proficient in data manipulation, data analysis, and have the ability to design, build, and deploy predictive models. You will work with a diverse range of stakeholders to support both operational and strategic objectives across different business domains.\\n\\nKey Responsibilities\\n\\nData Analysis &amp; Modeling\\nAnalyze large and complex datasets to identify trends, patterns, and actionable insights.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Pattern Effects Labs</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>WHAT WE DO\\nAt PE we are building applications where financial decisions are data driven, adaptive and domain focused. We Use AI/ML to uncover hidden patterns from big data from across industries, enabling business and better quality of life.\\nUncovering the hidden\\nAI is used to find pattern and correlation which hide deep within Big Data.\\n\\nEver Adapting\\nOur AI system is designed to pick the best response from millions of possible options in a given scenario. These scenarios can be as diverse as capital markets to healthcare.\\nAccuracy</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Maruti Suzuki India Ltd</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>JOB PURPOSE\\n\\nBuild &amp; Deploy Machine learning models to drive customer retention/satisfaction/Lifetime value\\n\\nWork closely with business to identify issues and use data to propose solutions for effective decision making\\n\\nUse analytical, statistical, and programming skills to collect large data sets and develop data-driven solutions\\n\\nInterpret raw data and extract valuable meaning out of it then use this information to find patterns and develop solutions that organization needs to grow and compete\\n\\nPRINCIPAL ACCOUNTABILITIES\\n\\nCreate various Machine learning based tools or processes such as recommendation engine /lead scoring systems\\n\\nUsing machine learning tools to select features, create and optimize classifiers\\n\\nDiscover information in the huge database and help organization make smarter data drive decision to deliver better customer experience &amp; products\\n\\nUndertaking data collection, preprocessing, and analysis (EDA)\\n\\nBuild models to address business problems\\n\\nPresent information using data visualization techniques\\n\\nIdentify valuable data sources and automate collection processes\\n\\nCollaborate with multiple marketing and product planning teams\\n\\nData preparation, make sense of data from multiple data sources, be compliant to data security norms\\n\\nUnderstanding the business problem\\n\\nEffective communication with Non-Technical stakeholders\\n\\nPossess exceptional knowledge of the business domain along with expertise in technology, math and statistics\\n\\nLook at big data with a view to solve a business problem\\n\\nAbility to create and gain buy-in for novel ideas with the main motive to produce a working model that can help business make effective data driven decisions\\n\\nCreate stories from number crunching\\n\\nBe the data storyteller to gain business confidence\\n\\nSKILLS AND KNOWLEDGE\\n\\n\\nGraduate/Post graduate with understanding of basic data science (Knowledge of SQL ,HIVE, Python, R or SAS - Any 2), knowledge of basic auto industry and sales and marketing operations\\n\\nb) Work Experience 2- 5 Years\\n\\nPlease note that the Educational qualification should be from AICTE/UGC approved colleges only.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ESJ Asthra Edutech Pvt Ltd</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Job Title: Data Scientist\\nJob Type: Full-Time\\nJob Summary\\nWe are looking for a skilled Data Scientist to join our team. You will be responsible for analyzing large volumes of data, creating predictive models, and delivering actionable insights that drive business decisions and improve our learning systems.\\nKey Responsibilities\\nCollect, clean, and preprocess data from multiple sources.\\nBuild and evaluate predictive models and machine learning algorithms.\\nAnalyze data trends and patterns to provide business insights.\\nCollaborate with cross-functional teams including product, marketing, and tech.\\nDesign experiments and interpret their results using statistical techniques.\\nCommunicate findings through visualizations and reports.\\nStay up-to-date with the latest developments in data science and AI.\\nRequirements\\nBachelor’s or Master’s degree in Computer Science, Data Science, Statistics, Mathematics, or a related field.\\nStrong programming skills in Python or R.\\nProficient in SQL and working with large datasets.\\nExperience with machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch).\\nKnowledge of data visualization tools (e.g., Power BI, Tableau, matplotlib, seaborn).\\nExcellent problem-solving and analytical skills.\\nStrong communication skills to explain complex data in a simple way.\\nJob Types: Full-time, Fresher\\nEducation:\\nBachelor's (Required)\\nWork Location: In person</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Agnik</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Position: Data Scientist (Intern)\\nStatus: Open\\nAGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:\\n1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing\\n2) Some Experience in Programming in C++/Java/Distributed Programming\\n3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics\\nPositions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with \"Application for Data Science Intern\" in the Subject line.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>G2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist - I</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Location\\nBengaluru\\nEmployment Type\\nFull time\\nLocation Type\\nOn-site\\nDepartment\\nProduct R&amp;D\\n\\nAbout G2 - The Company\\nWhen you join G2, you’re joining the team that helps businesses reach their peak potential by powering decisions and strategies with trusted insights from real software users.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Pricelabs</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Data Scientist (Remote)</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Preferable Location(s): Pune, India | Bengaluru, India | Delhi, India | Chennai, India | Mumbai, India | Noida, India | Gurugram, India | Hyderabad, India | Coimbatore, India\\nWork Type: Full Time\\n\\nAbout the Role: Design, develop and enhance our pricing algorithms to enable new capabilities. Process, analyse, model, and visualise findings from our market-level supply and demand data. Build and enhance internal and customer-facing dashboards to better track metrics and trends that help customers use PriceLabs in a better way. Take ownership of product ideas and design discussions. Occasional travel to conferences to interact with prospective users and partners, and learn where the industry is headed. About You: You have a minimum of two (2) years of relevant experience. Strong understanding of analysis of algorithms, data structures and statistics. Solid programming experience. Including being able to quickly prototype an idea and test it out. Strong communication skills, including the ability and willingness to explain complicated algorithms and concepts in simple terms. Experience with relational databases and strong knowledge of SQL. Prior experience working in a fast-paced environment. Willingness to wear many hats. Good to have: Experience in the vacation rental industry. Experience developing dynamic pricing models. How to apply for this position? Please fill out the form with the required details. If your profile is shortlisted, our team will reach out to you via email. If you don't find the emails in your inbox, please check your spam folder. Tip: Avoid using AI-generated responses. We want to hear from you! About PriceLabs: PriceLabs is a revenue management solution for the short-term rental and hospitality industry, founded in 2014 and headquartered in Chicago, IL. Our platform helps individual hosts and hospitality professionals optimize their pricing and revenue management, adapting to changing market trends and occupancy levels. With dynamic pricing, automation rules, and customizations, we manage pricing and minimum-stay restrictions for any portfolio size, with prices automatically uploaded to preferred channels. Every day, we price over 500,000+ listings globally across 150+ countries, offering world-class tools like the Base Price Help and Minimum Stay Recommendation Engine. In 2025, we scaled to; 500K+ properties syncing daily 60K+ customers worldwide 270+ globally remote team 36% diversity Industry awards won: SaasBoomi 2021 The Shortyz 2020 The Shortyz 2023 STRive Awards 2025 We continue to grow exponentially backed by a strong team to take us to the next level. Why join PriceLabs? We are a remote-first organization and accept work from home as the norm. Work with an industry-leading product that has thousands of customers worldwide, and our customers love the product! (NPS in the 70s, ) Work with a global team (18 countries and counting) of passionate individuals that accept open communication, empowerment, and a shared focus on customer success. We are a freemium product, so marketing leads the charge on customer acquisition. PriceLabs is an equal-opportunity employer. We are committed to providing equal opportunity in all aspects of employment. We do not discriminate based on race, colour, religious creed, national origin, ancestry, sex, age, veteran status, marital status or physical challenges.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Crypto Mize</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Data expert Jobs in Delhi at CryptoMize - Check Out data scientist job description, data scientist salary to our product, sales, leadership and marketing teams with insights gained from analyzing company data. A Data Expert is a person who works with stakeholders to enhance business outcomes by delivering solutions and identifying solutions hidden in massive data sets. He or she must be able to perfect in data mining and data analysis procedures, as well as use a number of data tools, design and execute models, use/create algorithms, and create/run simulations. for a Data Scientist job in Delhi at CryptoMize, A Conglomerate Digital Agency and Digital Privacy Company in India.\\n\\nData Scientist job Responsibilities\\n\\nCombining computer science, modeling, statistics, analytics, and math skills—along with sound business sense—data scientists uncover the answers to major questions that help organizations make objective decisions. The ability to transform a sea of data into actionable insights can have a profound impact—for predicting the best new diabetes treatment to identifying and thwarting national security threats. That’s why businesses and government agencies are rushing to hire data science professionals who can help do just that. The first step toward establishing an active data analytics platform is to collect structured and unstructured data from different sources. Unstructured data consists of things like what customers are saying about the organization on social media, while structured data is a measurable metric, such as customer lifetime value.\\n\\nA data scientist cleans and validates the data to ensure its accuracy and completeness. While AI-powered data analytics tools can automate part of this process, cleaning data still makes up the bulk of a data scientist’s job duties. Once the data is clean, the data scientist analyzes the data to identify patterns and trends using advanced statistics skills. Work throughout the organization to identify opportunities for leveraging company data to drive business solutions. Develop custom data models and algorithms to apply data sets. Strong problem solving skills with an emphasis on product development.\\n\\nAbout Us\\n\\nCryptoMize is a Conglomerate Digital Agency with presence in 3 Continents evolving for a decade, having served elite clients such as Governments, Politicians, MNCs, Celebrities and HNIs in 30+ Countries. Over the years, we have garnered and trained a team of industry experts that are capable of providing the best quality results.\\n\\n\\nDelhi\\n\\n\\nAvailable\\n\\n\\nFull time\\n\\n\\nPermanent\\n\\n\\nImmediate\\n\\n\\nBased on experience\\n\\nThe application for this opening can be submitted via the application form linked below, ONLY. Direct phone calls and emails will not be entertained.\\n\\nOur Principles\\n\\nThese are some of the principles that we strongly believe in, preach and actually follow as well.\\n\\nCommitments\\n\\nWe clearly commit what we can do, by when can we do it and how we would do it, And then we do it.\\n\\nConfidentiality\\n\\nWe are extremely paranoid about protecting the confidentiality of what we do, for whom and how we do it.\\n\\nComfortability\\n\\nWe ensure comfortability of you and your team with ours, which can only come from complete transparency.\\n\\nCapability\\n\\nWe keep improving our already awesome capabilities by investing all resources at our disposal.\\n\\nData Scientist Job\\n\\nData scientist jobs for freshers\\n\\nData Scientist Job Requirements\\n\\nData Scientist Qualification\\n\\nOur Services\\nKnow More About Us\\nPerception Perfection\\n\\nCryptoMize is dedicated to ensure a prominent progress to how the world perceives you. We help you to establish your perception to the extent of perfection with our devised strategic plan and techniques.\\n\\nPromotional Parlance\\n\\nCryptoMize introduces you to Promotional Parlance which not only promotes your cause but provides a personalized-edge. Our solutions are tailored in a strategic way that attracts the audience in a way that they are most receptive to.\\n\\nPublic Relations\\n\\nCryptoMize formulates a proactive strategy to amplify your Media Outreach without compromising your reputation. CryptoMize assists you in communicating with your intended audience to achieve a global outreach.\\n\\nPolitical Catalysis\\n\\nWe bring efficiency to governance operations through intelligence and strategic thinking. By integrating digital approaches, CryptoMize seeks to improve Campaign Strategies and governance in general.\\n\\nPolicing Phronesis\\n\\nCryptoMize, with the help of its special mix of Forensics and Consultancy, aims to handle all sorts of cyber crimes affecting your organisation and provide you with the best guidance for such situations.\\n\\nPrivacy Enforcement\\n\\nCryptoMize is driven by the belief that none of your valuable data should go unprotected. Our experts put concerted effort to preserve your privacy in order to minimize the impact of cybercrime.\\n\\nWhat Makes Us Different?\\n\\nCryptoMize offers a full spectrum of elite services derived with preemptive analysis and strategic planning to our clients. We work efficiently with our proficient and proactive team by utilising extraordinary tools.\\n\\nCollaboration with Dignitaries\\n\\nWe collaborate with highly influential and prominent personalities around the world. Being transcendental and visionary has its own benefits, our supremacy of being omnipresent empowers us to command, control and maneuver information from the internet.\\n\\n01\\nPowerful Team\\n\\nCryptoMize is the combination of a powerful team that works on a supportive, transparent and encouraging platform. With spontaneity and dedication to the advancement of technology, we aspire to be better at what we do for people who trust us with their information and projects.\\n\\n02\\nTriple-Proof Approach\\n\\nWe execute a triple-proof approach from conducting thorough research, developing strong strategies, to guaranteeing information security. This proves beneficial for our clients to reach their desired goal.\\n\\n03\\nOur Core Values\\nTrust\\n\\nWe seek to connect and build relationships with our clients.That is our core principle of our work ethic which we fully-abide to. We works on 3 principles: Respect, Honesty and Transparency.\\n\\nReliability\\n\\nCommitment is an act, not a word. We believe in delivering and living up to your expectations. We have grown into a global agency only through our commitment to deliver and our reliability factor.\\n\\nSafety\\n\\nWe are extremely paranoid about protecting our client’s safety of what we do, for whom and how we do it. We maintain absolute non disclosure and confidentiality to ensure that nothing sensitive goes out.\\n\\nPassion\\n\\nOur passion generates enthusiasm for what we do and how we do it. We inspire, find creative ways and nurture ideas with passion. We strategize based on audience attention.\\n\\nInnovation\\n\\nWe believe in innovation, change and risk taking. With technology, we reinvent ourselves. Innovation is the reason how we are able to eliminate obstacles for cultivating growth.\\n\\nExcellence\\n\\nWe ensure to maintain your eminence by reinventing ourselves with our core values that inspire excellence. We strive for quality in everything we do.\\n\\nOUR PRESENCE\\nOur Journey So Far\\nOur presence is all across the globe. Our impact can be seen in 03+ continents and 30+ countries, we know how to shape people's digital lives. We have a vast range of projects, from running political campaigns, shaping people's perceptions to enforcing privacy, we work with a futuristic approach and always look ahead of time. We never restrict ourselves to specific sectors rather make sure that our services are requisites for any and everybody in the world. With our elite clientele we show supremacy of work and build trustworthy relationships. We believe intelligence is the future and aim towards collective good and growth of all!\\n3+\\nOur Presence\\n\\nSuccessfully establishing ourselves globally in 3+ continents.\\n\\n70+\\nOur Services\\n\\nGiving us an edge over everyone else who is trying to solve similar problems.\\n\\n10+\\nYears of Experience\\n\\nServing great value to our clients since the past decade.\\n\\nNEVERENDING OPPORTUNITIES FOR YOU\\nOur Vision\\n\\nIn the days of yore, gathering intelligence was a matter of sending out spies. Today the world has changed, and intelligence is as much about technology as it is about people. We are redefining what it means to truly protect you and your business. From network security, to cloud recovery, to data recovery, CryptoMize focuses on your technology’s vulnerabilities so you can avoid pitfalls and stay ahead.\\n\\nWe have a singular vision – to be the ultimate ‘go-to’ company for digital reputation management. Our approach is holistic, covering reputation management, social media management, and crisis management.\\nWe uncover security flaws in your technology, identify new threats, and create proactive measures to protect you.\\nWe provide innovative IT solutions to clients of all sizes. Our expertise is in all levels of the information technology stack, including network architecture and cybersecurity.\\nWhy Us?\\n\\nWhy are we so amazing?\\n\\nYUMMY\\n\\nOur awesome chef prepares freshly Maison-made breakfasts, lunches, diners, beverages, coffees everyday to provide the fuel you need to innovate and Execute Best Ideas.\\n\\nEVENTS AND HACKATHONS\\n\\nWant to organize, talk or attend an event? We give you two days per month to attend or organize team-buildings, conferences, trainings, meetups or hackathons.\\n\\nCOMPANY OUTINGS\\n\\nWork hard, play hard! We have an in-house bar with a large choice of wines, beers and arcade games. Plus, we organize memorable &amp; engaging team events at least twice a month.\\n\\nFun Days\\n\\nBesides a day off, we present you with a day that is full of fun. You get to choose from a vast array of fun activities from outdoor activities to pool parties.\\n\\nFLEXIBLE EVERYTHING\\n\\nWe choose to work in a flex office environment to grow new collaborative ideas and practices. We work in small product oriented teams to focus &amp; execute faster.\\n\\nNO DIPLOMAS REQUIRED\\n\\nAt CryptoMize, we don’t care about your degrees, we only care about what you know. Your skillset will be evaluated in regard to your technical experiences and skills.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BirlaSoft</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Country/Region: IN\\nRequisition ID: 26870\\nWork Model:\\nPosition Type:\\nSalary Range:\\nLocation: INDIA - PUNE - BIRLASOFT OFFICE - HINJAWADI\\nTitle: Data Scientist\\nDescription:\\nArea(s) of responsibility\\nKey Responsibilities:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Application Square Infotech Pvt Ltd</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Job Summary:\\nWe are seeking a skilled Data Scientist to analyze large datasets, build predictive models, and derive actionable insights to support business decisions. The ideal candidate has strong statistical knowledge, proficiency in programming, and a problem-solving mindset.\\nKey Responsibilities:\\nCollect, clean, and preprocess structured and unstructured data\\nPerform exploratory data analysis and visualize insights\\nDevelop, test, and deploy machine learning and statistical models\\nCommunicate findings and recommendations through reports and presentations\\nCollaborate with cross-functional teams to identify business opportunities\\nMaintain and improve data pipelines and model performance over time\\nRequired Skills &amp; Qualifications:\\nBachelor’s or Master’s in Computer Science, Statistics, Mathematics, Data Science, or related field\\nProficiency in Python or R, and SQL\\nExperience with machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch)\\nKnowledge of statistical analysis and experimental design\\nFamiliarity with data visualization tools (e.g., Tableau, Power BI, matplotlib, seaborn)\\nExcellent analytical and problem-solving skills\\nStrong communication and presentation abilities\\nPreferred:\\nExperience with big data technologies (e.g., Spark, Hadoop)\\nKnowledge of cloud platforms (AWS, Azure, GCP)\\nExperience- 1-2 Year.\\nMonday To Friday.\\nMorning Shift.\\nhr@applicationsquare.com\\nJob Type: Full-time\\nSchedule:\\nDay shift\\nMonday to Friday\\nWeekend availability\\nWork Location: In person</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Zensar Technologies</td>\n",
       "      <td>3.8</td>\n",
       "      <td>DE&amp;A - AIML - Data Science - Conventional AI - Search</td>\n",
       "      <td>India</td>\n",
       "      <td>Engineered a scalable data pipeline that seamlessly moved data from diverse sources, including REST APIs, on-premise databases, and SharePoint, into Snowflake using Azure Data Factory, significantly improving data integration efficiency. • Led successful requirement gathering sessions, translating complex business needs into actionable technical specifications, which directly contributed to the project's successful delivery. • Implemented robust CI/CD pipelines for Azure Data Factory components and Azure Databricks notebooks, enabling smooth and reliable deployments to higher environments using Azure DevOps. • Automated the data ingestion process,eliminating 90% of manual data processing, drastically improving operational efficiency and reducing human error. • Developed an enterprise-wide data model,consolidating data from multiple sources and ensuring consistent, organization-wide data access, leading to improved decision-making capabilities. • Optimized data processing capabilities,allowing the system to handle 2GB of data every 2 hours with high performance and reliability, ensuring the infrastructure met business needs. • Implemented parallelism in data pipelines,reducing pipeline execution time significantly, boosting performance, and enhancing data flow efficiency. • Designed and documented a comprehensive architecture, detailing data transformation logic and Snowflake schema design, establishing a clear framework for future scalability and maintenance. • Collaborated effectively with business users,ensuring data accessibility, gathering critical feedback, and providing ongoing support that enhanced user satisfaction and system usability.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Futops Technologies India Pvt. Ltd</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Job Title: Data Scientist\\nExperience: 2 to 4 Years\\nLocation: Delhi/NCR\\nIndustry: Information Technology &amp; Services\\nEmployment Type: Full-time\\nAbout the Role:\\nWe are looking for a passionate and results-driven Data Scientist to join our growing analytics and AI/ML team. The ideal candidate will bring hands-on experience in data exploration, model building, and deployment. You will work closely with cross-functional teams to deliver actionable insights and machine learning solutions that drive business value.\\nKey Responsibilities:</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name  Company_Rating  \\\n",
       "12                                PayPal             3.7   \n",
       "37                      Procter & Gamble             4.1   \n",
       "51                             Numerator             4.3   \n",
       "68                                Akamai             4.5   \n",
       "73                 MOLECULAR CONNECTIONS             3.5   \n",
       "77                            Halo Media             3.3   \n",
       "78                                   WTW             3.8   \n",
       "84                             Nestlé IT             4.1   \n",
       "91                        Rolling Arrays             4.3   \n",
       "101                 Pattern Effects Labs             3.4   \n",
       "103              Maruti Suzuki India Ltd             3.8   \n",
       "106           ESJ Asthra Edutech Pvt Ltd             3.9   \n",
       "108                                Agnik             4.6   \n",
       "110                                   G2             4.0   \n",
       "114                            Pricelabs             4.7   \n",
       "126                          Crypto Mize             4.8   \n",
       "134                            BirlaSoft             3.5   \n",
       "143  Application Square Infotech Pvt Ltd             3.9   \n",
       "144                  Zensar Technologies             3.8   \n",
       "147   Futops Technologies India Pvt. Ltd             4.2   \n",
       "\n",
       "                                                 Job_Title    Location  \\\n",
       "12                                          Data Scientist     Chennai   \n",
       "37                         Data Scientist - Product Supply         Goa   \n",
       "51                                          Data Scientist       India   \n",
       "68                                          Data Scientist       India   \n",
       "73                                          Data Scientist      Remote   \n",
       "77                    Data Scientist - India, Fully Remote      Remote   \n",
       "78                                          Data Scientist       India   \n",
       "84                                          Data Scientist   Bengaluru   \n",
       "91                                          Data Scientist       India   \n",
       "101                                         Data Scientist   Bengaluru   \n",
       "103                                         Data Scientist       Delhi   \n",
       "106                                         Data Scientist  Coimbatore   \n",
       "108                                         Data Scientist       India   \n",
       "110                                     Data Scientist - I   Bengaluru   \n",
       "114                                Data Scientist (Remote)        Pune   \n",
       "126                                         Data Scientist       Delhi   \n",
       "134                                         Data Scientist       India   \n",
       "143                                         Data Scientist       India   \n",
       "144  DE&A - AIML - Data Science - Conventional AI - Search       India   \n",
       "147                                         Data Scientist       Delhi   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Description  \\\n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The Company\\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\\n\\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\\n\\nWe offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.   \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the world’s largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but significant ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship. The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and clear, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.\\n\\nDedication from Us:\\nYou will be at core of Ground- breaking innovations, be given exciting opportunities, lead initiatives, and take charge and responsibility, in creative workspaces where new insights thrive. All the while, you'll receive outstanding training to help you become a leader in your field. What we Offer: Continuous mentorship – work with peers and receive both formal training as well as day-to-day mentoring from your manager multifaceted and encouraging work environment– employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance.   \n",
       "51                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         We’re reinventing the market research industry. Let’s reinvent it together.\\nAt Numerator, we believe tomorrow’s success starts with today’s market intelligence. We empower the world’s leading brands and retailers with unmatched insights into consumer behavior and the influencers that drive it.\\nResponsibilities:\\nDeliver complex analytics projects, providing data-driven insights to address critical business challenges by analyzing disaggregated data utilizing modeling, statistics, and machine learning.\\nWork with diverse data sets to clean, manipulate, and analyze data using tools such as R, Python, and SQL\\nApply a range of statistical techniques and modeling processes to transactional and attitudinal data to help answer our clients’ business questions\\nDevelop expertise in all our analytical solutions, understanding their technical intricacies and their value to clients   \n",
       "68                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Do you want to see your data insights directly strengthen the defenses of critical security products?\\nDo you thrive on dissecting complex data to outsmart sophisticated attackers?\\nJoin our Global Web Security group\\nOur team is part of the Application Security organization, responsible for the technologies powering Akamai's security products and protecting some of the world's major internet brands. Working in partnership with Global Services, Engineering, and Product teams we help our customers get the best protection against threat actors.\\nShape internet security\\nIn this role, you'll play a key part in strengthening security products by analyzing data, addressing customer challenges, and driving product improvements. You'll collaborate across teams to implement solutions, enhance detection accuracy, and provide insights that shape strategy and performance.\\nAs a Data Scientist, you will be responsible for:   \n",
       "73                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Requirement Details.\\nJob Description:\\nJob Designation: Data Scientist\\nRequired Education and experience:\\nBA/ BS in biostatistics, math, statistics, public health, or biological sciences with a minimum of 2 year of experience/ Masters in statistics\\n[Plus] real-world data, clinical trial data or Oncology experience\\n[Plus] Advanced degree in the aforementioned fields\\nRequired knowledge, skills and abilities:\\nStrong knowledge of the R programming language with a minimum of 2 year of experience   \n",
       "77                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Halo believes in innovation by inclusion to solve digital problems. As an international agency of over 200 people specializing in interactive media strategy and development, we embrace equity and empowerment in a serious way. Our interdisciplinary teams of unique designers, developers and entrepreneurial minds with a variety of backgrounds, viewpoints, and skills connect to solve business challenges of every shape and size. We empathize to form deep, meaningful relationships with our clients so they can do the same with their audience. Working at Halo feels like belonging. Learn more about our philosophy, benefits, and team at https://halopowered.com/As an AI Architect, you will lead the design of scalable, secure, and modern technology solutions, leveraging artificial intelligence, cloud platforms, and microservices—while ensuring alignment with AI governance principles, agile delivery, and platform modernization strategies\\nAs a Data Scientist, you’ll be part of a multidisciplinary team applying advanced analytics, machine learning, and generative AI to solve real-world problems across our consulting, health, wealth, and career businesses. You will collaborate closely with engineering, product, and business stakeholders to develop scalable models, design intelligent pipelines, and influence data-driven decision-making across the enterprise.   \n",
       "78                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     202504116\\nIndia\\nMumbai, Maharashtra, India\\nBevorzugt\\nDescription\\nGain a comprehensive understanding of the process and data flow.\\nAcquire in-depth knowledge of the reports provided by GB Outsourcing.\\nCreate analytics and reports for insurers to enable strategic decision-making based on various facts, figures, and trends.   \n",
       "84                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        About You\\nYou are an expert in applying advanced analytics to solve marketing and sales business problems. You are equally comfortable applying your knowledge to optimize marketing spend or working with sales to optimize trade spend.\\nYou are hands-on in your ability to build models, but you are also comfortable coaching less experienced team members in how to solve problems, or managing agencies to deliver where needed.\\nYou know that having a great model isn’t enough, you love to derive the “so what” from your models and tell compelling stories which inspire action and drive growth.\\n\\nA day in the life of...\\nYou’ll be responsible for using advanced analytics to provide robust measurements of marketing &amp; trade investment across different business models, product categories and\\nvaried geographies.\\nYou will work closely with your stakeholders to provide guidance on how best to optimize and allocate marketing &amp; trade investments in order to support the delivery of our commercial strategy.   \n",
       "91                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              (Location: India/Remote)\\nWe are seeking an experienced Data Scientist with experience in data analytics, machine learning, and statistical modeling. The ideal candidate will be proficient in data manipulation, data analysis, and have the ability to design, build, and deploy predictive models. You will work with a diverse range of stakeholders to support both operational and strategic objectives across different business domains.\\n\\nKey Responsibilities\\n\\nData Analysis & Modeling\\nAnalyze large and complex datasets to identify trends, patterns, and actionable insights.   \n",
       "101                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            WHAT WE DO\\nAt PE we are building applications where financial decisions are data driven, adaptive and domain focused. We Use AI/ML to uncover hidden patterns from big data from across industries, enabling business and better quality of life.\\nUncovering the hidden\\nAI is used to find pattern and correlation which hide deep within Big Data.\\n\\nEver Adapting\\nOur AI system is designed to pick the best response from millions of possible options in a given scenario. These scenarios can be as diverse as capital markets to healthcare.\\nAccuracy   \n",
       "103                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            JOB PURPOSE\\n\\nBuild & Deploy Machine learning models to drive customer retention/satisfaction/Lifetime value\\n\\nWork closely with business to identify issues and use data to propose solutions for effective decision making\\n\\nUse analytical, statistical, and programming skills to collect large data sets and develop data-driven solutions\\n\\nInterpret raw data and extract valuable meaning out of it then use this information to find patterns and develop solutions that organization needs to grow and compete\\n\\nPRINCIPAL ACCOUNTABILITIES\\n\\nCreate various Machine learning based tools or processes such as recommendation engine /lead scoring systems\\n\\nUsing machine learning tools to select features, create and optimize classifiers\\n\\nDiscover information in the huge database and help organization make smarter data drive decision to deliver better customer experience & products\\n\\nUndertaking data collection, preprocessing, and analysis (EDA)\\n\\nBuild models to address business problems\\n\\nPresent information using data visualization techniques\\n\\nIdentify valuable data sources and automate collection processes\\n\\nCollaborate with multiple marketing and product planning teams\\n\\nData preparation, make sense of data from multiple data sources, be compliant to data security norms\\n\\nUnderstanding the business problem\\n\\nEffective communication with Non-Technical stakeholders\\n\\nPossess exceptional knowledge of the business domain along with expertise in technology, math and statistics\\n\\nLook at big data with a view to solve a business problem\\n\\nAbility to create and gain buy-in for novel ideas with the main motive to produce a working model that can help business make effective data driven decisions\\n\\nCreate stories from number crunching\\n\\nBe the data storyteller to gain business confidence\\n\\nSKILLS AND KNOWLEDGE\\n\\n\\nGraduate/Post graduate with understanding of basic data science (Knowledge of SQL ,HIVE, Python, R or SAS - Any 2), knowledge of basic auto industry and sales and marketing operations\\n\\nb) Work Experience 2- 5 Years\\n\\nPlease note that the Educational qualification should be from AICTE/UGC approved colleges only.   \n",
       "106                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Job Title: Data Scientist\\nJob Type: Full-Time\\nJob Summary\\nWe are looking for a skilled Data Scientist to join our team. You will be responsible for analyzing large volumes of data, creating predictive models, and delivering actionable insights that drive business decisions and improve our learning systems.\\nKey Responsibilities\\nCollect, clean, and preprocess data from multiple sources.\\nBuild and evaluate predictive models and machine learning algorithms.\\nAnalyze data trends and patterns to provide business insights.\\nCollaborate with cross-functional teams including product, marketing, and tech.\\nDesign experiments and interpret their results using statistical techniques.\\nCommunicate findings through visualizations and reports.\\nStay up-to-date with the latest developments in data science and AI.\\nRequirements\\nBachelor’s or Master’s degree in Computer Science, Data Science, Statistics, Mathematics, or a related field.\\nStrong programming skills in Python or R.\\nProficient in SQL and working with large datasets.\\nExperience with machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch).\\nKnowledge of data visualization tools (e.g., Power BI, Tableau, matplotlib, seaborn).\\nExcellent problem-solving and analytical skills.\\nStrong communication skills to explain complex data in a simple way.\\nJob Types: Full-time, Fresher\\nEducation:\\nBachelor's (Required)\\nWork Location: In person   \n",
       "108                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Position: Data Scientist (Intern)\\nStatus: Open\\nAGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:\\n1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing\\n2) Some Experience in Programming in C++/Java/Distributed Programming\\n3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics\\nPositions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with \"Application for Data Science Intern\" in the Subject line.   \n",
       "110                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Location\\nBengaluru\\nEmployment Type\\nFull time\\nLocation Type\\nOn-site\\nDepartment\\nProduct R&D\\n\\nAbout G2 - The Company\\nWhen you join G2, you’re joining the team that helps businesses reach their peak potential by powering decisions and strategies with trusted insights from real software users.   \n",
       "114                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Preferable Location(s): Pune, India | Bengaluru, India | Delhi, India | Chennai, India | Mumbai, India | Noida, India | Gurugram, India | Hyderabad, India | Coimbatore, India\\nWork Type: Full Time\\n\\nAbout the Role: Design, develop and enhance our pricing algorithms to enable new capabilities. Process, analyse, model, and visualise findings from our market-level supply and demand data. Build and enhance internal and customer-facing dashboards to better track metrics and trends that help customers use PriceLabs in a better way. Take ownership of product ideas and design discussions. Occasional travel to conferences to interact with prospective users and partners, and learn where the industry is headed. About You: You have a minimum of two (2) years of relevant experience. Strong understanding of analysis of algorithms, data structures and statistics. Solid programming experience. Including being able to quickly prototype an idea and test it out. Strong communication skills, including the ability and willingness to explain complicated algorithms and concepts in simple terms. Experience with relational databases and strong knowledge of SQL. Prior experience working in a fast-paced environment. Willingness to wear many hats. Good to have: Experience in the vacation rental industry. Experience developing dynamic pricing models. How to apply for this position? Please fill out the form with the required details. If your profile is shortlisted, our team will reach out to you via email. If you don't find the emails in your inbox, please check your spam folder. Tip: Avoid using AI-generated responses. We want to hear from you! About PriceLabs: PriceLabs is a revenue management solution for the short-term rental and hospitality industry, founded in 2014 and headquartered in Chicago, IL. Our platform helps individual hosts and hospitality professionals optimize their pricing and revenue management, adapting to changing market trends and occupancy levels. With dynamic pricing, automation rules, and customizations, we manage pricing and minimum-stay restrictions for any portfolio size, with prices automatically uploaded to preferred channels. Every day, we price over 500,000+ listings globally across 150+ countries, offering world-class tools like the Base Price Help and Minimum Stay Recommendation Engine. In 2025, we scaled to; 500K+ properties syncing daily 60K+ customers worldwide 270+ globally remote team 36% diversity Industry awards won: SaasBoomi 2021 The Shortyz 2020 The Shortyz 2023 STRive Awards 2025 We continue to grow exponentially backed by a strong team to take us to the next level. Why join PriceLabs? We are a remote-first organization and accept work from home as the norm. Work with an industry-leading product that has thousands of customers worldwide, and our customers love the product! (NPS in the 70s, ) Work with a global team (18 countries and counting) of passionate individuals that accept open communication, empowerment, and a shared focus on customer success. We are a freemium product, so marketing leads the charge on customer acquisition. PriceLabs is an equal-opportunity employer. We are committed to providing equal opportunity in all aspects of employment. We do not discriminate based on race, colour, religious creed, national origin, ancestry, sex, age, veteran status, marital status or physical challenges.   \n",
       "126  Data expert Jobs in Delhi at CryptoMize - Check Out data scientist job description, data scientist salary to our product, sales, leadership and marketing teams with insights gained from analyzing company data. A Data Expert is a person who works with stakeholders to enhance business outcomes by delivering solutions and identifying solutions hidden in massive data sets. He or she must be able to perfect in data mining and data analysis procedures, as well as use a number of data tools, design and execute models, use/create algorithms, and create/run simulations. for a Data Scientist job in Delhi at CryptoMize, A Conglomerate Digital Agency and Digital Privacy Company in India.\\n\\nData Scientist job Responsibilities\\n\\nCombining computer science, modeling, statistics, analytics, and math skills—along with sound business sense—data scientists uncover the answers to major questions that help organizations make objective decisions. The ability to transform a sea of data into actionable insights can have a profound impact—for predicting the best new diabetes treatment to identifying and thwarting national security threats. That’s why businesses and government agencies are rushing to hire data science professionals who can help do just that. The first step toward establishing an active data analytics platform is to collect structured and unstructured data from different sources. Unstructured data consists of things like what customers are saying about the organization on social media, while structured data is a measurable metric, such as customer lifetime value.\\n\\nA data scientist cleans and validates the data to ensure its accuracy and completeness. While AI-powered data analytics tools can automate part of this process, cleaning data still makes up the bulk of a data scientist’s job duties. Once the data is clean, the data scientist analyzes the data to identify patterns and trends using advanced statistics skills. Work throughout the organization to identify opportunities for leveraging company data to drive business solutions. Develop custom data models and algorithms to apply data sets. Strong problem solving skills with an emphasis on product development.\\n\\nAbout Us\\n\\nCryptoMize is a Conglomerate Digital Agency with presence in 3 Continents evolving for a decade, having served elite clients such as Governments, Politicians, MNCs, Celebrities and HNIs in 30+ Countries. Over the years, we have garnered and trained a team of industry experts that are capable of providing the best quality results.\\n\\n\\nDelhi\\n\\n\\nAvailable\\n\\n\\nFull time\\n\\n\\nPermanent\\n\\n\\nImmediate\\n\\n\\nBased on experience\\n\\nThe application for this opening can be submitted via the application form linked below, ONLY. Direct phone calls and emails will not be entertained.\\n\\nOur Principles\\n\\nThese are some of the principles that we strongly believe in, preach and actually follow as well.\\n\\nCommitments\\n\\nWe clearly commit what we can do, by when can we do it and how we would do it, And then we do it.\\n\\nConfidentiality\\n\\nWe are extremely paranoid about protecting the confidentiality of what we do, for whom and how we do it.\\n\\nComfortability\\n\\nWe ensure comfortability of you and your team with ours, which can only come from complete transparency.\\n\\nCapability\\n\\nWe keep improving our already awesome capabilities by investing all resources at our disposal.\\n\\nData Scientist Job\\n\\nData scientist jobs for freshers\\n\\nData Scientist Job Requirements\\n\\nData Scientist Qualification\\n\\nOur Services\\nKnow More About Us\\nPerception Perfection\\n\\nCryptoMize is dedicated to ensure a prominent progress to how the world perceives you. We help you to establish your perception to the extent of perfection with our devised strategic plan and techniques.\\n\\nPromotional Parlance\\n\\nCryptoMize introduces you to Promotional Parlance which not only promotes your cause but provides a personalized-edge. Our solutions are tailored in a strategic way that attracts the audience in a way that they are most receptive to.\\n\\nPublic Relations\\n\\nCryptoMize formulates a proactive strategy to amplify your Media Outreach without compromising your reputation. CryptoMize assists you in communicating with your intended audience to achieve a global outreach.\\n\\nPolitical Catalysis\\n\\nWe bring efficiency to governance operations through intelligence and strategic thinking. By integrating digital approaches, CryptoMize seeks to improve Campaign Strategies and governance in general.\\n\\nPolicing Phronesis\\n\\nCryptoMize, with the help of its special mix of Forensics and Consultancy, aims to handle all sorts of cyber crimes affecting your organisation and provide you with the best guidance for such situations.\\n\\nPrivacy Enforcement\\n\\nCryptoMize is driven by the belief that none of your valuable data should go unprotected. Our experts put concerted effort to preserve your privacy in order to minimize the impact of cybercrime.\\n\\nWhat Makes Us Different?\\n\\nCryptoMize offers a full spectrum of elite services derived with preemptive analysis and strategic planning to our clients. We work efficiently with our proficient and proactive team by utilising extraordinary tools.\\n\\nCollaboration with Dignitaries\\n\\nWe collaborate with highly influential and prominent personalities around the world. Being transcendental and visionary has its own benefits, our supremacy of being omnipresent empowers us to command, control and maneuver information from the internet.\\n\\n01\\nPowerful Team\\n\\nCryptoMize is the combination of a powerful team that works on a supportive, transparent and encouraging platform. With spontaneity and dedication to the advancement of technology, we aspire to be better at what we do for people who trust us with their information and projects.\\n\\n02\\nTriple-Proof Approach\\n\\nWe execute a triple-proof approach from conducting thorough research, developing strong strategies, to guaranteeing information security. This proves beneficial for our clients to reach their desired goal.\\n\\n03\\nOur Core Values\\nTrust\\n\\nWe seek to connect and build relationships with our clients.That is our core principle of our work ethic which we fully-abide to. We works on 3 principles: Respect, Honesty and Transparency.\\n\\nReliability\\n\\nCommitment is an act, not a word. We believe in delivering and living up to your expectations. We have grown into a global agency only through our commitment to deliver and our reliability factor.\\n\\nSafety\\n\\nWe are extremely paranoid about protecting our client’s safety of what we do, for whom and how we do it. We maintain absolute non disclosure and confidentiality to ensure that nothing sensitive goes out.\\n\\nPassion\\n\\nOur passion generates enthusiasm for what we do and how we do it. We inspire, find creative ways and nurture ideas with passion. We strategize based on audience attention.\\n\\nInnovation\\n\\nWe believe in innovation, change and risk taking. With technology, we reinvent ourselves. Innovation is the reason how we are able to eliminate obstacles for cultivating growth.\\n\\nExcellence\\n\\nWe ensure to maintain your eminence by reinventing ourselves with our core values that inspire excellence. We strive for quality in everything we do.\\n\\nOUR PRESENCE\\nOur Journey So Far\\nOur presence is all across the globe. Our impact can be seen in 03+ continents and 30+ countries, we know how to shape people's digital lives. We have a vast range of projects, from running political campaigns, shaping people's perceptions to enforcing privacy, we work with a futuristic approach and always look ahead of time. We never restrict ourselves to specific sectors rather make sure that our services are requisites for any and everybody in the world. With our elite clientele we show supremacy of work and build trustworthy relationships. We believe intelligence is the future and aim towards collective good and growth of all!\\n3+\\nOur Presence\\n\\nSuccessfully establishing ourselves globally in 3+ continents.\\n\\n70+\\nOur Services\\n\\nGiving us an edge over everyone else who is trying to solve similar problems.\\n\\n10+\\nYears of Experience\\n\\nServing great value to our clients since the past decade.\\n\\nNEVERENDING OPPORTUNITIES FOR YOU\\nOur Vision\\n\\nIn the days of yore, gathering intelligence was a matter of sending out spies. Today the world has changed, and intelligence is as much about technology as it is about people. We are redefining what it means to truly protect you and your business. From network security, to cloud recovery, to data recovery, CryptoMize focuses on your technology’s vulnerabilities so you can avoid pitfalls and stay ahead.\\n\\nWe have a singular vision – to be the ultimate ‘go-to’ company for digital reputation management. Our approach is holistic, covering reputation management, social media management, and crisis management.\\nWe uncover security flaws in your technology, identify new threats, and create proactive measures to protect you.\\nWe provide innovative IT solutions to clients of all sizes. Our expertise is in all levels of the information technology stack, including network architecture and cybersecurity.\\nWhy Us?\\n\\nWhy are we so amazing?\\n\\nYUMMY\\n\\nOur awesome chef prepares freshly Maison-made breakfasts, lunches, diners, beverages, coffees everyday to provide the fuel you need to innovate and Execute Best Ideas.\\n\\nEVENTS AND HACKATHONS\\n\\nWant to organize, talk or attend an event? We give you two days per month to attend or organize team-buildings, conferences, trainings, meetups or hackathons.\\n\\nCOMPANY OUTINGS\\n\\nWork hard, play hard! We have an in-house bar with a large choice of wines, beers and arcade games. Plus, we organize memorable & engaging team events at least twice a month.\\n\\nFun Days\\n\\nBesides a day off, we present you with a day that is full of fun. You get to choose from a vast array of fun activities from outdoor activities to pool parties.\\n\\nFLEXIBLE EVERYTHING\\n\\nWe choose to work in a flex office environment to grow new collaborative ideas and practices. We work in small product oriented teams to focus & execute faster.\\n\\nNO DIPLOMAS REQUIRED\\n\\nAt CryptoMize, we don’t care about your degrees, we only care about what you know. Your skillset will be evaluated in regard to your technical experiences and skills.   \n",
       "134                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Country/Region: IN\\nRequisition ID: 26870\\nWork Model:\\nPosition Type:\\nSalary Range:\\nLocation: INDIA - PUNE - BIRLASOFT OFFICE - HINJAWADI\\nTitle: Data Scientist\\nDescription:\\nArea(s) of responsibility\\nKey Responsibilities:   \n",
       "143                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Job Summary:\\nWe are seeking a skilled Data Scientist to analyze large datasets, build predictive models, and derive actionable insights to support business decisions. The ideal candidate has strong statistical knowledge, proficiency in programming, and a problem-solving mindset.\\nKey Responsibilities:\\nCollect, clean, and preprocess structured and unstructured data\\nPerform exploratory data analysis and visualize insights\\nDevelop, test, and deploy machine learning and statistical models\\nCommunicate findings and recommendations through reports and presentations\\nCollaborate with cross-functional teams to identify business opportunities\\nMaintain and improve data pipelines and model performance over time\\nRequired Skills & Qualifications:\\nBachelor’s or Master’s in Computer Science, Statistics, Mathematics, Data Science, or related field\\nProficiency in Python or R, and SQL\\nExperience with machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch)\\nKnowledge of statistical analysis and experimental design\\nFamiliarity with data visualization tools (e.g., Tableau, Power BI, matplotlib, seaborn)\\nExcellent analytical and problem-solving skills\\nStrong communication and presentation abilities\\nPreferred:\\nExperience with big data technologies (e.g., Spark, Hadoop)\\nKnowledge of cloud platforms (AWS, Azure, GCP)\\nExperience- 1-2 Year.\\nMonday To Friday.\\nMorning Shift.\\nhr@applicationsquare.com\\nJob Type: Full-time\\nSchedule:\\nDay shift\\nMonday to Friday\\nWeekend availability\\nWork Location: In person   \n",
       "144                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Engineered a scalable data pipeline that seamlessly moved data from diverse sources, including REST APIs, on-premise databases, and SharePoint, into Snowflake using Azure Data Factory, significantly improving data integration efficiency. • Led successful requirement gathering sessions, translating complex business needs into actionable technical specifications, which directly contributed to the project's successful delivery. • Implemented robust CI/CD pipelines for Azure Data Factory components and Azure Databricks notebooks, enabling smooth and reliable deployments to higher environments using Azure DevOps. • Automated the data ingestion process,eliminating 90% of manual data processing, drastically improving operational efficiency and reducing human error. • Developed an enterprise-wide data model,consolidating data from multiple sources and ensuring consistent, organization-wide data access, leading to improved decision-making capabilities. • Optimized data processing capabilities,allowing the system to handle 2GB of data every 2 hours with high performance and reliability, ensuring the infrastructure met business needs. • Implemented parallelism in data pipelines,reducing pipeline execution time significantly, boosting performance, and enhancing data flow efficiency. • Designed and documented a comprehensive architecture, detailing data transformation logic and Snowflake schema design, establishing a clear framework for future scalability and maintenance. • Collaborated effectively with business users,ensuring data accessibility, gathering critical feedback, and providing ongoing support that enhanced user satisfaction and system usability.   \n",
       "147                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Job Title: Data Scientist\\nExperience: 2 to 4 Years\\nLocation: Delhi/NCR\\nIndustry: Information Technology & Services\\nEmployment Type: Full-time\\nAbout the Role:\\nWe are looking for a passionate and results-driven Data Scientist to join our growing analytics and AI/ML team. The ideal candidate will bring hands-on experience in data exploration, model building, and deployment. You will work closely with cross-functional teams to deliver actionable insights and machine learning solutions that drive business value.\\nKey Responsibilities:   \n",
       "\n",
       "    Salary_Range Median_Salary Salary_Source Salary_Range_Standardized  \\\n",
       "12          None           NaN          None                      None   \n",
       "37          None           NaN          None                      None   \n",
       "51          None           NaN          None                      None   \n",
       "68          None           NaN          None                      None   \n",
       "73          None           NaN          None                      None   \n",
       "77          None           NaN          None                      None   \n",
       "78          None           NaN          None                      None   \n",
       "84          None           NaN          None                      None   \n",
       "91          None           NaN          None                      None   \n",
       "101         None           NaN          None                      None   \n",
       "103         None           NaN          None                      None   \n",
       "106         None           NaN          None                      None   \n",
       "108         None           NaN          None                      None   \n",
       "110         None           NaN          None                      None   \n",
       "114         None           NaN          None                      None   \n",
       "126         None           NaN          None                      None   \n",
       "134         None           NaN          None                      None   \n",
       "143         None           NaN          None                      None   \n",
       "144         None           NaN          None                      None   \n",
       "147         None           NaN          None                      None   \n",
       "\n",
       "    Median_Salary_Standardized  Intern  \n",
       "12                         NaN     NaN  \n",
       "37                         NaN     NaN  \n",
       "51                         NaN     NaN  \n",
       "68                         NaN     NaN  \n",
       "73                         NaN     NaN  \n",
       "77                         NaN     NaN  \n",
       "78                         NaN     NaN  \n",
       "84                         NaN     NaN  \n",
       "91                         NaN     NaN  \n",
       "101                        NaN     NaN  \n",
       "103                        NaN     NaN  \n",
       "106                        NaN     NaN  \n",
       "108                        NaN     NaN  \n",
       "110                        NaN     NaN  \n",
       "114                        NaN     NaN  \n",
       "126                        NaN     NaN  \n",
       "134                        NaN     NaN  \n",
       "143                        NaN     NaN  \n",
       "144                        NaN     NaN  \n",
       "147                        NaN     NaN  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[ds_mask][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ead6c577-3da8-46f3-807e-928263470f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>The Company\\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\\n\\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\\n\\nWe offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>The Company\\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\\n\\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\\n\\nWe offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company_Name          Job_Title  Company_Rating   Location  \\\n",
       "12       PayPal     Data Scientist             3.7    Chennai   \n",
       "95       PayPal  Sr Data Scientist             3.7  Bengaluru   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Description  \\\n",
       "12  The Company\\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\\n\\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\\n\\nWe offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.   \n",
       "95  The Company\\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\\n\\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\\n\\nWe offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.   \n",
       "\n",
       "   Median_Salary_Standardized  \n",
       "12                        NaN  \n",
       "95                     300000  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Company_Name'].str.contains('PayPal', regex=False, na=False)][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Description', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75711690-fedc-433f-a122-b4caf13502b0",
   "metadata": {},
   "source": [
    "#### Imputing missing values based on Rating & Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "f371ba09-e69d-4a0d-9021-0f5f4e952df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>InvestCloud</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Exeliq Consulting</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2.7</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Articul8</td>\n",
       "      <td>GenAI Data Scientist - India (BLR/HYD)</td>\n",
       "      <td>2.9</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Kovai.co</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Liases Foras</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>EVERSANA</td>\n",
       "      <td>Data science intern</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>BIZ-METRIC PARTNERS</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.3</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Halo Media</td>\n",
       "      <td>Data Scientist - India, Fully Remote</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Pattern Effects Labs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Kotak Mahindra</td>\n",
       "      <td>Data Scientist-I-SUPPORT SERVICES-CTO Head</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>InitiateFirst.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BirlaSoft</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MOLECULAR CONNECTIONS</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Linde plc</td>\n",
       "      <td>Data Scientist for AI Products (Global)</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Sixt</td>\n",
       "      <td>Data Scientist III</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Gallagher</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Clarivate</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Cloud Kinetics</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Pune</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Comscore</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Pune</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>DataRobot</td>\n",
       "      <td>Customer-Facing Data Scientist - India</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Commonwealth Bank</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Nihilent</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Colan Infotech</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>DMI Housing Finance</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>TechSophy</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.7</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Luxoft</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Thoucentric</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Kanini Software Solutions</td>\n",
       "      <td>Data Scientist (Job ID - 2239)</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Maruti Suzuki India Ltd</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Seismic</td>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>WTW</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Zensar Technologies</td>\n",
       "      <td>DE&amp;A - AIML - Data Science - Conventional AI - Search</td>\n",
       "      <td>3.8</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Growexx</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Sculpsoft</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Continental</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Digitap.AI Enterprise Solutions</td>\n",
       "      <td>Data Scientist (ML/NLP Developer)</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Sybrant Data</td>\n",
       "      <td>Designation –Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ESJ Asthra Edutech Pvt Ltd</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Precognitas Health</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Application Square Infotech Pvt Ltd</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>eBay</td>\n",
       "      <td>Snr Data Scientist, Knowledge Management</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>ChicMic Studios</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Amanstra Consulting</td>\n",
       "      <td>Python Developer with Data Science Background</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>G2</td>\n",
       "      <td>Data Scientist - I</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Techblocks</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>Imurgence</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Jamshedpur</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>Pisoft Informatics</td>\n",
       "      <td>Data Science Developer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Nestlé IT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Meesho</td>\n",
       "      <td>Data Scientist III</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>Mahindra Teqo</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>Navikenz</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Dozee</td>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Procter &amp; Gamble</td>\n",
       "      <td>Data Scientist - Product Supply</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Goa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Datamatics Financial Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Futops Technologies India Pvt. Ltd</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>Knowledge Excel</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Daydreamsoft</td>\n",
       "      <td>AI / ML / Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>Photon</td>\n",
       "      <td>Data Scientist-Snowflake, Python - CHN</td>\n",
       "      <td>4.2</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Ayruz Data Marketing</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Photon</td>\n",
       "      <td>Data Scientist - Pune</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Pune</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Hilabs</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Numerator</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Rolling Arrays</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>WorldQuant</td>\n",
       "      <td>BRAIN Data Scientist</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Dicetek LLC</td>\n",
       "      <td>Data Scientist (AI)</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Sciffer</td>\n",
       "      <td>Data Scientist (Audio/Speech)</td>\n",
       "      <td>4.4</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Hire IT People</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Pune</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>MNJ Software</td>\n",
       "      <td>Data Science (AI &amp; Python Program Developers)</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Akamai</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Emgage</td>\n",
       "      <td>Python Data Scientist</td>\n",
       "      <td>4.5</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>MSys Tech India</td>\n",
       "      <td>Data Scientist / AI Architect</td>\n",
       "      <td>4.5</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Agnik</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.6</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>WinZO</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>TechStep</td>\n",
       "      <td>Data Scientist (Machine Learning)</td>\n",
       "      <td>4.7</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>SkillCircle</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>4.7</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Pricelabs</td>\n",
       "      <td>Data Scientist (Remote)</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Pune</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Crypto Mize</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Rulesiq</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>ONLEI Technologies</td>\n",
       "      <td>Data Science Trainer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name  \\\n",
       "538                          InvestCloud   \n",
       "419                    Exeliq Consulting   \n",
       "477                             Articul8   \n",
       "286                             Kovai.co   \n",
       "776                         Liases Foras   \n",
       "355                             EVERSANA   \n",
       "342                  BIZ-METRIC PARTNERS   \n",
       "77                            Halo Media   \n",
       "101                 Pattern Effects Labs   \n",
       "256                       Kotak Mahindra   \n",
       "297                       InitiateFirst.   \n",
       "134                            BirlaSoft   \n",
       "73                 MOLECULAR CONNECTIONS   \n",
       "428                      Infosys Limited   \n",
       "603                            Linde plc   \n",
       "665                                 Sixt   \n",
       "361                            Gallagher   \n",
       "436                            Clarivate   \n",
       "449                       Cloud Kinetics   \n",
       "733                             Comscore   \n",
       "255                            DataRobot   \n",
       "262                    Commonwealth Bank   \n",
       "299                             Nihilent   \n",
       "362                       Colan Infotech   \n",
       "12                                PayPal   \n",
       "564                  DMI Housing Finance   \n",
       "591                            TechSophy   \n",
       "383                               Luxoft   \n",
       "518                          Thoucentric   \n",
       "185            Kanini Software Solutions   \n",
       "103              Maruti Suzuki India Ltd   \n",
       "413                              Seismic   \n",
       "78                                   WTW   \n",
       "144                  Zensar Technologies   \n",
       "374              Gujarat Fluorochemicals   \n",
       "248                              Growexx   \n",
       "429                            Sculpsoft   \n",
       "266                          Continental   \n",
       "612      Digitap.AI Enterprise Solutions   \n",
       "224                         Sybrant Data   \n",
       "106           ESJ Asthra Edutech Pvt Ltd   \n",
       "566                   Precognitas Health   \n",
       "143  Application Square Infotech Pvt Ltd   \n",
       "637                                 eBay   \n",
       "807                      ChicMic Studios   \n",
       "560                  Amanstra Consulting   \n",
       "110                                   G2   \n",
       "244                           Techblocks   \n",
       "743                            Imurgence   \n",
       "768                   Pisoft Informatics   \n",
       "84                             Nestlé IT   \n",
       "220                               Meesho   \n",
       "581                        Mahindra Teqo   \n",
       "657                             Navikenz   \n",
       "683                                Dozee   \n",
       "37                      Procter & Gamble   \n",
       "521        Datamatics Financial Services   \n",
       "147   Futops Technologies India Pvt. Ltd   \n",
       "608                      Knowledge Excel   \n",
       "252                         Daydreamsoft   \n",
       "487                               Photon   \n",
       "194                 Ayruz Data Marketing   \n",
       "190                               Photon   \n",
       "346                               Hilabs   \n",
       "51                             Numerator   \n",
       "91                        Rolling Arrays   \n",
       "373                           WorldQuant   \n",
       "205                          Dicetek LLC   \n",
       "589                              Sciffer   \n",
       "289                       Hire IT People   \n",
       "801                         MNJ Software   \n",
       "68                                Akamai   \n",
       "261                               Emgage   \n",
       "688                      MSys Tech India   \n",
       "108                                Agnik   \n",
       "164                                WinZO   \n",
       "432                             TechStep   \n",
       "761                          SkillCircle   \n",
       "114                            Pricelabs   \n",
       "126                          Crypto Mize   \n",
       "165                              Rulesiq   \n",
       "257                   ONLEI Technologies   \n",
       "\n",
       "                                                 Job_Title  Company_Rating  \\\n",
       "538                                         Data Scientist             2.3   \n",
       "419                                         Data Scientist             2.7   \n",
       "477                 GenAI Data Scientist - India (BLR/HYD)             2.9   \n",
       "286                                         Data Scientist             3.1   \n",
       "776                                         DATA SCIENTIST             3.1   \n",
       "355                                    Data science intern             3.2   \n",
       "342                                         Data Scientist             3.3   \n",
       "77                    Data Scientist - India, Fully Remote             3.3   \n",
       "101                                         Data Scientist             3.4   \n",
       "256             Data Scientist-I-SUPPORT SERVICES-CTO Head             3.5   \n",
       "297                                         Data Scientist             3.5   \n",
       "134                                         Data Scientist             3.5   \n",
       "73                                          Data Scientist             3.5   \n",
       "428                                         Data Scientist             3.6   \n",
       "603                Data Scientist for AI Products (Global)             3.6   \n",
       "665                                     Data Scientist III             3.6   \n",
       "361                                         Data Scientist             3.6   \n",
       "436                                         Data Scientist             3.6   \n",
       "449                                         Data Scientist             3.6   \n",
       "733                                         Data Scientist             3.6   \n",
       "255                 Customer-Facing Data Scientist - India             3.6   \n",
       "262                                         Data Scientist             3.7   \n",
       "299                                         Data Scientist             3.7   \n",
       "362                                         Data Scientist             3.7   \n",
       "12                                          Data Scientist             3.7   \n",
       "564                                         Data Scientist             3.7   \n",
       "591                                         Data Scientist             3.7   \n",
       "383                                         Data Scientist             3.8   \n",
       "518                                         Data Scientist             3.8   \n",
       "185                         Data Scientist (Job ID - 2239)             3.8   \n",
       "103                                         Data Scientist             3.8   \n",
       "413                                      Data Scientist II             3.8   \n",
       "78                                          Data Scientist             3.8   \n",
       "144  DE&A - AIML - Data Science - Conventional AI - Search             3.8   \n",
       "374                                         Data Scientist             3.8   \n",
       "248                                         Data Scientist             3.9   \n",
       "429                                         Data Scientist             3.9   \n",
       "266                                         Data Scientist             3.9   \n",
       "612                      Data Scientist (ML/NLP Developer)             3.9   \n",
       "224                            Designation –Data Scientist             3.9   \n",
       "106                                         Data Scientist             3.9   \n",
       "566                                         Data Scientist             3.9   \n",
       "143                                         Data Scientist             3.9   \n",
       "637               Snr Data Scientist, Knowledge Management             3.9   \n",
       "807                                         Data Scientist             3.9   \n",
       "560          Python Developer with Data Science Background             3.9   \n",
       "110                                     Data Scientist - I             4.0   \n",
       "244                                         Data Scientist             4.0   \n",
       "743                                         Data Scientist             4.0   \n",
       "768                                 Data Science Developer             4.0   \n",
       "84                                          Data Scientist             4.1   \n",
       "220                                     Data Scientist III             4.1   \n",
       "581                                         Data Scientist             4.1   \n",
       "657                                         Data Scientist             4.1   \n",
       "683                                      Data Scientist II             4.1   \n",
       "37                         Data Scientist - Product Supply             4.1   \n",
       "521                                         Data Scientist             4.1   \n",
       "147                                         Data Scientist             4.2   \n",
       "608                                         Data Scientist             4.2   \n",
       "252                               AI / ML / Data Scientist             4.2   \n",
       "487                 Data Scientist-Snowflake, Python - CHN             4.2   \n",
       "194                                         Data Scientist             4.2   \n",
       "190                                  Data Scientist - Pune             4.2   \n",
       "346                                         Data Scientist             4.3   \n",
       "51                                          Data Scientist             4.3   \n",
       "91                                          Data Scientist             4.3   \n",
       "373                                   BRAIN Data Scientist             4.3   \n",
       "205                                    Data Scientist (AI)             4.3   \n",
       "589                          Data Scientist (Audio/Speech)             4.4   \n",
       "289                                         Data Scientist             4.4   \n",
       "801          Data Science (AI & Python Program Developers)             4.4   \n",
       "68                                          Data Scientist             4.5   \n",
       "261                                  Python Data Scientist             4.5   \n",
       "688                          Data Scientist / AI Architect             4.5   \n",
       "108                                         Data Scientist             4.6   \n",
       "164                                         Data Scientist             4.7   \n",
       "432                      Data Scientist (Machine Learning)             4.7   \n",
       "761                                           Data Science             4.7   \n",
       "114                                Data Scientist (Remote)             4.7   \n",
       "126                                         Data Scientist             4.8   \n",
       "165                                         Data Scientist             5.0   \n",
       "257                                   Data Science Trainer             5.0   \n",
       "\n",
       "       Location Median_Salary_Standardized  \n",
       "538   Karnataka                        NaN  \n",
       "419       India                        NaN  \n",
       "477       India                        NaN  \n",
       "286  Coimbatore                        NaN  \n",
       "776      Mumbai                        NaN  \n",
       "355   Bengaluru                        NaN  \n",
       "342       India                        NaN  \n",
       "77       Remote                        NaN  \n",
       "101   Bengaluru                        NaN  \n",
       "256   Bengaluru                        NaN  \n",
       "297   Bengaluru                        NaN  \n",
       "134       India                        NaN  \n",
       "73       Remote                        NaN  \n",
       "428   Bengaluru                        NaN  \n",
       "603   Bengaluru                        NaN  \n",
       "665   Bengaluru                        NaN  \n",
       "361       India                        NaN  \n",
       "436   Karnataka                        NaN  \n",
       "449        Pune                        NaN  \n",
       "733        Pune                        NaN  \n",
       "255      Remote                        NaN  \n",
       "262   Bengaluru                        NaN  \n",
       "299   Bengaluru                        NaN  \n",
       "362   Bengaluru                        NaN  \n",
       "12      Chennai                        NaN  \n",
       "564       Delhi                        NaN  \n",
       "591       India                        NaN  \n",
       "383   Bengaluru                        NaN  \n",
       "518   Bengaluru                        NaN  \n",
       "185     Chennai                        NaN  \n",
       "103       Delhi                        NaN  \n",
       "413   Hyderābād                        NaN  \n",
       "78        India                        NaN  \n",
       "144       India                        NaN  \n",
       "374       Noida                        NaN  \n",
       "248   Ahmedabad                        NaN  \n",
       "429   Ahmedabad                        NaN  \n",
       "266   Bengaluru                        NaN  \n",
       "612   Bengaluru                        NaN  \n",
       "224     Chennai                        NaN  \n",
       "106  Coimbatore                        NaN  \n",
       "566       Delhi                        NaN  \n",
       "143       India                        NaN  \n",
       "637   Karnataka                        NaN  \n",
       "807      Mohali                        NaN  \n",
       "560      Remote                        NaN  \n",
       "110   Bengaluru                        NaN  \n",
       "244   Hyderābād                        NaN  \n",
       "743  Jamshedpur                        NaN  \n",
       "768      Mohali                        NaN  \n",
       "84    Bengaluru                        NaN  \n",
       "220   Bengaluru                        NaN  \n",
       "581   Bengaluru                        NaN  \n",
       "657   Bengaluru                        NaN  \n",
       "683   Bengaluru                        NaN  \n",
       "37          Goa                        NaN  \n",
       "521       India                        NaN  \n",
       "147       Delhi                        NaN  \n",
       "608       Delhi                        NaN  \n",
       "252     Gujarat                        NaN  \n",
       "487       India                        NaN  \n",
       "194      Kerala                        NaN  \n",
       "190        Pune                        NaN  \n",
       "346   Bengaluru                        NaN  \n",
       "51        India                        NaN  \n",
       "91        India                        NaN  \n",
       "373      Mumbai                        NaN  \n",
       "205      Remote                        NaN  \n",
       "589       India                        NaN  \n",
       "289        Pune                        NaN  \n",
       "801      Remote                        NaN  \n",
       "68        India                        NaN  \n",
       "261       India                        NaN  \n",
       "688       India                        NaN  \n",
       "108       India                        NaN  \n",
       "164       Delhi                        NaN  \n",
       "432       India                        NaN  \n",
       "761       India                        NaN  \n",
       "114        Pune                        NaN  \n",
       "126       Delhi                        NaN  \n",
       "165      Remote                        NaN  \n",
       "257      Remote                        NaN  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_copy.loc[ds_mask, ['Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Median_Salary_Standardized'\n",
    "                     ]].sort_values(by=['Company_Rating', 'Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "8f1d3cf9-3ddc-4535-ba49-7773204ba1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([538, 419, 477, 286, 776, 355, 342,  77, 101, 256, 297, 134,  73, 428,\n",
       "       603, 665, 361, 436, 449, 733, 255, 262, 299, 362,  12, 564, 591, 383,\n",
       "       518, 185, 103, 413,  78, 144, 374, 248, 429, 266, 612, 224, 106, 566,\n",
       "       143, 637, 807, 560, 110, 244, 743, 768,  84, 220, 581, 657, 683,  37,\n",
       "       521, 147, 608, 252, 487, 194, 190, 346,  51,  91, 373, 205, 589, 289,\n",
       "       801,  68, 261, 688, 108, 164, 432, 761, 114, 126, 165, 257],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[ds_mask].sort_values(by=['Company_Rating', 'Location']).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0f6d1-f731-49fb-ac68-0bccc561f3eb",
   "metadata": {},
   "source": [
    "#### Imputing rows with ratings up to 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "e7b465b8-84a2-4e3b-8974-c2d13d38bac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>InvestCloud</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>About InvestCloud\\nInvestCloud is at the forefront of wealth technology, offering innovative solutions that redefine how the financial services industry operates. With a global presence and a client-first approach, we specialize in digital transformations powered by our flexible, modular technology.\\nAbout the Team\\nYou will be joining the newly formed global AI, Data &amp; Analytics team, as the lead Data Scientist in our India office. Your primary responsibility will be as a hands-on Data Scientist leading various projects. You will lead a small team locally and will operate as part of the global team. The new team is focused on driving increased value from the data InvestCloud captures to enable a smarter financial future for our clients, in particular focused on “enhanced intelligence”. Ensuring we have fit-for-purpose modern capabilities is a key goal for the team.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Exeliq Consulting</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Currently we are looking for a Senior Computer Vision Engineer who is passionate about the sphere of Big Data, Data Science and AI.\\n\\nResponsibilities:\\nCreating solutions and products for leading representatives of different industries;\\nAnalysing business problems, looking for better technical solutions and their implementation;\\nExpanding company’s expertise in the field of Computer Vision;\\nManagement of the direction of the company in the future.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Articul8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>GenAI Data Scientist - India (BLR/HYD)</td>\n",
       "      <td>India</td>\n",
       "      <td>About Us:\\nAt Articul8 AI, we relentlessly pursue excellence and create exceptional GenAI products that exceed customer expectations. We are a team of dedicated individuals who take pride in our work and strive for greatness in every aspect of our business. We believe in using our advantages to make a positive impact on the world and inspiring others to do the same\\nJob Description:\\nArticul8 AI is seeking a Data Scientist to design, develop, and deploy AI-driven solutions that solve real-world problems at scale. You will work on machine learning models, large language models (LLMs), and AI applications while optimizing performance for production environments. This role requires expertise in AI/ML frameworks, cloud platforms, and software engineering best practices.\\nYou will be developing and deploying advanced deep learning and generative AI models and algorithms to enhance existing products or to create new products that fulfill critical business needs. In this role, you will be working closely with Product Management and Engineering teams to build GenAI products at scale. You will be responsible for transforming business needs to technical requirements and for leveraging state of the art research to develop and deliver products. You will also support Engineering with testing and validation of the product.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Company_Name  Company_Rating  \\\n",
       "538        InvestCloud             2.3   \n",
       "419  Exeliq Consulting             2.7   \n",
       "477           Articul8             2.9   \n",
       "\n",
       "                                  Job_Title   Location  \\\n",
       "538                          Data Scientist  Karnataka   \n",
       "419                          Data Scientist      India   \n",
       "477  GenAI Data Scientist - India (BLR/HYD)      India   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Description  \\\n",
       "538                                                                                                                                                                                                                                                                                                                                                                                                                                                                      About InvestCloud\\nInvestCloud is at the forefront of wealth technology, offering innovative solutions that redefine how the financial services industry operates. With a global presence and a client-first approach, we specialize in digital transformations powered by our flexible, modular technology.\\nAbout the Team\\nYou will be joining the newly formed global AI, Data & Analytics team, as the lead Data Scientist in our India office. Your primary responsibility will be as a hands-on Data Scientist leading various projects. You will lead a small team locally and will operate as part of the global team. The new team is focused on driving increased value from the data InvestCloud captures to enable a smarter financial future for our clients, in particular focused on “enhanced intelligence”. Ensuring we have fit-for-purpose modern capabilities is a key goal for the team.   \n",
       "419                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Currently we are looking for a Senior Computer Vision Engineer who is passionate about the sphere of Big Data, Data Science and AI.\\n\\nResponsibilities:\\nCreating solutions and products for leading representatives of different industries;\\nAnalysing business problems, looking for better technical solutions and their implementation;\\nExpanding company’s expertise in the field of Computer Vision;\\nManagement of the direction of the company in the future.   \n",
       "477  About Us:\\nAt Articul8 AI, we relentlessly pursue excellence and create exceptional GenAI products that exceed customer expectations. We are a team of dedicated individuals who take pride in our work and strive for greatness in every aspect of our business. We believe in using our advantages to make a positive impact on the world and inspiring others to do the same\\nJob Description:\\nArticul8 AI is seeking a Data Scientist to design, develop, and deploy AI-driven solutions that solve real-world problems at scale. You will work on machine learning models, large language models (LLMs), and AI applications while optimizing performance for production environments. This role requires expertise in AI/ML frameworks, cloud platforms, and software engineering best practices.\\nYou will be developing and deploying advanced deep learning and generative AI models and algorithms to enhance existing products or to create new products that fulfill critical business needs. In this role, you will be working closely with Product Management and Engineering teams to build GenAI products at scale. You will be responsible for transforming business needs to technical requirements and for leveraging state of the art research to develop and deliver products. You will also support Engineering with testing and validation of the product.   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "538                        NaN  \n",
       "419                        NaN  \n",
       "477                        NaN  "
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[538, 419, 477], ['Company_Name', 'Company_Rating', 'Job_Title', 'Location', 'Description', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931701db-939a-4ad2-a6d0-a8c176bd2709",
   "metadata": {},
   "source": [
    "#### Imputing rows with ratings from 3.1 to 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "417d8f5e-6bfb-46f8-9c99-275824b1f38f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Kovai.co</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Kovai.co is a catalyst, sparking a revolution in the world of enterprise software and B2B SaaS, we are a technology powerhouse delivering best-in-class enterprise software and game-changing SaaS solutions across industries.\\n\\nAt Kovai.co, we're rewriting the B2B landscape by empowering over 2,500 businesses worldwide with our award-winning SaaS solutions.\\n\\nOur Products:\\nBiztalk360\\nTurbo360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Liases Foras</td>\n",
       "      <td>3.1</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Job Description\\nWe are looking for a Data Scientist who will support our products and leadership with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for products and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>EVERSANA</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Data science intern</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Company Description\\n\\nAt EVERSANA, we are proud to be certified as a Great Place to Work across the globe. We’re fueled by our vision to create a healthier world. How? Our global team of more than 7,000 employees is committed to creating and delivering next-generation commercialization services to the life sciences industry. We are grounded in our cultural beliefs and serve more than 650 clients ranging from innovative biotech start-ups to established pharmaceutical companies. Our products, services and solutions help bring innovative therapies to market and support the patients who depend on them. Our jobs, skills and talents are unique, but together we make an impact every day. Join us!\\nAcross our growing organization, we embrace diversity in backgrounds and experiences. Improving patient lives around the world is a priority, and we need people from all backgrounds and swaths of life to help build the future of the healthcare and the life sciences industry. We believe our people make all the difference in cultivating an inclusive culture that embraces our cultural beliefs. We are deliberate and self-reflective about the kind of team and culture we are building. We look for team members that are not only strong in their own aptitudes but also who care deeply about EVERSANA, our people, clients and most importantly, the patients we serve. We are EVERSANA.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>BIZ-METRIC PARTNERS</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Full Time All Locations Jun 10 2025\\nNotice Period: Immediate or Serving Notice Period\\nExperience: 5-10 Years\\nAbout Bizmetric:\\nBizmetric is a dynamic and innovative technology solutions company specializing in cutting-edge\\nservices in Data Analytics, Cloud Solutions, Artificial Intelligence, and Machine Learning. We help\\nbusinesses optimize their operations through intelligent automation, data-driven insights, and scalable\\ninfrastructure solutions, delivering value-driven results across industries.\\nWhy Join Us?\\nLearning &amp; Certification Opportunities: Enhance your professional growth.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Halo Media</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Data Scientist - India, Fully Remote</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Halo believes in innovation by inclusion to solve digital problems. As an international agency of over 200 people specializing in interactive media strategy and development, we embrace equity and empowerment in a serious way. Our interdisciplinary teams of unique designers, developers and entrepreneurial minds with a variety of backgrounds, viewpoints, and skills connect to solve business challenges of every shape and size. We empathize to form deep, meaningful relationships with our clients so they can do the same with their audience. Working at Halo feels like belonging. Learn more about our philosophy, benefits, and team at https://halopowered.com/As an AI Architect, you will lead the design of scalable, secure, and modern technology solutions, leveraging artificial intelligence, cloud platforms, and microservices—while ensuring alignment with AI governance principles, agile delivery, and platform modernization strategies\\nAs a Data Scientist, you’ll be part of a multidisciplinary team applying advanced analytics, machine learning, and generative AI to solve real-world problems across our consulting, health, wealth, and career businesses. You will collaborate closely with engineering, product, and business stakeholders to develop scalable models, design intelligent pipelines, and influence data-driven decision-making across the enterprise.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Pattern Effects Labs</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>WHAT WE DO\\nAt PE we are building applications where financial decisions are data driven, adaptive and domain focused. We Use AI/ML to uncover hidden patterns from big data from across industries, enabling business and better quality of life.\\nUncovering the hidden\\nAI is used to find pattern and correlation which hide deep within Big Data.\\n\\nEver Adapting\\nOur AI system is designed to pick the best response from millions of possible options in a given scenario. These scenarios can be as diverse as capital markets to healthcare.\\nAccuracy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Kotak Mahindra</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Data Scientist-I-SUPPORT SERVICES-CTO Head</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About Kotak Mahindra Group:\\nEstablished in 1985, the Kotak Mahindra Group is one of India’s leading financial services conglomerates. In February 2003, Kotak Mahindra Finance Ltd (KMFL), the group’s flagship company, received a banking license from the Reserve Bank of India (RBI). With this, KMFL became the first non-banking finance company in India to become a bank – Kotak Mahindra Bank Limited.\\nThe Group offers a wide range of financial services that encompass every sphere of life. From commercial banking, to stock broking, mutual funds, life insurance and investment banking, the Group caters to the diverse financial needs of individuals and the corporate sector. The Group has a wide distribution network through branches and franchisees across India, the international offices in London, New York, California, Dubai, Abu Dhabi, Bahrain, Mauritius and Singapore. For information, please visit the company’s website at\\nhttp://www.kotak.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>InitiateFirst.</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Requirements:\\nExperience: 3 to 5 Years\\n3–5 years of experience in data science, with a strong focus on experimental design and analysis\\nProficient in Microsoft tools including Excel, Power BI, and especially Copilot\\nSkilled in SQL, Python, and R for end-to-end data workflows\\nFamiliarity with cloud platforms, particularly Microsoft Azure\\nProven experience using statistical and machine learning methods to drive decisions\\nDemonstrated success leading A/B testing and other experimentation techniques\\nExcellent attention to detail and analytical rigor\\nStrong communication skills for translating complex data insights to non-technical audiences</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BirlaSoft</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Country/Region: IN\\nRequisition ID: 26870\\nWork Model:\\nPosition Type:\\nSalary Range:\\nLocation: INDIA - PUNE - BIRLASOFT OFFICE - HINJAWADI\\nTitle: Data Scientist\\nDescription:\\nArea(s) of responsibility\\nKey Responsibilities:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MOLECULAR CONNECTIONS</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Requirement Details.\\nJob Description:\\nJob Designation: Data Scientist\\nRequired Education and experience:\\nBA/ BS in biostatistics, math, statistics, public health, or biological sciences with a minimum of 2 year of experience/ Masters in statistics\\n[Plus] real-world data, clinical trial data or Oncology experience\\n[Plus] Advanced degree in the aforementioned fields\\nRequired knowledge, skills and abilities:\\nStrong knowledge of the R programming language with a minimum of 2 year of experience</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Company_Name  Company_Rating  \\\n",
       "286               Kovai.co             3.1   \n",
       "776           Liases Foras             3.1   \n",
       "355               EVERSANA             3.2   \n",
       "342    BIZ-METRIC PARTNERS             3.3   \n",
       "77              Halo Media             3.3   \n",
       "101   Pattern Effects Labs             3.4   \n",
       "256         Kotak Mahindra             3.5   \n",
       "297         InitiateFirst.             3.5   \n",
       "134              BirlaSoft             3.5   \n",
       "73   MOLECULAR CONNECTIONS             3.5   \n",
       "\n",
       "                                      Job_Title    Location  \\\n",
       "286                              Data Scientist  Coimbatore   \n",
       "776                              DATA SCIENTIST      Mumbai   \n",
       "355                         Data science intern   Bengaluru   \n",
       "342                              Data Scientist       India   \n",
       "77         Data Scientist - India, Fully Remote      Remote   \n",
       "101                              Data Scientist   Bengaluru   \n",
       "256  Data Scientist-I-SUPPORT SERVICES-CTO Head   Bengaluru   \n",
       "297                              Data Scientist   Bengaluru   \n",
       "134                              Data Scientist       India   \n",
       "73                               Data Scientist      Remote   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Description  \\\n",
       "286                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Kovai.co is a catalyst, sparking a revolution in the world of enterprise software and B2B SaaS, we are a technology powerhouse delivering best-in-class enterprise software and game-changing SaaS solutions across industries.\\n\\nAt Kovai.co, we're rewriting the B2B landscape by empowering over 2,500 businesses worldwide with our award-winning SaaS solutions.\\n\\nOur Products:\\nBiztalk360\\nTurbo360   \n",
       "776                                                                                                                                                                                                                                                                                                                              Job Description\\nWe are looking for a Data Scientist who will support our products and leadership with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for products and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field.   \n",
       "355  Company Description\\n\\nAt EVERSANA, we are proud to be certified as a Great Place to Work across the globe. We’re fueled by our vision to create a healthier world. How? Our global team of more than 7,000 employees is committed to creating and delivering next-generation commercialization services to the life sciences industry. We are grounded in our cultural beliefs and serve more than 650 clients ranging from innovative biotech start-ups to established pharmaceutical companies. Our products, services and solutions help bring innovative therapies to market and support the patients who depend on them. Our jobs, skills and talents are unique, but together we make an impact every day. Join us!\\nAcross our growing organization, we embrace diversity in backgrounds and experiences. Improving patient lives around the world is a priority, and we need people from all backgrounds and swaths of life to help build the future of the healthcare and the life sciences industry. We believe our people make all the difference in cultivating an inclusive culture that embraces our cultural beliefs. We are deliberate and self-reflective about the kind of team and culture we are building. We look for team members that are not only strong in their own aptitudes but also who care deeply about EVERSANA, our people, clients and most importantly, the patients we serve. We are EVERSANA.   \n",
       "342                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Full Time All Locations Jun 10 2025\\nNotice Period: Immediate or Serving Notice Period\\nExperience: 5-10 Years\\nAbout Bizmetric:\\nBizmetric is a dynamic and innovative technology solutions company specializing in cutting-edge\\nservices in Data Analytics, Cloud Solutions, Artificial Intelligence, and Machine Learning. We help\\nbusinesses optimize their operations through intelligent automation, data-driven insights, and scalable\\ninfrastructure solutions, delivering value-driven results across industries.\\nWhy Join Us?\\nLearning & Certification Opportunities: Enhance your professional growth.   \n",
       "77                  Halo believes in innovation by inclusion to solve digital problems. As an international agency of over 200 people specializing in interactive media strategy and development, we embrace equity and empowerment in a serious way. Our interdisciplinary teams of unique designers, developers and entrepreneurial minds with a variety of backgrounds, viewpoints, and skills connect to solve business challenges of every shape and size. We empathize to form deep, meaningful relationships with our clients so they can do the same with their audience. Working at Halo feels like belonging. Learn more about our philosophy, benefits, and team at https://halopowered.com/As an AI Architect, you will lead the design of scalable, secure, and modern technology solutions, leveraging artificial intelligence, cloud platforms, and microservices—while ensuring alignment with AI governance principles, agile delivery, and platform modernization strategies\\nAs a Data Scientist, you’ll be part of a multidisciplinary team applying advanced analytics, machine learning, and generative AI to solve real-world problems across our consulting, health, wealth, and career businesses. You will collaborate closely with engineering, product, and business stakeholders to develop scalable models, design intelligent pipelines, and influence data-driven decision-making across the enterprise.   \n",
       "101                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    WHAT WE DO\\nAt PE we are building applications where financial decisions are data driven, adaptive and domain focused. We Use AI/ML to uncover hidden patterns from big data from across industries, enabling business and better quality of life.\\nUncovering the hidden\\nAI is used to find pattern and correlation which hide deep within Big Data.\\n\\nEver Adapting\\nOur AI system is designed to pick the best response from millions of possible options in a given scenario. These scenarios can be as diverse as capital markets to healthcare.\\nAccuracy   \n",
       "256                                                                                                                                                                                                                                                                                                                                                                                                                                             About Kotak Mahindra Group:\\nEstablished in 1985, the Kotak Mahindra Group is one of India’s leading financial services conglomerates. In February 2003, Kotak Mahindra Finance Ltd (KMFL), the group’s flagship company, received a banking license from the Reserve Bank of India (RBI). With this, KMFL became the first non-banking finance company in India to become a bank – Kotak Mahindra Bank Limited.\\nThe Group offers a wide range of financial services that encompass every sphere of life. From commercial banking, to stock broking, mutual funds, life insurance and investment banking, the Group caters to the diverse financial needs of individuals and the corporate sector. The Group has a wide distribution network through branches and franchisees across India, the international offices in London, New York, California, Dubai, Abu Dhabi, Bahrain, Mauritius and Singapore. For information, please visit the company’s website at\\nhttp://www.kotak.com   \n",
       "297                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Requirements:\\nExperience: 3 to 5 Years\\n3–5 years of experience in data science, with a strong focus on experimental design and analysis\\nProficient in Microsoft tools including Excel, Power BI, and especially Copilot\\nSkilled in SQL, Python, and R for end-to-end data workflows\\nFamiliarity with cloud platforms, particularly Microsoft Azure\\nProven experience using statistical and machine learning methods to drive decisions\\nDemonstrated success leading A/B testing and other experimentation techniques\\nExcellent attention to detail and analytical rigor\\nStrong communication skills for translating complex data insights to non-technical audiences   \n",
       "134                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Country/Region: IN\\nRequisition ID: 26870\\nWork Model:\\nPosition Type:\\nSalary Range:\\nLocation: INDIA - PUNE - BIRLASOFT OFFICE - HINJAWADI\\nTitle: Data Scientist\\nDescription:\\nArea(s) of responsibility\\nKey Responsibilities:   \n",
       "73                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Requirement Details.\\nJob Description:\\nJob Designation: Data Scientist\\nRequired Education and experience:\\nBA/ BS in biostatistics, math, statistics, public health, or biological sciences with a minimum of 2 year of experience/ Masters in statistics\\n[Plus] real-world data, clinical trial data or Oncology experience\\n[Plus] Advanced degree in the aforementioned fields\\nRequired knowledge, skills and abilities:\\nStrong knowledge of the R programming language with a minimum of 2 year of experience   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "286                        NaN  \n",
       "776                        NaN  \n",
       "355                        NaN  \n",
       "342                        NaN  \n",
       "77                         NaN  \n",
       "101                        NaN  \n",
       "256                        NaN  \n",
       "297                        NaN  \n",
       "134                        NaN  \n",
       "73                         NaN  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[286, 776, 355, 342,  77, 101, 256, 297, 134, 73], [\n",
    "    'Company_Name', 'Company_Rating', 'Job_Title', 'Location', 'Description', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842b666-4a27-4b88-82ba-1e20d1d1a33e",
   "metadata": {},
   "source": [
    "- Row 95's salary of 3,00,000 has been mentioned in the job posting itself, sometimes the salary mentioned in the glassdoor website are either lower than market salary or it is incorrect.\n",
    "- For row 12, Lets impute the salary with 7,00,000.\n",
    "<br>\n",
    "\n",
    "- Row 538, the role is a lead data scientist, will be part of the Indian team and also global team, involves leading various DS projects, lets impute the salary with 20,00,000.\n",
    "- Row 419, the role involes computer vision technology, lets impute the salary with 8,00,000.\n",
    "- Row 477, the role involves ML, DL, AI skills, expertise in AI/ML frameworks, cloud platforms, and software engineering, the seniority of the role in not mentioned, lets impute the salary with 9,00,000.\n",
    "<br>\n",
    "\n",
    "- Row 286, lets impute the salary with 4,00,000.\n",
    "- Row 776, the role requires 5-7 years of experience, master's or phd, the salary must be around in 16,00,000.\n",
    "- Row 355, the role is an intern, lets impute the salary with 1,20,000.\n",
    "- Row 342, requires 5-10 years of experience, lets impute the salary with 15,00,000.\n",
    "- Row 77, the role involves both ML/AI skills, its a remote role, the pay would be around 12,00,000.\n",
    "- Row 101, there isn't enough information about the role, lets impute with a basic salary of 6,00,000.\n",
    "- Row 256, the title of the role is Data Scientist-I-SUPPORT SERVICES-CTO Head and the location is bengaluru, the salary of CTO Head would be a lot higher than an average senior/Principal level roles, to avoid overfitting its best to drop this row.\n",
    "- Row 297, requires 3-5 years of experience, expertise in SQL, Python, and R for end-to-end data workflows, cloud platforms(Azure), A/B testing and other experimentation techniques, the salary provided will be in the range of 12,00,000.\n",
    "- Row 134, lets impute the missing salary with 6,00,000.\n",
    "- Row 73, lets impute the salary with 8,00,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "0b0284c5-02bf-48e2-b340-68e243a0d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[12, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[538, 'Median_Salary_Standardized'] = 2000000\n",
    "\n",
    "df_copy.loc[419, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[477, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[286, 'Median_Salary_Standardized'] = 400000\n",
    "\n",
    "df_copy.loc[776, 'Median_Salary_Standardized'] = 1600000\n",
    "\n",
    "df_copy.loc[355, 'Median_Salary_Standardized'] = 120000\n",
    "df_copy.loc[355, 'Intern'] = 1 \n",
    "\n",
    "df_copy.loc[342, 'Median_Salary_Standardized'] = 1500000\n",
    "\n",
    "df_copy.loc[77, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[101, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.drop(256, axis=0, inplace=True)\n",
    "\n",
    "df_copy.loc[297, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[134, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[73, 'Median_Salary_Standardized'] = 800000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5aeed-0d46-4a63-bd16-e571b15304e1",
   "metadata": {},
   "source": [
    "#### Imputing rows with ratings from 3.5 to 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "660f13f9-13ff-4695-a883-1424fdc52815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description:\\n\\nWe are seeking a highly motivated and experienced Senior Data Scientist with a proven track record of success in conducting in depth data analysis developing machine learning models and delivering actionable insights to drive business decisions\\nThe ideal candidate will have a deep understanding of statistics machine learning algorithms and data science best practices\\n\\nKey Responsibilities:\\n\\n\\n\\n\\n\\n\\nTechnology-&gt;Analytics - Techniques-&gt;Cluster Analysis,Technology-&gt;Analytics - Techniques-&gt;Decision Trees,Technology-&gt;Analytics - Techniques-&gt;Linear Regression,Technology-&gt;Machine Learning-&gt;Python</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Linde plc</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Data Scientist for AI Products (Global)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Praxair India Private Limited | Business Area: Digitalisation\\nData Scientist for AI Products (Global)\\nBangalore, Karnataka, India | Working Scheme: On-Site | Job Type: Regular / Permanent / Unlimited / FTE | Reference Code: req23348\\n\\nIt's about Being What's next.\\nWhat's in it for you?\\n\\nA Data Scientist for AI Products (Global) will be responsible for working in the Artificial Intelligence team, Linde's AI global corporate division engaged with real business challenges and opportunities in multiple countries. Focus of this role is to support the AI team with extending existing and building new AI products for a vast amount of uses cases across Linde’s business and value chain. You'll collaborate across different business and corporate functions in international team composed of Project Managers, Data Scientists, Data and Software Engineers in the AI team and others in the Linde's Global AI team. As a Data Scientist AI, you will support Linde’s AI team with extending existing and building new AI products for a vast amount of uses cases across Linde’s business and value chain\"\\n\\nAt Linde, the sky is not the limit. If you’re looking to build a career where your work reaches beyond your job description and betters the people with whom you work, the communities we serve, and the world in which we all live, at Linde, your opportunities are limitless. Be Linde. Be Limitless.\\n\\nMaking an impact. What will you do?\\n\\nYou will work directly with a variety of different data sources, types and structures to derive actionable insights\\nDevelop, customize and manage AI software products based on Machine and Deep Learning backends will be your tasks\\nYour role includes strong support on replication of existing products and pipelines to other systems and geographies\\nIn addition to that you will support in architectural design and defining data requirements for new developments\\nIt will be your responsibility to interact with business functions in identifying opportunities with potential business impact and to support development and deployment of models into production\\n\\nWinning in your role. Do you have what it takes?\\n\\nYou have a Bachelor or master’s degree in data science, Computational Statistics/Mathematics, Computer Science, Operations Research or related field\\nYou have a strong understanding of and practical experience with Multivariate Statistics, Machine Learning and Probability concepts\\nFurther, you gained experience in articulating business questions and using quantitative techniques to arrive at a solution using available data\\nYou demonstrate hands-on experience with preprocessing, feature engineering, feature selection and data cleansing on real world datasets\\nPreferably you have work experience in an engineering or technology role\\nYou bring a strong background of Python and handling large data sets using SQL in a business environment (pandas, numpy, matplotlib, seaborn, sklearn, keras, tensorflow, pytorch, statsmodels etc.) to the role\\nIn addition you have a sound knowledge of data architectures and concepts and practical experience in the visualization of large datasets, e.g. with Tableau or PowerBI\\nResult driven mindset and excellent communication skills with high social competence gives you the ability to structure a project from idea to experimentation to prototype to implementation\\nVery good English language skills are required\\nAs a plus you have hands-on experience with DevOps and MS Azure, experience in Azure ML, Kedro or Airflow, experience in MLflow or similar\\n\\nWhy you will love working for us!\\n\\nLinde is a leading global industrial gases and engineering company, operating in more than 100 countries worldwide. We live our mission of making our world more productive every day by providing high-quality solutions, technologies and services which are making our customers more successful and helping to sustain and protect our planet.\\n\\nOn the 1st of April 2020, Linde India Limited and Praxair India Private Limited successfully formed a joint venture, LSAS Services Private Limited. This company will provide Operations and Management (O&amp;M) services to both existing organizations, which will continue to operate separately. LSAS carries forward the commitment towards sustainable development, championed by both legacy organizations. It also takes ahead the tradition of the development of processes and technologies that have revolutionized the industrial gases industry, serving a variety of end markets including chemicals &amp; refining, food &amp; beverage, electronics, healthcare, manufacturing, and primary metals.\\n\\nWhatever you seek to accomplish, and wherever you want those accomplishments to take you, a career at Linde provides limitless ways to achieve your potential, while making a positive impact in the world. Be Linde. Be Limitless.\\n\\nHave we inspired you? Let's talk about it!\\n\\nWe are looking forward to receiving your complete application (motivation letter, CV, certificates) via our online job market.\\n\\nAny designations used of course apply to persons of all genders. The form of speech used here is for simplicity only.\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, protected veteran status, pregnancy, sexual orientation, gender identity or expression, or any other reason prohibited by applicable law.\\n\\nPraxair India Private Limited acts responsibly towards its shareholders, business partners, employees, society and the environment in every one of its business areas, regions and locations across the globe. The company is committed to technologies and products that unite the goals of customer value and sustainable development.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Sixt</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Data Scientist III</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are currently looking to hire a highly motivated Senior Data Scientist to join our team of data science and machine learning experts to shape the next generation of intelligent pricing strategies. Our mission is to apply cutting-edge techniques—including reinforcement learning, multi-armed bandits, and Bayesian inference—to optimize dynamic pricing decisions. We build scalable models and systems that directly impact millions of customers, enabling more efficient revenue management processes and a superior user experience. If you want to be part of our journey and make an impact. Apply now!\\nYOUR ROLE AT SIXT\\nYou will design, implement, and maintain production-grade machine learning systems, with a strong focus on bandit algorithms and reinforcement learning methods for dynamic pricing\\nYou will work closely with teams in data science, engineering, product management, and business operations to bring experimental models into a robust production environment</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Gallagher</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Introduction\\n\\nWe believe that every candidate brings something special to the table, including you! So, even if you feel that you’re close but not an exact match, we encourage you to apply. We’d be thrilled to receive applications from exceptional individuals like yourself.\\n\\nGallagher, a global industry leader in insurance, risk management, and consulting services, boasts a team of over 50,000 professionals worldwide. Our culture, known as \"The Gallagher Way,\" is driven by shared values and a passion for excellence. At the heart of our global operations, the Gallagher Center of Excellence (GCoE) in India, founded in 2006, upholds the values of quality, innovation, and teamwork. With 10,000+ professionals across five India locations, GCoE is where knowledge-driven individuals make a significant impact and build rewarding, long-term careers.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Clarivate</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>We are looking for a highly motivated real-world evidence (RWE) data scientist who has experience in generating insights/evidence from claims and EHR real world data (RWD) to join our growing Bangalore-based RWE analytics team at Clarivate.\\nAbout You – experience, education, skills, and accomplishments\\nGraduate degree in Data science/analytics, Epidemiology, Biostatistics, or related quantitative field\\nAt least 3 years’ experience in a consultative, client-facing role\\nAt least 3 years’ experience using SQL, Python, programming against large relational databases leveraging interoperable-linked, patient-level data at scale\\nHealthcare data expert across various data types (e.g. open/closed claims, inpatient/ambulatory EMR, commercial labs, social determinants, etc.) and codified healthcare data standards (e.g. ICD, CPT, HCPCS, LOINC, Snomed, etc.)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Cloud Kinetics</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Job Information\\nDate Opened\\n11/11/2024\\nJob Type\\nFull time\\nWork Experience\\n3-7 years\\nIndustry\\nIT Services\\nCity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Comscore</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "      <td>What You'll Do:\\nEffectively handle large data files in the course of developing and implementing solutions\\nPrecisely execute multiple analytic projects, each involving a great number of steps and analytic decisions\\nConcisely summarize real-world implications of findings from custom projects and the value proposition of real-world offerings\\nInterpret results, present findings and recommend alternative solutions to software and business decision makers\\nTranslate statistical modeling results into measures of business impact\\nInterface with clients to aid in the qualification of custom analytical solutions\\nManage expectations and coordinate project delivery with internal team</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>DataRobot</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Customer-Facing Data Scientist - India</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Job Description:\\nDataRobot delivers AI that maximizes impact and minimizes business risk. Our platform and applications integrate into core business processes so teams can develop, deliver, and govern AI at scale. DataRobot empowers practitioners to deliver predictive and generative AI, and enables leaders to secure their AI assets. Organizations worldwide rely on DataRobot for AI that makes sense for their business — today and in the future.\\nDataRobot is the world’s premier AI and data science platform. Our Customer Facing Data Scientists are experienced applied data scientists, passionate about using machine learning to achieve real-world results. As a Customer Facing Data Scientist at DataRobot, you will collaborate closely with DataRobot customers, bringing expertise in data science and the DataRobot platform, to help customers achieve their organization’s objectives with AI. You’ll work with clients in a range of industries on diverse use cases, and with both business (executive, line of business) and technical (data science, engineering, analytics) stakeholders.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Commonwealth Bank</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Organization:\\nAt CommBank, we never lose sight of the role we play in other people’s financial wellbeing. Our focus is to help people and businesses move forward to progress. To make the right financial decisions and achieve their dreams, targets, and aspirations. Regardless of where you work within our organisation, your initiative, talent, ideas, and energy all contribute to the impact that we can make with our work. Together we can achieve great things.\\nJob Title: Data Scientist\\nLocation: Bangalore\\nBusiness &amp; Team: BB Advanced Analytics and Artificial Intelligence COE\\nImpact &amp; contribution:\\nAs a Senior Data Scientist, you will be instrumental in pioneering Gen AI and multi-agentic systems at scale within CommBank. You will architect, build, and operationalize advanced generative AI solutions—leveraging large language models (LLMs), collaborative agentic frameworks, and state-of-the-art toolchains. You will drive innovation, helping set the organizational strategy for advanced AI, multi-agent collaboration, and responsible next-gen model deployment.\\n\\n\\n\\n\\n\\n\\n\\n\\nAdvertising End Date: 25/07/2025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Nihilent</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Location:\\nBangalore\\nExperience:\\n5+ Years\\nAbout the Job Opening:\\nKey Requirements:\\n5+ years of experience in BI, data analysis, or business consulting.\\nStrong domain expertise in manufacturing and/or sales.\\nProven experience in client-facing roles with stakeholder management.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Colan Infotech</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Summary\\nJob Code\\n:JD021\\nDesignation\\n:Data Scientist\\nQualification\\n:Any graduate\\nExperience\\n:5+ Years\\nJob type\\n:Full Time</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>DMI Housing Finance</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Job Reference id: H00015\\n\\nJob Description\\nResponsible for preparation, manipulation, analysis, and utilization of customer data through complex programming and slicing and dicing for utilization by senior member in such a way that most pertinent business inferences can be formed. Drive analytical insight, leverage immense datasets (i.e. demographics, financial, asset info, repayment behaviour, geolocation, payments) and work with our Product, Risk, Policy, and Tech teams, to drive decision making and solving business use case.\\nResponsibilities:\\n1. Creating Models for underwriting and behavior ranking/scoring</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>TechSophy</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>At Techsophy, we believe that technology has the power to elevate lives. We’re not just building solutions; we’re building a future where everyone has the tools to thrive in four crucial dimensions of well-being:\\nPhysical Health: Offering accessible, high-quality healthcare that reaches everyone, everywhere, ensuring no one is left behind.\\nFinancial Health: Providing financial security and insurance support, creating opportunities for everyone to build a stable, prosperous future.\\nMental Health: Delivering compassionate mental and emotional support to individuals and organizations, fostering resilience and well-being at every level.\\nCyber Health: Protecting the digital world, making sure every person and organization remains safe, secure, and free from cyber threats.\\nYour Impact, Your Purpose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Luxoft</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Project description\\nWe are seeking a highly skilled and motivated Data Scientist with 5+ years of experience to join our team. The ideal candidate will bring strong data science, programming, and data engineering expertise, along with hands-on experience in generative AI, large language models, and modern LLM application frameworks. This role also demands excellent communication and stakeholder management skills to collaborate effectively across business units.\\nResponsibilities\\nWe are seeking a highly skilled and motivated Data Scientist with 5+ years of experience to join our team. The ideal candidate will bring strong data science, programming, and data engineering expertise, along with hands-on experience in generative AI, large language models, and modern LLM application frameworks. This role also demands excellent communication and stakeholder management skills to collaborate effectively across business units.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Thoucentric</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About Us\\nAt Thoucentric, we offer end-to-end consulting solutions designed to address the most pressing business challenges across industries. Leveraging deep domain expertise, cutting-edge technology, and a results-driven approach, we help organizations streamline operations, enhance decision-making, and accelerate growth. We are headquartered in Bangalore with presence across multiple locations in India, US, UK, Singapore &amp; Australia Globally.\\n\\nWe help clients with Business Consulting, Program &amp; Project Management, Digital Transformation, Product Management, Process &amp; Technology Solutioning and Execution including Analytics &amp; Emerging Tech areas cutting across functional areas such as Supply Chain, Finance &amp; HR, Sales &amp; Distribution across US, UK, Singapore and Australia. Our unique consulting framework allows us to focus on execution rather than pure advisory. We are working closely with marquee names in the global consumer &amp; packaged goods (CPG) industry, new age tech and start-up ecosystem.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Kanini Software Solutions</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist (Job ID - 2239)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Job Description\\nWant to join KANINI?\\n\\nWe are looking for someone who is intellectual and analytical in their approach and is at the forefront of new advances in technology. As a Data Scientist, you will be developing and deploying scalable and reproducible data science models for solving a variety of business problems.\\n\\nYou are all set to:\\n\\nAnalyze, design, develop, deploy and monitor complex AI/ML solutions. You are well-versed in Python, R, Analytics, AWS Quick Sight, Open-source Models and Solutions, Big Data, Feature Engineering, Elastic Search, Mark Logic, and Cloud-infra-architecture.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Maruti Suzuki India Ltd</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>JOB PURPOSE\\n\\nBuild &amp; Deploy Machine learning models to drive customer retention/satisfaction/Lifetime value\\n\\nWork closely with business to identify issues and use data to propose solutions for effective decision making\\n\\nUse analytical, statistical, and programming skills to collect large data sets and develop data-driven solutions\\n\\nInterpret raw data and extract valuable meaning out of it then use this information to find patterns and develop solutions that organization needs to grow and compete\\n\\nPRINCIPAL ACCOUNTABILITIES\\n\\nCreate various Machine learning based tools or processes such as recommendation engine /lead scoring systems\\n\\nUsing machine learning tools to select features, create and optimize classifiers\\n\\nDiscover information in the huge database and help organization make smarter data drive decision to deliver better customer experience &amp; products\\n\\nUndertaking data collection, preprocessing, and analysis (EDA)\\n\\nBuild models to address business problems\\n\\nPresent information using data visualization techniques\\n\\nIdentify valuable data sources and automate collection processes\\n\\nCollaborate with multiple marketing and product planning teams\\n\\nData preparation, make sense of data from multiple data sources, be compliant to data security norms\\n\\nUnderstanding the business problem\\n\\nEffective communication with Non-Technical stakeholders\\n\\nPossess exceptional knowledge of the business domain along with expertise in technology, math and statistics\\n\\nLook at big data with a view to solve a business problem\\n\\nAbility to create and gain buy-in for novel ideas with the main motive to produce a working model that can help business make effective data driven decisions\\n\\nCreate stories from number crunching\\n\\nBe the data storyteller to gain business confidence\\n\\nSKILLS AND KNOWLEDGE\\n\\n\\nGraduate/Post graduate with understanding of basic data science (Knowledge of SQL ,HIVE, Python, R or SAS - Any 2), knowledge of basic auto industry and sales and marketing operations\\n\\nb) Work Experience 2- 5 Years\\n\\nPlease note that the Educational qualification should be from AICTE/UGC approved colleges only.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Seismic</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>About Us:\\nPlease be aware we have noticed an increase in hiring scams potentially targeting Seismic candidates. Read our full statement on our Careers page.\\nSeismic is the global leader in AI-powered enablement, empowering go-to-market leaders to drive strategic growth and deliver exceptional customer experiences at scale. The Seismic Enablement Cloud™ is the only unified AI-powered platform that prepares customer-facing teams with the skills, content, tools, and insights needed to maximize every buyer interaction and strengthen client relationships. Trusted by more than 2,000 organizations worldwide, Seismic helps businesses achieve measurable outcomes and accelerate revenue growth. Seismic is headquartered in San Diego with offices across North America, Europe, Asia and Australia. Learn more at seismic.com.\\nSeismic is committed to building an inclusive workplace that ignites growth for our employees and creates a culture of belonging that allows all employees to be seen and valued for who they are. Learn more about DEI at Seismic\\nOverview:\\n\\nWho you are::\\nWhat you'll be doing::\\nJob Posting Footer:\\n\\n\\n\\nLinkedin Posting Section: #LI-SN1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>WTW</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>202504116\\nIndia\\nMumbai, Maharashtra, India\\nBevorzugt\\nDescription\\nGain a comprehensive understanding of the process and data flow.\\nAcquire in-depth knowledge of the reports provided by GB Outsourcing.\\nCreate analytics and reports for insurers to enable strategic decision-making based on various facts, figures, and trends.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Zensar Technologies</td>\n",
       "      <td>3.8</td>\n",
       "      <td>DE&amp;A - AIML - Data Science - Conventional AI - Search</td>\n",
       "      <td>India</td>\n",
       "      <td>Engineered a scalable data pipeline that seamlessly moved data from diverse sources, including REST APIs, on-premise databases, and SharePoint, into Snowflake using Azure Data Factory, significantly improving data integration efficiency. • Led successful requirement gathering sessions, translating complex business needs into actionable technical specifications, which directly contributed to the project's successful delivery. • Implemented robust CI/CD pipelines for Azure Data Factory components and Azure Databricks notebooks, enabling smooth and reliable deployments to higher environments using Azure DevOps. • Automated the data ingestion process,eliminating 90% of manual data processing, drastically improving operational efficiency and reducing human error. • Developed an enterprise-wide data model,consolidating data from multiple sources and ensuring consistent, organization-wide data access, leading to improved decision-making capabilities. • Optimized data processing capabilities,allowing the system to handle 2GB of data every 2 hours with high performance and reliability, ensuring the infrastructure met business needs. • Implemented parallelism in data pipelines,reducing pipeline execution time significantly, boosting performance, and enhancing data flow efficiency. • Designed and documented a comprehensive architecture, detailing data transformation logic and Snowflake schema design, establishing a clear framework for future scalability and maintenance. • Collaborated effectively with business users,ensuring data accessibility, gathering critical feedback, and providing ongoing support that enhanced user satisfaction and system usability.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Company\\nGujarat Fluorochemicals Limited\\n\\nGrade / Level\\nIII\\n\\nDivision / Department\\nInformation Technology\\n\\nJob Purpose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Company_Name  Company_Rating  \\\n",
       "428            Infosys Limited             3.6   \n",
       "603                  Linde plc             3.6   \n",
       "665                       Sixt             3.6   \n",
       "361                  Gallagher             3.6   \n",
       "436                  Clarivate             3.6   \n",
       "449             Cloud Kinetics             3.6   \n",
       "733                   Comscore             3.6   \n",
       "255                  DataRobot             3.6   \n",
       "262          Commonwealth Bank             3.7   \n",
       "299                   Nihilent             3.7   \n",
       "362             Colan Infotech             3.7   \n",
       "564        DMI Housing Finance             3.7   \n",
       "591                  TechSophy             3.7   \n",
       "383                     Luxoft             3.8   \n",
       "518                Thoucentric             3.8   \n",
       "185  Kanini Software Solutions             3.8   \n",
       "103    Maruti Suzuki India Ltd             3.8   \n",
       "413                    Seismic             3.8   \n",
       "78                         WTW             3.8   \n",
       "144        Zensar Technologies             3.8   \n",
       "374    Gujarat Fluorochemicals             3.8   \n",
       "\n",
       "                                                 Job_Title   Location  \\\n",
       "428                                         Data Scientist  Bengaluru   \n",
       "603                Data Scientist for AI Products (Global)  Bengaluru   \n",
       "665                                     Data Scientist III  Bengaluru   \n",
       "361                                         Data Scientist      India   \n",
       "436                                         Data Scientist  Karnataka   \n",
       "449                                         Data Scientist       Pune   \n",
       "733                                         Data Scientist       Pune   \n",
       "255                 Customer-Facing Data Scientist - India     Remote   \n",
       "262                                         Data Scientist  Bengaluru   \n",
       "299                                         Data Scientist  Bengaluru   \n",
       "362                                         Data Scientist  Bengaluru   \n",
       "564                                         Data Scientist      Delhi   \n",
       "591                                         Data Scientist      India   \n",
       "383                                         Data Scientist  Bengaluru   \n",
       "518                                         Data Scientist  Bengaluru   \n",
       "185                         Data Scientist (Job ID - 2239)    Chennai   \n",
       "103                                         Data Scientist      Delhi   \n",
       "413                                      Data Scientist II  Hyderābād   \n",
       "78                                          Data Scientist      India   \n",
       "144  DE&A - AIML - Data Science - Conventional AI - Search      India   \n",
       "374                                         Data Scientist      Noida   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Description  \\\n",
       "428                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Job Description:\\n\\nWe are seeking a highly motivated and experienced Senior Data Scientist with a proven track record of success in conducting in depth data analysis developing machine learning models and delivering actionable insights to drive business decisions\\nThe ideal candidate will have a deep understanding of statistics machine learning algorithms and data science best practices\\n\\nKey Responsibilities:\\n\\n\\n\\n\\n\\n\\nTechnology->Analytics - Techniques->Cluster Analysis,Technology->Analytics - Techniques->Decision Trees,Technology->Analytics - Techniques->Linear Regression,Technology->Machine Learning->Python   \n",
       "603  Praxair India Private Limited | Business Area: Digitalisation\\nData Scientist for AI Products (Global)\\nBangalore, Karnataka, India | Working Scheme: On-Site | Job Type: Regular / Permanent / Unlimited / FTE | Reference Code: req23348\\n\\nIt's about Being What's next.\\nWhat's in it for you?\\n\\nA Data Scientist for AI Products (Global) will be responsible for working in the Artificial Intelligence team, Linde's AI global corporate division engaged with real business challenges and opportunities in multiple countries. Focus of this role is to support the AI team with extending existing and building new AI products for a vast amount of uses cases across Linde’s business and value chain. You'll collaborate across different business and corporate functions in international team composed of Project Managers, Data Scientists, Data and Software Engineers in the AI team and others in the Linde's Global AI team. As a Data Scientist AI, you will support Linde’s AI team with extending existing and building new AI products for a vast amount of uses cases across Linde’s business and value chain\"\\n\\nAt Linde, the sky is not the limit. If you’re looking to build a career where your work reaches beyond your job description and betters the people with whom you work, the communities we serve, and the world in which we all live, at Linde, your opportunities are limitless. Be Linde. Be Limitless.\\n\\nMaking an impact. What will you do?\\n\\nYou will work directly with a variety of different data sources, types and structures to derive actionable insights\\nDevelop, customize and manage AI software products based on Machine and Deep Learning backends will be your tasks\\nYour role includes strong support on replication of existing products and pipelines to other systems and geographies\\nIn addition to that you will support in architectural design and defining data requirements for new developments\\nIt will be your responsibility to interact with business functions in identifying opportunities with potential business impact and to support development and deployment of models into production\\n\\nWinning in your role. Do you have what it takes?\\n\\nYou have a Bachelor or master’s degree in data science, Computational Statistics/Mathematics, Computer Science, Operations Research or related field\\nYou have a strong understanding of and practical experience with Multivariate Statistics, Machine Learning and Probability concepts\\nFurther, you gained experience in articulating business questions and using quantitative techniques to arrive at a solution using available data\\nYou demonstrate hands-on experience with preprocessing, feature engineering, feature selection and data cleansing on real world datasets\\nPreferably you have work experience in an engineering or technology role\\nYou bring a strong background of Python and handling large data sets using SQL in a business environment (pandas, numpy, matplotlib, seaborn, sklearn, keras, tensorflow, pytorch, statsmodels etc.) to the role\\nIn addition you have a sound knowledge of data architectures and concepts and practical experience in the visualization of large datasets, e.g. with Tableau or PowerBI\\nResult driven mindset and excellent communication skills with high social competence gives you the ability to structure a project from idea to experimentation to prototype to implementation\\nVery good English language skills are required\\nAs a plus you have hands-on experience with DevOps and MS Azure, experience in Azure ML, Kedro or Airflow, experience in MLflow or similar\\n\\nWhy you will love working for us!\\n\\nLinde is a leading global industrial gases and engineering company, operating in more than 100 countries worldwide. We live our mission of making our world more productive every day by providing high-quality solutions, technologies and services which are making our customers more successful and helping to sustain and protect our planet.\\n\\nOn the 1st of April 2020, Linde India Limited and Praxair India Private Limited successfully formed a joint venture, LSAS Services Private Limited. This company will provide Operations and Management (O&M) services to both existing organizations, which will continue to operate separately. LSAS carries forward the commitment towards sustainable development, championed by both legacy organizations. It also takes ahead the tradition of the development of processes and technologies that have revolutionized the industrial gases industry, serving a variety of end markets including chemicals & refining, food & beverage, electronics, healthcare, manufacturing, and primary metals.\\n\\nWhatever you seek to accomplish, and wherever you want those accomplishments to take you, a career at Linde provides limitless ways to achieve your potential, while making a positive impact in the world. Be Linde. Be Limitless.\\n\\nHave we inspired you? Let's talk about it!\\n\\nWe are looking forward to receiving your complete application (motivation letter, CV, certificates) via our online job market.\\n\\nAny designations used of course apply to persons of all genders. The form of speech used here is for simplicity only.\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, protected veteran status, pregnancy, sexual orientation, gender identity or expression, or any other reason prohibited by applicable law.\\n\\nPraxair India Private Limited acts responsibly towards its shareholders, business partners, employees, society and the environment in every one of its business areas, regions and locations across the globe. The company is committed to technologies and products that unite the goals of customer value and sustainable development.   \n",
       "665                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We are currently looking to hire a highly motivated Senior Data Scientist to join our team of data science and machine learning experts to shape the next generation of intelligent pricing strategies. Our mission is to apply cutting-edge techniques—including reinforcement learning, multi-armed bandits, and Bayesian inference—to optimize dynamic pricing decisions. We build scalable models and systems that directly impact millions of customers, enabling more efficient revenue management processes and a superior user experience. If you want to be part of our journey and make an impact. Apply now!\\nYOUR ROLE AT SIXT\\nYou will design, implement, and maintain production-grade machine learning systems, with a strong focus on bandit algorithms and reinforcement learning methods for dynamic pricing\\nYou will work closely with teams in data science, engineering, product management, and business operations to bring experimental models into a robust production environment   \n",
       "361                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Introduction\\n\\nWe believe that every candidate brings something special to the table, including you! So, even if you feel that you’re close but not an exact match, we encourage you to apply. We’d be thrilled to receive applications from exceptional individuals like yourself.\\n\\nGallagher, a global industry leader in insurance, risk management, and consulting services, boasts a team of over 50,000 professionals worldwide. Our culture, known as \"The Gallagher Way,\" is driven by shared values and a passion for excellence. At the heart of our global operations, the Gallagher Center of Excellence (GCoE) in India, founded in 2006, upholds the values of quality, innovation, and teamwork. With 10,000+ professionals across five India locations, GCoE is where knowledge-driven individuals make a significant impact and build rewarding, long-term careers.   \n",
       "436                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We are looking for a highly motivated real-world evidence (RWE) data scientist who has experience in generating insights/evidence from claims and EHR real world data (RWD) to join our growing Bangalore-based RWE analytics team at Clarivate.\\nAbout You – experience, education, skills, and accomplishments\\nGraduate degree in Data science/analytics, Epidemiology, Biostatistics, or related quantitative field\\nAt least 3 years’ experience in a consultative, client-facing role\\nAt least 3 years’ experience using SQL, Python, programming against large relational databases leveraging interoperable-linked, patient-level data at scale\\nHealthcare data expert across various data types (e.g. open/closed claims, inpatient/ambulatory EMR, commercial labs, social determinants, etc.) and codified healthcare data standards (e.g. ICD, CPT, HCPCS, LOINC, Snomed, etc.)   \n",
       "449                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Job Information\\nDate Opened\\n11/11/2024\\nJob Type\\nFull time\\nWork Experience\\n3-7 years\\nIndustry\\nIT Services\\nCity   \n",
       "733                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      What You'll Do:\\nEffectively handle large data files in the course of developing and implementing solutions\\nPrecisely execute multiple analytic projects, each involving a great number of steps and analytic decisions\\nConcisely summarize real-world implications of findings from custom projects and the value proposition of real-world offerings\\nInterpret results, present findings and recommend alternative solutions to software and business decision makers\\nTranslate statistical modeling results into measures of business impact\\nInterface with clients to aid in the qualification of custom analytical solutions\\nManage expectations and coordinate project delivery with internal team   \n",
       "255                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Job Description:\\nDataRobot delivers AI that maximizes impact and minimizes business risk. Our platform and applications integrate into core business processes so teams can develop, deliver, and govern AI at scale. DataRobot empowers practitioners to deliver predictive and generative AI, and enables leaders to secure their AI assets. Organizations worldwide rely on DataRobot for AI that makes sense for their business — today and in the future.\\nDataRobot is the world’s premier AI and data science platform. Our Customer Facing Data Scientists are experienced applied data scientists, passionate about using machine learning to achieve real-world results. As a Customer Facing Data Scientist at DataRobot, you will collaborate closely with DataRobot customers, bringing expertise in data science and the DataRobot platform, to help customers achieve their organization’s objectives with AI. You’ll work with clients in a range of industries on diverse use cases, and with both business (executive, line of business) and technical (data science, engineering, analytics) stakeholders.   \n",
       "262                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Organization:\\nAt CommBank, we never lose sight of the role we play in other people’s financial wellbeing. Our focus is to help people and businesses move forward to progress. To make the right financial decisions and achieve their dreams, targets, and aspirations. Regardless of where you work within our organisation, your initiative, talent, ideas, and energy all contribute to the impact that we can make with our work. Together we can achieve great things.\\nJob Title: Data Scientist\\nLocation: Bangalore\\nBusiness & Team: BB Advanced Analytics and Artificial Intelligence COE\\nImpact & contribution:\\nAs a Senior Data Scientist, you will be instrumental in pioneering Gen AI and multi-agentic systems at scale within CommBank. You will architect, build, and operationalize advanced generative AI solutions—leveraging large language models (LLMs), collaborative agentic frameworks, and state-of-the-art toolchains. You will drive innovation, helping set the organizational strategy for advanced AI, multi-agent collaboration, and responsible next-gen model deployment.\\n\\n\\n\\n\\n\\n\\n\\n\\nAdvertising End Date: 25/07/2025   \n",
       "299                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Location:\\nBangalore\\nExperience:\\n5+ Years\\nAbout the Job Opening:\\nKey Requirements:\\n5+ years of experience in BI, data analysis, or business consulting.\\nStrong domain expertise in manufacturing and/or sales.\\nProven experience in client-facing roles with stakeholder management.   \n",
       "362                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Job Summary\\nJob Code\\n:JD021\\nDesignation\\n:Data Scientist\\nQualification\\n:Any graduate\\nExperience\\n:5+ Years\\nJob type\\n:Full Time   \n",
       "564                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Job Reference id: H00015\\n\\nJob Description\\nResponsible for preparation, manipulation, analysis, and utilization of customer data through complex programming and slicing and dicing for utilization by senior member in such a way that most pertinent business inferences can be formed. Drive analytical insight, leverage immense datasets (i.e. demographics, financial, asset info, repayment behaviour, geolocation, payments) and work with our Product, Risk, Policy, and Tech teams, to drive decision making and solving business use case.\\nResponsibilities:\\n1. Creating Models for underwriting and behavior ranking/scoring   \n",
       "591                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            At Techsophy, we believe that technology has the power to elevate lives. We’re not just building solutions; we’re building a future where everyone has the tools to thrive in four crucial dimensions of well-being:\\nPhysical Health: Offering accessible, high-quality healthcare that reaches everyone, everywhere, ensuring no one is left behind.\\nFinancial Health: Providing financial security and insurance support, creating opportunities for everyone to build a stable, prosperous future.\\nMental Health: Delivering compassionate mental and emotional support to individuals and organizations, fostering resilience and well-being at every level.\\nCyber Health: Protecting the digital world, making sure every person and organization remains safe, secure, and free from cyber threats.\\nYour Impact, Your Purpose   \n",
       "383                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Project description\\nWe are seeking a highly skilled and motivated Data Scientist with 5+ years of experience to join our team. The ideal candidate will bring strong data science, programming, and data engineering expertise, along with hands-on experience in generative AI, large language models, and modern LLM application frameworks. This role also demands excellent communication and stakeholder management skills to collaborate effectively across business units.\\nResponsibilities\\nWe are seeking a highly skilled and motivated Data Scientist with 5+ years of experience to join our team. The ideal candidate will bring strong data science, programming, and data engineering expertise, along with hands-on experience in generative AI, large language models, and modern LLM application frameworks. This role also demands excellent communication and stakeholder management skills to collaborate effectively across business units.   \n",
       "518                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               About Us\\nAt Thoucentric, we offer end-to-end consulting solutions designed to address the most pressing business challenges across industries. Leveraging deep domain expertise, cutting-edge technology, and a results-driven approach, we help organizations streamline operations, enhance decision-making, and accelerate growth. We are headquartered in Bangalore with presence across multiple locations in India, US, UK, Singapore & Australia Globally.\\n\\nWe help clients with Business Consulting, Program & Project Management, Digital Transformation, Product Management, Process & Technology Solutioning and Execution including Analytics & Emerging Tech areas cutting across functional areas such as Supply Chain, Finance & HR, Sales & Distribution across US, UK, Singapore and Australia. Our unique consulting framework allows us to focus on execution rather than pure advisory. We are working closely with marquee names in the global consumer & packaged goods (CPG) industry, new age tech and start-up ecosystem.   \n",
       "185                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Job Description\\nWant to join KANINI?\\n\\nWe are looking for someone who is intellectual and analytical in their approach and is at the forefront of new advances in technology. As a Data Scientist, you will be developing and deploying scalable and reproducible data science models for solving a variety of business problems.\\n\\nYou are all set to:\\n\\nAnalyze, design, develop, deploy and monitor complex AI/ML solutions. You are well-versed in Python, R, Analytics, AWS Quick Sight, Open-source Models and Solutions, Big Data, Feature Engineering, Elastic Search, Mark Logic, and Cloud-infra-architecture.   \n",
       "103                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   JOB PURPOSE\\n\\nBuild & Deploy Machine learning models to drive customer retention/satisfaction/Lifetime value\\n\\nWork closely with business to identify issues and use data to propose solutions for effective decision making\\n\\nUse analytical, statistical, and programming skills to collect large data sets and develop data-driven solutions\\n\\nInterpret raw data and extract valuable meaning out of it then use this information to find patterns and develop solutions that organization needs to grow and compete\\n\\nPRINCIPAL ACCOUNTABILITIES\\n\\nCreate various Machine learning based tools or processes such as recommendation engine /lead scoring systems\\n\\nUsing machine learning tools to select features, create and optimize classifiers\\n\\nDiscover information in the huge database and help organization make smarter data drive decision to deliver better customer experience & products\\n\\nUndertaking data collection, preprocessing, and analysis (EDA)\\n\\nBuild models to address business problems\\n\\nPresent information using data visualization techniques\\n\\nIdentify valuable data sources and automate collection processes\\n\\nCollaborate with multiple marketing and product planning teams\\n\\nData preparation, make sense of data from multiple data sources, be compliant to data security norms\\n\\nUnderstanding the business problem\\n\\nEffective communication with Non-Technical stakeholders\\n\\nPossess exceptional knowledge of the business domain along with expertise in technology, math and statistics\\n\\nLook at big data with a view to solve a business problem\\n\\nAbility to create and gain buy-in for novel ideas with the main motive to produce a working model that can help business make effective data driven decisions\\n\\nCreate stories from number crunching\\n\\nBe the data storyteller to gain business confidence\\n\\nSKILLS AND KNOWLEDGE\\n\\n\\nGraduate/Post graduate with understanding of basic data science (Knowledge of SQL ,HIVE, Python, R or SAS - Any 2), knowledge of basic auto industry and sales and marketing operations\\n\\nb) Work Experience 2- 5 Years\\n\\nPlease note that the Educational qualification should be from AICTE/UGC approved colleges only.   \n",
       "413                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        About Us:\\nPlease be aware we have noticed an increase in hiring scams potentially targeting Seismic candidates. Read our full statement on our Careers page.\\nSeismic is the global leader in AI-powered enablement, empowering go-to-market leaders to drive strategic growth and deliver exceptional customer experiences at scale. The Seismic Enablement Cloud™ is the only unified AI-powered platform that prepares customer-facing teams with the skills, content, tools, and insights needed to maximize every buyer interaction and strengthen client relationships. Trusted by more than 2,000 organizations worldwide, Seismic helps businesses achieve measurable outcomes and accelerate revenue growth. Seismic is headquartered in San Diego with offices across North America, Europe, Asia and Australia. Learn more at seismic.com.\\nSeismic is committed to building an inclusive workplace that ignites growth for our employees and creates a culture of belonging that allows all employees to be seen and valued for who they are. Learn more about DEI at Seismic\\nOverview:\\n\\nWho you are::\\nWhat you'll be doing::\\nJob Posting Footer:\\n\\n\\n\\nLinkedin Posting Section: #LI-SN1   \n",
       "78                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            202504116\\nIndia\\nMumbai, Maharashtra, India\\nBevorzugt\\nDescription\\nGain a comprehensive understanding of the process and data flow.\\nAcquire in-depth knowledge of the reports provided by GB Outsourcing.\\nCreate analytics and reports for insurers to enable strategic decision-making based on various facts, figures, and trends.   \n",
       "144                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Engineered a scalable data pipeline that seamlessly moved data from diverse sources, including REST APIs, on-premise databases, and SharePoint, into Snowflake using Azure Data Factory, significantly improving data integration efficiency. • Led successful requirement gathering sessions, translating complex business needs into actionable technical specifications, which directly contributed to the project's successful delivery. • Implemented robust CI/CD pipelines for Azure Data Factory components and Azure Databricks notebooks, enabling smooth and reliable deployments to higher environments using Azure DevOps. • Automated the data ingestion process,eliminating 90% of manual data processing, drastically improving operational efficiency and reducing human error. • Developed an enterprise-wide data model,consolidating data from multiple sources and ensuring consistent, organization-wide data access, leading to improved decision-making capabilities. • Optimized data processing capabilities,allowing the system to handle 2GB of data every 2 hours with high performance and reliability, ensuring the infrastructure met business needs. • Implemented parallelism in data pipelines,reducing pipeline execution time significantly, boosting performance, and enhancing data flow efficiency. • Designed and documented a comprehensive architecture, detailing data transformation logic and Snowflake schema design, establishing a clear framework for future scalability and maintenance. • Collaborated effectively with business users,ensuring data accessibility, gathering critical feedback, and providing ongoing support that enhanced user satisfaction and system usability.   \n",
       "374                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Company\\nGujarat Fluorochemicals Limited\\n\\nGrade / Level\\nIII\\n\\nDivision / Department\\nInformation Technology\\n\\nJob Purpose   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "428                        NaN  \n",
       "603                        NaN  \n",
       "665                        NaN  \n",
       "361                        NaN  \n",
       "436                        NaN  \n",
       "449                        NaN  \n",
       "733                        NaN  \n",
       "255                        NaN  \n",
       "262                        NaN  \n",
       "299                        NaN  \n",
       "362                        NaN  \n",
       "564                        NaN  \n",
       "591                        NaN  \n",
       "383                        NaN  \n",
       "518                        NaN  \n",
       "185                        NaN  \n",
       "103                        NaN  \n",
       "413                        NaN  \n",
       "78                         NaN  \n",
       "144                        NaN  \n",
       "374                        NaN  "
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[\n",
    "    428, 603, 665, 361, 436, 449, 733, 255, 262, 299, 362, 564, 591, 383,\n",
    "    518, 185, 103, 413,  78, 144, 374\n",
    "], ['Company_Name', 'Company_Rating', 'Job_Title', 'Location', 'Description', 'Median_Salary_Standardized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa0cc4-7930-4572-a3f0-1c3c62470453",
   "metadata": {},
   "source": [
    "- Row 428, not enough information about the role, lets impute the salary with 5,00,000.\n",
    "- Row 603, lets impute the salary with 8,00,000.\n",
    "- Row 665, the pay range should be around 8,00,00.\n",
    "- Row 361, not enough info about the role 5,00,000.\n",
    "- Row 436, lets impute the salary with 8,00,000.\n",
    "- Row 449, requires 3-7 years of experience, the salary should be around 7,00,000.\n",
    "- Row 733, the role seems to be a decent data scientist role, lets impute the salary with 9,00,000.\n",
    "- Row 255, lets impute the salary with 8,00,000.\n",
    "- Row 262, lets impute the salary with 10,00,000.\n",
    "- Row 299, requries 5+ years of experience, the salary will be around 12,00,000.\n",
    "- Row 362, not enough info about the role, rough salary of 8,00,000.\n",
    "- Row 564, lets impute the salary with 7,00,000.\n",
    "- Row 591, not enough information about the role, lets impute the salary with 5,00,000.\n",
    "- Row 383, requires 5+ years of experience, all data science skills, the ideal salary should be around 30,00,000.\n",
    "- Row 518, not enough info about the role, let impute the salary with 5,00,000.\n",
    "- Row 185, requires a lot of skill sets, lets impute the salary with 10,00,000.\n",
    "- Row 103, this role requires 2-5 years of experience and a bunch of Data science skills, lets impute the salary with 15,00,000.\n",
    "- Row 413, lets impute with 5,00,000.\n",
    "- Row 78, the pay will be around 6,00,000.\n",
    "- Row 144 & 374 not enough information about the role, lets impute the salary with 6,00,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "29bb869d-d361-44a9-b8a7-613dce6ac4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[428, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[603, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[665, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[361, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[436, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[449, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[733, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[255, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[262, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[299, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[362, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[564, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[591, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[383, 'Median_Salary_Standardized'] = 3000000\n",
    "\n",
    "df_copy.loc[518, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[185, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[103, 'Median_Salary_Standardized'] = 1500000\n",
    "\n",
    "df_copy.loc[413, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[78, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[[144, 374], 'Median_Salary_Standardized'] = 600000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7f9f0-8f8e-44cf-a599-c0f24b02816d",
   "metadata": {},
   "source": [
    "#### Imputing rows with ratings from 3.8 to 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "39e560b8-8077-49a2-b7b8-6e6fc00c093e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Growexx</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Growexx is looking for a smart and passionate Data Scientist, who will empower Marketing, Product, and Sales teams to make strategic, data-driven decisions.\\nKey Responsibilities\\nMine, process, and analyze web, product, sales, and digital marketing data at an event level.\\nUtilize traditional machine learning techniques and language models (LLMs) to build great AI agents for different business needs.\\nAssist in developing and optimizing LLM-driven solutions for tasks such as text summarization and basic customer support automation.\\nContribute to building and deploying predictive models and machine learning algorithms across customer profile and usage datasets.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Sculpsoft</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Join the SculptSoft Voyage\\n\\nAt SculptSoft, our people come first. We cultivate talent and it shows in everything – from what we design and create, to what we value and believe.\\n\\nCurrent Openings\\nGrow With Us\\nWe Let You Build\\n\\nOur staff’s career path and professional journey is equally important to us as our client’s delivery satisfaction and quality. Rather than coercing them into becoming the best at something, we believe in making the best of every individual’s unique quality.\\n\\nWe Let You Bloom\\n\\nWe allow every individual to take the time they need to get into the zone where they can perform their best. We also believe in providing all the required training and prerequisite knowledge to make sure they feel confident at what they do. Along with periodic training sessions, our team of experts is always happy to guide you whenever you need them.\\n\\nWe Believe in Balance\\n\\nWe believe in a healthy work-life balance, which is why we are a 5-workdays organisation. Moreover, we plan our work in a way that does not end up with our team having to work during the non-working hours every time, because we truly believe that the more you are away from your screens during the non-working hours, the more efficient you will be during your work hours.\\n\\nWe Believe in Bringing Out the Best\\n\\nWe believe in giving our best because that’s all we can do, give our best! We have incorporated this very philosophy in our work habits as well, thus ensuring that we enjoy what we do. No achievement is small and we celebrate all your achievements with much gusto! We never miss an opportunity to recognize every individual’s efforts, contributions and good work.\\n\\nLet us be a part of your professional journey\\nLet us get to know each other!\\n\\nIn 1st conversation, the HR team will get to know you and your needs/expectations and will introduce us well. This is to determine if we can be a suitable fit for each other on a high level.\\n\\nLet us get to know your technical skills!\\n\\nIn the 2nd meeting, our respective technical experts will try to understand your technical skills and expertise. In this meeting, we will determine if we are a suitable fit for each other in terms of the technical aspect of the opening/position.\\n\\nLet us get to a win-win state!\\n\\nIn our final meeting, we will share the detailed work profile, the high-level future career path of yours with us. In this meeting, we will determine how we can be in a win-win state that too not just financially but work-wise too.\\n\\nEmployee Benefits\\nMedical Insurance\\nOpen Door Policy\\nCompetency Development\\nLearn from the experts\\nCareer advancement opportunities\\nAppreciations and Rewards\\nGoal setting and accountability\\nFlexible Time\\nWork-Life Balance\\nReferral Bonus\\nCultural Events and Sports\\nWhat Our Team Says About Us: Employees Thoughts\\nCurrent Openings\\n\\nCurrently no Vacancies.\\n\\nSenior Java Engineer\\n\\nExperience : 5+ years\\n\\nNo of opening - 1\\n\\nView More\\nSenior Python Engineer\\n\\nExperience : 4+ years\\n\\nNo of opening - 1\\n\\nView More\\nMid-level Python Engineer\\n\\nExperience : 2 - 3 years\\n\\nNo of opening - 1\\n\\nView More\\nProject Manager\\n\\nExperience : 5 - 6 years\\n\\nNo of opening - 1\\n\\nView More\\nQA Automation Engineer\\n\\nExperience : 3 - 6 years\\n\\nNo of opening - 1\\n\\nView More\\nSr. Frontend Developer\\n\\nExperience: 5+ Years\\n\\nNo of opening - 1\\n\\nView More\\nData Engineer\\n\\nExperience: 3 to 5 Years\\n\\nNo of opening - 1\\n\\nView More\\nData Scientist\\n\\nExperience: 4 to 6 Years\\n\\nNo of opening - 1\\n\\nView More\\nSenior Backend Engineer\\n\\nExperience: 8 to 10 years\\n\\nNo of opening - 1\\n\\nView More\\nSenior Backend Engineer\\n\\nExperience: 3-5 years\\n\\nNo of opening - 1\\n\\nView More\\nQA Engineer (Manual &amp; Automation)\\n\\nExperience: 1-2 Years\\n\\nNo of opening - 1\\n\\nView More\\nSenior Data Engineer (Azure)\\n\\nExperience: 6+ Years\\n\\nNo of opening - 1\\n\\nView More\\nSenior DevOps Engineer\\n\\nExperience: 2 Years\\n\\nNo of opening - 1\\n\\nView More\\nXamarin Developer\\n\\nExperience: 5+ years\\n\\nNo of opening - 1\\n\\nView More\\nSenior .Net Developer\\n\\nExperience: 3 to 6 years\\n\\nNo of opening - 1\\n\\nView More</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Continental</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Your tasks\\nYour tasks\\nAs a team member of the Group Sector Central Function Technology of ContiTech, you will be globally responsible to drive success of applied data science and effective usage in all areas of the organization. Design and implement innovative data-drive solutions to solve complex business problems, using cutting-edge techniques to build up customer centric platforms to reduce complexity, ensure standards, maximize cost savings as well as developing innovative material-driven solutions for a carbon-neutral and 100% circular product portfolio.\\nYou\\nConsult on effectively applying Data Science methodology, technology, and good practices, complementing AI/DS platform owners, AI/DS sector owners, AI/DS project owners.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Digitap.AI Enterprise Solutions</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist (ML/NLP Developer)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About Us:\\nDIGITAP.AI is a cutting-edge provider of AI/ML solutions tailored for the modern, internet-driven business landscape. Our advanced technologies empower businesses with reliable, fast, and fully compliant customer onboarding, automated risk management, and big data-enabled services, including Risk Analytics and Customised Scorecards.\\n\\nOur proprietary machine learning algorithms and modules boast some of the highest success rates in the market. Partnering with the largest digital lenders in India, our team is a vibrant mix of expertise in Fintech Product &amp; Risk Management, Fraud Detection, and Big Data Analytics.\\n\\nCulture and Benefits:\\nInnovative Start-up Environment: Enjoy the flexibility to design, implement, and influence the development of cutting-edge solutions.\\nTransparency and Meritocracy: We value clear communication, eschew politics, and promote an open culture where contributions are recognized and rewarded.\\nOwnership and Impact: We encourage team members to take ownership, think beyond their roles, and contribute to the company's success in meaningful ways.\\nCompetitive Compensation: We offer a competitive salary and a potential equity package, aligning your success with the company's growth.\\n\\nJob Description:\\nAs a Senior NLP/ML Developer, you will design, develop, and optimize AI-driven applications with a strong focus on natural language processing (NLP) and machine learning (ML). You will work on cutting-edge NLP models for text classification, entity recognition, and sentiment analysis, while also contributing to credit scoring models in the fintech and risk management domains.\\n\\nKey Responsibilities:\\nDevelop NLP Solutions: Build and deploy advanced NLP models for tasks such as text categorization, named entity recognition, sentiment analysis, and document classification.\\nEnhance Credit Scoring Models: Contribute to the development and optimization of ML models for credit risk assessment and scorecard development.\\nData Exploration &amp; Preprocessing: Process and analyze unstructured text data using NLP techniques, including tokenization, lemmatization, word embeddings, and vectorization.\\nModel Research &amp; Development: Collaborate with data scientists and researchers to develop, evaluate, and refine deep learning and transformer-based models (e.g., BERT, GPT) to solve complex business challenges.\\nProduct Integration &amp; Optimization: Work closely with engineering and product teams to integrate ML/NLP models into production, ensuring scalability and efficiency.\\nResearch &amp; Innovation: Stay up to date with advancements in NLP, ML, and AI research, translating cutting-edge techniques into practical, real-world applications.\\n\\nRequired Skills and Experience:\\nNLP &amp; Deep Learning Expertise: Min 2 years of experience in NLP and ML, particularly in text classification, entity recognition, and semantic analysis.\\nML Frameworks Proficiency: Strong experience with frameworks like PyTorch, TensorFlow, Hugging Face Transformers, and Keras.\\nPython Programming: Proficiency in Python and familiarity with libraries such as NLTK, spaCy, scikit-learn, NumPy, pandas, and OpenAI’s API.\\nDatabase &amp; API Integration: Experience with SQL and NoSQL databases, as well as developing and integrating RESTful APIs.\\nProblem-Solving Mindset: Strong analytical skills with the ability to independently solve complex NLP challenges.\\nHands-on expertise with Regular Expressions.\\nPreferred Qualifications:\\nQualification: BE, BTech, MTech, ME, MCA (minimum 4 years of degree)\\nExperience: 1-2 Years\\nContinuous Learning: A strong desire to stay updated with the latest research and advancements in AI, ML, and computer vision.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Sybrant Data</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Designation –Data Scientist</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Experience – 2 to 4 Years\\nEducation - B.Sc / M.Sc (Maths / Statistics) B.Tech /B.E. – Computer Science\\nJob Description:\\n2 - 4 years of experience in machine learning and data mining\\nExcellent understanding of different software such as Perl, Python, Hadoop, Java and R programming\\nStrong technical background and have excellent problem-solving abilities\\nGood in at least one programming or scripting language\\nUnderstanding of databases and ability to write SQL queries\\nExcellent oral and written communication skills with business acumen\\nShould be a self-starter with high initiative and enthusiastic to learn and deliver on latest tools and technologies\\nExperience worked in big data environment is an added advantage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ESJ Asthra Edutech Pvt Ltd</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>Job Title: Data Scientist\\nJob Type: Full-Time\\nJob Summary\\nWe are looking for a skilled Data Scientist to join our team. You will be responsible for analyzing large volumes of data, creating predictive models, and delivering actionable insights that drive business decisions and improve our learning systems.\\nKey Responsibilities\\nCollect, clean, and preprocess data from multiple sources.\\nBuild and evaluate predictive models and machine learning algorithms.\\nAnalyze data trends and patterns to provide business insights.\\nCollaborate with cross-functional teams including product, marketing, and tech.\\nDesign experiments and interpret their results using statistical techniques.\\nCommunicate findings through visualizations and reports.\\nStay up-to-date with the latest developments in data science and AI.\\nRequirements\\nBachelor’s or Master’s degree in Computer Science, Data Science, Statistics, Mathematics, or a related field.\\nStrong programming skills in Python or R.\\nProficient in SQL and working with large datasets.\\nExperience with machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch).\\nKnowledge of data visualization tools (e.g., Power BI, Tableau, matplotlib, seaborn).\\nExcellent problem-solving and analytical skills.\\nStrong communication skills to explain complex data in a simple way.\\nJob Types: Full-time, Fresher\\nEducation:\\nBachelor's (Required)\\nWork Location: In person</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Precognitas Health</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Data Scientist\\nFull-Time Software Developer\\nRequirements\\nThree (3) or more years of work experience in a software development team,\\nOr a Master of Science in statistics, math, computer science, or related field\\nExcellent knowledge of data analysis, statistics, and probability\\nDesired but optional is experience with statistical software packages such as R or SAS\\nExcellent coding skills in Python\\nDesired but optional is familiarity with numpy, matplotlib, pandas, and/or scikit learn\\nFamiliarity with git and agile workflows</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Application Square Infotech Pvt Ltd</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Job Summary:\\nWe are seeking a skilled Data Scientist to analyze large datasets, build predictive models, and derive actionable insights to support business decisions. The ideal candidate has strong statistical knowledge, proficiency in programming, and a problem-solving mindset.\\nKey Responsibilities:\\nCollect, clean, and preprocess structured and unstructured data\\nPerform exploratory data analysis and visualize insights\\nDevelop, test, and deploy machine learning and statistical models\\nCommunicate findings and recommendations through reports and presentations\\nCollaborate with cross-functional teams to identify business opportunities\\nMaintain and improve data pipelines and model performance over time\\nRequired Skills &amp; Qualifications:\\nBachelor’s or Master’s in Computer Science, Statistics, Mathematics, Data Science, or related field\\nProficiency in Python or R, and SQL\\nExperience with machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch)\\nKnowledge of statistical analysis and experimental design\\nFamiliarity with data visualization tools (e.g., Tableau, Power BI, matplotlib, seaborn)\\nExcellent analytical and problem-solving skills\\nStrong communication and presentation abilities\\nPreferred:\\nExperience with big data technologies (e.g., Spark, Hadoop)\\nKnowledge of cloud platforms (AWS, Azure, GCP)\\nExperience- 1-2 Year.\\nMonday To Friday.\\nMorning Shift.\\nhr@applicationsquare.com\\nJob Type: Full-time\\nSchedule:\\nDay shift\\nMonday to Friday\\nWeekend availability\\nWork Location: In person</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>eBay</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Snr Data Scientist, Knowledge Management</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.\\nOur customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.\\nJoin a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.\\nAbout Team and role\\nWe’re building the future of eCommerce product discovery, and we need a data-driven, AI-savvy problem solver to help us, do it.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>ChicMic Studios</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>Chicmic Studios\\nJob Role: Data Scientist\\nExperience Required: 3+ Years\\nSkills Required: Data Science, Python, Pandas, Matplotlibs\\nJob Description:\\nWe are seeking a Data Scientist with strong expertise in data analysis, machine learning, and visualization. The ideal candidate should be proficient in Python, Pandas, and Matplotlib, with experience in building and optimizing data-driven models. Some experience in Natural Language Processing (NLP) and Named Entity Recognition (NER) models would be a plus.\\nRoles &amp; Duties:\\nAnalyze and process large datasets using Python and Pandas.\\nDevelop and optimize machine learning models for predictive analytics.\\nCreate data visualizations using Matplotlib and Seaborn to support decision-making.\\nPerform data cleaning, feature engineering, and statistical analysis.\\nWork with structured and unstructured data to extract meaningful insights.\\nImplement and fine-tune NER models for specific use cases (if required).\\nCollaborate with cross-functional teams to drive data-driven solutions\\nRequired Skills &amp; Qualifications:\\nStrong proficiency in Python and data science libraries (Pandas, NumPy, Scikit-learn, etc.).\\nExperience in data analysis, statistical modeling, and machine learning.\\nHands-on expertise in data visualization using Matplotlib and Seaborn.\\nUnderstanding of SQL and database querying.\\nFamiliarity with NLP techniques and NER models is a plus.\\nStrong problem-solving and analytical skills.\\nContact: 9875952836\\nOffice Address: F273, Phase 8B industrial Area, Mohali, Punjab.\\nJob Type: Full-time\\nApplication Question(s):\\nWhat is your Native &amp; Current Location?\\n*\\nWhat is your Highest Qualification?\\nWork Location: In person</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Amanstra Consulting</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Python Developer with Data Science Background</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Summary\\nWe’re looking for an experienced Python professional with a strong data science foundation, especially in forecasting. You should be someone who’s confident writing clean, efficient code, understanding and improving existing codebases, and developing models that solve real-world business problems.\\nThe role involves hands-on coding, building and refining forecasting models, and collaborating with analysts and project teams to deliver data-driven solutions.\\nKey Responsibilities\\nDevelop and maintain Python code for forecasting and data modeling\\nUnderstand, review, and rewrite code written by other developers or data scientists\\nCollaborate with business teams to understand requirements and translate them into technical solutions\\nWork with historical and real-time data to improve forecast accuracy\\nDocument code logic, assumptions, and workflows clearly\\nJob Types: Full-time, Contractual / Temporary\\nContract length: 1 month\\nSchedule:\\nDay shift\\nWork Location: Remote</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>G2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist - I</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Location\\nBengaluru\\nEmployment Type\\nFull time\\nLocation Type\\nOn-site\\nDepartment\\nProduct R&amp;D\\n\\nAbout G2 - The Company\\nWhen you join G2, you’re joining the team that helps businesses reach their peak potential by powering decisions and strategies with trusted insights from real software users.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Techblocks</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>We are seeking a Data Science &amp; Optimization Engineer to develop and implement advanced predictive models and optimization solutions. The ideal candidate will have expertise in predictive modeling, integer programming, Python development, and cloud-based data processing. This role will involve working with large datasets, solving complex optimization problems (e.g., bin packing, TSP), and managing cloud infrastructure for scalable solutions.\\n\\nKey Responsibilities:\\nDevelop and implement predictive models using statistical methods (e.g., Bayesian models).\\nSolve optimization problems such as bin packing, TSP, and clustering using integer programming.\\nDevelop Python-based solutions using Git/Poetry for code and library management.\\nWork with data processing libraries such as Pandas, Polars, and others.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>Imurgence</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Jamshedpur</td>\n",
       "      <td>Educational qualifications\\nB Tech/ BE, M.Sc.(Maths) or M Tech/ MS or equivalent in Mechanical/Metallurgical/ Electrical/ Electronics/ Computer Science/Instrumentation/Industrial Engineering/Operations Research or in any other relevant discipline.\\n\\nRelevant experience (Type/ Nature and years of relevant experience required to execute the role)\\nMin. 2-4 years of experience\\n\\nLocations: Jamshedpur / Kalinga nagar / Kolkata/ Mumbai\\n\\nExperience related to advanced analytics\\nMachine learning, Deep learning, Fuzzy logic, data visualisation, statistics, Derived data analysis etc.\\nProgramming and process trouble-shooting experience will be preferred.\\nExposure to mathematical modelling will be preferred.\\nUnderstanding of statistics and statistical modelling will be required.\\nGood process knowledge related to supply chain, iron and steel manufacturing, marketing or mining/mineral processing is preferable.\\nProgramming skills using a high level language (preferably in .net environment) will be necessary.\\nKnowledge on data acquisition, analytics, statistics and other mathematical modelling tools will be useful.\\nSound concepts on Big data analytics will be helpful.\\n\\n\\nStatistics, Data analytics, Artificial intelligence, programming, system engineering and flow design, Logic building, Scenario analysis.\\nCoding in R/ Python language is Compulsory.\\n\\n\\nLearning inclination, Collaboration, Achievement orientation, change orientation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>Pisoft Informatics</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Science Developer</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>We are seeking a curious and analytical Data Science Intern to join our data-driven team. This internship provides a fantastic opportunity to work on real-world data projects, apply statistical methods, and gain hands-on experience with data analysis and machine learning techniques. If you’re passionate about data and eager to learn, we want to hear from you!\\nAssist in collecting, cleaning, and analyzing large datasets\\nDevelop predictive models and perform statistical analysis\\nCollaborate with team members to interpret data and generate insights\\nSupport the creation of data visualizations and reports\\nExperience preferred - 0 - 5 years\\nLocation : Mohali</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name  Company_Rating  \\\n",
       "248                              Growexx             3.9   \n",
       "429                            Sculpsoft             3.9   \n",
       "266                          Continental             3.9   \n",
       "612      Digitap.AI Enterprise Solutions             3.9   \n",
       "224                         Sybrant Data             3.9   \n",
       "106           ESJ Asthra Edutech Pvt Ltd             3.9   \n",
       "566                   Precognitas Health             3.9   \n",
       "143  Application Square Infotech Pvt Ltd             3.9   \n",
       "637                                 eBay             3.9   \n",
       "807                      ChicMic Studios             3.9   \n",
       "560                  Amanstra Consulting             3.9   \n",
       "110                                   G2             4.0   \n",
       "244                           Techblocks             4.0   \n",
       "743                            Imurgence             4.0   \n",
       "768                   Pisoft Informatics             4.0   \n",
       "\n",
       "                                         Job_Title    Location  \\\n",
       "248                                 Data Scientist   Ahmedabad   \n",
       "429                                 Data Scientist   Ahmedabad   \n",
       "266                                 Data Scientist   Bengaluru   \n",
       "612              Data Scientist (ML/NLP Developer)   Bengaluru   \n",
       "224                    Designation –Data Scientist     Chennai   \n",
       "106                                 Data Scientist  Coimbatore   \n",
       "566                                 Data Scientist       Delhi   \n",
       "143                                 Data Scientist       India   \n",
       "637       Snr Data Scientist, Knowledge Management   Karnataka   \n",
       "807                                 Data Scientist      Mohali   \n",
       "560  Python Developer with Data Science Background      Remote   \n",
       "110                             Data Scientist - I   Bengaluru   \n",
       "244                                 Data Scientist   Hyderābād   \n",
       "743                                 Data Scientist  Jamshedpur   \n",
       "768                         Data Science Developer      Mohali   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Description  \\\n",
       "248                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Growexx is looking for a smart and passionate Data Scientist, who will empower Marketing, Product, and Sales teams to make strategic, data-driven decisions.\\nKey Responsibilities\\nMine, process, and analyze web, product, sales, and digital marketing data at an event level.\\nUtilize traditional machine learning techniques and language models (LLMs) to build great AI agents for different business needs.\\nAssist in developing and optimizing LLM-driven solutions for tasks such as text summarization and basic customer support automation.\\nContribute to building and deploying predictive models and machine learning algorithms across customer profile and usage datasets.   \n",
       "429  Join the SculptSoft Voyage\\n\\nAt SculptSoft, our people come first. We cultivate talent and it shows in everything – from what we design and create, to what we value and believe.\\n\\nCurrent Openings\\nGrow With Us\\nWe Let You Build\\n\\nOur staff’s career path and professional journey is equally important to us as our client’s delivery satisfaction and quality. Rather than coercing them into becoming the best at something, we believe in making the best of every individual’s unique quality.\\n\\nWe Let You Bloom\\n\\nWe allow every individual to take the time they need to get into the zone where they can perform their best. We also believe in providing all the required training and prerequisite knowledge to make sure they feel confident at what they do. Along with periodic training sessions, our team of experts is always happy to guide you whenever you need them.\\n\\nWe Believe in Balance\\n\\nWe believe in a healthy work-life balance, which is why we are a 5-workdays organisation. Moreover, we plan our work in a way that does not end up with our team having to work during the non-working hours every time, because we truly believe that the more you are away from your screens during the non-working hours, the more efficient you will be during your work hours.\\n\\nWe Believe in Bringing Out the Best\\n\\nWe believe in giving our best because that’s all we can do, give our best! We have incorporated this very philosophy in our work habits as well, thus ensuring that we enjoy what we do. No achievement is small and we celebrate all your achievements with much gusto! We never miss an opportunity to recognize every individual’s efforts, contributions and good work.\\n\\nLet us be a part of your professional journey\\nLet us get to know each other!\\n\\nIn 1st conversation, the HR team will get to know you and your needs/expectations and will introduce us well. This is to determine if we can be a suitable fit for each other on a high level.\\n\\nLet us get to know your technical skills!\\n\\nIn the 2nd meeting, our respective technical experts will try to understand your technical skills and expertise. In this meeting, we will determine if we are a suitable fit for each other in terms of the technical aspect of the opening/position.\\n\\nLet us get to a win-win state!\\n\\nIn our final meeting, we will share the detailed work profile, the high-level future career path of yours with us. In this meeting, we will determine how we can be in a win-win state that too not just financially but work-wise too.\\n\\nEmployee Benefits\\nMedical Insurance\\nOpen Door Policy\\nCompetency Development\\nLearn from the experts\\nCareer advancement opportunities\\nAppreciations and Rewards\\nGoal setting and accountability\\nFlexible Time\\nWork-Life Balance\\nReferral Bonus\\nCultural Events and Sports\\nWhat Our Team Says About Us: Employees Thoughts\\nCurrent Openings\\n\\nCurrently no Vacancies.\\n\\nSenior Java Engineer\\n\\nExperience : 5+ years\\n\\nNo of opening - 1\\n\\nView More\\nSenior Python Engineer\\n\\nExperience : 4+ years\\n\\nNo of opening - 1\\n\\nView More\\nMid-level Python Engineer\\n\\nExperience : 2 - 3 years\\n\\nNo of opening - 1\\n\\nView More\\nProject Manager\\n\\nExperience : 5 - 6 years\\n\\nNo of opening - 1\\n\\nView More\\nQA Automation Engineer\\n\\nExperience : 3 - 6 years\\n\\nNo of opening - 1\\n\\nView More\\nSr. Frontend Developer\\n\\nExperience: 5+ Years\\n\\nNo of opening - 1\\n\\nView More\\nData Engineer\\n\\nExperience: 3 to 5 Years\\n\\nNo of opening - 1\\n\\nView More\\nData Scientist\\n\\nExperience: 4 to 6 Years\\n\\nNo of opening - 1\\n\\nView More\\nSenior Backend Engineer\\n\\nExperience: 8 to 10 years\\n\\nNo of opening - 1\\n\\nView More\\nSenior Backend Engineer\\n\\nExperience: 3-5 years\\n\\nNo of opening - 1\\n\\nView More\\nQA Engineer (Manual & Automation)\\n\\nExperience: 1-2 Years\\n\\nNo of opening - 1\\n\\nView More\\nSenior Data Engineer (Azure)\\n\\nExperience: 6+ Years\\n\\nNo of opening - 1\\n\\nView More\\nSenior DevOps Engineer\\n\\nExperience: 2 Years\\n\\nNo of opening - 1\\n\\nView More\\nXamarin Developer\\n\\nExperience: 5+ years\\n\\nNo of opening - 1\\n\\nView More\\nSenior .Net Developer\\n\\nExperience: 3 to 6 years\\n\\nNo of opening - 1\\n\\nView More   \n",
       "266                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Your tasks\\nYour tasks\\nAs a team member of the Group Sector Central Function Technology of ContiTech, you will be globally responsible to drive success of applied data science and effective usage in all areas of the organization. Design and implement innovative data-drive solutions to solve complex business problems, using cutting-edge techniques to build up customer centric platforms to reduce complexity, ensure standards, maximize cost savings as well as developing innovative material-driven solutions for a carbon-neutral and 100% circular product portfolio.\\nYou\\nConsult on effectively applying Data Science methodology, technology, and good practices, complementing AI/DS platform owners, AI/DS sector owners, AI/DS project owners.   \n",
       "612                                                                                                                                                                                                                                                                                                                                                                                                                                                                   About Us:\\nDIGITAP.AI is a cutting-edge provider of AI/ML solutions tailored for the modern, internet-driven business landscape. Our advanced technologies empower businesses with reliable, fast, and fully compliant customer onboarding, automated risk management, and big data-enabled services, including Risk Analytics and Customised Scorecards.\\n\\nOur proprietary machine learning algorithms and modules boast some of the highest success rates in the market. Partnering with the largest digital lenders in India, our team is a vibrant mix of expertise in Fintech Product & Risk Management, Fraud Detection, and Big Data Analytics.\\n\\nCulture and Benefits:\\nInnovative Start-up Environment: Enjoy the flexibility to design, implement, and influence the development of cutting-edge solutions.\\nTransparency and Meritocracy: We value clear communication, eschew politics, and promote an open culture where contributions are recognized and rewarded.\\nOwnership and Impact: We encourage team members to take ownership, think beyond their roles, and contribute to the company's success in meaningful ways.\\nCompetitive Compensation: We offer a competitive salary and a potential equity package, aligning your success with the company's growth.\\n\\nJob Description:\\nAs a Senior NLP/ML Developer, you will design, develop, and optimize AI-driven applications with a strong focus on natural language processing (NLP) and machine learning (ML). You will work on cutting-edge NLP models for text classification, entity recognition, and sentiment analysis, while also contributing to credit scoring models in the fintech and risk management domains.\\n\\nKey Responsibilities:\\nDevelop NLP Solutions: Build and deploy advanced NLP models for tasks such as text categorization, named entity recognition, sentiment analysis, and document classification.\\nEnhance Credit Scoring Models: Contribute to the development and optimization of ML models for credit risk assessment and scorecard development.\\nData Exploration & Preprocessing: Process and analyze unstructured text data using NLP techniques, including tokenization, lemmatization, word embeddings, and vectorization.\\nModel Research & Development: Collaborate with data scientists and researchers to develop, evaluate, and refine deep learning and transformer-based models (e.g., BERT, GPT) to solve complex business challenges.\\nProduct Integration & Optimization: Work closely with engineering and product teams to integrate ML/NLP models into production, ensuring scalability and efficiency.\\nResearch & Innovation: Stay up to date with advancements in NLP, ML, and AI research, translating cutting-edge techniques into practical, real-world applications.\\n\\nRequired Skills and Experience:\\nNLP & Deep Learning Expertise: Min 2 years of experience in NLP and ML, particularly in text classification, entity recognition, and semantic analysis.\\nML Frameworks Proficiency: Strong experience with frameworks like PyTorch, TensorFlow, Hugging Face Transformers, and Keras.\\nPython Programming: Proficiency in Python and familiarity with libraries such as NLTK, spaCy, scikit-learn, NumPy, pandas, and OpenAI’s API.\\nDatabase & API Integration: Experience with SQL and NoSQL databases, as well as developing and integrating RESTful APIs.\\nProblem-Solving Mindset: Strong analytical skills with the ability to independently solve complex NLP challenges.\\nHands-on expertise with Regular Expressions.\\nPreferred Qualifications:\\nQualification: BE, BTech, MTech, ME, MCA (minimum 4 years of degree)\\nExperience: 1-2 Years\\nContinuous Learning: A strong desire to stay updated with the latest research and advancements in AI, ML, and computer vision.   \n",
       "224                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Experience – 2 to 4 Years\\nEducation - B.Sc / M.Sc (Maths / Statistics) B.Tech /B.E. – Computer Science\\nJob Description:\\n2 - 4 years of experience in machine learning and data mining\\nExcellent understanding of different software such as Perl, Python, Hadoop, Java and R programming\\nStrong technical background and have excellent problem-solving abilities\\nGood in at least one programming or scripting language\\nUnderstanding of databases and ability to write SQL queries\\nExcellent oral and written communication skills with business acumen\\nShould be a self-starter with high initiative and enthusiastic to learn and deliver on latest tools and technologies\\nExperience worked in big data environment is an added advantage   \n",
       "106                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Job Title: Data Scientist\\nJob Type: Full-Time\\nJob Summary\\nWe are looking for a skilled Data Scientist to join our team. You will be responsible for analyzing large volumes of data, creating predictive models, and delivering actionable insights that drive business decisions and improve our learning systems.\\nKey Responsibilities\\nCollect, clean, and preprocess data from multiple sources.\\nBuild and evaluate predictive models and machine learning algorithms.\\nAnalyze data trends and patterns to provide business insights.\\nCollaborate with cross-functional teams including product, marketing, and tech.\\nDesign experiments and interpret their results using statistical techniques.\\nCommunicate findings through visualizations and reports.\\nStay up-to-date with the latest developments in data science and AI.\\nRequirements\\nBachelor’s or Master’s degree in Computer Science, Data Science, Statistics, Mathematics, or a related field.\\nStrong programming skills in Python or R.\\nProficient in SQL and working with large datasets.\\nExperience with machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch).\\nKnowledge of data visualization tools (e.g., Power BI, Tableau, matplotlib, seaborn).\\nExcellent problem-solving and analytical skills.\\nStrong communication skills to explain complex data in a simple way.\\nJob Types: Full-time, Fresher\\nEducation:\\nBachelor's (Required)\\nWork Location: In person   \n",
       "566                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Data Scientist\\nFull-Time Software Developer\\nRequirements\\nThree (3) or more years of work experience in a software development team,\\nOr a Master of Science in statistics, math, computer science, or related field\\nExcellent knowledge of data analysis, statistics, and probability\\nDesired but optional is experience with statistical software packages such as R or SAS\\nExcellent coding skills in Python\\nDesired but optional is familiarity with numpy, matplotlib, pandas, and/or scikit learn\\nFamiliarity with git and agile workflows   \n",
       "143                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Job Summary:\\nWe are seeking a skilled Data Scientist to analyze large datasets, build predictive models, and derive actionable insights to support business decisions. The ideal candidate has strong statistical knowledge, proficiency in programming, and a problem-solving mindset.\\nKey Responsibilities:\\nCollect, clean, and preprocess structured and unstructured data\\nPerform exploratory data analysis and visualize insights\\nDevelop, test, and deploy machine learning and statistical models\\nCommunicate findings and recommendations through reports and presentations\\nCollaborate with cross-functional teams to identify business opportunities\\nMaintain and improve data pipelines and model performance over time\\nRequired Skills & Qualifications:\\nBachelor’s or Master’s in Computer Science, Statistics, Mathematics, Data Science, or related field\\nProficiency in Python or R, and SQL\\nExperience with machine learning libraries (e.g., scikit-learn, TensorFlow, PyTorch)\\nKnowledge of statistical analysis and experimental design\\nFamiliarity with data visualization tools (e.g., Tableau, Power BI, matplotlib, seaborn)\\nExcellent analytical and problem-solving skills\\nStrong communication and presentation abilities\\nPreferred:\\nExperience with big data technologies (e.g., Spark, Hadoop)\\nKnowledge of cloud platforms (AWS, Azure, GCP)\\nExperience- 1-2 Year.\\nMonday To Friday.\\nMorning Shift.\\nhr@applicationsquare.com\\nJob Type: Full-time\\nSchedule:\\nDay shift\\nMonday to Friday\\nWeekend availability\\nWork Location: In person   \n",
       "637                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.\\nOur customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.\\nJoin a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.\\nAbout Team and role\\nWe’re building the future of eCommerce product discovery, and we need a data-driven, AI-savvy problem solver to help us, do it.   \n",
       "807                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Chicmic Studios\\nJob Role: Data Scientist\\nExperience Required: 3+ Years\\nSkills Required: Data Science, Python, Pandas, Matplotlibs\\nJob Description:\\nWe are seeking a Data Scientist with strong expertise in data analysis, machine learning, and visualization. The ideal candidate should be proficient in Python, Pandas, and Matplotlib, with experience in building and optimizing data-driven models. Some experience in Natural Language Processing (NLP) and Named Entity Recognition (NER) models would be a plus.\\nRoles & Duties:\\nAnalyze and process large datasets using Python and Pandas.\\nDevelop and optimize machine learning models for predictive analytics.\\nCreate data visualizations using Matplotlib and Seaborn to support decision-making.\\nPerform data cleaning, feature engineering, and statistical analysis.\\nWork with structured and unstructured data to extract meaningful insights.\\nImplement and fine-tune NER models for specific use cases (if required).\\nCollaborate with cross-functional teams to drive data-driven solutions\\nRequired Skills & Qualifications:\\nStrong proficiency in Python and data science libraries (Pandas, NumPy, Scikit-learn, etc.).\\nExperience in data analysis, statistical modeling, and machine learning.\\nHands-on expertise in data visualization using Matplotlib and Seaborn.\\nUnderstanding of SQL and database querying.\\nFamiliarity with NLP techniques and NER models is a plus.\\nStrong problem-solving and analytical skills.\\nContact: 9875952836\\nOffice Address: F273, Phase 8B industrial Area, Mohali, Punjab.\\nJob Type: Full-time\\nApplication Question(s):\\nWhat is your Native & Current Location?\\n*\\nWhat is your Highest Qualification?\\nWork Location: In person   \n",
       "560                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Summary\\nWe’re looking for an experienced Python professional with a strong data science foundation, especially in forecasting. You should be someone who’s confident writing clean, efficient code, understanding and improving existing codebases, and developing models that solve real-world business problems.\\nThe role involves hands-on coding, building and refining forecasting models, and collaborating with analysts and project teams to deliver data-driven solutions.\\nKey Responsibilities\\nDevelop and maintain Python code for forecasting and data modeling\\nUnderstand, review, and rewrite code written by other developers or data scientists\\nCollaborate with business teams to understand requirements and translate them into technical solutions\\nWork with historical and real-time data to improve forecast accuracy\\nDocument code logic, assumptions, and workflows clearly\\nJob Types: Full-time, Contractual / Temporary\\nContract length: 1 month\\nSchedule:\\nDay shift\\nWork Location: Remote   \n",
       "110                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Location\\nBengaluru\\nEmployment Type\\nFull time\\nLocation Type\\nOn-site\\nDepartment\\nProduct R&D\\n\\nAbout G2 - The Company\\nWhen you join G2, you’re joining the team that helps businesses reach their peak potential by powering decisions and strategies with trusted insights from real software users.   \n",
       "244                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             We are seeking a Data Science & Optimization Engineer to develop and implement advanced predictive models and optimization solutions. The ideal candidate will have expertise in predictive modeling, integer programming, Python development, and cloud-based data processing. This role will involve working with large datasets, solving complex optimization problems (e.g., bin packing, TSP), and managing cloud infrastructure for scalable solutions.\\n\\nKey Responsibilities:\\nDevelop and implement predictive models using statistical methods (e.g., Bayesian models).\\nSolve optimization problems such as bin packing, TSP, and clustering using integer programming.\\nDevelop Python-based solutions using Git/Poetry for code and library management.\\nWork with data processing libraries such as Pandas, Polars, and others.   \n",
       "743                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Educational qualifications\\nB Tech/ BE, M.Sc.(Maths) or M Tech/ MS or equivalent in Mechanical/Metallurgical/ Electrical/ Electronics/ Computer Science/Instrumentation/Industrial Engineering/Operations Research or in any other relevant discipline.\\n\\nRelevant experience (Type/ Nature and years of relevant experience required to execute the role)\\nMin. 2-4 years of experience\\n\\nLocations: Jamshedpur / Kalinga nagar / Kolkata/ Mumbai\\n\\nExperience related to advanced analytics\\nMachine learning, Deep learning, Fuzzy logic, data visualisation, statistics, Derived data analysis etc.\\nProgramming and process trouble-shooting experience will be preferred.\\nExposure to mathematical modelling will be preferred.\\nUnderstanding of statistics and statistical modelling will be required.\\nGood process knowledge related to supply chain, iron and steel manufacturing, marketing or mining/mineral processing is preferable.\\nProgramming skills using a high level language (preferably in .net environment) will be necessary.\\nKnowledge on data acquisition, analytics, statistics and other mathematical modelling tools will be useful.\\nSound concepts on Big data analytics will be helpful.\\n\\n\\nStatistics, Data analytics, Artificial intelligence, programming, system engineering and flow design, Logic building, Scenario analysis.\\nCoding in R/ Python language is Compulsory.\\n\\n\\nLearning inclination, Collaboration, Achievement orientation, change orientation   \n",
       "768                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 We are seeking a curious and analytical Data Science Intern to join our data-driven team. This internship provides a fantastic opportunity to work on real-world data projects, apply statistical methods, and gain hands-on experience with data analysis and machine learning techniques. If you’re passionate about data and eager to learn, we want to hear from you!\\nAssist in collecting, cleaning, and analyzing large datasets\\nDevelop predictive models and perform statistical analysis\\nCollaborate with team members to interpret data and generate insights\\nSupport the creation of data visualizations and reports\\nExperience preferred - 0 - 5 years\\nLocation : Mohali   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "248                        NaN  \n",
       "429                        NaN  \n",
       "266                        NaN  \n",
       "612                        NaN  \n",
       "224                        NaN  \n",
       "106                        NaN  \n",
       "566                        NaN  \n",
       "143                        NaN  \n",
       "637                        NaN  \n",
       "807                        NaN  \n",
       "560                        NaN  \n",
       "110                        NaN  \n",
       "244                        NaN  \n",
       "743                        NaN  \n",
       "768                        NaN  "
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[\n",
    "        248, 429, 266, 612, 224, 106, 566, 143, 637, 807, 560, 110, 244, 743, 768], [\n",
    "    'Company_Name', 'Company_Rating', 'Job_Title', 'Location', 'Description', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b940e7-b66a-4783-951e-a74817727785",
   "metadata": {},
   "source": [
    "- Row 248, this role requires both ML/AI skills, involves building AI agents, lets impute the salary with 10,00,000.\n",
    "- Row 429, this job posting seems to be very genuine and detailed, this is probably one of the best job posting which contains the necessary information, from analyzing the job posting lets impute the salary with 20,00,000.\n",
    "- Row 266, not enough info about the role, lets impute the salary with 5,00,000.\n",
    "- Row 612, NLP/ML developer, this role requires ML/NLP/AI skill sets and requires minimum of 4 years of education, 1-2 years of experience, lets impute the salary with 10,00,000.\n",
    "- Row 224, requires 2-4 years of experience, expertise in python, R, hadoop, java, perl the pay should be around 10,00,000.\n",
    "- Row 106, this role is for freshers and requires typical data science skill sets, the pay range would be around 7,00,000.\n",
    "- Row 566, this role requires 3+ years of experience in software development plus data science skills, the salary provided will be around 10,00,000.\n",
    "- Row 143, requires data science skills with cloud platforms expertise as well, 1-2 years of experience, lets impute the salary with 9,00,000.\n",
    "- Row 637, it is a senior level role, lets impute the salary with 12,00,000.\n",
    "- Row 807, 3+ years of experience, ideal data science role, the salary provided should be around 12,00,000.\n",
    "- Row 560, its a remote role and duration of 1 month, the role mostly involves python development, lets impute the salary with 2,40,000.\n",
    "- Row 110, lets impute the salary with 5,00,000.\n",
    "- Row 244, lets impute the salary with 7,00,000.\n",
    "- Row 743, requires 2-4 years of experience, expertise with mathematical, statistical models, the salary provided should be around 10,00,000.\n",
    "- Row 768, this is an intern role, the salary should be around 1,20,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "8763ebf3-4031-4138-8e6c-4a4b81565208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[248, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[429, 'Median_Salary_Standardized'] = 2000000\n",
    "\n",
    "df_copy.loc[266, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[612, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[224, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[106, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[566, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[143, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[637, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[807, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[560, 'Median_Salary_Standardized'] = 240000\n",
    "df_copy.loc[560, 'Intern'] = 1 \n",
    "\n",
    "df_copy.loc[110, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[244, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[743, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[768, 'Median_Salary_Standardized'] = 120000\n",
    "df_copy.loc[768, 'Intern'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "327cbe9b-9177-4422-87fd-e754efe2a4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecf9b3-6e08-4599-9b73-008b00b0320c",
   "metadata": {},
   "source": [
    "#### Imputing rows with ratings from 4.1 to 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "7747d002-1ad3-41c9-a398-09c5b26420d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Nestlé IT</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About You\\nYou are an expert in applying advanced analytics to solve marketing and sales business problems. You are equally comfortable applying your knowledge to optimize marketing spend or working with sales to optimize trade spend.\\nYou are hands-on in your ability to build models, but you are also comfortable coaching less experienced team members in how to solve problems, or managing agencies to deliver where needed.\\nYou know that having a great model isn’t enough, you love to derive the “so what” from your models and tell compelling stories which inspire action and drive growth.\\n\\nA day in the life of...\\nYou’ll be responsible for using advanced analytics to provide robust measurements of marketing &amp;amp; trade investment across different business models, product categories and\\nvaried geographies.\\nYou will work closely with your stakeholders to provide guidance on how best to optimize and allocate marketing &amp;amp; trade investments in order to support the delivery of our commercial strategy.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Meesho</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist III</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>About the Team\\n\\nOur Data Science team is the Avengers to Meesho’s S.H.I.E.L.D ️. And why not? We are the ones who assemble during the toughest challenges and devise creative solutions, building intelligent systems for millions of our users looking at a thousand different categories of products. We’ve barely scratched the surface, and have amazing challenges in charting the future of commerce for Bharat.\\n\\nOur typical day involves dealing with fraud detection, inventory optimisation, and platform vernacularisation.\\n\\nAs Data Scientist, you will navigate uncharted territories with us, discovering new paths to creating solutions for our users. You will be at the forefront of interesting challenges and solve unique customer problems in an untapped market.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>Mahindra Teqo</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Designation : Data Scientist\\nDepartment : Software\\nReporting to : Lead Data Scientist\\nGrade : M6A\\nLocation : Bangalore\\nCompany Description :\\nMahindra Teqo is a new age tech-enabled Renewable Energy Asset Management offering from the flagship Mahindra Group – A USD 21 Billion Group spread across 100+ countries. Mahindra Teqo offers complete suite of products &amp; services for streamlined asset management to help global renewable industry maximize returns from your RE assets.\\nMahindra Teqo brings to the industry cutting edge Renewable Asset Monitoring solutions, Operations &amp; Maintenance, Asset Management services and Performance analysis services with more than 6 years of experience and a total portfolio (O&amp;M + SCADA) of over 4GWp under management. We also offer leading data analytics solutions from cloud-based storage to actionable insights on how to get more out of the same Asset.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>Navikenz</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Summary:\\nWe are seeking a highly experienced Data Scientist with a strong foundation in ML/DL, experience in Computer Vision, with affinity towards upcoming technologies like Generative AI (GenAI) and Large Language Models (LLMs). The ideal candidate will lead and deploy cutting-edge AI solutions, bridging the gap between intelligent models and scalable backend architectures.\\nKey Responsibilities:\\nDesign, develop, and deploy advanced Machine Learning and Deep Learning models for business-critical use cases.\\nBuild and optimize Computer Vision pipelines using models like YOLO, EfficientNet, or Transformer-based vision architectures.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Dozee</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Overview: Dozee Health AI is a pioneer in Contactless Remote Patient Monitoring (RPM), proven to drive transformation at scale. Headquartered in Bengaluru, India, Dozee has emerged as India’s no. 1 RPM Company.\\nWe are seeking visionary individuals to help us in this very exciting journey. As a part of our dynamic team, you’ll have the opportunity to collaborate with top healthcare providers in the country, applying AI-powered RPM solutions to tackle some of the most pressing challenges in healthcare - enhancing staff efficiency, improving patient outcomes, and pioneering the next generation of care models.\\n\\nResponsibilities\\nTo initiate, develop and optimize algorithms to solve healthcare problems\\nTo ensure a constant flow of case studies/publications from acquired health datasets</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Procter &amp; Gamble</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist - Product Supply</td>\n",
       "      <td>Goa</td>\n",
       "      <td>P&amp;G was founded over 180 years ago as a simple soap and candle company. Today, we're the world’s largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but significant ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship. The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and clear, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.\\n\\nDedication from Us:\\nYou will be at core of Ground- breaking innovations, be given exciting opportunities, lead initiatives, and take charge and responsibility, in creative workspaces where new insights thrive. All the while, you'll receive outstanding training to help you become a leader in your field. What we Offer: Continuous mentorship – work with peers and receive both formal training as well as day-to-day mentoring from your manager multifaceted and encouraging work environment– employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Datamatics Financial Services</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>IT Support and Technology\\nFull Time\\nIndia\\n\\nJobs\\nData Scientist\\n\\nWe are seeking a skilled and motivated Data Engineer to join our team. The ideal candidate will be responsible for designing, implementing, and maintaining our data infrastructure to support our B2B intelligence platform.\\n\\nResponsibilities\\n\\nDesign, build, and maintain scalable data pipelines for collecting, processing, and storing large volumes of business data\\nDevelop ETL processes to integrate data from various sources, including web scraping, APIs, and third-party data providers\\nImplement data quality checks and monitoring systems to ensure data accuracy and integrity\\nOptimize data storage and retrieval processes for high performance and scalability\\nCollaborate with data scientists to implement machine learning models in production environments\\nWork with the backend team to design and implement APIs for data access\\nCollaborate with data scientists to develop and deploy machine learning models.\\nImplement data security and privacy measures to protect sensitive information.\\nStay up to date with the latest big data technologies and best practices\\n\\nRequirements\\n\\nBachelor’s or Master’s degree in Computer Science, Engineering, or a related field\\n4+ years of experience in data engineering roles\\nStrong programming skills in Python, Scala and/or Java\\nExpertise in SQL and experience with NoSQL databases (e.g., MongoDB, Cassandra)\\nProficiency with big data technologies such as Apache Spark, Hadoop, and Kafka\\nExperience with cloud platforms (AWS, GCP, or Azure) and their data services\\nFamiliarity with data warehousing concepts and ETL processes\\nExperience with data warehousing solutions (e.g., AWS Redshift, Snowflake).\\nKnowledge of data modelling, data architecture, and data pipeline design\\nExperience with version control systems (e.g., Git) and CI/CD practices\\nExcellent problem-solving skills and attention to detail\\n\\nPreferred Qualifications\\n\\nExperience in the B2B data or sales intelligence industry\\nFamiliarity with web scraping techniques and tools\\nKnowledge of data privacy regulations (e.g., GDPR, CCPA)\\nExperience with real-time data processing and streaming architectures</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Futops Technologies India Pvt. Ltd</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Job Title: Data Scientist\\nExperience: 2 to 4 Years\\nLocation: Delhi/NCR\\nIndustry: Information Technology &amp; Services\\nEmployment Type: Full-time\\nAbout the Role:\\nWe are looking for a passionate and results-driven Data Scientist to join our growing analytics and AI/ML team. The ideal candidate will bring hands-on experience in data exploration, model building, and deployment. You will work closely with cross-functional teams to deliver actionable insights and machine learning solutions that drive business value.\\nKey Responsibilities:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>Knowledge Excel</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Roles and Responsibilities:\\nDevelop and optimize machine learning models to address business problems or user needs\\nDevelop and implement recommendation engines to match buyers' needs with suitable properties.\\nDesign and deploy a conversational AI system to answer queries related to the home buying process.\\nCreate and optimize machine learning models to provide accurate price recommendations for properties\\nMany more such models\\nPrepare models for deployment in production environments, ensuring scalability and reliability.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Daydreamsoft</td>\n",
       "      <td>4.2</td>\n",
       "      <td>AI / ML / Data Scientist</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Required experience : 0-4 Years\\nJob brief\\nWe are searching for a data scientist to examine vast amounts of unstructured data in order to spot trends that may enhance our business. We will rely on you to provide data products from which we can obtain insightful business information. You should have a strong analytical mind and a talent for arithmetic, statistics, and analysis for this position. For the purpose of understanding data, critical thinking and problem-solving abilities are crucial. In addition, we look for enthusiasm for research and machine learning.\\nJob responsibilities\\nIdentify valuable data sources and automate collection processes\\nUndertake preprocessing of structured and unstructured data</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>Photon</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist-Snowflake, Python - CHN</td>\n",
       "      <td>India</td>\n",
       "      <td>Location: Bangalore\\nExperience: 6 - 9 Years\\nMust have - Snowflake/Python/AWS (atleast working with S3 storage)/Control M/DevOps for developers\\nGood to have Data modeling, problem solving skills Shall be good in communication skills/ work independently.\\nIt will be good if knows somewhat on Financial terminology. 6-9 yrs experience</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Ayruz Data Marketing</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Experience: 1 year or more\\nQualification: B-Tech, M-Tech, MSc (IT, Computer Science, Electronics Science)\\nVacancies: 02\\nDescription: We are looking for a Data Scientist who will support our product, sales, leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large datasets and working with stakeholders to improve business outcomes.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Photon</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Data Scientist - Pune</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Work Location: Pune, India\\nPosition Overview:\\nWe are seeking a talented Mid-Level Data Scientist to join our dynamic team. The ideal candidate will have a strong analytical background and the ability to translate complex data into actionable insights. This role involves collaborating with cross-functional teams to enhance our data-driven decision-making processes, particularly within the retail sector .\\nResponsibilities:\\nAnalyze large datasets to identify trends, patterns, and insights that drive business strategy.\\nDevelop and implement predictive models and statistical analyses to support decision-making.\\nConduct exploratory data analysis (EDA) to uncover meaningful insights and effectively communicate findings.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Hilabs</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>The HiLabs Story\\nHiLabs is a leading provider of AI-powered solutions to clean dirty data, unlocking its hidden potential for healthcare transformation. HiLabs is committed to transforming the healthcare industry through innovation, collaboration, and a relentless focus on improving patient outcomes.\\nHiLabs Team\\nMultidisciplinary industry leaders\\nHealthcare domain experts\\nAI/ML and data science experts\\nProfessionals hailing from the worlds best universities, business schools, and engineering institutes including Harvard, Yale, Carnegie Mellon, Duke, Georgia Tech, Indian Institute of Management (IIM), and Indian Institute of Technology (IIT).</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Numerator</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>We’re reinventing the market research industry. Let’s reinvent it together.\\nAt Numerator, we believe tomorrow’s success starts with today’s market intelligence. We empower the world’s leading brands and retailers with unmatched insights into consumer behavior and the influencers that drive it.\\nResponsibilities:\\nDeliver complex analytics projects, providing data-driven insights to address critical business challenges by analyzing disaggregated data utilizing modeling, statistics, and machine learning.\\nWork with diverse data sets to clean, manipulate, and analyze data using tools such as R, Python, and SQL\\nApply a range of statistical techniques and modeling processes to transactional and attitudinal data to help answer our clients’ business questions\\nDevelop expertise in all our analytical solutions, understanding their technical intricacies and their value to clients</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Rolling Arrays</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>(Location: India/Remote)\\nWe are seeking an experienced Data Scientist with experience in data analytics, machine learning, and statistical modeling. The ideal candidate will be proficient in data manipulation, data analysis, and have the ability to design, build, and deploy predictive models. You will work with a diverse range of stakeholders to support both operational and strategic objectives across different business domains.\\n\\nKey Responsibilities\\n\\nData Analysis &amp; Modeling\\nAnalyze large and complex datasets to identify trends, patterns, and actionable insights.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>WorldQuant</td>\n",
       "      <td>4.3</td>\n",
       "      <td>BRAIN Data Scientist</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>WorldQuant develops and deploys systematic financial strategies across a broad range of asset classes and global markets. We seek to produce high-quality predictive signals (alphas) through our proprietary research platform to employ financial strategies focused on market inefficiencies. Our teams work collaboratively to drive the production of alphas and financial strategies – the foundation of a balanced, global investment platform.\\nWorldQuant is built on a culture that pairs academic sensibility with accountability for results. Employees are encouraged to think openly about problems, balancing intellectualism and practicality. Excellent ideas come from anyone, anywhere. Employees are encouraged to challenge conventional thinking and possess an attitude of continuous improvement.\\nOur goal is to hire the best and the brightest. We value intellectual horsepower first and foremost, and people who demonstrate an outstanding talent. There is no roadmap to future success, so we need people who can help us build it.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Dicetek LLC</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Data Scientist (AI)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>We are looking for a hands-on Data Scientist with strong technical expertise and a passion for building AI-driven solutions that create real business value. In this role, you will be at the forefront of transforming business problems into scalable AI/ML models using tools such as Python, TensorFlow, PyTorch, Hugging Face, Scikit-learn, and Spark. The ideal candidate will work with structured and unstructured data, leveraging cloud platforms (e.g., Vertex AI, or Azure ML) and integrating models into production environments using MLOps frameworks like MLflow, Kubeflow, and Airflow.\\nHe will collaborate with cross-functional teams including product managers, data engineers, and domain experts to identify opportunities for AI, rapidly prototype models, and deploy solutions on a scale. A strong grasp of NLP, large language models (LLMs), and generative AI is a big plus, especially for use cases involving customer experience, automation, and intelligent decision systems.\\nThis role blends data science rigor with real-world application—perfect for someone who thrives at the intersection of innovation, technology, and business impact.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Sciffer</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Data Scientist (Audio/Speech)</td>\n",
       "      <td>India</td>\n",
       "      <td>Email us your CV at careers@sciffer.com\\nJob Descriptions:\\nResearch and implement novel approaches and models for audio and speech\\nStay up to date on industry trends and best practices\\nBreak down a complex problem into simpler elements &amp; solving them\\nKey Project Objectives - automated speech recognition (ASR), text to speech (TTS), speech to text (STT), and natural language processing (NLP)\\nQualifications:\\nGraduate in Electrical / Electronics / Computer Science Engineering with specialization in signal/speech processing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Hire IT People</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Company Description\\n\\nSynergy Tech Solutions\\n\\nJob Description\\n\\nUrgent Requirement - Data Scientist\\nPune: Baner\\nPosition: Full Time (Permanent)\\nABOUT ROLE:\\nLooking for a Data Scientist who is excited by the prospects of creating machine learning algorithms which work on billions of data points and have a direct impact on business.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>MNJ Software</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Data Science (AI &amp; Python Program Developers)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>About Us\\nEnergize your career with one of Information Technology’s fastest growing companies.\\nYou dream of a great career with a great company – where you can make an impact and help people. We dream of giving you the opportunity to do just this. And with the incredible growth of our business, it’s a dream that definitely can come true. Already one of the world’s leading IT companies, MNJ SOFTWARE is restlessly pursuing new ways to operate our service centers, improve our service levels and help people lead healthier lives. We live for the opportunity to make a difference and right now, we are living it up.\\nMNJ SOFTWARE is an IT services, business solutions and outsourcing organization that delivers real results to global businesses, ensuring a level of certainty no other firm can match.\\nMNJ SOFTWARE offers a consulting-led, integrated portfolio of IT and IT-enabled services delivered through its unique Global Network Delivery Model, recognized as the benchmark of excellence in software development.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company_Name  Company_Rating  \\\n",
       "84                            Nestlé IT             4.1   \n",
       "220                              Meesho             4.1   \n",
       "581                       Mahindra Teqo             4.1   \n",
       "657                            Navikenz             4.1   \n",
       "683                               Dozee             4.1   \n",
       "37                     Procter & Gamble             4.1   \n",
       "521       Datamatics Financial Services             4.1   \n",
       "147  Futops Technologies India Pvt. Ltd             4.2   \n",
       "608                     Knowledge Excel             4.2   \n",
       "252                        Daydreamsoft             4.2   \n",
       "487                              Photon             4.2   \n",
       "194                Ayruz Data Marketing             4.2   \n",
       "190                              Photon             4.2   \n",
       "346                              Hilabs             4.3   \n",
       "51                            Numerator             4.3   \n",
       "91                       Rolling Arrays             4.3   \n",
       "373                          WorldQuant             4.3   \n",
       "205                         Dicetek LLC             4.3   \n",
       "589                             Sciffer             4.4   \n",
       "289                      Hire IT People             4.4   \n",
       "801                        MNJ Software             4.4   \n",
       "\n",
       "                                         Job_Title   Location  \\\n",
       "84                                  Data Scientist  Bengaluru   \n",
       "220                             Data Scientist III  Bengaluru   \n",
       "581                                 Data Scientist  Bengaluru   \n",
       "657                                 Data Scientist  Bengaluru   \n",
       "683                              Data Scientist II  Bengaluru   \n",
       "37                 Data Scientist - Product Supply        Goa   \n",
       "521                                 Data Scientist      India   \n",
       "147                                 Data Scientist      Delhi   \n",
       "608                                 Data Scientist      Delhi   \n",
       "252                       AI / ML / Data Scientist    Gujarat   \n",
       "487         Data Scientist-Snowflake, Python - CHN      India   \n",
       "194                                 Data Scientist     Kerala   \n",
       "190                          Data Scientist - Pune       Pune   \n",
       "346                                 Data Scientist  Bengaluru   \n",
       "51                                  Data Scientist      India   \n",
       "91                                  Data Scientist      India   \n",
       "373                           BRAIN Data Scientist     Mumbai   \n",
       "205                            Data Scientist (AI)     Remote   \n",
       "589                  Data Scientist (Audio/Speech)      India   \n",
       "289                                 Data Scientist       Pune   \n",
       "801  Data Science (AI & Python Program Developers)     Remote   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Description  \\\n",
       "84                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          About You\\nYou are an expert in applying advanced analytics to solve marketing and sales business problems. You are equally comfortable applying your knowledge to optimize marketing spend or working with sales to optimize trade spend.\\nYou are hands-on in your ability to build models, but you are also comfortable coaching less experienced team members in how to solve problems, or managing agencies to deliver where needed.\\nYou know that having a great model isn’t enough, you love to derive the “so what” from your models and tell compelling stories which inspire action and drive growth.\\n\\nA day in the life of...\\nYou’ll be responsible for using advanced analytics to provide robust measurements of marketing &amp; trade investment across different business models, product categories and\\nvaried geographies.\\nYou will work closely with your stakeholders to provide guidance on how best to optimize and allocate marketing &amp; trade investments in order to support the delivery of our commercial strategy.   \n",
       "220                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  About the Team\\n\\nOur Data Science team is the Avengers to Meesho’s S.H.I.E.L.D ️. And why not? We are the ones who assemble during the toughest challenges and devise creative solutions, building intelligent systems for millions of our users looking at a thousand different categories of products. We’ve barely scratched the surface, and have amazing challenges in charting the future of commerce for Bharat.\\n\\nOur typical day involves dealing with fraud detection, inventory optimisation, and platform vernacularisation.\\n\\nAs Data Scientist, you will navigate uncharted territories with us, discovering new paths to creating solutions for our users. You will be at the forefront of interesting challenges and solve unique customer problems in an untapped market.   \n",
       "581                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Designation : Data Scientist\\nDepartment : Software\\nReporting to : Lead Data Scientist\\nGrade : M6A\\nLocation : Bangalore\\nCompany Description :\\nMahindra Teqo is a new age tech-enabled Renewable Energy Asset Management offering from the flagship Mahindra Group – A USD 21 Billion Group spread across 100+ countries. Mahindra Teqo offers complete suite of products & services for streamlined asset management to help global renewable industry maximize returns from your RE assets.\\nMahindra Teqo brings to the industry cutting edge Renewable Asset Monitoring solutions, Operations & Maintenance, Asset Management services and Performance analysis services with more than 6 years of experience and a total portfolio (O&M + SCADA) of over 4GWp under management. We also offer leading data analytics solutions from cloud-based storage to actionable insights on how to get more out of the same Asset.   \n",
       "657                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Job Summary:\\nWe are seeking a highly experienced Data Scientist with a strong foundation in ML/DL, experience in Computer Vision, with affinity towards upcoming technologies like Generative AI (GenAI) and Large Language Models (LLMs). The ideal candidate will lead and deploy cutting-edge AI solutions, bridging the gap between intelligent models and scalable backend architectures.\\nKey Responsibilities:\\nDesign, develop, and deploy advanced Machine Learning and Deep Learning models for business-critical use cases.\\nBuild and optimize Computer Vision pipelines using models like YOLO, EfficientNet, or Transformer-based vision architectures.   \n",
       "683                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Overview: Dozee Health AI is a pioneer in Contactless Remote Patient Monitoring (RPM), proven to drive transformation at scale. Headquartered in Bengaluru, India, Dozee has emerged as India’s no. 1 RPM Company.\\nWe are seeking visionary individuals to help us in this very exciting journey. As a part of our dynamic team, you’ll have the opportunity to collaborate with top healthcare providers in the country, applying AI-powered RPM solutions to tackle some of the most pressing challenges in healthcare - enhancing staff efficiency, improving patient outcomes, and pioneering the next generation of care models.\\n\\nResponsibilities\\nTo initiate, develop and optimize algorithms to solve healthcare problems\\nTo ensure a constant flow of case studies/publications from acquired health datasets   \n",
       "37                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  P&G was founded over 180 years ago as a simple soap and candle company. Today, we're the world’s largest consumer goods company and home to iconic, trusted brands that make life a little bit easier in small but significant ways. We've spanned three centuries thanks to three simple ideas: leadership, innovation and citizenship. The insight, innovation and passion of hardworking teams has helped us grow into a global company that is governed responsibly and ethically, that is open and clear, and that supports good causes and protects the environment. This is a place where you can be proud to work and do something that matters.\\n\\nDedication from Us:\\nYou will be at core of Ground- breaking innovations, be given exciting opportunities, lead initiatives, and take charge and responsibility, in creative workspaces where new insights thrive. All the while, you'll receive outstanding training to help you become a leader in your field. What we Offer: Continuous mentorship – work with peers and receive both formal training as well as day-to-day mentoring from your manager multifaceted and encouraging work environment– employees are at the centre, we value every individual and support initiatives, promoting agility and work/life balance.   \n",
       "521  IT Support and Technology\\nFull Time\\nIndia\\n\\nJobs\\nData Scientist\\n\\nWe are seeking a skilled and motivated Data Engineer to join our team. The ideal candidate will be responsible for designing, implementing, and maintaining our data infrastructure to support our B2B intelligence platform.\\n\\nResponsibilities\\n\\nDesign, build, and maintain scalable data pipelines for collecting, processing, and storing large volumes of business data\\nDevelop ETL processes to integrate data from various sources, including web scraping, APIs, and third-party data providers\\nImplement data quality checks and monitoring systems to ensure data accuracy and integrity\\nOptimize data storage and retrieval processes for high performance and scalability\\nCollaborate with data scientists to implement machine learning models in production environments\\nWork with the backend team to design and implement APIs for data access\\nCollaborate with data scientists to develop and deploy machine learning models.\\nImplement data security and privacy measures to protect sensitive information.\\nStay up to date with the latest big data technologies and best practices\\n\\nRequirements\\n\\nBachelor’s or Master’s degree in Computer Science, Engineering, or a related field\\n4+ years of experience in data engineering roles\\nStrong programming skills in Python, Scala and/or Java\\nExpertise in SQL and experience with NoSQL databases (e.g., MongoDB, Cassandra)\\nProficiency with big data technologies such as Apache Spark, Hadoop, and Kafka\\nExperience with cloud platforms (AWS, GCP, or Azure) and their data services\\nFamiliarity with data warehousing concepts and ETL processes\\nExperience with data warehousing solutions (e.g., AWS Redshift, Snowflake).\\nKnowledge of data modelling, data architecture, and data pipeline design\\nExperience with version control systems (e.g., Git) and CI/CD practices\\nExcellent problem-solving skills and attention to detail\\n\\nPreferred Qualifications\\n\\nExperience in the B2B data or sales intelligence industry\\nFamiliarity with web scraping techniques and tools\\nKnowledge of data privacy regulations (e.g., GDPR, CCPA)\\nExperience with real-time data processing and streaming architectures   \n",
       "147                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Job Title: Data Scientist\\nExperience: 2 to 4 Years\\nLocation: Delhi/NCR\\nIndustry: Information Technology & Services\\nEmployment Type: Full-time\\nAbout the Role:\\nWe are looking for a passionate and results-driven Data Scientist to join our growing analytics and AI/ML team. The ideal candidate will bring hands-on experience in data exploration, model building, and deployment. You will work closely with cross-functional teams to deliver actionable insights and machine learning solutions that drive business value.\\nKey Responsibilities:   \n",
       "608                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Roles and Responsibilities:\\nDevelop and optimize machine learning models to address business problems or user needs\\nDevelop and implement recommendation engines to match buyers' needs with suitable properties.\\nDesign and deploy a conversational AI system to answer queries related to the home buying process.\\nCreate and optimize machine learning models to provide accurate price recommendations for properties\\nMany more such models\\nPrepare models for deployment in production environments, ensuring scalability and reliability.   \n",
       "252                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Required experience : 0-4 Years\\nJob brief\\nWe are searching for a data scientist to examine vast amounts of unstructured data in order to spot trends that may enhance our business. We will rely on you to provide data products from which we can obtain insightful business information. You should have a strong analytical mind and a talent for arithmetic, statistics, and analysis for this position. For the purpose of understanding data, critical thinking and problem-solving abilities are crucial. In addition, we look for enthusiasm for research and machine learning.\\nJob responsibilities\\nIdentify valuable data sources and automate collection processes\\nUndertake preprocessing of structured and unstructured data   \n",
       "487                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Location: Bangalore\\nExperience: 6 - 9 Years\\nMust have - Snowflake/Python/AWS (atleast working with S3 storage)/Control M/DevOps for developers\\nGood to have Data modeling, problem solving skills Shall be good in communication skills/ work independently.\\nIt will be good if knows somewhat on Financial terminology. 6-9 yrs experience   \n",
       "194                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Experience: 1 year or more\\nQualification: B-Tech, M-Tech, MSc (IT, Computer Science, Electronics Science)\\nVacancies: 02\\nDescription: We are looking for a Data Scientist who will support our product, sales, leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large datasets and working with stakeholders to improve business outcomes.   \n",
       "190                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Work Location: Pune, India\\nPosition Overview:\\nWe are seeking a talented Mid-Level Data Scientist to join our dynamic team. The ideal candidate will have a strong analytical background and the ability to translate complex data into actionable insights. This role involves collaborating with cross-functional teams to enhance our data-driven decision-making processes, particularly within the retail sector .\\nResponsibilities:\\nAnalyze large datasets to identify trends, patterns, and insights that drive business strategy.\\nDevelop and implement predictive models and statistical analyses to support decision-making.\\nConduct exploratory data analysis (EDA) to uncover meaningful insights and effectively communicate findings.   \n",
       "346                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The HiLabs Story\\nHiLabs is a leading provider of AI-powered solutions to clean dirty data, unlocking its hidden potential for healthcare transformation. HiLabs is committed to transforming the healthcare industry through innovation, collaboration, and a relentless focus on improving patient outcomes.\\nHiLabs Team\\nMultidisciplinary industry leaders\\nHealthcare domain experts\\nAI/ML and data science experts\\nProfessionals hailing from the worlds best universities, business schools, and engineering institutes including Harvard, Yale, Carnegie Mellon, Duke, Georgia Tech, Indian Institute of Management (IIM), and Indian Institute of Technology (IIT).   \n",
       "51                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           We’re reinventing the market research industry. Let’s reinvent it together.\\nAt Numerator, we believe tomorrow’s success starts with today’s market intelligence. We empower the world’s leading brands and retailers with unmatched insights into consumer behavior and the influencers that drive it.\\nResponsibilities:\\nDeliver complex analytics projects, providing data-driven insights to address critical business challenges by analyzing disaggregated data utilizing modeling, statistics, and machine learning.\\nWork with diverse data sets to clean, manipulate, and analyze data using tools such as R, Python, and SQL\\nApply a range of statistical techniques and modeling processes to transactional and attitudinal data to help answer our clients’ business questions\\nDevelop expertise in all our analytical solutions, understanding their technical intricacies and their value to clients   \n",
       "91                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                (Location: India/Remote)\\nWe are seeking an experienced Data Scientist with experience in data analytics, machine learning, and statistical modeling. The ideal candidate will be proficient in data manipulation, data analysis, and have the ability to design, build, and deploy predictive models. You will work with a diverse range of stakeholders to support both operational and strategic objectives across different business domains.\\n\\nKey Responsibilities\\n\\nData Analysis & Modeling\\nAnalyze large and complex datasets to identify trends, patterns, and actionable insights.   \n",
       "373                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           WorldQuant develops and deploys systematic financial strategies across a broad range of asset classes and global markets. We seek to produce high-quality predictive signals (alphas) through our proprietary research platform to employ financial strategies focused on market inefficiencies. Our teams work collaboratively to drive the production of alphas and financial strategies – the foundation of a balanced, global investment platform.\\nWorldQuant is built on a culture that pairs academic sensibility with accountability for results. Employees are encouraged to think openly about problems, balancing intellectualism and practicality. Excellent ideas come from anyone, anywhere. Employees are encouraged to challenge conventional thinking and possess an attitude of continuous improvement.\\nOur goal is to hire the best and the brightest. We value intellectual horsepower first and foremost, and people who demonstrate an outstanding talent. There is no roadmap to future success, so we need people who can help us build it.   \n",
       "205                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       We are looking for a hands-on Data Scientist with strong technical expertise and a passion for building AI-driven solutions that create real business value. In this role, you will be at the forefront of transforming business problems into scalable AI/ML models using tools such as Python, TensorFlow, PyTorch, Hugging Face, Scikit-learn, and Spark. The ideal candidate will work with structured and unstructured data, leveraging cloud platforms (e.g., Vertex AI, or Azure ML) and integrating models into production environments using MLOps frameworks like MLflow, Kubeflow, and Airflow.\\nHe will collaborate with cross-functional teams including product managers, data engineers, and domain experts to identify opportunities for AI, rapidly prototype models, and deploy solutions on a scale. A strong grasp of NLP, large language models (LLMs), and generative AI is a big plus, especially for use cases involving customer experience, automation, and intelligent decision systems.\\nThis role blends data science rigor with real-world application—perfect for someone who thrives at the intersection of innovation, technology, and business impact.   \n",
       "589                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Email us your CV at careers@sciffer.com\\nJob Descriptions:\\nResearch and implement novel approaches and models for audio and speech\\nStay up to date on industry trends and best practices\\nBreak down a complex problem into simpler elements & solving them\\nKey Project Objectives - automated speech recognition (ASR), text to speech (TTS), speech to text (STT), and natural language processing (NLP)\\nQualifications:\\nGraduate in Electrical / Electronics / Computer Science Engineering with specialization in signal/speech processing   \n",
       "289                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Company Description\\n\\nSynergy Tech Solutions\\n\\nJob Description\\n\\nUrgent Requirement - Data Scientist\\nPune: Baner\\nPosition: Full Time (Permanent)\\nABOUT ROLE:\\nLooking for a Data Scientist who is excited by the prospects of creating machine learning algorithms which work on billions of data points and have a direct impact on business.   \n",
       "801                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     About Us\\nEnergize your career with one of Information Technology’s fastest growing companies.\\nYou dream of a great career with a great company – where you can make an impact and help people. We dream of giving you the opportunity to do just this. And with the incredible growth of our business, it’s a dream that definitely can come true. Already one of the world’s leading IT companies, MNJ SOFTWARE is restlessly pursuing new ways to operate our service centers, improve our service levels and help people lead healthier lives. We live for the opportunity to make a difference and right now, we are living it up.\\nMNJ SOFTWARE is an IT services, business solutions and outsourcing organization that delivers real results to global businesses, ensuring a level of certainty no other firm can match.\\nMNJ SOFTWARE offers a consulting-led, integrated portfolio of IT and IT-enabled services delivered through its unique Global Network Delivery Model, recognized as the benchmark of excellence in software development.   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "84                         NaN  \n",
       "220                        NaN  \n",
       "581                        NaN  \n",
       "657                        NaN  \n",
       "683                        NaN  \n",
       "37                         NaN  \n",
       "521                        NaN  \n",
       "147                        NaN  \n",
       "608                        NaN  \n",
       "252                        NaN  \n",
       "487                        NaN  \n",
       "194                        NaN  \n",
       "190                        NaN  \n",
       "346                        NaN  \n",
       "51                         NaN  \n",
       "91                         NaN  \n",
       "373                        NaN  \n",
       "205                        NaN  \n",
       "589                        NaN  \n",
       "289                        NaN  \n",
       "801                        NaN  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[\n",
    "    84, 220, 581, 657, 683,  37,521, 147, 608, 252, 487, 194, 190, 346,  51,  91, 373, 205, 589, 289, 801], [\n",
    "    'Company_Name', 'Company_Rating', 'Job_Title', 'Location', 'Description', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f638c5-0ec9-4a46-81e9-e77b9b09e3fb",
   "metadata": {},
   "source": [
    "- Row 84, from similar job posting, lets impute the salary with 8,00,000.\n",
    "- Row 220, row 567 with data scientist 4 has a salary of 7,00,000 and for row 220 with data scientist 3, the salary has to be higher, lets impute the salary with 10,00,000.\n",
    "- Row 581, not enough info about the role, lets impute the salary with 9,00,000, the company has higher rating.\n",
    "- Row 657, the role is an ideal data science role, lets impute the salary with 9,00,000.\n",
    "- Row 683, no info about the job, rough salary of 6,00,000.\n",
    "- Row 37, the salary should be around 6,00,000.\n",
    "- Row 521, requires 4+ years of experience, advanced skill sets including cloud platforms, lets impute the salary with 20,00,000.\n",
    "- Row 147, requires 2-4 years of experience, AI/ML skills, the salary provided should be around 8,00,000.\n",
    "- Row 608, lets impute the salary with 8,00,000.\n",
    "- Row 252, requires 0-4 years of experience so freshers are also suitable for this role, lets impute the salary with 7,00,000.\n",
    "- Row 487, requires 6-9 years of experience, advanced skill sets lets impute the salary with 40,00,000.\n",
    "- Row 194, lets impute the salary with 7,00,000.\n",
    "- Row 190, lets impute the salary with 8,00,000.\n",
    "- Row 346, lets impute the salary with 7,00,000.\n",
    "- Row 51, the salary would be 6,00,000.\n",
    "- Row 91, involves analyzing data, finding patterns, actionable insights, the ideal salary for this role would be 7,00,000.\n",
    "- Row 373, not enough info about the role, lets impute the salary with 5,00,000.\n",
    "- Row 205, requires ML/NLP/LLM/AI/Cloud platforms skill sets, lets impute the salary with 12,00,000.\n",
    "- Row 589, requires signal/speech processing degree, this role involves applying data science skills for audio/speech related tasks, lets impute the salary with 10,00,000.\n",
    "- Row 289, an ideal data science role, lets impute the salary with 9,00,000.\n",
    "- Row 801, not enough information about the role, rough salary of 6,00,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "d36e5fc9-ff7f-413c-b152-dfd36b066fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[84, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[220, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[581, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[657, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[683, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[37, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[521, 'Median_Salary_Standardized'] = 2000000\n",
    "\n",
    "df_copy.loc[147, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[608, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[252, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[487, 'Median_Salary_Standardized'] = 4000000\n",
    "\n",
    "df_copy.loc[194, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[190, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[346, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[51, 'Median_Salary_Standardized'] = 600000\n",
    "\n",
    "df_copy.loc[91, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[373, 'Median_Salary_Standardized'] = 500000\n",
    "\n",
    "df_copy.loc[205, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[589, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.loc[289, 'Median_Salary_Standardized'] = 900000\n",
    "\n",
    "df_copy.loc[801, 'Median_Salary_Standardized'] = 600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "9c171487-e663-4728-b0f5-7f86c2b6d85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afc29b-deb9-4b33-a571-7e92f7a36198",
   "metadata": {},
   "source": [
    "#### Imputing rows with ratings from 4.5 to 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "381afe92-75b6-4e3d-8931-3a2fc997b0f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Akamai</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Do you want to see your data insights directly strengthen the defenses of critical security products?\\nDo you thrive on dissecting complex data to outsmart sophisticated attackers?\\nJoin our Global Web Security group\\nOur team is part of the Application Security organization, responsible for the technologies powering Akamai's security products and protecting some of the world's major internet brands. Working in partnership with Global Services, Engineering, and Product teams we help our customers get the best protection against threat actors.\\nShape internet security\\nIn this role, you'll play a key part in strengthening security products by analyzing data, addressing customer challenges, and driving product improvements. You'll collaborate across teams to implement solutions, enhance detection accuracy, and provide insights that shape strategy and performance.\\nAs a Data Scientist, you will be responsible for:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Emgage</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Python Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Python Data Scientist/Analyst\\nA NASDAQ-listed international enterprise with a focus on both services and products for the Internet is looking for a Python Data Scientist/Analyst. The selected candidate will be responsible for writing effective, high-quality Python code to validate the efficiency of their LLM. The company has managed to single-handedly dominate the I.T. industry by establishing themselves as the leading Internet media giant.\\nJob Responsibilities:\\nEffectively communicate with researchers to grasp requirements, deliver findings, and assist the business in realizing its goals\\nDebugging programs and producing thorough documentation\\nUsing free datasets (such as Kaggle, the UN, the US government, etc.), use your data analytic skills to formulate and respond to important business issues</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>MSys Tech India</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Data Scientist / AI Architect</td>\n",
       "      <td>India</td>\n",
       "      <td>Data Scientist / AI Architect\\n10+ yrs\\nAny Location</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Agnik</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Position: Data Scientist (Intern)\\nStatus: Open\\nAGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:\\n1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing\\n2) Some Experience in Programming in C++/Java/Distributed Programming\\n3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics\\nPositions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with \"Application for Data Science Intern\" in the Subject line.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>WinZO</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>About WinZO Games\\nWinZO is India’s largest social gaming platform aiming at building an astronomical tech strong gaming ecosystem in India. WinZO in a short span of time has emerged as the leanest Series C funded gaming startup in the Indian startup ecosystem. WinZO has so far raised over $100MM and handles more than 4+ Bn micro transactions monthly, a number which is fast growing. WinZO with a data driven DNA is working towards becoming the one-stop-shop for online gaming users spread across every household in Bharat. With a vision of becoming a household name for Bharat, catering to their entertainment needs through interactive engagements, Paavan Nanda (Co-Founder, WinZO, Zostel &amp; ZO Rooms) and Saumya Singh Rathore (Co-Founder, WinZO, Ex-Chief of Staff &amp; Growth- ZO Rooms, Zostel, Ex-Times Group), are aggressively building the platform to not just capture market opportunities but also explore and maximize potential of social interactions as consumption drivers. Both of them are putting together WinZO piece by piece using tech and data to create a transparent and unique gaming experience for its users.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>TechStep</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Data Scientist (Machine Learning)</td>\n",
       "      <td>India</td>\n",
       "      <td>Data Scientist (Machine Learning). Job ID - TSKDSML100\\nBasic Qualifications\\nBE/B.Tech/ME/M.Tech in Computer Science or related field\\n2-4 years experience of building and deploying Machine Learning models, preferably in internet industry\\nSound knowledge of R, Python and different data mining tools (Advanced Excel, MySQL etc.)\\nDeep knowledge of various predictive modeling and machine learning algorithms and underlying Maths and Stats behind them\\nStrong analytical, numerical, interpersonal skills and business acumen\\nStrong technical architecture, design, deployment and operational level knowledge of AI platforms, standards, protocols and devices</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>SkillCircle</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>India</td>\n",
       "      <td>– Foundation Course – 3 Months\\n– Skill Degree Course – 4 Months\\n– Masters Course – 6 Months\\n– Diploma Course – 9 Months\\n– Foundation Course – 3 Months\\n– Skill Degree Course – 4 Months\\n– Masters Course – 6 Months\\n– Diploma Course – 9 Months\\nOnline Program</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Pricelabs</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Data Scientist (Remote)</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Preferable Location(s): Pune, India | Bengaluru, India | Delhi, India | Chennai, India | Mumbai, India | Noida, India | Gurugram, India | Hyderabad, India | Coimbatore, India\\nWork Type: Full Time\\n\\nAbout the Role: Design, develop and enhance our pricing algorithms to enable new capabilities. Process, analyse, model, and visualise findings from our market-level supply and demand data. Build and enhance internal and customer-facing dashboards to better track metrics and trends that help customers use PriceLabs in a better way. Take ownership of product ideas and design discussions. Occasional travel to conferences to interact with prospective users and partners, and learn where the industry is headed. About You: You have a minimum of two (2) years of relevant experience. Strong understanding of analysis of algorithms, data structures and statistics. Solid programming experience. Including being able to quickly prototype an idea and test it out. Strong communication skills, including the ability and willingness to explain complicated algorithms and concepts in simple terms. Experience with relational databases and strong knowledge of SQL. Prior experience working in a fast-paced environment. Willingness to wear many hats. Good to have: Experience in the vacation rental industry. Experience developing dynamic pricing models. How to apply for this position? Please fill out the form with the required details. If your profile is shortlisted, our team will reach out to you via email. If you don't find the emails in your inbox, please check your spam folder. Tip: Avoid using AI-generated responses. We want to hear from you! About PriceLabs: PriceLabs is a revenue management solution for the short-term rental and hospitality industry, founded in 2014 and headquartered in Chicago, IL. Our platform helps individual hosts and hospitality professionals optimize their pricing and revenue management, adapting to changing market trends and occupancy levels. With dynamic pricing, automation rules, and customizations, we manage pricing and minimum-stay restrictions for any portfolio size, with prices automatically uploaded to preferred channels. Every day, we price over 500,000+ listings globally across 150+ countries, offering world-class tools like the Base Price Help and Minimum Stay Recommendation Engine. In 2025, we scaled to; 500K+ properties syncing daily 60K+ customers worldwide 270+ globally remote team 36% diversity Industry awards won: SaasBoomi 2021 The Shortyz 2020 The Shortyz 2023 STRive Awards 2025 We continue to grow exponentially backed by a strong team to take us to the next level. Why join PriceLabs? We are a remote-first organization and accept work from home as the norm. Work with an industry-leading product that has thousands of customers worldwide, and our customers love the product! (NPS in the 70s, ) Work with a global team (18 countries and counting) of passionate individuals that accept open communication, empowerment, and a shared focus on customer success. We are a freemium product, so marketing leads the charge on customer acquisition. PriceLabs is an equal-opportunity employer. We are committed to providing equal opportunity in all aspects of employment. We do not discriminate based on race, colour, religious creed, national origin, ancestry, sex, age, veteran status, marital status or physical challenges.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Crypto Mize</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Data expert Jobs in Delhi at CryptoMize - Check Out data scientist job description, data scientist salary to our product, sales, leadership and marketing teams with insights gained from analyzing company data. A Data Expert is a person who works with stakeholders to enhance business outcomes by delivering solutions and identifying solutions hidden in massive data sets. He or she must be able to perfect in data mining and data analysis procedures, as well as use a number of data tools, design and execute models, use/create algorithms, and create/run simulations. for a Data Scientist job in Delhi at CryptoMize, A Conglomerate Digital Agency and Digital Privacy Company in India.\\n\\nData Scientist job Responsibilities\\n\\nCombining computer science, modeling, statistics, analytics, and math skills—along with sound business sense—data scientists uncover the answers to major questions that help organizations make objective decisions. The ability to transform a sea of data into actionable insights can have a profound impact—for predicting the best new diabetes treatment to identifying and thwarting national security threats. That’s why businesses and government agencies are rushing to hire data science professionals who can help do just that. The first step toward establishing an active data analytics platform is to collect structured and unstructured data from different sources. Unstructured data consists of things like what customers are saying about the organization on social media, while structured data is a measurable metric, such as customer lifetime value.\\n\\nA data scientist cleans and validates the data to ensure its accuracy and completeness. While AI-powered data analytics tools can automate part of this process, cleaning data still makes up the bulk of a data scientist’s job duties. Once the data is clean, the data scientist analyzes the data to identify patterns and trends using advanced statistics skills. Work throughout the organization to identify opportunities for leveraging company data to drive business solutions. Develop custom data models and algorithms to apply data sets. Strong problem solving skills with an emphasis on product development.\\n\\nAbout Us\\n\\nCryptoMize is a Conglomerate Digital Agency with presence in 3 Continents evolving for a decade, having served elite clients such as Governments, Politicians, MNCs, Celebrities and HNIs in 30+ Countries. Over the years, we have garnered and trained a team of industry experts that are capable of providing the best quality results.\\n\\n\\nDelhi\\n\\n\\nAvailable\\n\\n\\nFull time\\n\\n\\nPermanent\\n\\n\\nImmediate\\n\\n\\nBased on experience\\n\\nThe application for this opening can be submitted via the application form linked below, ONLY. Direct phone calls and emails will not be entertained.\\n\\nOur Principles\\n\\nThese are some of the principles that we strongly believe in, preach and actually follow as well.\\n\\nCommitments\\n\\nWe clearly commit what we can do, by when can we do it and how we would do it, And then we do it.\\n\\nConfidentiality\\n\\nWe are extremely paranoid about protecting the confidentiality of what we do, for whom and how we do it.\\n\\nComfortability\\n\\nWe ensure comfortability of you and your team with ours, which can only come from complete transparency.\\n\\nCapability\\n\\nWe keep improving our already awesome capabilities by investing all resources at our disposal.\\n\\nData Scientist Job\\n\\nData scientist jobs for freshers\\n\\nData Scientist Job Requirements\\n\\nData Scientist Qualification\\n\\nOur Services\\nKnow More About Us\\nPerception Perfection\\n\\nCryptoMize is dedicated to ensure a prominent progress to how the world perceives you. We help you to establish your perception to the extent of perfection with our devised strategic plan and techniques.\\n\\nPromotional Parlance\\n\\nCryptoMize introduces you to Promotional Parlance which not only promotes your cause but provides a personalized-edge. Our solutions are tailored in a strategic way that attracts the audience in a way that they are most receptive to.\\n\\nPublic Relations\\n\\nCryptoMize formulates a proactive strategy to amplify your Media Outreach without compromising your reputation. CryptoMize assists you in communicating with your intended audience to achieve a global outreach.\\n\\nPolitical Catalysis\\n\\nWe bring efficiency to governance operations through intelligence and strategic thinking. By integrating digital approaches, CryptoMize seeks to improve Campaign Strategies and governance in general.\\n\\nPolicing Phronesis\\n\\nCryptoMize, with the help of its special mix of Forensics and Consultancy, aims to handle all sorts of cyber crimes affecting your organisation and provide you with the best guidance for such situations.\\n\\nPrivacy Enforcement\\n\\nCryptoMize is driven by the belief that none of your valuable data should go unprotected. Our experts put concerted effort to preserve your privacy in order to minimize the impact of cybercrime.\\n\\nWhat Makes Us Different?\\n\\nCryptoMize offers a full spectrum of elite services derived with preemptive analysis and strategic planning to our clients. We work efficiently with our proficient and proactive team by utilising extraordinary tools.\\n\\nCollaboration with Dignitaries\\n\\nWe collaborate with highly influential and prominent personalities around the world. Being transcendental and visionary has its own benefits, our supremacy of being omnipresent empowers us to command, control and maneuver information from the internet.\\n\\n01\\nPowerful Team\\n\\nCryptoMize is the combination of a powerful team that works on a supportive, transparent and encouraging platform. With spontaneity and dedication to the advancement of technology, we aspire to be better at what we do for people who trust us with their information and projects.\\n\\n02\\nTriple-Proof Approach\\n\\nWe execute a triple-proof approach from conducting thorough research, developing strong strategies, to guaranteeing information security. This proves beneficial for our clients to reach their desired goal.\\n\\n03\\nOur Core Values\\nTrust\\n\\nWe seek to connect and build relationships with our clients.That is our core principle of our work ethic which we fully-abide to. We works on 3 principles: Respect, Honesty and Transparency.\\n\\nReliability\\n\\nCommitment is an act, not a word. We believe in delivering and living up to your expectations. We have grown into a global agency only through our commitment to deliver and our reliability factor.\\n\\nSafety\\n\\nWe are extremely paranoid about protecting our client’s safety of what we do, for whom and how we do it. We maintain absolute non disclosure and confidentiality to ensure that nothing sensitive goes out.\\n\\nPassion\\n\\nOur passion generates enthusiasm for what we do and how we do it. We inspire, find creative ways and nurture ideas with passion. We strategize based on audience attention.\\n\\nInnovation\\n\\nWe believe in innovation, change and risk taking. With technology, we reinvent ourselves. Innovation is the reason how we are able to eliminate obstacles for cultivating growth.\\n\\nExcellence\\n\\nWe ensure to maintain your eminence by reinventing ourselves with our core values that inspire excellence. We strive for quality in everything we do.\\n\\nOUR PRESENCE\\nOur Journey So Far\\nOur presence is all across the globe. Our impact can be seen in 03+ continents and 30+ countries, we know how to shape people's digital lives. We have a vast range of projects, from running political campaigns, shaping people's perceptions to enforcing privacy, we work with a futuristic approach and always look ahead of time. We never restrict ourselves to specific sectors rather make sure that our services are requisites for any and everybody in the world. With our elite clientele we show supremacy of work and build trustworthy relationships. We believe intelligence is the future and aim towards collective good and growth of all!\\n3+\\nOur Presence\\n\\nSuccessfully establishing ourselves globally in 3+ continents.\\n\\n70+\\nOur Services\\n\\nGiving us an edge over everyone else who is trying to solve similar problems.\\n\\n10+\\nYears of Experience\\n\\nServing great value to our clients since the past decade.\\n\\nNEVERENDING OPPORTUNITIES FOR YOU\\nOur Vision\\n\\nIn the days of yore, gathering intelligence was a matter of sending out spies. Today the world has changed, and intelligence is as much about technology as it is about people. We are redefining what it means to truly protect you and your business. From network security, to cloud recovery, to data recovery, CryptoMize focuses on your technology’s vulnerabilities so you can avoid pitfalls and stay ahead.\\n\\nWe have a singular vision – to be the ultimate ‘go-to’ company for digital reputation management. Our approach is holistic, covering reputation management, social media management, and crisis management.\\nWe uncover security flaws in your technology, identify new threats, and create proactive measures to protect you.\\nWe provide innovative IT solutions to clients of all sizes. Our expertise is in all levels of the information technology stack, including network architecture and cybersecurity.\\nWhy Us?\\n\\nWhy are we so amazing?\\n\\nYUMMY\\n\\nOur awesome chef prepares freshly Maison-made breakfasts, lunches, diners, beverages, coffees everyday to provide the fuel you need to innovate and Execute Best Ideas.\\n\\nEVENTS AND HACKATHONS\\n\\nWant to organize, talk or attend an event? We give you two days per month to attend or organize team-buildings, conferences, trainings, meetups or hackathons.\\n\\nCOMPANY OUTINGS\\n\\nWork hard, play hard! We have an in-house bar with a large choice of wines, beers and arcade games. Plus, we organize memorable &amp; engaging team events at least twice a month.\\n\\nFun Days\\n\\nBesides a day off, we present you with a day that is full of fun. You get to choose from a vast array of fun activities from outdoor activities to pool parties.\\n\\nFLEXIBLE EVERYTHING\\n\\nWe choose to work in a flex office environment to grow new collaborative ideas and practices. We work in small product oriented teams to focus &amp; execute faster.\\n\\nNO DIPLOMAS REQUIRED\\n\\nAt CryptoMize, we don’t care about your degrees, we only care about what you know. Your skillset will be evaluated in regard to your technical experiences and skills.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Rulesiq</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Job Description:\\nPosition Title: Data Scientist/Machine Learning Engineer\\nExperience: - Minimum 3 Years\\nLocation: Remote\\nEmployment Type: Full-Time with Rulesiq\\n\\nRole Summary\\nWe are seeking a highly skilled and versatile Data Scientist/Machine Learning Engineer to join our team. The ideal candidate will have a strong foundation in machine learning, data science, and software engineering, coupled with the ability to design and implement end-to-end systems. This role involves working with cutting-edge technologies, including LLMs, recommendation models, and NLP, while leveraging big data engineering, system design, and cloud infrastructure to deliver impactful solutions.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>ONLEI Technologies</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Data Science Trainer</td>\n",
       "      <td>Remote</td>\n",
       "      <td>As a Data Science &amp; Analytics trainer, you will be responsible for training college students , freshers and Professionals . We are looking to hire a Data Science Trainer .\\nFreshers can Apply\\nWork From Home/Office</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company_Name  Company_Rating                          Job_Title  \\\n",
       "68               Akamai             4.5                     Data Scientist   \n",
       "261              Emgage             4.5              Python Data Scientist   \n",
       "688     MSys Tech India             4.5      Data Scientist / AI Architect   \n",
       "108               Agnik             4.6                     Data Scientist   \n",
       "164               WinZO             4.7                     Data Scientist   \n",
       "432            TechStep             4.7  Data Scientist (Machine Learning)   \n",
       "761         SkillCircle             4.7                       Data Science   \n",
       "114           Pricelabs             4.7            Data Scientist (Remote)   \n",
       "126         Crypto Mize             4.8                     Data Scientist   \n",
       "165             Rulesiq             5.0                     Data Scientist   \n",
       "257  ONLEI Technologies             5.0               Data Science Trainer   \n",
       "\n",
       "    Location  \\\n",
       "68     India   \n",
       "261    India   \n",
       "688    India   \n",
       "108    India   \n",
       "164    Delhi   \n",
       "432    India   \n",
       "761    India   \n",
       "114     Pune   \n",
       "126    Delhi   \n",
       "165   Remote   \n",
       "257   Remote   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Description  \\\n",
       "68                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Do you want to see your data insights directly strengthen the defenses of critical security products?\\nDo you thrive on dissecting complex data to outsmart sophisticated attackers?\\nJoin our Global Web Security group\\nOur team is part of the Application Security organization, responsible for the technologies powering Akamai's security products and protecting some of the world's major internet brands. Working in partnership with Global Services, Engineering, and Product teams we help our customers get the best protection against threat actors.\\nShape internet security\\nIn this role, you'll play a key part in strengthening security products by analyzing data, addressing customer challenges, and driving product improvements. You'll collaborate across teams to implement solutions, enhance detection accuracy, and provide insights that shape strategy and performance.\\nAs a Data Scientist, you will be responsible for:   \n",
       "261                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Python Data Scientist/Analyst\\nA NASDAQ-listed international enterprise with a focus on both services and products for the Internet is looking for a Python Data Scientist/Analyst. The selected candidate will be responsible for writing effective, high-quality Python code to validate the efficiency of their LLM. The company has managed to single-handedly dominate the I.T. industry by establishing themselves as the leading Internet media giant.\\nJob Responsibilities:\\nEffectively communicate with researchers to grasp requirements, deliver findings, and assist the business in realizing its goals\\nDebugging programs and producing thorough documentation\\nUsing free datasets (such as Kaggle, the UN, the US government, etc.), use your data analytic skills to formulate and respond to important business issues   \n",
       "688                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Data Scientist / AI Architect\\n10+ yrs\\nAny Location   \n",
       "108                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Position: Data Scientist (Intern)\\nStatus: Open\\nAGNIK is hiring a Data Science Intern with some background in the following areas and strong motivation. Candidates must have:\\n1) Familiarity with Machine Learning, Data Mining, Statistics, and Signal Processing\\n2) Some Experience in Programming in C++/Java/Distributed Programming\\n3) Pursuing a Degree in Electrical Engineering, Math, Physics, Statistics\\nPositions do not require US citizenship but the candidates should be authorized to work in the United States. If you are interested, please send resume to jobs@agnik.com with \"Application for Data Science Intern\" in the Subject line.   \n",
       "164                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            About WinZO Games\\nWinZO is India’s largest social gaming platform aiming at building an astronomical tech strong gaming ecosystem in India. WinZO in a short span of time has emerged as the leanest Series C funded gaming startup in the Indian startup ecosystem. WinZO has so far raised over $100MM and handles more than 4+ Bn micro transactions monthly, a number which is fast growing. WinZO with a data driven DNA is working towards becoming the one-stop-shop for online gaming users spread across every household in Bharat. With a vision of becoming a household name for Bharat, catering to their entertainment needs through interactive engagements, Paavan Nanda (Co-Founder, WinZO, Zostel & ZO Rooms) and Saumya Singh Rathore (Co-Founder, WinZO, Ex-Chief of Staff & Growth- ZO Rooms, Zostel, Ex-Times Group), are aggressively building the platform to not just capture market opportunities but also explore and maximize potential of social interactions as consumption drivers. Both of them are putting together WinZO piece by piece using tech and data to create a transparent and unique gaming experience for its users.   \n",
       "432                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Data Scientist (Machine Learning). Job ID - TSKDSML100\\nBasic Qualifications\\nBE/B.Tech/ME/M.Tech in Computer Science or related field\\n2-4 years experience of building and deploying Machine Learning models, preferably in internet industry\\nSound knowledge of R, Python and different data mining tools (Advanced Excel, MySQL etc.)\\nDeep knowledge of various predictive modeling and machine learning algorithms and underlying Maths and Stats behind them\\nStrong analytical, numerical, interpersonal skills and business acumen\\nStrong technical architecture, design, deployment and operational level knowledge of AI platforms, standards, protocols and devices   \n",
       "761                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       – Foundation Course – 3 Months\\n– Skill Degree Course – 4 Months\\n– Masters Course – 6 Months\\n– Diploma Course – 9 Months\\n– Foundation Course – 3 Months\\n– Skill Degree Course – 4 Months\\n– Masters Course – 6 Months\\n– Diploma Course – 9 Months\\nOnline Program   \n",
       "114                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Preferable Location(s): Pune, India | Bengaluru, India | Delhi, India | Chennai, India | Mumbai, India | Noida, India | Gurugram, India | Hyderabad, India | Coimbatore, India\\nWork Type: Full Time\\n\\nAbout the Role: Design, develop and enhance our pricing algorithms to enable new capabilities. Process, analyse, model, and visualise findings from our market-level supply and demand data. Build and enhance internal and customer-facing dashboards to better track metrics and trends that help customers use PriceLabs in a better way. Take ownership of product ideas and design discussions. Occasional travel to conferences to interact with prospective users and partners, and learn where the industry is headed. About You: You have a minimum of two (2) years of relevant experience. Strong understanding of analysis of algorithms, data structures and statistics. Solid programming experience. Including being able to quickly prototype an idea and test it out. Strong communication skills, including the ability and willingness to explain complicated algorithms and concepts in simple terms. Experience with relational databases and strong knowledge of SQL. Prior experience working in a fast-paced environment. Willingness to wear many hats. Good to have: Experience in the vacation rental industry. Experience developing dynamic pricing models. How to apply for this position? Please fill out the form with the required details. If your profile is shortlisted, our team will reach out to you via email. If you don't find the emails in your inbox, please check your spam folder. Tip: Avoid using AI-generated responses. We want to hear from you! About PriceLabs: PriceLabs is a revenue management solution for the short-term rental and hospitality industry, founded in 2014 and headquartered in Chicago, IL. Our platform helps individual hosts and hospitality professionals optimize their pricing and revenue management, adapting to changing market trends and occupancy levels. With dynamic pricing, automation rules, and customizations, we manage pricing and minimum-stay restrictions for any portfolio size, with prices automatically uploaded to preferred channels. Every day, we price over 500,000+ listings globally across 150+ countries, offering world-class tools like the Base Price Help and Minimum Stay Recommendation Engine. In 2025, we scaled to; 500K+ properties syncing daily 60K+ customers worldwide 270+ globally remote team 36% diversity Industry awards won: SaasBoomi 2021 The Shortyz 2020 The Shortyz 2023 STRive Awards 2025 We continue to grow exponentially backed by a strong team to take us to the next level. Why join PriceLabs? We are a remote-first organization and accept work from home as the norm. Work with an industry-leading product that has thousands of customers worldwide, and our customers love the product! (NPS in the 70s, ) Work with a global team (18 countries and counting) of passionate individuals that accept open communication, empowerment, and a shared focus on customer success. We are a freemium product, so marketing leads the charge on customer acquisition. PriceLabs is an equal-opportunity employer. We are committed to providing equal opportunity in all aspects of employment. We do not discriminate based on race, colour, religious creed, national origin, ancestry, sex, age, veteran status, marital status or physical challenges.   \n",
       "126  Data expert Jobs in Delhi at CryptoMize - Check Out data scientist job description, data scientist salary to our product, sales, leadership and marketing teams with insights gained from analyzing company data. A Data Expert is a person who works with stakeholders to enhance business outcomes by delivering solutions and identifying solutions hidden in massive data sets. He or she must be able to perfect in data mining and data analysis procedures, as well as use a number of data tools, design and execute models, use/create algorithms, and create/run simulations. for a Data Scientist job in Delhi at CryptoMize, A Conglomerate Digital Agency and Digital Privacy Company in India.\\n\\nData Scientist job Responsibilities\\n\\nCombining computer science, modeling, statistics, analytics, and math skills—along with sound business sense—data scientists uncover the answers to major questions that help organizations make objective decisions. The ability to transform a sea of data into actionable insights can have a profound impact—for predicting the best new diabetes treatment to identifying and thwarting national security threats. That’s why businesses and government agencies are rushing to hire data science professionals who can help do just that. The first step toward establishing an active data analytics platform is to collect structured and unstructured data from different sources. Unstructured data consists of things like what customers are saying about the organization on social media, while structured data is a measurable metric, such as customer lifetime value.\\n\\nA data scientist cleans and validates the data to ensure its accuracy and completeness. While AI-powered data analytics tools can automate part of this process, cleaning data still makes up the bulk of a data scientist’s job duties. Once the data is clean, the data scientist analyzes the data to identify patterns and trends using advanced statistics skills. Work throughout the organization to identify opportunities for leveraging company data to drive business solutions. Develop custom data models and algorithms to apply data sets. Strong problem solving skills with an emphasis on product development.\\n\\nAbout Us\\n\\nCryptoMize is a Conglomerate Digital Agency with presence in 3 Continents evolving for a decade, having served elite clients such as Governments, Politicians, MNCs, Celebrities and HNIs in 30+ Countries. Over the years, we have garnered and trained a team of industry experts that are capable of providing the best quality results.\\n\\n\\nDelhi\\n\\n\\nAvailable\\n\\n\\nFull time\\n\\n\\nPermanent\\n\\n\\nImmediate\\n\\n\\nBased on experience\\n\\nThe application for this opening can be submitted via the application form linked below, ONLY. Direct phone calls and emails will not be entertained.\\n\\nOur Principles\\n\\nThese are some of the principles that we strongly believe in, preach and actually follow as well.\\n\\nCommitments\\n\\nWe clearly commit what we can do, by when can we do it and how we would do it, And then we do it.\\n\\nConfidentiality\\n\\nWe are extremely paranoid about protecting the confidentiality of what we do, for whom and how we do it.\\n\\nComfortability\\n\\nWe ensure comfortability of you and your team with ours, which can only come from complete transparency.\\n\\nCapability\\n\\nWe keep improving our already awesome capabilities by investing all resources at our disposal.\\n\\nData Scientist Job\\n\\nData scientist jobs for freshers\\n\\nData Scientist Job Requirements\\n\\nData Scientist Qualification\\n\\nOur Services\\nKnow More About Us\\nPerception Perfection\\n\\nCryptoMize is dedicated to ensure a prominent progress to how the world perceives you. We help you to establish your perception to the extent of perfection with our devised strategic plan and techniques.\\n\\nPromotional Parlance\\n\\nCryptoMize introduces you to Promotional Parlance which not only promotes your cause but provides a personalized-edge. Our solutions are tailored in a strategic way that attracts the audience in a way that they are most receptive to.\\n\\nPublic Relations\\n\\nCryptoMize formulates a proactive strategy to amplify your Media Outreach without compromising your reputation. CryptoMize assists you in communicating with your intended audience to achieve a global outreach.\\n\\nPolitical Catalysis\\n\\nWe bring efficiency to governance operations through intelligence and strategic thinking. By integrating digital approaches, CryptoMize seeks to improve Campaign Strategies and governance in general.\\n\\nPolicing Phronesis\\n\\nCryptoMize, with the help of its special mix of Forensics and Consultancy, aims to handle all sorts of cyber crimes affecting your organisation and provide you with the best guidance for such situations.\\n\\nPrivacy Enforcement\\n\\nCryptoMize is driven by the belief that none of your valuable data should go unprotected. Our experts put concerted effort to preserve your privacy in order to minimize the impact of cybercrime.\\n\\nWhat Makes Us Different?\\n\\nCryptoMize offers a full spectrum of elite services derived with preemptive analysis and strategic planning to our clients. We work efficiently with our proficient and proactive team by utilising extraordinary tools.\\n\\nCollaboration with Dignitaries\\n\\nWe collaborate with highly influential and prominent personalities around the world. Being transcendental and visionary has its own benefits, our supremacy of being omnipresent empowers us to command, control and maneuver information from the internet.\\n\\n01\\nPowerful Team\\n\\nCryptoMize is the combination of a powerful team that works on a supportive, transparent and encouraging platform. With spontaneity and dedication to the advancement of technology, we aspire to be better at what we do for people who trust us with their information and projects.\\n\\n02\\nTriple-Proof Approach\\n\\nWe execute a triple-proof approach from conducting thorough research, developing strong strategies, to guaranteeing information security. This proves beneficial for our clients to reach their desired goal.\\n\\n03\\nOur Core Values\\nTrust\\n\\nWe seek to connect and build relationships with our clients.That is our core principle of our work ethic which we fully-abide to. We works on 3 principles: Respect, Honesty and Transparency.\\n\\nReliability\\n\\nCommitment is an act, not a word. We believe in delivering and living up to your expectations. We have grown into a global agency only through our commitment to deliver and our reliability factor.\\n\\nSafety\\n\\nWe are extremely paranoid about protecting our client’s safety of what we do, for whom and how we do it. We maintain absolute non disclosure and confidentiality to ensure that nothing sensitive goes out.\\n\\nPassion\\n\\nOur passion generates enthusiasm for what we do and how we do it. We inspire, find creative ways and nurture ideas with passion. We strategize based on audience attention.\\n\\nInnovation\\n\\nWe believe in innovation, change and risk taking. With technology, we reinvent ourselves. Innovation is the reason how we are able to eliminate obstacles for cultivating growth.\\n\\nExcellence\\n\\nWe ensure to maintain your eminence by reinventing ourselves with our core values that inspire excellence. We strive for quality in everything we do.\\n\\nOUR PRESENCE\\nOur Journey So Far\\nOur presence is all across the globe. Our impact can be seen in 03+ continents and 30+ countries, we know how to shape people's digital lives. We have a vast range of projects, from running political campaigns, shaping people's perceptions to enforcing privacy, we work with a futuristic approach and always look ahead of time. We never restrict ourselves to specific sectors rather make sure that our services are requisites for any and everybody in the world. With our elite clientele we show supremacy of work and build trustworthy relationships. We believe intelligence is the future and aim towards collective good and growth of all!\\n3+\\nOur Presence\\n\\nSuccessfully establishing ourselves globally in 3+ continents.\\n\\n70+\\nOur Services\\n\\nGiving us an edge over everyone else who is trying to solve similar problems.\\n\\n10+\\nYears of Experience\\n\\nServing great value to our clients since the past decade.\\n\\nNEVERENDING OPPORTUNITIES FOR YOU\\nOur Vision\\n\\nIn the days of yore, gathering intelligence was a matter of sending out spies. Today the world has changed, and intelligence is as much about technology as it is about people. We are redefining what it means to truly protect you and your business. From network security, to cloud recovery, to data recovery, CryptoMize focuses on your technology’s vulnerabilities so you can avoid pitfalls and stay ahead.\\n\\nWe have a singular vision – to be the ultimate ‘go-to’ company for digital reputation management. Our approach is holistic, covering reputation management, social media management, and crisis management.\\nWe uncover security flaws in your technology, identify new threats, and create proactive measures to protect you.\\nWe provide innovative IT solutions to clients of all sizes. Our expertise is in all levels of the information technology stack, including network architecture and cybersecurity.\\nWhy Us?\\n\\nWhy are we so amazing?\\n\\nYUMMY\\n\\nOur awesome chef prepares freshly Maison-made breakfasts, lunches, diners, beverages, coffees everyday to provide the fuel you need to innovate and Execute Best Ideas.\\n\\nEVENTS AND HACKATHONS\\n\\nWant to organize, talk or attend an event? We give you two days per month to attend or organize team-buildings, conferences, trainings, meetups or hackathons.\\n\\nCOMPANY OUTINGS\\n\\nWork hard, play hard! We have an in-house bar with a large choice of wines, beers and arcade games. Plus, we organize memorable & engaging team events at least twice a month.\\n\\nFun Days\\n\\nBesides a day off, we present you with a day that is full of fun. You get to choose from a vast array of fun activities from outdoor activities to pool parties.\\n\\nFLEXIBLE EVERYTHING\\n\\nWe choose to work in a flex office environment to grow new collaborative ideas and practices. We work in small product oriented teams to focus & execute faster.\\n\\nNO DIPLOMAS REQUIRED\\n\\nAt CryptoMize, we don’t care about your degrees, we only care about what you know. Your skillset will be evaluated in regard to your technical experiences and skills.   \n",
       "165                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Job Description:\\nPosition Title: Data Scientist/Machine Learning Engineer\\nExperience: - Minimum 3 Years\\nLocation: Remote\\nEmployment Type: Full-Time with Rulesiq\\n\\nRole Summary\\nWe are seeking a highly skilled and versatile Data Scientist/Machine Learning Engineer to join our team. The ideal candidate will have a strong foundation in machine learning, data science, and software engineering, coupled with the ability to design and implement end-to-end systems. This role involves working with cutting-edge technologies, including LLMs, recommendation models, and NLP, while leveraging big data engineering, system design, and cloud infrastructure to deliver impactful solutions.   \n",
       "257                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       As a Data Science & Analytics trainer, you will be responsible for training college students , freshers and Professionals . We are looking to hire a Data Science Trainer .\\nFreshers can Apply\\nWork From Home/Office   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "68                         NaN  \n",
       "261                        NaN  \n",
       "688                        NaN  \n",
       "108                        NaN  \n",
       "164                        NaN  \n",
       "432                        NaN  \n",
       "761                        NaN  \n",
       "114                        NaN  \n",
       "126                        NaN  \n",
       "165                        NaN  \n",
       "257                        NaN  "
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[\n",
    "    68, 261, 688, 108, 164, 432, 761, 114, 126, 165, 257\n",
    "], [\n",
    "    'Company_Name', 'Company_Rating', 'Job_Title', 'Location', 'Description', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a081e-0fc6-4539-b802-5870c2839231",
   "metadata": {},
   "source": [
    "- Row 68, not enough information about the role, rough salary of 8,00,000.\n",
    "- Row 261, requires python and LLM skills, lets impute the salary with 10,00,000.\n",
    "- Row 688, not enough info about anything, let just drop the row.\n",
    "- Row 108, it is an intern role, the location of the role is US, but the duration of the contract is not mentioned, its safe to drop this row.\n",
    "- Row 164, there is no info about the role, the company is a gaming platform worth millions of dollars, the pay should be good, lets impute the salary with 12,00,000.\n",
    "- Row 432, requires 2-4 years of experience, lets impute the salary with 8,00,000.\n",
    "- Row 761, this posting doesn't exactly look like a job posting, its more like a online program/course, which is irrelevant for us, so lets remove this row.\n",
    "- Row 114, requires min 2 years of experience, strong knowledge in ML algorithms/ data structures, statistics, databases (sql), it is a remote role as well, lets impute the salary with 10,00,000.\n",
    "- Row 126, drop the row as it doesn't contain any information about the role.\n",
    "- Row 165, requires min 3 years of experience, should be skilled in machine learning, data science, software engineering, LLMs, NLPs, cloud platforms, lets impute the salary with 12,00,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "917f0868-5948-4cd3-82ca-6a7cdfac1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[68, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[261, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.drop([688, 108], axis=0, inplace=True)\n",
    "\n",
    "df_copy.loc[164, 'Median_Salary_Standardized'] = 1200000\n",
    "\n",
    "df_copy.loc[432, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.drop(761, axis=0, inplace=True)\n",
    "\n",
    "df_copy.loc[114, 'Median_Salary_Standardized'] = 1000000\n",
    "\n",
    "df_copy.drop(126, axis=0, inplace=True)\n",
    "\n",
    "df_copy.loc[165, 'Median_Salary_Standardized'] = 1200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "2b9e6417-630d-4cb1-9587-9b44c38ef330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "dd2e63d4-1796-47c8-a186-224812c7d1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>ONLEI Technologies</td>\n",
       "      <td>Data Science Trainer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Excelencia Itech Consulting Pvt Ltd</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Data &amp; AI Solution Architecture</td>\n",
       "      <td>4.1</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>Elfonze Technologies</td>\n",
       "      <td>Gen AI</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Head of Practice, Data and AI</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>LARVOL</td>\n",
       "      <td>AI Developer - Predictive Modeling (Independent Contractor, 100% Remote)</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Application Square Infotech Pvt Ltd</td>\n",
       "      <td>AI AND ML TRAINEE</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>Dicetek LLC</td>\n",
       "      <td>Data Engineers and Data Scientists</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name  \\\n",
       "257                   ONLEI Technologies   \n",
       "490  Excelencia Itech Consulting Pvt Ltd   \n",
       "533                            Microsoft   \n",
       "629                 Elfonze Technologies   \n",
       "641                          Bosch Group   \n",
       "693                               LARVOL   \n",
       "738  Application Square Infotech Pvt Ltd   \n",
       "815                          Dicetek LLC   \n",
       "\n",
       "                                                                    Job_Title  \\\n",
       "257                                                      Data Science Trainer   \n",
       "490                                                              Statistician   \n",
       "533                                           Data & AI Solution Architecture   \n",
       "629                                                                    Gen AI   \n",
       "641                                             Head of Practice, Data and AI   \n",
       "693  AI Developer - Predictive Modeling (Independent Contractor, 100% Remote)   \n",
       "738                                                         AI AND ML TRAINEE   \n",
       "815                                        Data Engineers and Data Scientists   \n",
       "\n",
       "     Company_Rating   Location Salary_Range Median_Salary  \\\n",
       "257             5.0     Remote         None           NaN   \n",
       "490             4.2    Chennai         None           NaN   \n",
       "533             4.1      India         None           NaN   \n",
       "629             4.9     Remote         None           NaN   \n",
       "641             4.1  Bengaluru         None           NaN   \n",
       "693             3.4     Remote         None           NaN   \n",
       "738             3.9      India         None           NaN   \n",
       "815             4.3     Remote         None           NaN   \n",
       "\n",
       "    Median_Salary_Standardized  \n",
       "257                        NaN  \n",
       "490                        NaN  \n",
       "533                        NaN  \n",
       "629                        NaN  \n",
       "641                        NaN  \n",
       "693                        NaN  \n",
       "738                        NaN  \n",
       "815                        NaN  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna()][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Salary_Range', 'Median_Salary', 'Median_Salary_Standardized'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "124ed289-0e3c-4cbf-99c2-d78df2740536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([257, 490, 533, 629, 641, 693, 738, 815], dtype='int64')"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna()][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location'\n",
    "]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "fe0928bf-48dd-4a3b-a3c4-470676806fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>ONLEI Technologies</td>\n",
       "      <td>Data Science Trainer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Remote</td>\n",
       "      <td>As a Data Science &amp; Analytics trainer, you will be responsible for training college students , freshers and Professionals . We are looking to hire a Data Science Trainer .\\nFreshers can Apply\\nWork From Home/Office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Excelencia Itech Consulting Pvt Ltd</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Job Information\\nJob Type\\nPermanent\\nDate Opened\\n06/24/2025\\nWork Shift\\nMST\\nWork Experience\\n1 -3 years\\nIndustry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Data &amp; AI Solution Architecture</td>\n",
       "      <td>4.1</td>\n",
       "      <td>India</td>\n",
       "      <td>Data &amp; AI Solution Architecture\\nMultiple Locations, India\\n\\nDate posted\\nJul 14, 2025\\nJob number\\n1838477\\nWork site\\nUp to 50% work from home\\nTravel\\n25-50 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>Elfonze Technologies</td>\n",
       "      <td>Gen AI</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Job Information\\nDate Opened\\n07/08/2025\\nJob Type\\nFull time\\nIndustry\\nIT Services\\nRemote Job\\nJob Description\\nThis is a remote position.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Head of Practice, Data and AI</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Company Description\\n\\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 28,200+ associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\\n\\nJob Description\\n\\nJob Description Multi-Market engineering unit of BGSW provides services to Bosch consumer goods, industry, healthcare and energy business units and Global customers. Multi-Market unit hosts robust engineering capabilities and strong technology horizontals like Data and AI, Applications lifecycle and Value streams solutions. The Data and AI Practice within BGSW comprises of distinctive sub-practices with Global P&amp;L responsibilities:AI/ML Services and software Platform development on MLOps, Responsible AI and their GTM forays for Bosch Group and Its customers.Be the delivery units for GenAI program house for GenAI based Engg Efficiency, Customer experience and Engg design topics across Multi Market Engineering UnitsAI/ML offerings to Global Clientele in Service-Delivery model ( in the areas of AI/ML, GenAI, MLOps, Responsible AI, Gen AI for Engg, Hyper Automation , Conversational AI and Agentic AI )Data Engineering \"font-size:10.0pt;font-family:Arial\"&gt;offerings to Bosch and Global Clientele in Service-Delivery modelBring in Innovative end-to-end business solutions using advanced Data Science techniques, to unlock previously unknown, but meaningful, business relationships allowing clients to significantly improve profitability through more informed insights. Job Description Key responsibilities:People Leadership: Lead and manage a team and support their professional development. Foster a collaborative and productive team environment. Managing team targets and goals in line with a practice plan. Technical Leadership:Provide guidance and leadership in the development of embedded software and validation projects.Mentor team, providing support and knowledge transfer to enhance team capabilities.Stay updated on industry trends, emerging technologies, and best practices in embedded systems design.Enhance efficiency and productivity by implementing and improving engineering processes, workflows, and methodologies. Delivery Management:Manage the project lifecycle to ensure timely, high-quality deliverables.Ensuring projects are adequately staffed and deliver high-quality work.Ensure the delivery of high-quality services that meet customer expectations and project requirements.Implement quality assurance processes, conduct regular reviews, and address any quality issues or deviations. Thought Leadership:Develop and oversee the technical roadmap for the practice area, ensuring alignment with overall business goals.Drive innovation by identifying and developing assets, solutions and IP’s that align with organization’s needs.Remain at the forefront of innovation by staying updated on industry advancements. QualificationsBachelors / Master’s degree in Engineering, preferably with an MBA18+ years’ experience in leading Engineering IT teamsStrong delivery management experience with PMP certificationExperience working in complex, ambiguous environments with cross-functional teamsProven experience in productionizing AI/ML/NLP/CV projectsWillingness to keep up to date with latest industry tech trends on AI/ML and other niche technologies. Research mindset to understand upcoming trends and technologies and challenge the status quo.Providing thought leadership to develop and productionalize new operating model for the services of AI/ML, GenAI, MLOps, Responsible AI, Hyper Automation and Conversational AI .Possess strong interpersonal, com Qualifications Educational qualification: Bachelors / Master’s degree in Engineering, preferably with an MBA Experience : 18+ years Mandatory/requires Skills : Program Management,Project cost management,Product Life Cycle Management,Project Risk Management,Project Portfolio Management,Requirement Management,Resource Management,Risk Management,Task Force Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>LARVOL</td>\n",
       "      <td>AI Developer - Predictive Modeling (Independent Contractor, 100% Remote)</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Key Responsibilities:\\nDesign, develop, and deploy AI models for predictive analytics.\\nBuild and optimize machine learning models for tasks like classification, forecasting, and risk prediction.\\nPreprocess and clean data to improve model accuracy and efficiency.\\nExperiment with different feature engineering techniques to enhance predictions.\\nMonitor model performance and fine-tune parameters to improve results.\\nQualifications:\\n1+ years of experience in AI development or machine learning.\\nProficiency in Python and experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Application Square Infotech Pvt Ltd</td>\n",
       "      <td>AI AND ML TRAINEE</td>\n",
       "      <td>3.9</td>\n",
       "      <td>India</td>\n",
       "      <td>Role Summary:\\nWe are looking for an enthusiastic AI/ML Trainee to join our team and assist in developing, testing, and deploying machine learning models. The ideal candidate should have a strong academic background in computer science, data science, or related fields, with basic knowledge of AI/ML concepts and programming.\\nKey Responsibilities:\\nAssist in data collection, cleaning, and preprocessing\\nBuild and test machine learning models under supervision\\nAnalyze model performance and suggest improvements\\nWork with Python and ML libraries (e.g., scikit-learn, TensorFlow, PyTorch)\\nDocument experiments, findings, and processes\\nCollaborate with team members on AI/ML projects\\nRequirements:\\nBachelor’s degree (or pursuing final year) in Computer Science, Data Science, Mathematics, or related field\\nBasic knowledge of machine learning algorithms and data science concepts\\nProgramming skills in Python or R\\nFamiliarity with data analysis and visualization tools\\nEagerness to learn and explore new AI/ML technologies\\nGood problem-solving and communication skills\\nNice to Have:\\nExperience with deep learning frameworks (TensorFlow, PyTorch, Keras)\\nKnowledge of SQL and cloud platforms (AWS, GCP, Azure)\\nParticipation in AI/ML competitions or personal projects\\nExperiance - 1 to 2 year\\nJob Type: Full-time\\nSchedule:\\nDay shift\\nMonday to Friday\\nMorning shift\\nWeekend availability\\nWork Location: In person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>Dicetek LLC</td>\n",
       "      <td>Data Engineers and Data Scientists</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Python/Spark based Data Engineers and Data Scientists with Min Work Experience 7-10 Years\\nPrevious experience 7-10+ as a big data engineer.\\nIn-depth knowledge of Hadoop (Cloudera), Spark, and similar frameworks.\\nGood knowledge of Big Data querying tools, such as Pig, Hive, and Impala\\nKnowledge of scripting languages including Java, C++, Linux, Ruby, PHP, Python, and R.\\nOwn most deliverables for the Big Data team from a delivery perspective.\\nAbility to solve complex networking, data, and software issues.\\nAble to Effectively Plan &amp; Organize Their Work\\nStrong Interpersonal Communication\\nAssist others in the completion of their tasks to support the group goals.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company_Name  \\\n",
       "257                   ONLEI Technologies   \n",
       "490  Excelencia Itech Consulting Pvt Ltd   \n",
       "533                            Microsoft   \n",
       "629                 Elfonze Technologies   \n",
       "641                          Bosch Group   \n",
       "693                               LARVOL   \n",
       "738  Application Square Infotech Pvt Ltd   \n",
       "815                          Dicetek LLC   \n",
       "\n",
       "                                                                    Job_Title  \\\n",
       "257                                                      Data Science Trainer   \n",
       "490                                                              Statistician   \n",
       "533                                           Data & AI Solution Architecture   \n",
       "629                                                                    Gen AI   \n",
       "641                                             Head of Practice, Data and AI   \n",
       "693  AI Developer - Predictive Modeling (Independent Contractor, 100% Remote)   \n",
       "738                                                         AI AND ML TRAINEE   \n",
       "815                                        Data Engineers and Data Scientists   \n",
       "\n",
       "     Company_Rating   Location  \\\n",
       "257             5.0     Remote   \n",
       "490             4.2    Chennai   \n",
       "533             4.1      India   \n",
       "629             4.9     Remote   \n",
       "641             4.1  Bengaluru   \n",
       "693             3.4     Remote   \n",
       "738             3.9      India   \n",
       "815             4.3     Remote   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Description  \n",
       "257                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            As a Data Science & Analytics trainer, you will be responsible for training college students , freshers and Professionals . We are looking to hire a Data Science Trainer .\\nFreshers can Apply\\nWork From Home/Office  \n",
       "490                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Job Information\\nJob Type\\nPermanent\\nDate Opened\\n06/24/2025\\nWork Shift\\nMST\\nWork Experience\\n1 -3 years\\nIndustry  \n",
       "533                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Data & AI Solution Architecture\\nMultiple Locations, India\\n\\nDate posted\\nJul 14, 2025\\nJob number\\n1838477\\nWork site\\nUp to 50% work from home\\nTravel\\n25-50 %  \n",
       "629                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Job Information\\nDate Opened\\n07/08/2025\\nJob Type\\nFull time\\nIndustry\\nIT Services\\nRemote Job\\nJob Description\\nThis is a remote position.  \n",
       "641  Company Description\\n\\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 28,200+ associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\\n\\nJob Description\\n\\nJob Description Multi-Market engineering unit of BGSW provides services to Bosch consumer goods, industry, healthcare and energy business units and Global customers. Multi-Market unit hosts robust engineering capabilities and strong technology horizontals like Data and AI, Applications lifecycle and Value streams solutions. The Data and AI Practice within BGSW comprises of distinctive sub-practices with Global P&L responsibilities:AI/ML Services and software Platform development on MLOps, Responsible AI and their GTM forays for Bosch Group and Its customers.Be the delivery units for GenAI program house for GenAI based Engg Efficiency, Customer experience and Engg design topics across Multi Market Engineering UnitsAI/ML offerings to Global Clientele in Service-Delivery model ( in the areas of AI/ML, GenAI, MLOps, Responsible AI, Gen AI for Engg, Hyper Automation , Conversational AI and Agentic AI )Data Engineering \"font-size:10.0pt;font-family:Arial\">offerings to Bosch and Global Clientele in Service-Delivery modelBring in Innovative end-to-end business solutions using advanced Data Science techniques, to unlock previously unknown, but meaningful, business relationships allowing clients to significantly improve profitability through more informed insights. Job Description Key responsibilities:People Leadership: Lead and manage a team and support their professional development. Foster a collaborative and productive team environment. Managing team targets and goals in line with a practice plan. Technical Leadership:Provide guidance and leadership in the development of embedded software and validation projects.Mentor team, providing support and knowledge transfer to enhance team capabilities.Stay updated on industry trends, emerging technologies, and best practices in embedded systems design.Enhance efficiency and productivity by implementing and improving engineering processes, workflows, and methodologies. Delivery Management:Manage the project lifecycle to ensure timely, high-quality deliverables.Ensuring projects are adequately staffed and deliver high-quality work.Ensure the delivery of high-quality services that meet customer expectations and project requirements.Implement quality assurance processes, conduct regular reviews, and address any quality issues or deviations. Thought Leadership:Develop and oversee the technical roadmap for the practice area, ensuring alignment with overall business goals.Drive innovation by identifying and developing assets, solutions and IP’s that align with organization’s needs.Remain at the forefront of innovation by staying updated on industry advancements. QualificationsBachelors / Master’s degree in Engineering, preferably with an MBA18+ years’ experience in leading Engineering IT teamsStrong delivery management experience with PMP certificationExperience working in complex, ambiguous environments with cross-functional teamsProven experience in productionizing AI/ML/NLP/CV projectsWillingness to keep up to date with latest industry tech trends on AI/ML and other niche technologies. Research mindset to understand upcoming trends and technologies and challenge the status quo.Providing thought leadership to develop and productionalize new operating model for the services of AI/ML, GenAI, MLOps, Responsible AI, Hyper Automation and Conversational AI .Possess strong interpersonal, com Qualifications Educational qualification: Bachelors / Master’s degree in Engineering, preferably with an MBA Experience : 18+ years Mandatory/requires Skills : Program Management,Project cost management,Product Life Cycle Management,Project Risk Management,Project Portfolio Management,Requirement Management,Resource Management,Risk Management,Task Force Management  \n",
       "693                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Key Responsibilities:\\nDesign, develop, and deploy AI models for predictive analytics.\\nBuild and optimize machine learning models for tasks like classification, forecasting, and risk prediction.\\nPreprocess and clean data to improve model accuracy and efficiency.\\nExperiment with different feature engineering techniques to enhance predictions.\\nMonitor model performance and fine-tune parameters to improve results.\\nQualifications:\\n1+ years of experience in AI development or machine learning.\\nProficiency in Python and experience with machine learning libraries such as TensorFlow, PyTorch, or scikit-learn.  \n",
       "738                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Role Summary:\\nWe are looking for an enthusiastic AI/ML Trainee to join our team and assist in developing, testing, and deploying machine learning models. The ideal candidate should have a strong academic background in computer science, data science, or related fields, with basic knowledge of AI/ML concepts and programming.\\nKey Responsibilities:\\nAssist in data collection, cleaning, and preprocessing\\nBuild and test machine learning models under supervision\\nAnalyze model performance and suggest improvements\\nWork with Python and ML libraries (e.g., scikit-learn, TensorFlow, PyTorch)\\nDocument experiments, findings, and processes\\nCollaborate with team members on AI/ML projects\\nRequirements:\\nBachelor’s degree (or pursuing final year) in Computer Science, Data Science, Mathematics, or related field\\nBasic knowledge of machine learning algorithms and data science concepts\\nProgramming skills in Python or R\\nFamiliarity with data analysis and visualization tools\\nEagerness to learn and explore new AI/ML technologies\\nGood problem-solving and communication skills\\nNice to Have:\\nExperience with deep learning frameworks (TensorFlow, PyTorch, Keras)\\nKnowledge of SQL and cloud platforms (AWS, GCP, Azure)\\nParticipation in AI/ML competitions or personal projects\\nExperiance - 1 to 2 year\\nJob Type: Full-time\\nSchedule:\\nDay shift\\nMonday to Friday\\nMorning shift\\nWeekend availability\\nWork Location: In person  \n",
       "815                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Python/Spark based Data Engineers and Data Scientists with Min Work Experience 7-10 Years\\nPrevious experience 7-10+ as a big data engineer.\\nIn-depth knowledge of Hadoop (Cloudera), Spark, and similar frameworks.\\nGood knowledge of Big Data querying tools, such as Pig, Hive, and Impala\\nKnowledge of scripting languages including Java, C++, Linux, Ruby, PHP, Python, and R.\\nOwn most deliverables for the Big Data team from a delivery perspective.\\nAbility to solve complex networking, data, and software issues.\\nAble to Effectively Plan & Organize Their Work\\nStrong Interpersonal Communication\\nAssist others in the completion of their tasks to support the group goals.  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Median_Salary_Standardized'].isna()][[\n",
    "    'Company_Name', 'Job_Title', 'Company_Rating', 'Location', 'Description'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d70700-39f0-4129-9227-ce6b40adefcf",
   "metadata": {},
   "source": [
    "- Row 693, requires 1+ years of experience, ideal data science role, lets impute the salary with 8,00,000.\n",
    "- Row 738, requires 1-2 years of experience,  experience in AI/Ml,SQL, cloud platforms, lets impute the salary with 7,00,000.\n",
    "- Row 815, requires 7-10+ years of experience in big data engineering, strong knowledge of Hadoop (Cloudera), Spark, and Big Data querying tools, such as Pig, Hive, and Impala and languages including Java, C++, Linux, Ruby, PHP, Python, and R. The salary provided should be around 80,00,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "a0c1c120-bd30-42f8-bd23-71571d835764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[693, 'Median_Salary_Standardized'] = 800000\n",
    "\n",
    "df_copy.loc[738, 'Median_Salary_Standardized'] = 700000\n",
    "\n",
    "df_copy.loc[815, 'Median_Salary_Standardized'] = 8000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "fade9cb5-923a-4f19-931b-943d3f9ef4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop([257, 490, 533, 629, 641], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "99bb0f77-7d82-4b28-844c-44f2bb34653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Median_Salary_Standardized'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85201f29-9782-4de1-be15-7ac1ff05a032",
   "metadata": {},
   "source": [
    "## 2. Parsing Description column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "5fa92025-4f9f-4dd5-aec9-40d87c134fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "867c18af-979e-4c5a-a7ee-ef47f37a22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Description'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "2a554bfc-ac0f-40d7-a8cd-f4617544a1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Description'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "aae29095-500a-41fb-a5e0-76e9ce5e5986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 11)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff672b2-b0b0-4e3e-990c-990091624de1",
   "metadata": {},
   "source": [
    "### Parsing skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "203225c8-5b36-4f8a-b746-a456a175ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill normalization dictionary\n",
    "skill_synonyms = {\n",
    "    'excel': ['excel', 'microsoft excel'],\n",
    "    'python': ['python'],\n",
    "    'r': ['r', 'r studio'],  \n",
    "    'sql': ['sql', 'mysql', 'postgresql'],\n",
    "    'tableau': ['tableau'],\n",
    "    'power bi': ['power bi', 'powerbi'],\n",
    "    'tensorflow': ['tensorflow'],\n",
    "    'pytorch': ['pytorch'],\n",
    "    'data analysis': ['data analysis', 'data analytics'],\n",
    "    'statistics': ['statistics', 'statistic', 'statistical'],\n",
    "    'machine learning': ['machine learning', 'ml'],\n",
    "    'deep learning': ['deep learning', 'dl'],\n",
    "    'nlp': ['nlp', 'natural language processing'],\n",
    "    'ai': ['genai', 'gen ai', 'generative ai', 'ai models', 'gpt models', 'llms', 'llm', 'langchain', 'llamaindex', 'langgraph', \n",
    "          'huggingface', 'transformer models'],\n",
    "    'cloud_platforms': ['cloud platforms', 'aws', 'azure', 'azure ML', 'microsoft azure']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "51c8e32e-f897-45ff-81d7-505794a7aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for skill, aliases in skill_synonyms.items():\n",
    "    pattern = r'|'.join(rf'\\b{re.escape(alias)}\\b' for alias in aliases)\n",
    "    df_copy[skill] = df_copy['Description'].str.contains(pattern, case=False, regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "bfec75b5-bc06-4755-a98f-adbba521205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel\n",
      "0    750\n",
      "1     11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "python\n",
      "0    587\n",
      "1    174\n",
      "Name: count, dtype: int64\n",
      "\n",
      "r\n",
      "0    686\n",
      "1     75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sql\n",
      "0    686\n",
      "1     75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tableau\n",
      "0    740\n",
      "1     21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "power bi\n",
      "0    736\n",
      "1     25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tensorflow\n",
      "0    714\n",
      "1     47\n",
      "Name: count, dtype: int64\n",
      "\n",
      "pytorch\n",
      "0    709\n",
      "1     52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "data analysis\n",
      "0    646\n",
      "1    115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "statistics\n",
      "0    597\n",
      "1    164\n",
      "Name: count, dtype: int64\n",
      "\n",
      "machine learning\n",
      "0    391\n",
      "1    370\n",
      "Name: count, dtype: int64\n",
      "\n",
      "deep learning\n",
      "0    677\n",
      "1     84\n",
      "Name: count, dtype: int64\n",
      "\n",
      "nlp\n",
      "0    665\n",
      "1     96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ai\n",
      "0    632\n",
      "1    129\n",
      "Name: count, dtype: int64\n",
      "\n",
      "cloud_platforms\n",
      "0    686\n",
      "1     75\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for skill in skill_synonyms:\n",
    "    print(df_copy[skill].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15000d0e-010b-4c40-9135-5f263756e6ab",
   "metadata": {},
   "source": [
    "- From the above output we can see that    \n",
    "  - excel: appears only 11 of the rows     \n",
    "  - tableau: appears 21 of the rows    \n",
    "  - power bi: appears 25 of the rows    \n",
    "- the above newly created features does not provide much value to the model, therefore we can drop them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "b5fa279d-782c-4c63-8a4a-fc313f918b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary', 'Salary_Source',\n",
       "       'Salary_Range_Standardized', 'Median_Salary_Standardized', 'Intern',\n",
       "       'excel', 'python', 'r', 'sql', 'tableau', 'power bi', 'tensorflow',\n",
       "       'pytorch', 'data analysis', 'statistics', 'machine learning',\n",
       "       'deep learning', 'nlp', 'ai', 'cloud_platforms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "3f9dd605-2aec-4bd0-ae6f-0ac5e33a0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(['excel', 'tableau', 'power bi'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "c2b6c6ab-4df3-4a8b-979f-ea933c6bcad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary', 'Salary_Source',\n",
       "       'Salary_Range_Standardized', 'Median_Salary_Standardized', 'Intern',\n",
       "       'python', 'r', 'sql', 'tensorflow', 'pytorch', 'data analysis',\n",
       "       'statistics', 'machine learning', 'deep learning', 'nlp', 'ai',\n",
       "       'cloud_platforms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f2f1e0-8aeb-4a71-b381-4ac511048966",
   "metadata": {},
   "source": [
    "### Parsing Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "af27d0a3-b2a4-41b7-976d-0b0451ceb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv('data_modified', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedcf08f-d1d8-4950-a8fd-4e34146209c1",
   "metadata": {},
   "source": [
    "## 3. Extracting seniority infomation from job title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "c006b785-7f96-4ebf-a0bc-c6007a59cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Intern1'] = df_copy['Job_Title'].str.contains(r'\\bIntern(?:s|ship|ships)?\\b', \n",
    "                                                      case=False, regex=True, na=False).astype(int)\n",
    "df_copy['Junior_Associate'] = df_copy['Job_Title'].str.contains(r'\\bJunior\\b|\\bAssociate\\b', \n",
    "                                                                case=False, regex=True, na=False).astype(int)\n",
    "df_copy['Senior'] = df_copy['Job_Title'].str.contains(r'\\bSenior\\b|\\bSr\\b', \n",
    "                                                      case=False, regex=True, na=False).astype(int)\n",
    "df_copy['Staff_Principal'] = df_copy['Job_Title'].str.contains(r'\\bStaff\\b|\\bPrincipal\\b', \n",
    "                                                               case=False, regex=True, na=False).astype(int)\n",
    "df_copy['Lead_Manager'] = df_copy['Job_Title'].str.contains(r'\\bLead\\b|\\bManager\\b', \n",
    "                                                            case=False, regex=True, na=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "319d609e-6d2f-4ed7-80ee-e0192bcdadd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intern1</th>\n",
       "      <th>Junior_Associate</th>\n",
       "      <th>Senior</th>\n",
       "      <th>Staff_Principal</th>\n",
       "      <th>Lead_Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>721</td>\n",
       "      <td>711</td>\n",
       "      <td>647</td>\n",
       "      <td>744</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>114</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intern1  Junior_Associate  Senior  Staff_Principal  Lead_Manager\n",
       "0      721               711     647              744           733\n",
       "1       40                50     114               17            28"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[['Intern1', 'Junior_Associate', 'Senior', 'Staff_Principal', 'Lead_Manager']].apply(\n",
    "    pd.Series.value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "48c791a3-ad4a-4a08-a662-d40bad5c89fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intern\n",
       "1.0    4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Intern'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "6d8f4f95-6f07-463f-8ecb-a785e58d5fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([355, 560, 768, 809], dtype='int64')"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Intern'].notna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "018c0f89-4089-4b5f-9909-f132015269b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intern</th>\n",
       "      <th>Intern1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Intern  Intern1\n",
       "355     1.0        1\n",
       "560     1.0        0\n",
       "768     1.0        0\n",
       "809     1.0        0"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[355, 560, 768, 809], ['Intern', 'Intern1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d55188c6-3cbc-43cf-94d5-bc9fc460fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.loc[[560, 768, 809], 'Intern1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "34a626c2-fe7d-4f77-a254-4fcd333bf5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intern</th>\n",
       "      <th>Intern1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Intern  Intern1\n",
       "560     1.0        1\n",
       "768     1.0        1\n",
       "809     1.0        1"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[560, 768, 809], ['Intern', 'Intern1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "5f52d4cf-4cd1-4d88-b321-d8a42228fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop('Intern', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "237704c9-ba0f-462d-8894-788d97713427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary', 'Salary_Source',\n",
       "       'Salary_Range_Standardized', 'Median_Salary_Standardized', 'python',\n",
       "       'r', 'sql', 'tensorflow', 'pytorch', 'data analysis', 'statistics',\n",
       "       'machine learning', 'deep learning', 'nlp', 'ai', 'cloud_platforms',\n",
       "       'Intern1', 'Junior_Associate', 'Senior', 'Staff_Principal',\n",
       "       'Lead_Manager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "103e3fd5-7ba5-4dcd-9f3f-9d7ce8e7f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.rename(columns={'Intern1': 'Intern'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "1c668fbe-ebbd-4321-ae7b-4ce76fdd8f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary', 'Salary_Source',\n",
       "       'Salary_Range_Standardized', 'Median_Salary_Standardized', 'python',\n",
       "       'r', 'sql', 'tensorflow', 'pytorch', 'data analysis', 'statistics',\n",
       "       'machine learning', 'deep learning', 'nlp', 'ai', 'cloud_platforms',\n",
       "       'Intern', 'Junior_Associate', 'Senior', 'Staff_Principal',\n",
       "       'Lead_Manager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b01717-2727-4015-a341-fdc7e5acea6c",
   "metadata": {},
   "source": [
    "## 4. Categorizing job types \n",
    "### Scientist, Engineer, Analyst categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "c43bde50-1ed1-4e6f-b90c-ec5d1de61077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category 1: ML Engineer, Machine Learning Engineer, Engineer\n",
    "pattern_1 = r'\\b(?:ml engineer|machine learning engineer|engineer)\\b'\n",
    "\n",
    "# Category 2: Data Scientist, Data Science\n",
    "pattern_2 = r'\\b(?:data scientist|data science)\\b'\n",
    "\n",
    "# Category 3: Data Analyst, Analyst, Analytics\n",
    "pattern_3 = r'\\b(?:data analyst|analyst|analytics)\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "4a29379e-1ab9-4ad2-b0a8-9dff449bb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary indicator columns for job type categories\n",
    "df_copy['ML_Engineer'] = df_copy['Job_Title'].str.contains(pattern_1, \n",
    "                                                           case=False, regex=True, na=False).astype(int)\n",
    "df_copy['Data_Scientist'] = df_copy['Job_Title'].str.contains(pattern_2, \n",
    "                                                              case=False, regex=True, na=False).astype(int)\n",
    "df_copy['Data_Analyst'] = df_copy['Job_Title'].str.contains(pattern_3, \n",
    "                                                            case=False, regex=True, na=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "0e54a7b9-65b9-4958-8029-ac6387172b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML_Engineer</th>\n",
       "      <th>Data_Scientist</th>\n",
       "      <th>Data_Analyst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>694</td>\n",
       "      <td>137</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>624</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ML_Engineer  Data_Scientist  Data_Analyst\n",
       "0          694             137           707\n",
       "1           67             624            54"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[['ML_Engineer', 'Data_Scientist', 'Data_Analyst']].apply(\n",
    "    pd.Series.value_counts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "53890148-9654-4743-8069-739abcf33009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67+624+54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "3f99d200-3a79-440c-8932-9cfdb4e3678c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 30)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7cb80-814c-4970-8dea-1986b80bf5ec",
   "metadata": {},
   "source": [
    "## 5. Cleaning Salary_Source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "4c5eb486-6fd6-4ade-b825-fb8a07120342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Glassdoor Est.\n",
       "1       Glassdoor Est.\n",
       "2       Glassdoor Est.\n",
       "3       Glassdoor Est.\n",
       "4       Glassdoor Est.\n",
       "5    Employer provided\n",
       "6       Glassdoor Est.\n",
       "7                 None\n",
       "8                 None\n",
       "9    Employer provided\n",
       "Name: Salary_Source, dtype: object"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Source'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50ace7-3c9e-43ba-876f-ea4a408c48d0",
   "metadata": {},
   "source": [
    "### Imputing missing values in Salary_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "27405ca1-541f-45ad-8e99-15c9f26e5c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary_Source\n",
       "Glassdoor Est.       437\n",
       "Employer provided    129\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "525a248e-d21a-49c5-9d9b-ec33a034c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Salary_Source'] = df_copy['Salary_Source'].str.replace('.', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "d529478d-caab-4ee6-8167-1412f0cf1ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Glassdoor Est', 'Employer provided', None, nan], dtype=object)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de4c64-eb19-4f72-ba03-c342cab7d407",
   "metadata": {},
   "source": [
    "- Out of 716 rows 195 are missing values in Salary_Source column, lets fill them with 40:60 ratio (40% employer provided and 60% glassdoor est)  \n",
    "- ~78 as Employer provided (40%)  \n",
    "  ~117 as Glassdoor Est (60%)  \n",
    "- The end result will be:\n",
    "  - Employer Provided =  207\n",
    "  - Glassdoor Est = 554"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "577fcf3f-bd81-4e54-9851-998bbc993712",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [\"Employer provided\", \"Glassdoor Est\"]\n",
    "probs = [0.40, 0.60]\n",
    "\n",
    "# Fill missing values only\n",
    "df_copy['Salary_Source'] = df_copy['Salary_Source'].apply(\n",
    "    lambda x: np.random.choice(choices, p=probs) if pd.isna(x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "3215f2ce-3d7f-4783-9ed6-e1f6d23c12b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary_Source\n",
       "Glassdoor Est        541\n",
       "Employer provided    220\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "50eb8395-0888-4315-9dd2-e053f29a4043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Glassdoor Est', 'Employer provided'], dtype=object)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2362a847-ece3-44fe-a452-76ecb1c546b9",
   "metadata": {},
   "source": [
    "### Onehot encode Salary_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "01f57bad-0784-4bdb-a086-38efb68d0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Salary_Source_Glassdoor'] = (df_copy['Salary_Source'] == 'Glassdoor Est').astype(int)\n",
    "df_copy['Salary_Source_Employer'] = (df_copy['Salary_Source'] == 'Employer provided').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "b05aa4d9-d550-43bf-a20c-1af5b065567b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Name', 'Company_Rating', 'Job_Title', 'Location',\n",
       "       'Description', 'Salary_Range', 'Median_Salary', 'Salary_Source',\n",
       "       'Salary_Range_Standardized', 'Median_Salary_Standardized', 'python',\n",
       "       'r', 'sql', 'tensorflow', 'pytorch', 'data analysis', 'statistics',\n",
       "       'machine learning', 'deep learning', 'nlp', 'ai', 'cloud_platforms',\n",
       "       'Intern', 'Junior_Associate', 'Senior', 'Staff_Principal',\n",
       "       'Lead_Manager', 'ML_Engineer', 'Data_Scientist', 'Data_Analyst',\n",
       "       'Salary_Source_Glassdoor', 'Salary_Source_Employer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "66146881-ba06-4b76-854c-0b74ce12a0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary_Source_Employer\n",
       "0    541\n",
       "1    220\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Source_Employer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "fcd578e5-7bef-4cde-ba8c-5297b9e45871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Salary_Source_Glassdoor\n",
       "1    541\n",
       "0    220\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Salary_Source_Glassdoor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "1158af5b-0f9d-4b03-8657-761d91bfda09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop('Salary_Source', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd1b64-cee5-4280-8a15-871cd3c14f38",
   "metadata": {},
   "source": [
    "## 6. Onehot encoding Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "0090ca54-8dc1-485c-bb1b-c50da3cd2257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "Bengaluru             246\n",
       "India                  81\n",
       "Gurgaon                64\n",
       "Chennai                62\n",
       "Hyderābād              61\n",
       "Pune                   58\n",
       "Remote                 49\n",
       "Mumbai                 27\n",
       "Noida                  22\n",
       "Ahmedabad              14\n",
       "Delhi                   8\n",
       "Cochin                  8\n",
       "Mohali                  7\n",
       "Coimbatore              7\n",
       "Gujarat                 4\n",
       "Karnataka               4\n",
       "Indore                  4\n",
       "Vadodara                4\n",
       "Thiruvananthapuram      3\n",
       "Navi Mumbai             3\n",
       "Jamshedpur              2\n",
       "Calcutta                2\n",
       "Chandigarh              2\n",
       "Bhubaneshwar            2\n",
       "Kālkāji Devi            2\n",
       "Kerala                  1\n",
       "Goa                     1\n",
       "Jaipur                  1\n",
       "Calicut                 1\n",
       "Rāichūr                 1\n",
       "Haryana                 1\n",
       "Surat                   1\n",
       "Tirupati                1\n",
       "Thrissur                1\n",
       "Alleppey                1\n",
       "Raipur                  1\n",
       "Nagercoil               1\n",
       "Jodhpur                 1\n",
       "Lucknow                 1\n",
       "Dhārwād                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Location'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "6d611e8b-c71b-4aab-8bf1-65a8167be905",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_locations = df_copy['Location'].value_counts().nlargest(10).index\n",
    "df_copy['Location_Cleaned'] = df_copy['Location'].apply(lambda x: x if x in top_locations else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "580cd946-d802-4d1d-9b35-7c3b36751ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bengaluru', 'India', 'Gurgaon', 'Chennai', 'Hyderābād', 'Pune',\n",
       "       'Remote', 'Mumbai', 'Noida', 'Ahmedabad'],\n",
       "      dtype='object', name='Location')"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "dd378a2f-c19a-42af-a0c4-32e94053ae8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location_Cleaned\n",
       "Bengaluru    246\n",
       "India         81\n",
       "Other         77\n",
       "Gurgaon       64\n",
       "Chennai       62\n",
       "Hyderābād     61\n",
       "Pune          58\n",
       "Remote        49\n",
       "Mumbai        27\n",
       "Noida         22\n",
       "Ahmedabad     14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Location_Cleaned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "76485c51-e14a-4482-bf28-7169b065df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_dummies = pd.get_dummies(df_copy['Location_Cleaned'], prefix='Loc', dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "7efef919-1ec1-4eb4-9e37-d1efce47e17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loc_Ahmedabad</th>\n",
       "      <th>Loc_Bengaluru</th>\n",
       "      <th>Loc_Chennai</th>\n",
       "      <th>Loc_Gurgaon</th>\n",
       "      <th>Loc_Hyderābād</th>\n",
       "      <th>Loc_India</th>\n",
       "      <th>Loc_Mumbai</th>\n",
       "      <th>Loc_Noida</th>\n",
       "      <th>Loc_Other</th>\n",
       "      <th>Loc_Pune</th>\n",
       "      <th>Loc_Remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loc_Ahmedabad  Loc_Bengaluru  Loc_Chennai  Loc_Gurgaon  Loc_Hyderābād  \\\n",
       "0              0              0            0            0              0   \n",
       "1              0              0            0            1              0   \n",
       "2              0              1            0            0              0   \n",
       "3              0              0            0            0              0   \n",
       "4              0              0            0            0              1   \n",
       "\n",
       "   Loc_India  Loc_Mumbai  Loc_Noida  Loc_Other  Loc_Pune  Loc_Remote  \n",
       "0          0           0          1          0         0           0  \n",
       "1          0           0          0          0         0           0  \n",
       "2          0           0          0          0         0           0  \n",
       "3          0           0          0          0         1           0  \n",
       "4          0           0          0          0         0           0  "
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "a77f039a-ee0f-470b-bce6-3aa055f33ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = pd.concat([df_copy, location_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "65039595-4e4f-416d-8d9a-0d4edbd759ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Median_Salary</th>\n",
       "      <th>Salary_Range_Standardized</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>python</th>\n",
       "      <th>r</th>\n",
       "      <th>sql</th>\n",
       "      <th>tensorflow</th>\n",
       "      <th>pytorch</th>\n",
       "      <th>data analysis</th>\n",
       "      <th>statistics</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>nlp</th>\n",
       "      <th>ai</th>\n",
       "      <th>cloud_platforms</th>\n",
       "      <th>Intern</th>\n",
       "      <th>Junior_Associate</th>\n",
       "      <th>Senior</th>\n",
       "      <th>Staff_Principal</th>\n",
       "      <th>Lead_Manager</th>\n",
       "      <th>ML_Engineer</th>\n",
       "      <th>Data_Scientist</th>\n",
       "      <th>Data_Analyst</th>\n",
       "      <th>Salary_Source_Glassdoor</th>\n",
       "      <th>Salary_Source_Employer</th>\n",
       "      <th>Location_Cleaned</th>\n",
       "      <th>Loc_Ahmedabad</th>\n",
       "      <th>Loc_Bengaluru</th>\n",
       "      <th>Loc_Chennai</th>\n",
       "      <th>Loc_Gurgaon</th>\n",
       "      <th>Loc_Hyderābād</th>\n",
       "      <th>Loc_India</th>\n",
       "      <th>Loc_Mumbai</th>\n",
       "      <th>Loc_Noida</th>\n",
       "      <th>Loc_Other</th>\n",
       "      <th>Loc_Pune</th>\n",
       "      <th>Loc_Remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.</td>\n",
       "      <td>₹2L – ₹9L/yr</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "      <td>200000 – 900000</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Noida</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Senior Data Scientist - AIML</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nApply advanced statistical techniques, data science methodologies, and AI practices, including generative AI using GPT models\\nDesign, develop, and implement cutting-edge generative AI models and systems</td>\n",
       "      <td>₹2L – ₹9L/yr</td>\n",
       "      <td>₹4L/yr Median</td>\n",
       "      <td>200000 – 900000</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Director AI/ML Engineer</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together\\nOptum is seeking a highly skilled Director of Software Engineering to join our dynamic team. You will work on cutting-edge Generative AI technology projects to solve complex business problems across the company. You are a strong leader with skills and a foundation in software engineering, cloud infrastructure, and cloud-native system design.\\nPrimary Responsibilities:</td>\n",
       "      <td>₹3L – ₹7L/yr</td>\n",
       "      <td>₹5L/yr Median</td>\n",
       "      <td>300000 – 700000</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BP Energy</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Data Scientist Manager</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurface Group\\n\\nJob Description:\\nWe are a global energy business involved in every aspect of the energy system. We are working towards delivering light, heat, and mobility to millions of people every day. We are one of the very few companies equipped to solve some of the big complex challenges that matter for the future. We have a real contribution to make to the world's ambition of a low-carbon future. Join us and be part of what we can accomplish together. You can participate in our new ambition to become a net zero company by 2050 or sooner and help the world get to net zero.\\n\\nUp to 10% travel should be expected with this role\\n\\nThis role is eligible for relocation within country\\n\\nThis position is a hybrid of office/remote working</td>\n",
       "      <td>₹7L – ₹9L/yr</td>\n",
       "      <td>₹8L/yr Median</td>\n",
       "      <td>700000 – 900000</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zelis</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Science Engineer / Healthcare Data Analyst</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>About Us\\nZelis is modernizing the healthcare financial experience in the United States (U.S.) by providing a connected platform that bridges the gaps and aligns interests across payers, providers, and healthcare consumers. This platform serves more than 750 payers, including the top 5 health plans, BCBS insurers, regional health plans, TPAs and self-insured employers, and millions of healthcare providers and consumers in the U.S. Zelis sees across the system to identify, optimize, and solve problems holistically with technology built by healthcare experts—driving real, measurable results for clients.\\nWhy We Do What We Do\\nIn the U.S., consumers, payers, and providers face significant challenges throughout the healthcare financial journey. Zelis helps streamline the process by offering solutions that improve transparency, efficiency, and communication among all parties involved. By addressing the obstacles that patients face in accessing care, navigating the intricacies of insurance claims, and the logistical challenges healthcare providers encounter with processing payments, Zelis aims to create a more seamless and effective healthcare financial system.\\nData Analyst with deep experience in the US Healthcare industry with the skills around ML</td>\n",
       "      <td>₹2L – ₹7L/yr</td>\n",
       "      <td>₹3L/yr Median</td>\n",
       "      <td>200000 – 700000</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Name  Company_Rating  \\\n",
       "0        Optum             3.5   \n",
       "1        Optum             3.5   \n",
       "2        Optum             3.5   \n",
       "3    BP Energy             3.9   \n",
       "4        Zelis             3.7   \n",
       "\n",
       "                                         Job_Title   Location  \\\n",
       "0                            Senior Data Scientist      Noida   \n",
       "1                     Senior Data Scientist - AIML    Gurgaon   \n",
       "2                          Director AI/ML Engineer  Bengaluru   \n",
       "3                           Data Scientist Manager       Pune   \n",
       "4  Data Science Engineer / Healthcare Data Analyst  Hyderābād   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Description  \\\n",
       "0                                                                                                                                                                                Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\n\\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.\\nPrimary Responsibilities:\\nApply advanced statistical techniques, data science methodologies, and AI practices, including generative AI using GPT models\\nDesign, develop, and implement cutting-edge generative AI models and systems   \n",
       "2                                                                                                                                                                                                                                                                                                               Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together\\nOptum is seeking a highly skilled Director of Software Engineering to join our dynamic team. You will work on cutting-edge Generative AI technology projects to solve complex business problems across the company. You are a strong leader with skills and a foundation in software engineering, cloud infrastructure, and cloud-native system design.\\nPrimary Responsibilities:   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Entity:\\nFinance\\n\\nJob Family Group:\\nSubsurface Group\\n\\nJob Description:\\nWe are a global energy business involved in every aspect of the energy system. We are working towards delivering light, heat, and mobility to millions of people every day. We are one of the very few companies equipped to solve some of the big complex challenges that matter for the future. We have a real contribution to make to the world's ambition of a low-carbon future. Join us and be part of what we can accomplish together. You can participate in our new ambition to become a net zero company by 2050 or sooner and help the world get to net zero.\\n\\nUp to 10% travel should be expected with this role\\n\\nThis role is eligible for relocation within country\\n\\nThis position is a hybrid of office/remote working   \n",
       "4  About Us\\nZelis is modernizing the healthcare financial experience in the United States (U.S.) by providing a connected platform that bridges the gaps and aligns interests across payers, providers, and healthcare consumers. This platform serves more than 750 payers, including the top 5 health plans, BCBS insurers, regional health plans, TPAs and self-insured employers, and millions of healthcare providers and consumers in the U.S. Zelis sees across the system to identify, optimize, and solve problems holistically with technology built by healthcare experts—driving real, measurable results for clients.\\nWhy We Do What We Do\\nIn the U.S., consumers, payers, and providers face significant challenges throughout the healthcare financial journey. Zelis helps streamline the process by offering solutions that improve transparency, efficiency, and communication among all parties involved. By addressing the obstacles that patients face in accessing care, navigating the intricacies of insurance claims, and the logistical challenges healthcare providers encounter with processing payments, Zelis aims to create a more seamless and effective healthcare financial system.\\nData Analyst with deep experience in the US Healthcare industry with the skills around ML   \n",
       "\n",
       "   Salary_Range  Median_Salary Salary_Range_Standardized  \\\n",
       "0  ₹2L – ₹9L/yr  ₹4L/yr Median           200000 – 900000   \n",
       "1  ₹2L – ₹9L/yr  ₹4L/yr Median           200000 – 900000   \n",
       "2  ₹3L – ₹7L/yr  ₹5L/yr Median           300000 – 700000   \n",
       "3  ₹7L – ₹9L/yr  ₹8L/yr Median           700000 – 900000   \n",
       "4  ₹2L – ₹7L/yr  ₹3L/yr Median           200000 – 700000   \n",
       "\n",
       "  Median_Salary_Standardized  python  r  sql  tensorflow  pytorch  \\\n",
       "0                     400000       0  0    0           0        0   \n",
       "1                     400000       0  0    0           0        0   \n",
       "2                     500000       0  0    0           0        0   \n",
       "3                     800000       0  0    0           0        0   \n",
       "4                     300000       0  0    0           0        0   \n",
       "\n",
       "   data analysis  statistics  machine learning  deep learning  nlp  ai  \\\n",
       "0              0           0                 1              0    1   1   \n",
       "1              0           1                 0              0    0   1   \n",
       "2              0           0                 0              0    0   1   \n",
       "3              0           0                 0              0    0   0   \n",
       "4              0           0                 1              0    0   0   \n",
       "\n",
       "   cloud_platforms  Intern  Junior_Associate  Senior  Staff_Principal  \\\n",
       "0                0       0                 0       1                0   \n",
       "1                0       0                 0       1                0   \n",
       "2                0       0                 0       0                0   \n",
       "3                0       0                 0       0                0   \n",
       "4                0       0                 0       0                0   \n",
       "\n",
       "   Lead_Manager  ML_Engineer  Data_Scientist  Data_Analyst  \\\n",
       "0             0            0               1             0   \n",
       "1             0            0               1             0   \n",
       "2             0            1               0             0   \n",
       "3             1            0               1             0   \n",
       "4             0            1               1             1   \n",
       "\n",
       "   Salary_Source_Glassdoor  Salary_Source_Employer Location_Cleaned  \\\n",
       "0                        1                       0            Noida   \n",
       "1                        1                       0          Gurgaon   \n",
       "2                        1                       0        Bengaluru   \n",
       "3                        1                       0             Pune   \n",
       "4                        1                       0        Hyderābād   \n",
       "\n",
       "   Loc_Ahmedabad  Loc_Bengaluru  Loc_Chennai  Loc_Gurgaon  Loc_Hyderābād  \\\n",
       "0              0              0            0            0              0   \n",
       "1              0              0            0            1              0   \n",
       "2              0              1            0            0              0   \n",
       "3              0              0            0            0              0   \n",
       "4              0              0            0            0              1   \n",
       "\n",
       "   Loc_India  Loc_Mumbai  Loc_Noida  Loc_Other  Loc_Pune  Loc_Remote  \n",
       "0          0           0          1          0         0           0  \n",
       "1          0           0          0          0         0           0  \n",
       "2          0           0          0          0         0           0  \n",
       "3          0           0          0          0         1           0  \n",
       "4          0           0          0          0         0           0  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "b998a2d2-4def-4150-85f7-faf3719bb521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company_Name                    0\n",
       "Company_Rating                  0\n",
       "Job_Title                       0\n",
       "Location                        0\n",
       "Description                     0\n",
       "Salary_Range                  189\n",
       "Median_Salary                 277\n",
       "Salary_Range_Standardized     189\n",
       "Median_Salary_Standardized      0\n",
       "python                          0\n",
       "r                               0\n",
       "sql                             0\n",
       "tensorflow                      0\n",
       "pytorch                         0\n",
       "data analysis                   0\n",
       "statistics                      0\n",
       "machine learning                0\n",
       "deep learning                   0\n",
       "nlp                             0\n",
       "ai                              0\n",
       "cloud_platforms                 0\n",
       "Intern                          0\n",
       "Junior_Associate                0\n",
       "Senior                          0\n",
       "Staff_Principal                 0\n",
       "Lead_Manager                    0\n",
       "ML_Engineer                     0\n",
       "Data_Scientist                  0\n",
       "Data_Analyst                    0\n",
       "Salary_Source_Glassdoor         0\n",
       "Salary_Source_Employer          0\n",
       "Location_Cleaned                0\n",
       "Loc_Ahmedabad                   0\n",
       "Loc_Bengaluru                   0\n",
       "Loc_Chennai                     0\n",
       "Loc_Gurgaon                     0\n",
       "Loc_Hyderābād                   0\n",
       "Loc_India                       0\n",
       "Loc_Mumbai                      0\n",
       "Loc_Noida                       0\n",
       "Loc_Other                       0\n",
       "Loc_Pune                        0\n",
       "Loc_Remote                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089053c-ca4a-490a-8385-bef0a265b051",
   "metadata": {},
   "source": [
    "## 7. Removing unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f4c68-915a-4c98-b873-18759d73f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(['Company_Name', 'Job_Title', 'Location', 'Salary_Range', 'Median_Salary', \n",
    "              'Salary_Range_Standardized'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "9358b35b-5a79-487a-babc-7e67e2f7547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(['Location_Cleaned', 'Description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "a1165cc5-c98b-4f6b-896b-c39779c9bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Median_Salary_Standardized</th>\n",
       "      <th>python</th>\n",
       "      <th>r</th>\n",
       "      <th>sql</th>\n",
       "      <th>tensorflow</th>\n",
       "      <th>pytorch</th>\n",
       "      <th>data analysis</th>\n",
       "      <th>statistics</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>nlp</th>\n",
       "      <th>ai</th>\n",
       "      <th>cloud_platforms</th>\n",
       "      <th>Intern</th>\n",
       "      <th>Junior_Associate</th>\n",
       "      <th>Senior</th>\n",
       "      <th>Staff_Principal</th>\n",
       "      <th>Lead_Manager</th>\n",
       "      <th>ML_Engineer</th>\n",
       "      <th>Data_Scientist</th>\n",
       "      <th>Data_Analyst</th>\n",
       "      <th>Salary_Source_Glassdoor</th>\n",
       "      <th>Salary_Source_Employer</th>\n",
       "      <th>Loc_Ahmedabad</th>\n",
       "      <th>Loc_Bengaluru</th>\n",
       "      <th>Loc_Chennai</th>\n",
       "      <th>Loc_Gurgaon</th>\n",
       "      <th>Loc_Hyderābād</th>\n",
       "      <th>Loc_India</th>\n",
       "      <th>Loc_Mumbai</th>\n",
       "      <th>Loc_Noida</th>\n",
       "      <th>Loc_Other</th>\n",
       "      <th>Loc_Pune</th>\n",
       "      <th>Loc_Remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.9</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company_Rating Median_Salary_Standardized  python  r  sql  tensorflow  \\\n",
       "0             3.5                     400000       0  0    0           0   \n",
       "1             3.5                     400000       0  0    0           0   \n",
       "2             3.5                     500000       0  0    0           0   \n",
       "3             3.9                     800000       0  0    0           0   \n",
       "4             3.7                     300000       0  0    0           0   \n",
       "\n",
       "   pytorch  data analysis  statistics  machine learning  deep learning  nlp  \\\n",
       "0        0              0           0                 1              0    1   \n",
       "1        0              0           1                 0              0    0   \n",
       "2        0              0           0                 0              0    0   \n",
       "3        0              0           0                 0              0    0   \n",
       "4        0              0           0                 1              0    0   \n",
       "\n",
       "   ai  cloud_platforms  Intern  Junior_Associate  Senior  Staff_Principal  \\\n",
       "0   1                0       0                 0       1                0   \n",
       "1   1                0       0                 0       1                0   \n",
       "2   1                0       0                 0       0                0   \n",
       "3   0                0       0                 0       0                0   \n",
       "4   0                0       0                 0       0                0   \n",
       "\n",
       "   Lead_Manager  ML_Engineer  Data_Scientist  Data_Analyst  \\\n",
       "0             0            0               1             0   \n",
       "1             0            0               1             0   \n",
       "2             0            1               0             0   \n",
       "3             1            0               1             0   \n",
       "4             0            1               1             1   \n",
       "\n",
       "   Salary_Source_Glassdoor  Salary_Source_Employer  Loc_Ahmedabad  \\\n",
       "0                        1                       0              0   \n",
       "1                        1                       0              0   \n",
       "2                        1                       0              0   \n",
       "3                        1                       0              0   \n",
       "4                        1                       0              0   \n",
       "\n",
       "   Loc_Bengaluru  Loc_Chennai  Loc_Gurgaon  Loc_Hyderābād  Loc_India  \\\n",
       "0              0            0            0              0          0   \n",
       "1              0            0            1              0          0   \n",
       "2              1            0            0              0          0   \n",
       "3              0            0            0              0          0   \n",
       "4              0            0            0              1          0   \n",
       "\n",
       "   Loc_Mumbai  Loc_Noida  Loc_Other  Loc_Pune  Loc_Remote  \n",
       "0           0          1          0         0           0  \n",
       "1           0          0          0         0           0  \n",
       "2           0          0          0         0           0  \n",
       "3           0          0          0         1           0  \n",
       "4           0          0          0         0           0  "
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "ecccfd8e-5834-43ce-9a7b-6c6cb8afd245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Rating', 'Median_Salary_Standardized', 'python', 'r', 'sql',\n",
       "       'tensorflow', 'pytorch', 'data analysis', 'statistics',\n",
       "       'machine learning', 'deep learning', 'nlp', 'ai', 'cloud_platforms',\n",
       "       'Intern', 'Junior_Associate', 'Senior', 'Staff_Principal',\n",
       "       'Lead_Manager', 'ML_Engineer', 'Data_Scientist', 'Data_Analyst',\n",
       "       'Salary_Source_Glassdoor', 'Salary_Source_Employer', 'Loc_Ahmedabad',\n",
       "       'Loc_Bengaluru', 'Loc_Chennai', 'Loc_Gurgaon', 'Loc_Hyderābād',\n",
       "       'Loc_India', 'Loc_Mumbai', 'Loc_Noida', 'Loc_Other', 'Loc_Pune',\n",
       "       'Loc_Remote'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "42463c3a-c657-48fb-b7be-90f260900e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Rating</th>\n",
       "      <th>Salary</th>\n",
       "      <th>python</th>\n",
       "      <th>r</th>\n",
       "      <th>sql</th>\n",
       "      <th>tensorflow</th>\n",
       "      <th>pytorch</th>\n",
       "      <th>data analysis</th>\n",
       "      <th>statistics</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>deep learning</th>\n",
       "      <th>nlp</th>\n",
       "      <th>ai</th>\n",
       "      <th>cloud_platforms</th>\n",
       "      <th>Intern</th>\n",
       "      <th>Junior_Associate</th>\n",
       "      <th>Senior</th>\n",
       "      <th>Staff_Principal</th>\n",
       "      <th>Lead_Manager</th>\n",
       "      <th>ML_Engineer</th>\n",
       "      <th>Data_Scientist</th>\n",
       "      <th>Data_Analyst</th>\n",
       "      <th>Salary_Source_Glassdoor</th>\n",
       "      <th>Salary_Source_Employer</th>\n",
       "      <th>Loc_Ahmedabad</th>\n",
       "      <th>Loc_Bengaluru</th>\n",
       "      <th>Loc_Chennai</th>\n",
       "      <th>Loc_Gurgaon</th>\n",
       "      <th>Loc_Hyderābād</th>\n",
       "      <th>Loc_India</th>\n",
       "      <th>Loc_Mumbai</th>\n",
       "      <th>Loc_Noida</th>\n",
       "      <th>Loc_Other</th>\n",
       "      <th>Loc_Pune</th>\n",
       "      <th>Loc_Remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.9</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.7</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.9</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.2</td>\n",
       "      <td>3328000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>336000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>402903.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.2</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.5</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.5</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.6</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3.3</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.6</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3.4</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.2</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.1</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4.3</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4.3</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4.1</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3.5</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3.9</td>\n",
       "      <td>960000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3.7</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4.2</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4.2</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4.5</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3.9</td>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3.6</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4.3</td>\n",
       "      <td>1600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3.5</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3.9</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3.4</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3.9</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3.5</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4.3</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3.4</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3.7</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.8</td>\n",
       "      <td>2000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.0</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3.4</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3.8</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>4.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3.6</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4.9</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3.8</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>3.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>3.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3.8</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4.3</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>4.2</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3.5</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3.8</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.6</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3.4</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3.9</td>\n",
       "      <td>829864.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1030892.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3.8</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3.3</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>5.0</td>\n",
       "      <td>62400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>4.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>4.4</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3.9</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3.7</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3.9</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>3.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>3.8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>3.9</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2.8</td>\n",
       "      <td>5000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>4.2</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>5.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3.7</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>4.2</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>4.3</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>3.4</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>3.3</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>3.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>4.4</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>3.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>3.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>4.1</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>4.3</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>3.6</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>3.7</td>\n",
       "      <td>300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>3.8</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>3.5</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>4.3</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3.8</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>3.4</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>3.9</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>4.3</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>3.8</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>3.5</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>4.1</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>4.1</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>4.1</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>4.2</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1080000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>3.4</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>3.6</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>3.9</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>5.0</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>4.0</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3.5</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>3.9</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1164000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>3.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>3.5</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>4.4</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>3.8</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>4.3</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>3.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.7</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>3.4</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>3.9</td>\n",
       "      <td>180000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>4.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4.7</td>\n",
       "      <td>4300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>3.3</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4.1</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>3.9</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>4.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>3.5</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2.6</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>3.4</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>3.8</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>4.4</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>3.9</td>\n",
       "      <td>360000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>4.1</td>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>3.4</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4.2</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>3.5</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>4.2</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>3.4</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>3.5</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>5.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>4.3</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4.5</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3.7</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4.1</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>3.7</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3.7</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>3.8</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>3.2</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>3.6</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>4.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>3.5</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2044153.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>3.7</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>3.3</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>3.4</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>3.6</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>4.3</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>4.3</td>\n",
       "      <td>2000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>4.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>4.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>4.5</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>3.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>3.8</td>\n",
       "      <td>3000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>3.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4.2</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>3.8</td>\n",
       "      <td>8000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>3.8</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4.3</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>4.0</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>3.3</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>3.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>4.2</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4.0</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>4.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>3.6</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>4.6</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>3.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3.8</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1664000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3.8</td>\n",
       "      <td>360000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3.2</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>4.5</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>3.4</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>3.7</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>3.7</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>4.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>3.6</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>4.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>4.3</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>4.2</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>3.9</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>3.2</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>3.9</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>4.4</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>3.4</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>3.9</td>\n",
       "      <td>240000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>3.8</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>5.0</td>\n",
       "      <td>300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>4.1</td>\n",
       "      <td>300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>3.9</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>5.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>4.0</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>3.4</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>3.7</td>\n",
       "      <td>108000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1248000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>3.8</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>4.2</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>4.2</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4.3</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4.2</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>4.1</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>4.3</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>3.7</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4.2</td>\n",
       "      <td>4000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4.3</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3.0</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4.2</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>4.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>4.7</td>\n",
       "      <td>540000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>3.9</td>\n",
       "      <td>396000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>3.8</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>3.9</td>\n",
       "      <td>360000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>3.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>3.8</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>3.3</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>4.1</td>\n",
       "      <td>2000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>3.8</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>4.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>4.3</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>3.8</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>4.2</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>3.8</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>5.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>3.8</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2.3</td>\n",
       "      <td>2000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3.8</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>4.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>3.9</td>\n",
       "      <td>540000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>4.1</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>3.4</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>3.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>4.1</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>4.5</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>3.5</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>3.9</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>3.8</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>4.3</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>3.9</td>\n",
       "      <td>240000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>2.9</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>3.7</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>4.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>3.7</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>3.9</td>\n",
       "      <td>276000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>4.4</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>4.5</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>3.7</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>4.1</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>3.2</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>4.4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>3.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>3.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>3.9</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>4.3</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>3.7</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>3.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>4.1</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>3.4</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>4.5</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>4.2</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>4.2</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>3.9</td>\n",
       "      <td>360000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>4.5</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>3.7</td>\n",
       "      <td>2300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>4.2</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>4.0</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>3.2</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>4.1</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>3.7</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>4.3</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>2.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>5.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>4.5</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>3.9</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>3.9</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>4.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>4.0</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>4.2</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>4.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>4.0</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>4.2</td>\n",
       "      <td>1500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>3.9</td>\n",
       "      <td>77000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>4.1</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>4.2</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>4.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>3.9</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>3.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>3.9</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>4.1</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>3.4</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>3.4</td>\n",
       "      <td>1140000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>4.4</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>3.7</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>3.8</td>\n",
       "      <td>2000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>4.4</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>4.4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>4.0</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>3.2</td>\n",
       "      <td>96000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>4.3</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>4.2</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>3.6</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>4.0</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>3.4</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>3.6</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>3.5</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>3.2</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>3.9</td>\n",
       "      <td>5300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>3.9</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>4.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>4.2</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>3.3</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>3.4</td>\n",
       "      <td>480000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>3.4</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>3.9</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>3.8</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>4.3</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>4.3</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>4.8</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>3.9</td>\n",
       "      <td>792000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>5.0</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>4.1</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>4.0</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>4.2</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>4.1</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>3.6</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>3.9</td>\n",
       "      <td>3700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>3.5</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>3.9</td>\n",
       "      <td>700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>4.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>4.6</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>3.9</td>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3.9</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>4.4</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>4.8</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>3.6</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>4.7</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>4.2</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>4.3</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>3.8</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>3.1</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>3.8</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>4.0</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>4.4</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>4.1</td>\n",
       "      <td>240000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>3.5</td>\n",
       "      <td>93000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>3.8</td>\n",
       "      <td>7000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>3.9</td>\n",
       "      <td>216000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>3.1</td>\n",
       "      <td>1600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>4.0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>3.0</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>4.1</td>\n",
       "      <td>300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>3.6</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>4.4</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>3.8</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>3.9</td>\n",
       "      <td>492000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>3.9</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>3.4</td>\n",
       "      <td>660000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>3.5</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>3.7</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>2.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>3.4</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>4.3</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>3.6</td>\n",
       "      <td>700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>3.9</td>\n",
       "      <td>720000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>4.2</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>4.4</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>4.3</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>4.5</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>3.6</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>3.4</td>\n",
       "      <td>960000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>4.6</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>4.7</td>\n",
       "      <td>300000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>4.3</td>\n",
       "      <td>8000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>3.9</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>3.6</td>\n",
       "      <td>800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>3.5</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>4.1</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>3.9</td>\n",
       "      <td>900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>5.0</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>3.9</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>4.1</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>3.6</td>\n",
       "      <td>400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>3.9</td>\n",
       "      <td>500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>3.7</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>4.2</td>\n",
       "      <td>2000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>4.1</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>3.8</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company_Rating     Salary  python  r  sql  tensorflow  pytorch  \\\n",
       "0               3.5     400000       0  0    0           0        0   \n",
       "1               3.5     400000       0  0    0           0        0   \n",
       "2               3.5     500000       0  0    0           0        0   \n",
       "3               3.9     800000       0  0    0           0        0   \n",
       "4               3.7     300000       0  0    0           0        0   \n",
       "5               1.0    1200000       0  1    0           0        0   \n",
       "6               4.2     700000       0  0    0           0        0   \n",
       "7               4.1     800000       0  0    0           0        0   \n",
       "8               3.9     120000       1  1    1           0        0   \n",
       "9               3.9    1200000       1  1    0           0        0   \n",
       "10              3.9     120000       1  1    1           0        0   \n",
       "11              4.0     600000       0  0    0           0        0   \n",
       "12              3.7     700000       0  0    0           0        0   \n",
       "13              3.9     800000       1  0    1           0        1   \n",
       "14              4.7    1300000       0  0    0           0        0   \n",
       "15              3.8     600000       0  0    0           0        0   \n",
       "16              4.2    3328000       0  0    0           0        0   \n",
       "17              5.0     336000       0  0    0           0        0   \n",
       "18              5.0   402903.0       0  0    0           0        0   \n",
       "19              4.1     500000       1  1    0           0        0   \n",
       "20              3.7  1000000.0       1  0    0           0        0   \n",
       "21              3.3    1000000       0  0    0           0        0   \n",
       "22              3.9     120000       1  1    0           1        1   \n",
       "23              4.9  1200000.0       1  0    0           0        0   \n",
       "24              4.8     120000       0  0    0           0        0   \n",
       "25              4.2     600000       1  0    0           0        0   \n",
       "26              3.8     800000       0  0    0           0        0   \n",
       "27              3.9    1200000       0  0    0           0        0   \n",
       "28              3.9     900000       0  0    0           0        0   \n",
       "29              1.0     400000       0  0    1           0        0   \n",
       "30              3.5     400000       0  0    0           0        0   \n",
       "31              3.8     800000       0  0    0           0        0   \n",
       "32              3.5     800000       1  0    1           1        1   \n",
       "33              4.2     700000       1  0    0           1        1   \n",
       "34              3.5     500000       0  0    0           0        0   \n",
       "35              4.1     500000       0  0    0           0        0   \n",
       "36              4.1     700000       0  0    0           0        0   \n",
       "37              4.1     600000       0  0    0           0        0   \n",
       "38              3.9     900000       1  0    1           0        0   \n",
       "39              3.6     300000       0  0    0           0        0   \n",
       "40              3.3     400000       0  0    0           0        0   \n",
       "41              3.8     800000       0  0    0           0        0   \n",
       "42              3.6   300000.0       0  0    0           0        0   \n",
       "43              4.7    1600000       0  0    0           0        0   \n",
       "44              3.4     600000       0  0    0           0        0   \n",
       "45              3.9    1100000       0  0    0           0        0   \n",
       "46              4.2   200000.0       0  0    0           0        0   \n",
       "47              4.1  1000000.0       0  0    0           0        0   \n",
       "48              3.8     600000       0  0    0           0        0   \n",
       "49              3.9    1900000       0  0    0           0        0   \n",
       "50              3.7    1000000       0  1    0           0        0   \n",
       "51              4.3     600000       1  1    1           0        0   \n",
       "52              3.9     900000       0  0    0           0        0   \n",
       "53              4.3     400000       0  0    0           0        0   \n",
       "54              4.1  1000000.0       0  0    0           0        0   \n",
       "55              3.9     700000       0  0    0           0        0   \n",
       "56              3.5     700000       1  0    1           0        0   \n",
       "57              3.9     700000       0  0    0           0        0   \n",
       "58              3.9     960000       1  0    0           0        0   \n",
       "59              4.1     400000       0  0    0           0        0   \n",
       "60              3.7     400000       0  0    0           0        0   \n",
       "61              4.2     700000       0  0    0           0        0   \n",
       "62              4.2   500000.0       0  0    0           0        0   \n",
       "63              4.2     700000       1  0    0           1        1   \n",
       "64              4.1     500000       0  0    0           0        0   \n",
       "65              5.0     400000       1  1    0           0        0   \n",
       "66              4.2     400000       0  0    0           0        0   \n",
       "67              3.9     700000       0  0    0           0        0   \n",
       "68              4.5     800000       0  0    0           0        0   \n",
       "69              4.0     700000       0  0    0           0        0   \n",
       "70              3.9     200000       1  1    1           0        0   \n",
       "71              3.6     400000       0  0    0           0        0   \n",
       "72              4.3    1600000       0  0    0           0        0   \n",
       "73              3.5     800000       0  1    0           0        0   \n",
       "74              3.9   720000.0       1  0    0           1        1   \n",
       "75              3.6     600000       0  0    0           0        0   \n",
       "76              3.8     700000       0  0    0           0        0   \n",
       "77              3.3    1200000       0  0    0           0        0   \n",
       "78              3.8     600000       0  0    0           0        0   \n",
       "79              4.0     700000       0  0    0           0        0   \n",
       "80              3.6     800000       1  0    0           0        0   \n",
       "81              3.4     120000       0  0    0           0        0   \n",
       "82              3.7     600000       1  0    0           1        1   \n",
       "83              4.2     800000       1  0    0           0        0   \n",
       "84              4.1     800000       0  0    0           0        0   \n",
       "85              3.9     400000       0  0    0           0        0   \n",
       "86              3.5     600000       0  1    0           0        0   \n",
       "87              4.0     600000       0  0    0           0        0   \n",
       "88              3.9     600000       0  0    0           0        0   \n",
       "89              3.9  2000000.0       1  0    1           1        1   \n",
       "91              4.3     700000       0  0    0           0        0   \n",
       "92              3.7     800000       0  0    0           0        0   \n",
       "93              3.6     700000       0  0    0           0        0   \n",
       "94              3.4     900000       0  0    0           0        0   \n",
       "95              3.7     300000       0  0    0           0        0   \n",
       "96              5.0     800000       1  0    1           0        0   \n",
       "97              4.8    2000000       0  0    0           0        0   \n",
       "98              4.0     120000       0  0    0           0        0   \n",
       "99              4.1     600000       0  0    0           0        0   \n",
       "100             3.8     600000       1  0    0           0        0   \n",
       "101             3.4     600000       0  0    0           0        0   \n",
       "102             3.7     600000       1  1    1           1        1   \n",
       "103             3.8    1500000       1  1    1           0        0   \n",
       "104             4.0     800000       0  0    0           0        0   \n",
       "105             3.6     300000       0  0    0           0        0   \n",
       "106             3.9     700000       1  1    1           1        1   \n",
       "107             5.0     800000       1  0    1           0        0   \n",
       "109             4.9     400000       1  1    0           0        0   \n",
       "110             4.0     500000       0  1    0           0        0   \n",
       "111             3.6     600000       1  0    0           1        1   \n",
       "112             3.8   300000.0       0  0    0           0        0   \n",
       "113             3.9    1800000       1  0    1           0        0   \n",
       "114             4.7    1000000       0  0    1           0        0   \n",
       "115             3.7     500000       0  0    0           0        0   \n",
       "116             3.6     700000       0  0    0           0        0   \n",
       "117             3.7     500000       0  0    0           0        0   \n",
       "118             3.8     300000       0  0    0           0        0   \n",
       "119             3.7     800000       0  0    0           0        0   \n",
       "121             4.2     700000       1  1    1           0        0   \n",
       "123             4.1     600000       0  0    0           0        0   \n",
       "124             3.5  1000000.0       0  0    0           0        0   \n",
       "125             3.9   900000.0       0  0    0           0        0   \n",
       "127             4.3     800000       0  0    0           0        0   \n",
       "128             3.8     700000       0  0    0           0        0   \n",
       "129             4.0     600000       0  0    0           0        0   \n",
       "130             3.7     500000       0  0    0           0        0   \n",
       "131             3.9     900000       0  0    0           0        0   \n",
       "132             4.2     400000       0  0    0           0        0   \n",
       "133             4.0     600000       0  0    0           0        0   \n",
       "134             3.5     600000       0  0    0           0        0   \n",
       "135             3.8     500000       0  0    0           0        0   \n",
       "136             3.9     900000       1  1    0           1        1   \n",
       "137             2.6     400000       0  0    0           0        0   \n",
       "138             3.4     500000       1  1    0           0        0   \n",
       "139             3.8     600000       0  0    0           0        0   \n",
       "140             3.9   829864.0       0  0    0           0        0   \n",
       "141             3.6   800000.0       0  1    0           0        0   \n",
       "142             4.1     600000       0  0    0           0        0   \n",
       "143             3.9     900000       1  1    1           1        1   \n",
       "144             3.8     600000       0  0    0           0        0   \n",
       "145             3.6     600000       0  0    0           0        0   \n",
       "146             3.9   600000.0       0  0    0           0        0   \n",
       "147             4.2     800000       0  0    0           0        0   \n",
       "148             3.9  1030892.0       1  1    1           1        1   \n",
       "149             3.7     600000       0  0    0           0        0   \n",
       "157             3.9  2400000.0       0  0    0           0        0   \n",
       "158             3.8     500000       0  0    0           0        0   \n",
       "159             4.1     800000       1  0    0           1        1   \n",
       "160             3.3     800000       0  0    0           0        0   \n",
       "161             3.8     800000       0  0    0           0        0   \n",
       "162             3.8     600000       1  0    0           0        0   \n",
       "163             4.0     400000       0  0    0           0        0   \n",
       "164             4.7    1200000       0  0    0           0        0   \n",
       "165             5.0    1200000       0  0    0           0        0   \n",
       "166             5.0      62400       0  0    0           0        0   \n",
       "167             3.9     700000       0  0    1           0        0   \n",
       "168             4.1     800000       0  0    0           0        0   \n",
       "169             4.1     700000       0  0    0           0        0   \n",
       "170             3.9     900000       1  0    0           0        0   \n",
       "171             4.4     800000       0  0    0           0        0   \n",
       "172             3.6     700000       1  1    1           0        0   \n",
       "173             4.0   700000.0       0  0    0           0        0   \n",
       "174             3.9   400000.0       0  0    0           0        0   \n",
       "175             4.6    1300000       0  0    0           0        0   \n",
       "176             3.7     700000       0  0    0           0        0   \n",
       "177             4.1     800000       0  0    0           0        0   \n",
       "178             3.9  3500000.0       1  0    1           0        0   \n",
       "179             3.8     600000       0  0    0           0        0   \n",
       "180             3.5     400000       0  0    0           0        0   \n",
       "182             3.8     600000       0  0    0           0        0   \n",
       "183             2.9     700000       0  0    0           0        0   \n",
       "184             3.1     500000       0  0    0           0        0   \n",
       "185             3.8    1000000       1  1    0           0        0   \n",
       "186             3.9     800000       0  0    0           0        0   \n",
       "187             4.1     800000       0  0    0           0        0   \n",
       "188             2.8    5000000       0  0    0           0        0   \n",
       "189             1.0     400000       0  0    0           1        0   \n",
       "190             4.2     800000       0  0    0           0        0   \n",
       "191             3.9     900000       1  1    0           1        1   \n",
       "192             4.2     600000       0  0    0           0        0   \n",
       "193             3.9     500000       0  0    0           0        0   \n",
       "194             4.2     700000       0  0    0           0        0   \n",
       "195             4.0     700000       1  0    0           0        0   \n",
       "196             3.1     400000       0  0    0           0        0   \n",
       "197             3.9    1500000       0  0    0           0        0   \n",
       "198             3.5    1000000       1  1    1           0        0   \n",
       "199             4.1     800000       0  0    0           0        0   \n",
       "200             3.9     600000       0  0    0           0        0   \n",
       "201             2.9     700000       0  0    0           0        0   \n",
       "202             5.0     500000       1  0    0           1        0   \n",
       "203             3.7     700000       0  0    0           0        0   \n",
       "204             4.2     500000       0  0    0           0        0   \n",
       "205             4.3    1200000       1  0    0           1        1   \n",
       "206             3.4     400000       1  0    0           0        0   \n",
       "207             3.3     400000       0  0    0           0        0   \n",
       "208             3.7     500000       1  1    1           0        0   \n",
       "209             3.7  1000000.0       0  0    0           0        0   \n",
       "211             4.2     700000       0  0    0           0        0   \n",
       "215             4.5    3000000       0  0    0           0        0   \n",
       "216             4.4     500000       1  0    1           0        1   \n",
       "217             3.1     400000       0  0    0           0        0   \n",
       "218             3.4     700000       0  0    0           0        0   \n",
       "219             4.1     400000       0  0    0           0        0   \n",
       "220             4.1    1000000       0  0    0           0        0   \n",
       "221             4.1     400000       0  0    0           0        0   \n",
       "222             3.9     700000       0  0    0           0        0   \n",
       "223             4.0     400000       0  0    0           0        0   \n",
       "224             3.9    1000000       1  1    1           0        0   \n",
       "225             4.3     800000       0  0    0           0        0   \n",
       "226             3.7     600000       0  0    0           0        0   \n",
       "227             3.6     500000       0  0    0           0        0   \n",
       "228             3.7     300000       1  1    1           1        0   \n",
       "229             3.8     400000       0  1    0           0        0   \n",
       "230             4.1     400000       0  0    0           0        0   \n",
       "231             3.7  1000000.0       0  0    0           0        0   \n",
       "232             3.5     500000       0  0    0           0        0   \n",
       "233             4.3     900000       0  0    0           0        0   \n",
       "234             3.8     300000       0  0    0           0        0   \n",
       "235             4.1     400000       0  0    0           0        0   \n",
       "236             3.4   200000.0       0  0    0           0        0   \n",
       "237             4.0     600000       0  0    0           0        0   \n",
       "238             3.9     600000       0  0    0           0        0   \n",
       "239             3.9     400000       0  0    0           0        0   \n",
       "242             4.3     400000       1  0    0           1        1   \n",
       "243             3.8     400000       0  0    0           0        0   \n",
       "244             4.0     700000       1  0    0           0        0   \n",
       "245             3.5     300000       0  0    0           0        0   \n",
       "246             4.1   300000.0       0  0    0           0        0   \n",
       "247             3.9     500000       1  1    1           0        0   \n",
       "248             3.9    1000000       0  0    0           0        0   \n",
       "249             4.1     120000       0  0    0           0        0   \n",
       "250             4.1  1000000.0       0  0    0           0        0   \n",
       "251             3.4     700000       0  0    0           0        0   \n",
       "252             4.2     700000       0  0    0           0        0   \n",
       "253             4.2     120000       0  0    0           0        0   \n",
       "254             3.9    1300000       1  0    1           0        0   \n",
       "255             3.6     800000       0  0    0           0        0   \n",
       "258             4.1     400000       0  0    0           0        0   \n",
       "259             3.9  1080000.0       0  0    0           0        0   \n",
       "260             3.5     400000       0  0    0           0        0   \n",
       "261             4.5    1000000       1  0    0           0        0   \n",
       "262             3.7    1000000       0  0    0           0        0   \n",
       "263             3.9     500000       0  0    0           0        0   \n",
       "264             3.9   120000.0       1  0    0           0        0   \n",
       "265             3.4     800000       0  0    0           0        0   \n",
       "266             3.9     500000       0  0    0           0        0   \n",
       "267             3.6     400000       0  0    0           0        0   \n",
       "268             3.9     9000.0       1  0    0           0        0   \n",
       "269             3.9  1800000.0       1  1    0           0        0   \n",
       "271             4.2     700000       1  1    1           0        0   \n",
       "276             4.1     600000       0  0    0           0        0   \n",
       "277             3.9     600000       0  1    0           0        0   \n",
       "278             5.0     300000       0  0    0           0        0   \n",
       "279             4.0     900000       0  0    0           0        0   \n",
       "280             3.5     800000       1  1    1           0        1   \n",
       "281             3.6     600000       1  0    1           1        1   \n",
       "282             3.8     700000       1  1    1           0        0   \n",
       "283             3.9    60000.0       0  0    0           0        0   \n",
       "284             3.9    1164000       0  0    0           0        0   \n",
       "285             3.8     700000       0  0    0           0        0   \n",
       "286             3.1     400000       0  0    0           0        0   \n",
       "287             3.5     600000       1  0    0           0        0   \n",
       "288             3.8     700000       0  0    0           0        0   \n",
       "289             4.4     900000       0  0    0           0        0   \n",
       "290             3.8     400000       0  0    0           0        0   \n",
       "291             4.3    1200000       1  1    0           0        0   \n",
       "292             3.4     700000       0  0    0           0        0   \n",
       "293             4.0  1000000.0       0  0    0           0        0   \n",
       "294             3.9    1000000       1  0    0           0        0   \n",
       "295             3.8     700000       0  0    0           0        0   \n",
       "296             4.0     500000       1  0    1           0        0   \n",
       "297             3.5    1200000       1  1    1           0        0   \n",
       "298             2.7     400000       0  0    0           0        0   \n",
       "299             3.7    1200000       0  0    0           0        0   \n",
       "300             3.7     600000       0  0    0           0        0   \n",
       "303             4.1     400000       0  0    0           0        0   \n",
       "304             3.8     600000       1  0    0           0        0   \n",
       "305             3.4     500000       0  0    0           0        0   \n",
       "306             3.9     180000       0  1    0           1        1   \n",
       "307             3.9   120000.0       0  0    0           0        0   \n",
       "308             4.4     700000       0  0    0           0        0   \n",
       "309             3.9    1200000       1  0    0           0        0   \n",
       "310             3.9    1800000       0  0    0           0        0   \n",
       "311             4.7    4300000       0  0    0           0        0   \n",
       "312             3.3     700000       0  0    0           0        0   \n",
       "313             4.0     400000       0  0    0           0        0   \n",
       "314             4.1  1000000.0       1  0    0           0        0   \n",
       "315             3.9   180000.0       0  0    0           0        0   \n",
       "316             4.7     500000       0  0    0           0        0   \n",
       "317             4.0     500000       0  0    0           0        0   \n",
       "318             3.5     600000       1  0    1           0        0   \n",
       "319             2.6     500000       0  0    0           0        0   \n",
       "320             3.4     400000       0  0    0           0        0   \n",
       "321             3.9     700000       1  0    0           1        1   \n",
       "322             3.9    1100000       1  0    0           0        1   \n",
       "323             3.8    1200000       0  0    0           0        0   \n",
       "324             4.4     400000       0  0    0           0        0   \n",
       "325             4.0     600000       0  0    0           0        0   \n",
       "326             3.9     360000       0  0    0           0        0   \n",
       "327             4.0     600000       0  0    0           0        0   \n",
       "328             4.1     200000       1  0    1           0        0   \n",
       "329             3.9   120000.0       0  0    0           0        0   \n",
       "330             3.7     500000       0  0    0           0        0   \n",
       "334             3.4     600000       1  0    1           0        0   \n",
       "335             4.2   200000.0       0  0    0           0        0   \n",
       "336             3.8     600000       0  0    0           0        0   \n",
       "337             3.7     800000       0  0    0           0        0   \n",
       "338             3.5     600000       1  0    1           0        0   \n",
       "339             1.0    2800000       0  0    0           0        0   \n",
       "340             4.2     500000       0  0    0           0        0   \n",
       "341             3.4     400000       0  0    0           0        0   \n",
       "342             3.3    1500000       0  0    0           0        0   \n",
       "343             3.9  1800000.0       0  0    0           0        0   \n",
       "344             3.5     500000       0  0    0           0        0   \n",
       "345             5.0     500000       0  0    0           0        0   \n",
       "346             4.3     700000       0  0    0           0        0   \n",
       "347             4.5     300000       0  0    0           0        0   \n",
       "348             3.7     400000       0  0    0           0        0   \n",
       "349             3.8     600000       0  0    0           0        0   \n",
       "350             4.1     200000       0  0    0           0        0   \n",
       "351             3.7     300000       0  0    0           0        0   \n",
       "352             3.7     400000       1  0    0           0        1   \n",
       "353             3.8     400000       0  0    0           0        0   \n",
       "354             4.0     500000       0  0    0           0        0   \n",
       "355             3.2     120000       0  0    0           0        0   \n",
       "356             4.0     700000       0  0    0           0        0   \n",
       "357             3.9     900000       0  0    0           0        0   \n",
       "358             4.1     500000       0  0    0           0        0   \n",
       "359             4.0     400000       0  0    0           0        0   \n",
       "361             3.6     500000       0  0    0           0        0   \n",
       "362             3.7     800000       0  0    0           0        0   \n",
       "363             4.6     800000       0  0    1           0        0   \n",
       "364             3.5     500000       1  1    1           0        0   \n",
       "365             3.9  2044153.0       1  1    1           1        1   \n",
       "366             4.5     400000       0  0    0           0        0   \n",
       "367             3.7     600000       0  0    0           0        0   \n",
       "368             3.7     400000       0  0    0           0        0   \n",
       "369             4.0    1000000       0  0    0           0        0   \n",
       "370             3.3     600000       0  0    0           0        0   \n",
       "371             3.4     500000       0  0    0           0        0   \n",
       "372             3.6     900000       1  1    0           0        0   \n",
       "373             4.3     500000       0  0    0           0        0   \n",
       "374             3.8     600000       0  0    0           0        0   \n",
       "375             4.3    2000000       0  0    0           0        0   \n",
       "376             4.0     800000       0  0    0           0        0   \n",
       "377             4.1     700000       0  0    0           0        0   \n",
       "378             4.5     500000       1  0    0           0        1   \n",
       "379             4.0     500000       0  0    0           0        0   \n",
       "380             3.0     400000       0  0    0           0        0   \n",
       "381             4.0     400000       0  0    0           0        0   \n",
       "382             3.9     900000       0  0    0           0        0   \n",
       "383             3.8    3000000       0  0    0           0        0   \n",
       "384             3.8     700000       0  0    0           0        0   \n",
       "385             3.1     700000       0  0    0           0        0   \n",
       "386             3.8     600000       0  0    0           0        0   \n",
       "387             3.9    1000000       0  0    0           0        0   \n",
       "388             4.2     600000       1  0    1           1        1   \n",
       "389             3.8    8000000       0  0    0           1        1   \n",
       "392             4.2     800000       0  0    0           0        0   \n",
       "396             3.8     400000       0  0    0           0        0   \n",
       "397             4.3     900000       0  0    0           0        0   \n",
       "398             4.0     900000       0  0    0           0        0   \n",
       "399             4.1     600000       0  0    0           0        0   \n",
       "400             3.3     700000       1  0    1           0        0   \n",
       "402             3.9     900000       1  0    0           0        0   \n",
       "403             4.1     400000       0  0    0           0        0   \n",
       "404             3.4     700000       1  0    0           0        0   \n",
       "405             4.2     400000       0  1    0           0        0   \n",
       "406             4.0     300000       0  0    0           0        0   \n",
       "407             4.1     700000       1  0    0           0        1   \n",
       "408             3.6     500000       1  1    0           1        1   \n",
       "409             4.6     120000       1  0    0           0        0   \n",
       "410             3.8     700000       0  0    0           0        0   \n",
       "411             3.4     700000       0  0    0           0        0   \n",
       "412             3.6  1000000.0       0  0    0           0        0   \n",
       "413             3.8     500000       0  0    0           0        0   \n",
       "414             3.9    1664000       1  0    0           0        0   \n",
       "415             3.8     360000       0  0    0           0        0   \n",
       "416             3.2     300000       0  0    0           0        0   \n",
       "417             4.5     120000       0  0    0           0        0   \n",
       "418             3.9    1500000       1  0    0           0        0   \n",
       "419             2.7     800000       0  0    0           0        0   \n",
       "423             3.4     800000       0  0    0           0        0   \n",
       "424             4.0     700000       0  0    0           0        0   \n",
       "425             3.7     120000       1  0    0           0        1   \n",
       "426             3.7   900000.0       1  1    0           0        0   \n",
       "427             4.0     800000       0  0    0           0        0   \n",
       "428             3.6     500000       1  0    0           0        0   \n",
       "429             3.9    2000000       1  0    0           0        0   \n",
       "430             3.9  1400000.0       0  0    0           0        0   \n",
       "431             4.0     800000       0  0    0           0        0   \n",
       "432             4.7     800000       1  1    1           0        0   \n",
       "433             4.3  1000000.0       0  0    0           0        0   \n",
       "434             4.2     700000       0  0    0           0        0   \n",
       "435             3.9     400000       0  0    0           0        0   \n",
       "436             3.6     800000       1  0    1           0        0   \n",
       "437             3.8     800000       0  0    0           0        0   \n",
       "438             4.0     600000       0  0    0           0        0   \n",
       "439             3.8     700000       0  0    0           0        0   \n",
       "440             3.2     600000       1  0    0           0        0   \n",
       "441             3.9    1800000       0  0    0           0        0   \n",
       "442             4.0    2000000       0  0    0           0        0   \n",
       "443             3.9     500000       0  0    0           0        0   \n",
       "444             3.6     800000       0  0    0           0        0   \n",
       "445             3.9   400000.0       0  0    0           0        0   \n",
       "446             4.4     120000       0  0    0           0        0   \n",
       "447             3.4   500000.0       0  0    0           0        0   \n",
       "448             3.8   800000.0       0  0    0           0        0   \n",
       "449             3.6     700000       0  0    0           0        0   \n",
       "455             4.1     500000       1  0    0           0        0   \n",
       "456             3.9     240000       0  1    0           0        0   \n",
       "457             3.8     200000       0  0    0           0        0   \n",
       "458             5.0     300000       1  0    1           0        0   \n",
       "459             3.6     600000       0  0    0           0        0   \n",
       "460             4.1     300000       1  0    0           0        0   \n",
       "461             3.9   200000.0       0  0    0           0        0   \n",
       "462             3.7    1000000       0  0    0           0        0   \n",
       "463             3.8     600000       0  0    0           0        0   \n",
       "464             3.9  1000000.0       0  0    0           0        0   \n",
       "465             5.0     800000       0  0    0           0        0   \n",
       "466             4.5    1000000       0  0    0           0        0   \n",
       "467             4.0   480000.0       0  0    0           0        0   \n",
       "468             3.4     500000       0  0    0           0        0   \n",
       "469             3.7     108000       0  0    0           0        0   \n",
       "470             3.9    1248000       1  0    0           0        0   \n",
       "471             3.8    1000000       0  0    0           0        0   \n",
       "472             4.2     600000       0  1    0           0        0   \n",
       "473             4.2     600000       0  0    0           0        0   \n",
       "474             3.8     600000       0  0    0           0        0   \n",
       "475             4.3     400000       0  0    0           0        0   \n",
       "476             4.2   520000.0       0  0    0           0        0   \n",
       "477             2.9     900000       0  0    0           0        0   \n",
       "478             3.9     900000       0  0    0           0        0   \n",
       "479             3.9    1300000       1  0    0           0        0   \n",
       "484             4.1     200000       0  0    0           0        0   \n",
       "485             4.3     400000       1  1    1           0        0   \n",
       "486             3.7   200000.0       0  0    0           0        0   \n",
       "487             4.2    4000000       1  0    0           0        0   \n",
       "488             4.3     400000       0  0    0           0        0   \n",
       "489             3.9    1300000       0  0    0           0        0   \n",
       "491             3.0     120000       1  0    0           0        0   \n",
       "492             3.5  1200000.0       0  0    0           0        0   \n",
       "493             3.8     600000       0  0    0           0        0   \n",
       "494             3.8     700000       1  0    0           0        0   \n",
       "495             4.0     400000       0  0    0           0        0   \n",
       "496             3.9    2400000       1  0    0           0        0   \n",
       "497             4.2   800000.0       1  1    1           0        0   \n",
       "498             3.6     600000       0  0    0           0        0   \n",
       "499             4.2     500000       0  0    0           0        0   \n",
       "500             4.0     500000       0  1    0           0        0   \n",
       "501             3.9    1500000       1  0    0           0        0   \n",
       "502             4.0     800000       0  0    0           0        0   \n",
       "503             4.7     540000       1  0    0           0        0   \n",
       "504             3.9   120000.0       0  0    0           0        0   \n",
       "505             3.8     700000       0  0    0           0        0   \n",
       "506             3.9     500000       0  0    0           0        0   \n",
       "507             3.9     396000       1  1    0           0        0   \n",
       "508             3.8     500000       0  0    0           0        0   \n",
       "509             4.0     400000       0  0    0           0        0   \n",
       "510             3.9     360000       0  0    0           0        0   \n",
       "511             5.0    2000000       0  0    0           0        0   \n",
       "512             3.9     700000       0  0    0           0        0   \n",
       "513             3.1     700000       0  0    0           0        0   \n",
       "514             3.9     120000       0  0    0           0        0   \n",
       "515             3.7    1200000       1  0    0           0        0   \n",
       "516             3.9     600000       0  0    0           0        0   \n",
       "517             3.7     600000       0  0    0           0        0   \n",
       "518             3.8     500000       0  0    0           0        0   \n",
       "519             3.9     500000       0  0    0           0        0   \n",
       "520             3.3     600000       1  1    0           1        1   \n",
       "521             4.1    2000000       1  0    1           0        0   \n",
       "522             3.7     800000       0  0    0           0        0   \n",
       "523             3.9    1000000       0  0    0           0        0   \n",
       "524             4.0  1500000.0       1  0    0           1        1   \n",
       "525             3.8  1000000.0       0  0    0           0        0   \n",
       "526             3.9   120000.0       0  0    0           0        0   \n",
       "527             4.5     400000       1  0    0           0        0   \n",
       "528             4.3     500000       0  0    0           0        0   \n",
       "529             3.8     600000       1  1    0           0        0   \n",
       "530             3.8     500000       0  0    0           0        0   \n",
       "531             4.2    1200000       0  0    0           0        0   \n",
       "532             3.8     900000       0  0    0           0        0   \n",
       "534             5.0     500000       1  0    1           1        1   \n",
       "535             3.7     800000       0  0    0           0        0   \n",
       "536             3.9   120000.0       0  0    0           0        0   \n",
       "537             3.8     300000       0  0    0           0        0   \n",
       "538             2.3    2000000       0  0    0           0        0   \n",
       "539             3.8     400000       0  0    0           0        0   \n",
       "543             4.0     800000       0  0    0           0        0   \n",
       "544             3.3  1000000.0       0  0    0           0        0   \n",
       "545             4.0     700000       0  0    0           0        0   \n",
       "546             3.9     540000       1  0    0           0        0   \n",
       "547             4.1    1200000       0  0    0           0        0   \n",
       "548             3.9     900000       0  0    0           0        0   \n",
       "549             3.4     400000       0  0    0           0        0   \n",
       "550             3.4     700000       0  0    0           0        0   \n",
       "551             4.1     120000       0  0    0           0        0   \n",
       "552             4.5     500000       0  0    0           0        0   \n",
       "553             3.5   600000.0       0  0    0           0        0   \n",
       "554             3.9     300000       0  0    0           0        0   \n",
       "555             4.0     600000       0  0    0           0        0   \n",
       "556             3.8     500000       1  1    0           0        0   \n",
       "557             4.3     700000       0  0    0           0        0   \n",
       "558             4.0     700000       0  0    0           0        0   \n",
       "559             3.9    1000000       0  0    0           0        0   \n",
       "560             3.9     240000       1  0    0           0        0   \n",
       "561             5.0    2400000       0  0    0           0        0   \n",
       "562             3.9    2900000       1  1    1           0        0   \n",
       "563             2.9     300000       0  0    0           0        0   \n",
       "564             3.7     700000       0  0    0           0        0   \n",
       "565             3.0     800000       0  0    0           0        0   \n",
       "566             3.9    1000000       1  1    0           0        0   \n",
       "567             4.1     700000       0  0    0           0        0   \n",
       "568             3.9     900000       0  0    0           0        0   \n",
       "569             4.0     500000       0  0    0           0        0   \n",
       "570             3.5     400000       1  0    1           0        0   \n",
       "571             3.6     700000       1  1    1           0        0   \n",
       "572             3.7     400000       1  1    0           0        0   \n",
       "573             3.9     276000       0  0    0           0        0   \n",
       "574             3.6     600000       0  0    0           0        0   \n",
       "575             3.6     700000       0  0    0           0        0   \n",
       "576             4.4     400000       0  0    0           0        0   \n",
       "577             4.5     800000       0  0    0           0        0   \n",
       "578             2.9     700000       0  0    0           0        0   \n",
       "579             3.9  1000000.0       0  0    0           0        0   \n",
       "580             3.7     700000       0  0    0           0        0   \n",
       "581             4.1     900000       0  0    0           0        0   \n",
       "582             3.2     500000       0  0    0           0        0   \n",
       "583             3.8     600000       0  0    0           0        0   \n",
       "584             3.7    1500000       0  0    0           0        0   \n",
       "585             4.0     500000       0  0    0           0        0   \n",
       "586             3.8   800000.0       0  0    0           0        0   \n",
       "587             3.9  2400000.0       1  0    0           0        0   \n",
       "588             4.1     500000       0  0    0           0        0   \n",
       "589             4.4    1000000       0  0    0           0        0   \n",
       "590             3.7     500000       0  0    0           0        0   \n",
       "591             3.7     500000       0  0    0           0        0   \n",
       "592             3.7     800000       0  0    0           0        0   \n",
       "593             3.9     800000       0  0    0           0        0   \n",
       "594             3.8     600000       0  0    0           0        0   \n",
       "595             4.3     500000       1  0    0           0        0   \n",
       "596             4.1     800000       0  0    0           0        0   \n",
       "597             3.7     500000       0  0    0           0        0   \n",
       "598             3.4     700000       1  0    0           0        0   \n",
       "599             3.9   600000.0       1  0    0           1        1   \n",
       "601             3.9     700000       1  1    1           0        0   \n",
       "602             4.1     900000       0  0    0           0        0   \n",
       "603             3.6     800000       1  0    1           1        1   \n",
       "604             3.4     600000       0  0    0           0        0   \n",
       "605             4.5     800000       0  0    0           0        0   \n",
       "606             4.2   200000.0       0  0    0           0        0   \n",
       "607             3.5     400000       0  0    0           0        0   \n",
       "608             4.2     800000       0  0    0           0        0   \n",
       "609             3.8   600000.0       0  0    0           0        0   \n",
       "610             4.2   520000.0       0  0    0           0        0   \n",
       "611             3.9     360000       0  1    0           0        0   \n",
       "612             3.9    1000000       1  0    1           1        1   \n",
       "613             3.8     600000       0  0    0           0        0   \n",
       "614             4.1     500000       0  0    0           0        0   \n",
       "615             3.6   800000.0       0  1    0           0        0   \n",
       "616             4.5     600000       0  0    0           0        0   \n",
       "617             3.7    2300000       0  0    1           0        0   \n",
       "618             4.2  2200000.0       0  0    0           0        0   \n",
       "619             4.0     900000       0  0    0           0        0   \n",
       "620             3.2   300000.0       0  0    0           0        0   \n",
       "621             4.1     200000       0  0    0           0        0   \n",
       "622             3.7   400000.0       0  0    0           0        0   \n",
       "623             4.3     500000       0  0    0           0        0   \n",
       "624             4.0     600000       0  0    0           0        0   \n",
       "625             2.1     500000       0  0    0           0        0   \n",
       "626             3.9     500000       0  0    0           0        0   \n",
       "627             2.9     600000       0  0    0           0        0   \n",
       "628             4.1     600000       0  0    0           0        0   \n",
       "634             3.9     600000       0  0    0           0        0   \n",
       "635             5.0     600000       0  0    0           0        0   \n",
       "636             3.9    2400000       1  0    0           0        0   \n",
       "637             3.9    1200000       0  0    0           0        0   \n",
       "638             4.5     120000       0  0    0           0        0   \n",
       "639             3.9     400000       0  0    0           0        0   \n",
       "640             3.9     120000       0  0    0           0        0   \n",
       "642             4.1     700000       0  0    0           0        0   \n",
       "643             4.0     900000       0  0    0           0        0   \n",
       "644             3.9    1000000       0  0    0           0        0   \n",
       "645             4.1     500000       0  0    0           0        0   \n",
       "646             1.0    3800000       0  0    0           0        0   \n",
       "647             4.2   400000.0       0  0    0           0        0   \n",
       "648             4.2     800000       0  0    0           0        0   \n",
       "649             4.1     700000       0  0    1           0        0   \n",
       "650             3.9    2500000       1  0    1           0        0   \n",
       "651             3.6     700000       0  0    0           0        0   \n",
       "652             4.1     400000       0  0    0           0        0   \n",
       "653             4.0     800000       0  0    0           0        0   \n",
       "654             4.2    1500000       0  0    0           0        0   \n",
       "655             3.9      77000       0  0    0           0        0   \n",
       "656             3.8     800000       0  0    0           1        1   \n",
       "657             4.1     900000       0  0    0           0        0   \n",
       "658             3.6     600000       0  0    0           0        0   \n",
       "659             4.2     600000       0  0    1           0        0   \n",
       "660             3.7  1000000.0       0  0    0           0        0   \n",
       "661             4.0     500000       1  1    1           0        0   \n",
       "662             3.9     500000       0  0    0           0        0   \n",
       "663             3.9     400000       0  0    0           0        0   \n",
       "664             3.4     700000       0  0    0           0        0   \n",
       "665             3.6     800000       0  0    0           0        0   \n",
       "666             3.9     900000       0  0    0           0        0   \n",
       "667             3.9     800000       0  0    0           0        0   \n",
       "668             3.9    1300000       1  0    1           1        1   \n",
       "669             4.1     700000       0  0    0           0        0   \n",
       "670             4.2     800000       0  0    0           0        0   \n",
       "671             3.4     900000       0  0    0           0        0   \n",
       "672             3.4    1140000       0  0    0           0        0   \n",
       "673             4.4     700000       0  0    0           0        0   \n",
       "674             3.7  1000000.0       0  0    0           0        0   \n",
       "675             3.6     600000       0  1    0           0        0   \n",
       "676             3.7    1000000       0  0    0           0        0   \n",
       "677             4.4    3000000       1  0    0           1        1   \n",
       "678             3.7     200000       0  0    0           0        0   \n",
       "679             3.9    1000000       0  0    0           0        0   \n",
       "680             3.9     700000       0  0    0           0        0   \n",
       "681             3.8    2000000       1  0    1           0        0   \n",
       "682             4.4   400000.0       1  0    0           0        0   \n",
       "683             4.1     600000       0  0    0           0        0   \n",
       "684             4.4    1000000       0  0    0           0        0   \n",
       "685             4.0     300000       0  0    0           0        0   \n",
       "686             3.7  1000000.0       0  0    0           0        0   \n",
       "687             3.2      96000       0  0    0           0        0   \n",
       "689             4.3     700000       0  0    0           0        0   \n",
       "690             4.2     500000       0  0    0           0        0   \n",
       "691             3.6     400000       0  0    0           0        0   \n",
       "692             4.0     900000       0  0    0           0        0   \n",
       "693             3.4     800000       1  0    0           1        1   \n",
       "694             3.7  1000000.0       0  0    0           0        0   \n",
       "695             3.8     600000       0  0    0           0        0   \n",
       "696             3.6     300000       0  0    0           0        0   \n",
       "697             3.5     900000       0  0    0           0        0   \n",
       "698             3.2     300000       0  0    0           0        0   \n",
       "699             3.8   700000.0       0  0    0           0        0   \n",
       "700             3.9     900000       0  0    0           0        0   \n",
       "701             3.9    5300000       0  0    0           0        0   \n",
       "702             3.7     800000       0  0    0           0        0   \n",
       "703             3.8     600000       0  0    0           0        0   \n",
       "704             3.9    18000.0       1  0    0           0        0   \n",
       "705             4.1     800000       0  0    0           0        0   \n",
       "706             3.7    1000000       0  0    0           0        0   \n",
       "707             4.2   300000.0       0  0    0           0        0   \n",
       "708             3.6     800000       0  0    0           0        0   \n",
       "709             3.3     300000       0  0    0           0        0   \n",
       "710             3.4     480000       1  0    0           0        0   \n",
       "711             3.4     900000       0  0    0           0        0   \n",
       "712             4.1     500000       0  0    0           0        0   \n",
       "713             3.9    1600000       0  0    0           0        0   \n",
       "714             3.9     800000       0  0    0           0        0   \n",
       "715             3.8     700000       0  0    0           0        0   \n",
       "716             4.3     400000       1  1    1           0        0   \n",
       "717             3.6     600000       1  1    1           0        0   \n",
       "718             3.9    2800000       1  0    1           1        1   \n",
       "719             4.3     800000       0  0    0           0        0   \n",
       "720             3.6     800000       0  0    0           0        0   \n",
       "721             4.0     400000       0  0    0           0        0   \n",
       "722             3.9     900000       0  0    0           0        0   \n",
       "723             3.9    1200000       0  0    0           0        0   \n",
       "724             4.8     900000       0  0    0           0        0   \n",
       "725             3.9     792000       0  0    0           0        0   \n",
       "726             5.0     300000       0  0    0           0        0   \n",
       "727             4.1     500000       0  0    0           0        0   \n",
       "728             4.0     700000       0  0    0           0        0   \n",
       "729             4.2     400000       0  1    0           0        0   \n",
       "730             3.9     700000       0  0    0           0        0   \n",
       "731             3.9  1000000.0       0  0    0           0        0   \n",
       "732             4.1     400000       0  0    0           0        0   \n",
       "733             3.6     900000       0  0    0           0        0   \n",
       "734             3.7     800000       0  0    0           0        0   \n",
       "735             3.9  1100000.0       0  0    0           0        0   \n",
       "736             3.9    3700000       0  0    0           0        0   \n",
       "737             3.5     400000       0  0    0           0        0   \n",
       "738             3.9     700000       1  1    1           1        1   \n",
       "739             3.9    1400000       0  0    0           0        0   \n",
       "740             4.0     400000       0  0    0           0        0   \n",
       "741             4.6   600000.0       0  0    0           1        1   \n",
       "742             3.0    1500000       0  0    0           0        0   \n",
       "743             4.0    1000000       1  1    0           0        0   \n",
       "744             3.6     600000       0  0    0           0        0   \n",
       "745             3.9     400000       1  0    0           0        0   \n",
       "746             4.1     600000       0  0    0           0        0   \n",
       "747             3.9    2500000       1  0    0           1        1   \n",
       "748             3.9   100000.0       0  0    0           0        0   \n",
       "749             3.6     600000       1  0    0           0        0   \n",
       "753             4.4     900000       1  1    1           0        0   \n",
       "754             4.8    1200000       1  0    0           1        0   \n",
       "755             3.6     300000       0  0    0           0        0   \n",
       "756             3.8     800000       0  0    0           0        0   \n",
       "757             4.7     300000       0  0    0           0        0   \n",
       "758             4.2   400000.0       0  0    0           0        0   \n",
       "759             3.9    2400000       0  0    0           0        0   \n",
       "760             4.3  1000000.0       0  0    0           0        0   \n",
       "762             3.8     300000       0  0    0           0        0   \n",
       "763             3.6     600000       1  0    0           0        0   \n",
       "764             3.1     800000       0  0    0           0        0   \n",
       "765             3.8     800000       0  0    0           0        0   \n",
       "766             3.9     600000       0  0    0           0        0   \n",
       "767             3.9     900000       0  0    0           0        0   \n",
       "768             4.0     120000       0  0    0           0        0   \n",
       "769             4.4     800000       0  0    0           0        0   \n",
       "770             4.1     240000       1  1    0           0        0   \n",
       "771             3.5      93000       0  0    0           0        0   \n",
       "772             3.8    7000000       1  1    0           0        0   \n",
       "773             3.9     216000       0  0    0           0        0   \n",
       "774             3.9     900000       0  0    0           0        0   \n",
       "775             3.9    1200000       0  0    0           0        0   \n",
       "776             3.1    1600000       0  0    0           0        0   \n",
       "777             4.0     600000       0  0    0           0        0   \n",
       "778             3.0     400000       0  0    0           0        0   \n",
       "779             4.1     300000       1  0    0           0        0   \n",
       "783             3.6     600000       0  0    0           0        0   \n",
       "784             4.4     400000       0  0    0           0        0   \n",
       "785             3.8  1000000.0       1  0    0           0        1   \n",
       "786             3.6     700000       0  0    0           0        0   \n",
       "787             3.9     492000       0  0    0           0        0   \n",
       "788             3.9     600000       0  0    0           0        0   \n",
       "789             3.9   300000.0       1  0    1           1        1   \n",
       "790             3.4     660000       1  0    0           0        0   \n",
       "791             3.5     800000       0  0    0           0        0   \n",
       "792             3.9     600000       1  0    0           0        0   \n",
       "793             3.7     800000       0  0    0           0        0   \n",
       "795             2.8     600000       0  0    0           0        0   \n",
       "796             3.4     500000       0  0    0           0        0   \n",
       "797             4.3     600000       0  0    0           0        0   \n",
       "798             3.6     700000       0  0    0           0        0   \n",
       "799             3.9     720000       1  0    0           0        0   \n",
       "800             4.2     800000       1  0    0           0        0   \n",
       "801             4.4     600000       0  0    0           0        0   \n",
       "802             4.3     500000       1  1    0           0        0   \n",
       "803             4.5     800000       0  0    0           0        0   \n",
       "804             3.6     500000       0  0    0           0        0   \n",
       "805             3.9     900000       1  0    1           0        0   \n",
       "806             3.4     960000       0  0    0           0        1   \n",
       "807             3.9    1200000       1  0    1           0        0   \n",
       "808             3.8     600000       0  0    0           0        0   \n",
       "809             4.6      50000       0  0    0           1        0   \n",
       "813             3.7     600000       0  0    1           0        0   \n",
       "814             4.7     300000       0  0    0           0        0   \n",
       "815             4.3    8000000       1  1    0           0        0   \n",
       "816             3.9   180000.0       1  0    1           1        1   \n",
       "817             3.6     800000       0  0    0           0        0   \n",
       "818             3.5     600000       0  0    0           0        0   \n",
       "819             4.1     600000       0  0    0           0        0   \n",
       "820             3.9    1500000       1  0    0           1        1   \n",
       "821             4.1     120000       0  0    0           0        0   \n",
       "822             3.9     900000       0  0    0           0        0   \n",
       "823             5.0     500000       0  0    0           0        0   \n",
       "824             3.9     600000       1  0    0           0        0   \n",
       "825             4.1  1000000.0       0  0    0           0        0   \n",
       "826             3.6     400000       0  0    0           0        0   \n",
       "827             4.0    1200000       0  0    0           0        0   \n",
       "828             3.9     500000       0  0    0           0        0   \n",
       "829             3.7     600000       0  0    0           0        0   \n",
       "830             3.8     600000       0  0    0           0        0   \n",
       "831             4.2    2000000       1  0    0           1        1   \n",
       "832             3.8     600000       0  0    0           0        0   \n",
       "833             4.1     600000       0  0    0           0        0   \n",
       "834             3.8     600000       0  0    0           0        0   \n",
       "\n",
       "     data analysis  statistics  machine learning  deep learning  nlp  ai  \\\n",
       "0                0           0                 1              0    1   1   \n",
       "1                0           1                 0              0    0   1   \n",
       "2                0           0                 0              0    0   1   \n",
       "3                0           0                 0              0    0   0   \n",
       "4                0           0                 1              0    0   0   \n",
       "5                0           0                 1              0    0   0   \n",
       "6                0           0                 0              0    0   0   \n",
       "7                0           0                 0              0    0   0   \n",
       "8                1           1                 0              0    0   0   \n",
       "9                1           1                 1              0    0   0   \n",
       "10               1           1                 1              0    0   0   \n",
       "11               0           0                 1              0    1   1   \n",
       "12               0           0                 0              0    0   0   \n",
       "13               0           0                 1              0    1   1   \n",
       "14               0           0                 1              0    1   0   \n",
       "15               0           1                 0              0    0   0   \n",
       "16               0           0                 1              0    0   0   \n",
       "17               1           0                 0              0    0   0   \n",
       "18               0           0                 0              0    0   0   \n",
       "19               0           1                 1              0    1   0   \n",
       "20               0           0                 1              0    0   0   \n",
       "21               0           0                 0              0    0   0   \n",
       "22               1           0                 1              0    0   0   \n",
       "23               0           0                 0              0    0   1   \n",
       "24               0           0                 0              0    0   0   \n",
       "25               0           0                 1              0    0   0   \n",
       "26               0           0                 0              0    0   0   \n",
       "27               0           0                 0              0    0   0   \n",
       "28               0           0                 1              0    0   0   \n",
       "29               0           0                 0              0    0   0   \n",
       "30               0           0                 1              0    1   1   \n",
       "31               1           0                 0              0    0   0   \n",
       "32               0           1                 1              0    0   0   \n",
       "33               0           1                 1              0    0   1   \n",
       "34               0           0                 1              0    0   0   \n",
       "35               0           0                 0              0    0   0   \n",
       "36               0           0                 0              0    0   0   \n",
       "37               0           0                 0              0    0   0   \n",
       "38               1           1                 1              0    1   1   \n",
       "39               0           0                 1              1    0   0   \n",
       "40               0           0                 1              0    1   0   \n",
       "41               0           0                 1              0    0   1   \n",
       "42               0           0                 1              0    0   0   \n",
       "43               0           0                 1              0    0   0   \n",
       "44               0           0                 0              0    0   0   \n",
       "45               1           1                 0              0    0   0   \n",
       "46               0           0                 1              0    0   0   \n",
       "47               0           1                 1              0    0   0   \n",
       "48               1           0                 0              0    0   0   \n",
       "49               1           0                 1              0    0   0   \n",
       "50               0           0                 1              0    0   0   \n",
       "51               0           1                 1              0    0   0   \n",
       "52               0           0                 1              0    0   0   \n",
       "53               0           0                 0              0    0   0   \n",
       "54               0           0                 0              0    0   0   \n",
       "55               0           0                 0              0    0   0   \n",
       "56               0           0                 1              0    1   1   \n",
       "57               0           0                 1              0    0   0   \n",
       "58               0           0                 1              0    0   0   \n",
       "59               0           0                 0              0    0   0   \n",
       "60               0           0                 1              0    0   1   \n",
       "61               0           0                 0              0    0   0   \n",
       "62               0           0                 0              0    0   0   \n",
       "63               0           1                 1              0    0   1   \n",
       "64               0           0                 0              0    0   0   \n",
       "65               0           1                 1              0    0   0   \n",
       "66               0           0                 0              0    0   0   \n",
       "67               0           0                 0              0    0   0   \n",
       "68               0           0                 0              0    0   0   \n",
       "69               0           0                 0              0    0   1   \n",
       "70               0           0                 0              0    0   0   \n",
       "71               0           0                 0              0    0   0   \n",
       "72               0           0                 0              0    0   0   \n",
       "73               0           1                 0              0    0   0   \n",
       "74               1           1                 1              0    0   0   \n",
       "75               0           1                 1              1    0   0   \n",
       "76               0           0                 0              0    0   0   \n",
       "77               0           0                 1              0    0   1   \n",
       "78               0           0                 0              0    0   0   \n",
       "79               1           0                 1              0    0   0   \n",
       "80               0           0                 0              0    0   0   \n",
       "81               0           0                 0              0    0   0   \n",
       "82               1           1                 1              1    0   0   \n",
       "83               0           0                 1              0    0   0   \n",
       "84               0           0                 0              0    0   0   \n",
       "85               0           0                 0              0    0   0   \n",
       "86               0           0                 0              0    0   0   \n",
       "87               0           0                 0              0    0   0   \n",
       "88               1           0                 1              0    0   0   \n",
       "89               0           0                 0              0    1   0   \n",
       "91               1           1                 1              0    0   0   \n",
       "92               0           0                 0              0    0   0   \n",
       "93               0           0                 0              0    0   0   \n",
       "94               0           0                 0              0    0   0   \n",
       "95               0           0                 0              0    0   0   \n",
       "96               0           0                 1              0    1   1   \n",
       "97               0           0                 0              0    0   0   \n",
       "98               0           0                 0              0    0   0   \n",
       "99               0           1                 1              0    0   0   \n",
       "100              0           1                 1              1    0   0   \n",
       "101              0           0                 1              0    0   0   \n",
       "102              1           1                 1              0    0   0   \n",
       "103              0           1                 1              0    0   0   \n",
       "104              0           0                 0              0    0   0   \n",
       "105              0           0                 0              0    0   0   \n",
       "106              0           1                 1              0    0   0   \n",
       "107              0           0                 1              1    1   1   \n",
       "109              0           1                 1              1    0   0   \n",
       "110              0           0                 0              0    0   0   \n",
       "111              0           0                 1              0    0   0   \n",
       "112              0           0                 0              0    0   0   \n",
       "113              0           0                 0              0    0   0   \n",
       "114              0           1                 0              0    0   0   \n",
       "115              0           0                 0              0    0   0   \n",
       "116              0           1                 1              0    0   0   \n",
       "117              0           0                 0              0    0   0   \n",
       "118              1           0                 0              0    0   0   \n",
       "119              0           0                 0              0    0   0   \n",
       "121              1           1                 1              0    1   0   \n",
       "123              0           0                 0              0    0   1   \n",
       "124              1           1                 1              0    0   0   \n",
       "125              0           0                 0              0    0   0   \n",
       "127              0           0                 1              0    0   0   \n",
       "128              0           0                 0              0    0   0   \n",
       "129              0           0                 0              0    0   0   \n",
       "130              0           0                 0              0    0   0   \n",
       "131              0           0                 0              0    0   0   \n",
       "132              0           0                 0              0    0   0   \n",
       "133              0           0                 1              0    0   0   \n",
       "134              0           0                 0              0    0   0   \n",
       "135              0           0                 1              1    0   0   \n",
       "136              0           1                 1              0    0   0   \n",
       "137              0           0                 1              0    0   0   \n",
       "138              1           1                 1              0    0   0   \n",
       "139              0           1                 0              0    0   0   \n",
       "140              0           0                 1              0    0   0   \n",
       "141              0           0                 0              0    0   0   \n",
       "142              0           0                 0              0    0   0   \n",
       "143              1           1                 1              0    0   0   \n",
       "144              0           0                 0              0    0   0   \n",
       "145              0           0                 0              0    0   0   \n",
       "146              1           1                 1              0    0   0   \n",
       "147              0           0                 1              0    0   0   \n",
       "148              0           0                 1              1    0   1   \n",
       "149              0           0                 0              0    0   0   \n",
       "157              0           0                 0              0    0   0   \n",
       "158              0           0                 0              0    0   0   \n",
       "159              0           0                 1              0    1   1   \n",
       "160              0           0                 0              0    0   0   \n",
       "161              0           0                 0              0    0   0   \n",
       "162              0           1                 1              1    0   0   \n",
       "163              0           0                 1              0    0   0   \n",
       "164              0           0                 0              0    0   0   \n",
       "165              0           0                 1              0    1   1   \n",
       "166              0           0                 0              0    0   0   \n",
       "167              0           0                 0              0    0   0   \n",
       "168              0           0                 0              0    0   0   \n",
       "169              1           1                 1              0    0   0   \n",
       "170              0           0                 1              0    0   0   \n",
       "171              0           0                 0              0    0   0   \n",
       "172              1           1                 1              0    0   0   \n",
       "173              0           0                 0              0    1   0   \n",
       "174              0           0                 1              0    0   0   \n",
       "175              0           0                 1              0    1   1   \n",
       "176              0           0                 0              0    0   0   \n",
       "177              0           1                 0              0    0   0   \n",
       "178              0           0                 0              0    0   0   \n",
       "179              0           1                 0              0    0   0   \n",
       "180              0           0                 0              0    0   0   \n",
       "182              0           1                 1              0    0   1   \n",
       "183              0           0                 1              1    0   1   \n",
       "184              1           0                 0              0    0   0   \n",
       "185              0           0                 1              0    0   0   \n",
       "186              0           0                 0              0    0   0   \n",
       "187              0           1                 0              0    0   0   \n",
       "188              0           0                 1              0    1   0   \n",
       "189              0           0                 1              1    1   1   \n",
       "190              1           1                 0              0    0   0   \n",
       "191              0           1                 1              0    0   0   \n",
       "192              0           0                 1              0    0   0   \n",
       "193              1           0                 0              0    1   0   \n",
       "194              1           0                 0              0    0   0   \n",
       "195              1           1                 1              0    1   0   \n",
       "196              0           0                 0              0    0   0   \n",
       "197              0           0                 1              0    1   0   \n",
       "198              0           0                 1              0    0   0   \n",
       "199              0           0                 0              0    0   0   \n",
       "200              0           0                 0              0    0   0   \n",
       "201              0           0                 1              1    0   1   \n",
       "202              0           1                 1              0    0   0   \n",
       "203              0           0                 0              0    0   0   \n",
       "204              0           0                 0              0    0   0   \n",
       "205              0           0                 1              0    1   1   \n",
       "206              0           0                 1              0    1   0   \n",
       "207              0           0                 0              0    0   0   \n",
       "208              0           1                 1              0    0   0   \n",
       "209              0           0                 1              0    0   0   \n",
       "211              0           0                 0              0    0   0   \n",
       "215              1           1                 1              0    0   0   \n",
       "216              0           1                 1              1    0   1   \n",
       "217              1           0                 0              0    0   0   \n",
       "218              0           0                 0              0    0   0   \n",
       "219              0           1                 1              0    0   0   \n",
       "220              0           0                 0              0    0   0   \n",
       "221              0           0                 0              0    0   0   \n",
       "222              1           1                 1              0    0   0   \n",
       "223              1           0                 0              0    0   0   \n",
       "224              0           1                 1              0    0   0   \n",
       "225              1           0                 0              0    0   0   \n",
       "226              1           0                 0              0    0   0   \n",
       "227              0           0                 1              0    0   0   \n",
       "228              0           1                 1              0    0   0   \n",
       "229              0           0                 0              0    0   0   \n",
       "230              1           0                 0              0    0   0   \n",
       "231              0           0                 1              0    0   0   \n",
       "232              0           1                 0              0    0   0   \n",
       "233              0           0                 0              0    0   0   \n",
       "234              0           0                 1              0    0   0   \n",
       "235              0           0                 0              0    0   0   \n",
       "236              0           0                 1              1    1   1   \n",
       "237              0           0                 0              0    0   0   \n",
       "238              0           0                 0              0    0   0   \n",
       "239              0           0                 0              0    0   0   \n",
       "242              0           0                 1              1    0   0   \n",
       "243              1           1                 1              1    0   0   \n",
       "244              0           1                 0              0    0   0   \n",
       "245              0           0                 0              0    0   0   \n",
       "246              0           0                 0              0    0   0   \n",
       "247              0           0                 1              0    0   0   \n",
       "248              0           0                 1              0    0   1   \n",
       "249              1           0                 1              1    0   0   \n",
       "250              1           0                 0              0    0   0   \n",
       "251              0           1                 0              0    0   0   \n",
       "252              0           1                 1              0    0   0   \n",
       "253              0           0                 0              0    0   0   \n",
       "254              0           0                 0              0    0   1   \n",
       "255              0           0                 1              0    0   1   \n",
       "258              0           0                 1              1    0   0   \n",
       "259              0           0                 1              0    0   1   \n",
       "260              0           0                 0              0    0   0   \n",
       "261              0           0                 0              0    0   1   \n",
       "262              0           0                 0              0    0   1   \n",
       "263              1           1                 1              0    0   0   \n",
       "264              0           0                 0              0    0   0   \n",
       "265              0           0                 0              0    0   0   \n",
       "266              0           0                 0              0    0   0   \n",
       "267              0           0                 1              0    0   0   \n",
       "268              0           0                 0              0    1   1   \n",
       "269              1           1                 1              0    0   0   \n",
       "271              1           1                 1              0    1   0   \n",
       "276              0           0                 0              0    0   0   \n",
       "277              0           0                 0              0    0   0   \n",
       "278              0           0                 0              0    1   0   \n",
       "279              0           0                 1              0    0   0   \n",
       "280              0           1                 1              0    0   0   \n",
       "281              0           1                 1              0    1   0   \n",
       "282              0           0                 0              0    0   0   \n",
       "283              0           0                 1              0    0   0   \n",
       "284              0           0                 0              0    0   0   \n",
       "285              0           0                 0              0    0   0   \n",
       "286              0           0                 0              0    0   0   \n",
       "287              0           0                 1              0    0   1   \n",
       "288              0           1                 1              0    0   0   \n",
       "289              0           0                 1              0    0   0   \n",
       "290              0           1                 1              0    0   0   \n",
       "291              0           0                 1              0    1   0   \n",
       "292              0           0                 0              0    0   0   \n",
       "293              0           0                 1              0    0   0   \n",
       "294              0           0                 1              0    1   1   \n",
       "295              0           0                 1              0    0   1   \n",
       "296              0           0                 1              0    0   0   \n",
       "297              0           1                 1              0    0   0   \n",
       "298              0           0                 1              0    0   0   \n",
       "299              1           0                 0              0    0   0   \n",
       "300              0           0                 0              0    0   0   \n",
       "303              0           1                 0              0    0   0   \n",
       "304              0           0                 1              1    0   0   \n",
       "305              0           0                 0              0    0   0   \n",
       "306              0           0                 0              1    0   0   \n",
       "307              0           0                 0              0    0   0   \n",
       "308              0           1                 1              0    0   0   \n",
       "309              0           0                 1              0    0   0   \n",
       "310              0           0                 0              0    1   0   \n",
       "311              0           0                 1              1    0   1   \n",
       "312              0           0                 0              0    0   0   \n",
       "313              0           0                 1              0    1   0   \n",
       "314              1           0                 0              0    0   0   \n",
       "315              0           0                 1              0    0   1   \n",
       "316              0           0                 1              0    1   1   \n",
       "317              0           0                 0              0    0   0   \n",
       "318              1           1                 1              0    0   0   \n",
       "319              1           0                 0              0    0   0   \n",
       "320              0           0                 0              0    0   0   \n",
       "321              0           0                 1              0    0   0   \n",
       "322              0           0                 1              0    0   0   \n",
       "323              0           0                 0              0    0   0   \n",
       "324              1           1                 1              0    0   0   \n",
       "325              0           0                 0              0    0   0   \n",
       "326              1           0                 0              0    0   0   \n",
       "327              0           0                 0              0    0   0   \n",
       "328              1           1                 1              0    0   1   \n",
       "329              1           1                 0              0    0   0   \n",
       "330              0           0                 1              1    0   0   \n",
       "334              0           0                 1              0    1   1   \n",
       "335              0           0                 0              0    0   0   \n",
       "336              0           0                 0              0    0   0   \n",
       "337              0           0                 0              0    0   0   \n",
       "338              0           0                 0              0    0   0   \n",
       "339              0           0                 1              0    0   1   \n",
       "340              0           0                 0              0    0   0   \n",
       "341              0           0                 0              0    0   0   \n",
       "342              1           0                 1              0    0   0   \n",
       "343              0           0                 0              0    0   0   \n",
       "344              0           0                 1              0    0   0   \n",
       "345              0           0                 0              0    0   0   \n",
       "346              0           0                 1              0    0   0   \n",
       "347              0           0                 0              0    0   0   \n",
       "348              0           0                 0              0    0   0   \n",
       "349              0           0                 0              0    0   0   \n",
       "350              0           0                 0              0    0   0   \n",
       "351              0           0                 1              0    0   1   \n",
       "352              1           0                 1              0    0   1   \n",
       "353              0           0                 0              0    0   0   \n",
       "354              1           0                 1              0    0   0   \n",
       "355              0           0                 0              0    0   0   \n",
       "356              0           0                 0              0    0   0   \n",
       "357              0           1                 0              0    0   0   \n",
       "358              0           1                 1              1    0   1   \n",
       "359              0           0                 0              0    0   0   \n",
       "361              0           0                 0              0    0   0   \n",
       "362              0           0                 0              0    0   0   \n",
       "363              0           1                 0              0    0   0   \n",
       "364              0           1                 1              1    1   0   \n",
       "365              1           1                 1              1    1   1   \n",
       "366              0           0                 1              0    0   1   \n",
       "367              0           0                 0              0    0   0   \n",
       "368              0           0                 0              0    0   0   \n",
       "369              0           1                 1              0    1   1   \n",
       "370              0           1                 0              0    0   0   \n",
       "371              0           0                 1              0    0   1   \n",
       "372              1           1                 1              0    1   0   \n",
       "373              0           0                 0              0    0   0   \n",
       "374              0           0                 0              0    0   0   \n",
       "375              0           0                 1              0    0   0   \n",
       "376              0           1                 1              0    1   1   \n",
       "377              1           0                 0              0    0   0   \n",
       "378              0           0                 1              0    0   0   \n",
       "379              0           0                 0              0    0   0   \n",
       "380              0           1                 1              0    1   1   \n",
       "381              1           1                 1              0    0   0   \n",
       "382              1           0                 0              0    0   0   \n",
       "383              0           0                 0              0    0   1   \n",
       "384              0           0                 1              0    0   1   \n",
       "385              0           0                 0              0    1   0   \n",
       "386              0           0                 0              0    0   0   \n",
       "387              0           0                 0              0    0   0   \n",
       "388              1           1                 1              1    0   0   \n",
       "389              0           0                 1              0    0   0   \n",
       "392              0           0                 0              0    0   0   \n",
       "396              0           0                 0              0    0   0   \n",
       "397              0           0                 1              0    1   0   \n",
       "398              0           0                 0              0    0   0   \n",
       "399              0           1                 1              0    0   0   \n",
       "400              0           1                 1              0    0   0   \n",
       "402              0           0                 1              0    0   0   \n",
       "403              0           0                 0              0    0   0   \n",
       "404              0           0                 1              1    0   0   \n",
       "405              0           0                 1              0    0   0   \n",
       "406              0           0                 0              0    0   0   \n",
       "407              0           1                 1              1    1   1   \n",
       "408              0           1                 1              1    0   0   \n",
       "409              0           0                 1              0    0   1   \n",
       "410              0           0                 0              0    0   0   \n",
       "411              0           0                 0              0    0   0   \n",
       "412              0           0                 1              0    1   0   \n",
       "413              0           0                 0              0    0   0   \n",
       "414              0           0                 1              0    1   1   \n",
       "415              0           0                 0              0    0   0   \n",
       "416              0           0                 1              0    0   0   \n",
       "417              1           0                 0              0    0   0   \n",
       "418              0           1                 1              0    0   0   \n",
       "419              0           0                 0              0    0   0   \n",
       "423              0           0                 0              0    0   0   \n",
       "424              0           1                 0              0    0   0   \n",
       "425              0           0                 1              0    0   1   \n",
       "426              1           0                 1              1    0   0   \n",
       "427              0           0                 0              0    0   0   \n",
       "428              1           1                 1              0    0   0   \n",
       "429              0           0                 0              0    0   0   \n",
       "430              0           0                 0              0    0   1   \n",
       "431              0           0                 1              0    1   1   \n",
       "432              0           0                 1              0    0   0   \n",
       "433              0           0                 0              0    0   0   \n",
       "434              0           0                 0              0    0   0   \n",
       "435              0           0                 0              0    0   0   \n",
       "436              0           0                 0              0    0   0   \n",
       "437              1           0                 0              0    0   0   \n",
       "438              1           1                 1              0    1   0   \n",
       "439              0           0                 0              0    0   0   \n",
       "440              0           0                 0              0    0   0   \n",
       "441              0           1                 1              0    0   0   \n",
       "442              0           0                 0              0    0   0   \n",
       "443              0           1                 1              1    1   0   \n",
       "444              0           0                 0              0    0   0   \n",
       "445              0           0                 1              0    0   1   \n",
       "446              0           0                 0              0    0   0   \n",
       "447              0           0                 1              0    0   1   \n",
       "448              0           1                 1              1    0   0   \n",
       "449              0           0                 0              0    0   0   \n",
       "455              0           0                 1              1    0   0   \n",
       "456              0           0                 1              1    1   1   \n",
       "457              0           1                 1              0    1   0   \n",
       "458              0           0                 1              0    0   1   \n",
       "459              0           0                 1              1    1   1   \n",
       "460              0           0                 0              0    0   1   \n",
       "461              0           0                 0              0    0   0   \n",
       "462              1           1                 0              0    0   0   \n",
       "463              0           0                 0              0    0   0   \n",
       "464              0           0                 1              0    0   0   \n",
       "465              1           0                 0              0    1   1   \n",
       "466              0           0                 0              0    0   0   \n",
       "467              0           0                 0              0    0   0   \n",
       "468              0           0                 0              0    0   0   \n",
       "469              1           1                 1              0    0   0   \n",
       "470              0           0                 1              0    1   1   \n",
       "471              0           0                 1              1    0   1   \n",
       "472              1           0                 1              0    1   0   \n",
       "473              0           0                 1              1    1   1   \n",
       "474              0           0                 0              0    0   0   \n",
       "475              0           1                 1              0    0   0   \n",
       "476              1           0                 1              0    0   1   \n",
       "477              0           0                 1              1    0   1   \n",
       "478              0           0                 0              0    0   0   \n",
       "479              0           0                 0              0    0   1   \n",
       "484              0           0                 0              0    0   1   \n",
       "485              0           1                 0              0    0   0   \n",
       "486              0           0                 0              0    0   0   \n",
       "487              0           0                 0              0    0   0   \n",
       "488              1           1                 1              0    0   0   \n",
       "489              1           0                 1              0    0   1   \n",
       "491              0           0                 1              1    0   0   \n",
       "492              0           0                 0              0    0   1   \n",
       "493              0           0                 0              0    0   0   \n",
       "494              0           0                 1              1    1   1   \n",
       "495              0           0                 0              0    0   0   \n",
       "496              0           1                 1              0    0   0   \n",
       "497              1           1                 1              0    0   0   \n",
       "498              0           0                 1              0    0   0   \n",
       "499              0           0                 1              0    0   1   \n",
       "500              0           0                 0              0    0   0   \n",
       "501              1           0                 1              0    1   0   \n",
       "502              0           1                 0              0    0   0   \n",
       "503              0           0                 1              0    0   1   \n",
       "504              0           0                 1              0    0   0   \n",
       "505              0           0                 0              0    0   0   \n",
       "506              0           1                 1              0    0   0   \n",
       "507              0           0                 0              0    0   0   \n",
       "508              0           0                 1              0    1   0   \n",
       "509              0           0                 0              0    0   0   \n",
       "510              0           0                 1              1    0   0   \n",
       "511              0           1                 1              0    0   0   \n",
       "512              0           0                 1              1    1   1   \n",
       "513              0           1                 1              0    0   0   \n",
       "514              0           0                 0              0    0   0   \n",
       "515              1           0                 0              0    0   0   \n",
       "516              0           0                 1              0    0   0   \n",
       "517              0           0                 0              0    0   0   \n",
       "518              0           0                 0              0    0   0   \n",
       "519              0           0                 0              0    0   0   \n",
       "520              0           1                 1              0    0   0   \n",
       "521              0           0                 1              0    0   0   \n",
       "522              0           0                 0              0    0   0   \n",
       "523              0           0                 1              0    0   0   \n",
       "524              0           1                 1              1    0   0   \n",
       "525              0           0                 0              0    0   0   \n",
       "526              1           0                 0              0    0   0   \n",
       "527              0           0                 1              1    1   0   \n",
       "528              1           0                 0              0    0   0   \n",
       "529              0           1                 1              1    0   0   \n",
       "530              0           0                 0              0    0   0   \n",
       "531              0           1                 1              0    0   1   \n",
       "532              0           0                 0              0    0   0   \n",
       "534              1           0                 1              0    1   1   \n",
       "535              0           0                 1              0    0   0   \n",
       "536              0           0                 1              0    0   0   \n",
       "537              0           0                 1              1    0   1   \n",
       "538              0           0                 0              0    0   0   \n",
       "539              1           1                 1              1    0   0   \n",
       "543              0           0                 1              0    0   1   \n",
       "544              1           0                 1              1    1   1   \n",
       "545              0           0                 0              0    0   0   \n",
       "546              1           1                 1              1    0   0   \n",
       "547              0           0                 1              0    0   0   \n",
       "548              0           0                 0              0    0   0   \n",
       "549              0           0                 1              0    0   0   \n",
       "550              0           0                 1              0    0   0   \n",
       "551              0           0                 1              0    1   0   \n",
       "552              0           0                 0              0    0   0   \n",
       "553              0           0                 0              0    0   1   \n",
       "554              0           0                 1              0    0   1   \n",
       "555              1           1                 1              0    0   0   \n",
       "556              1           1                 1              0    0   0   \n",
       "557              0           0                 1              0    0   0   \n",
       "558              0           0                 0              0    0   0   \n",
       "559              0           0                 1              0    0   1   \n",
       "560              0           0                 0              0    0   0   \n",
       "561              0           0                 1              0    1   0   \n",
       "562              0           1                 1              0    0   0   \n",
       "563              0           0                 0              0    0   0   \n",
       "564              0           0                 0              0    0   0   \n",
       "565              0           0                 1              1    1   1   \n",
       "566              1           1                 0              0    0   0   \n",
       "567              0           0                 0              0    0   0   \n",
       "568              0           0                 0              0    0   0   \n",
       "569              0           0                 0              0    0   0   \n",
       "570              1           0                 0              0    0   0   \n",
       "571              1           1                 1              0    0   0   \n",
       "572              1           1                 0              0    0   0   \n",
       "573              0           0                 0              0    0   0   \n",
       "574              0           0                 0              0    0   0   \n",
       "575              0           0                 0              0    0   0   \n",
       "576              0           0                 1              1    0   0   \n",
       "577              1           0                 0              0    0   0   \n",
       "578              0           1                 0              0    0   0   \n",
       "579              0           0                 0              0    0   0   \n",
       "580              0           0                 0              0    0   0   \n",
       "581              1           0                 0              0    0   0   \n",
       "582              0           0                 0              0    0   0   \n",
       "583              0           0                 0              0    0   0   \n",
       "584              0           1                 0              0    0   0   \n",
       "585              0           0                 1              1    1   0   \n",
       "586              0           0                 0              0    0   0   \n",
       "587              0           0                 1              0    1   1   \n",
       "588              0           0                 1              1    0   0   \n",
       "589              0           0                 0              0    1   0   \n",
       "590              0           0                 0              0    0   0   \n",
       "591              0           0                 0              0    0   0   \n",
       "592              0           0                 0              0    0   0   \n",
       "593              0           0                 1              0    0   0   \n",
       "594              0           0                 1              0    0   0   \n",
       "595              0           0                 1              1    1   0   \n",
       "596              0           0                 0              0    0   0   \n",
       "597              0           0                 0              0    0   0   \n",
       "598              0           0                 1              1    0   0   \n",
       "599              0           0                 1              1    0   0   \n",
       "601              0           0                 1              0    0   1   \n",
       "602              0           0                 0              0    0   0   \n",
       "603              0           1                 1              1    0   0   \n",
       "604              0           1                 0              0    0   0   \n",
       "605              0           1                 1              0    0   0   \n",
       "606              0           0                 0              0    0   0   \n",
       "607              0           0                 0              0    0   0   \n",
       "608              0           0                 1              0    0   0   \n",
       "609              0           0                 1              0    0   0   \n",
       "610              0           1                 1              1    0   0   \n",
       "611              0           0                 1              0    1   0   \n",
       "612              1           0                 1              1    1   0   \n",
       "613              0           0                 0              0    0   0   \n",
       "614              0           0                 1              0    0   0   \n",
       "615              0           0                 0              0    0   0   \n",
       "616              0           0                 0              0    0   0   \n",
       "617              1           1                 1              0    0   0   \n",
       "618              0           0                 1              0    0   0   \n",
       "619              0           0                 0              0    0   0   \n",
       "620              0           0                 0              0    0   0   \n",
       "621              0           0                 0              0    0   0   \n",
       "622              0           0                 1              1    0   0   \n",
       "623              0           0                 0              0    0   0   \n",
       "624              0           0                 0              0    1   1   \n",
       "625              0           0                 1              0    0   0   \n",
       "626              1           1                 0              0    0   0   \n",
       "627              0           0                 0              0    0   0   \n",
       "628              0           0                 0              0    0   1   \n",
       "634              0           0                 0              0    0   0   \n",
       "635              0           0                 0              0    0   0   \n",
       "636              0           0                 1              0    0   0   \n",
       "637              0           0                 0              0    0   0   \n",
       "638              0           0                 0              0    0   0   \n",
       "639              0           0                 0              0    0   0   \n",
       "640              0           0                 1              0    0   0   \n",
       "642              0           1                 1              0    1   0   \n",
       "643              0           0                 0              0    1   1   \n",
       "644              0           0                 0              0    0   0   \n",
       "645              0           0                 0              0    0   0   \n",
       "646              0           0                 1              0    0   1   \n",
       "647              0           0                 0              0    0   0   \n",
       "648              0           1                 1              0    0   0   \n",
       "649              1           0                 0              0    0   0   \n",
       "650              1           0                 1              0    1   1   \n",
       "651              0           0                 0              0    0   0   \n",
       "652              0           0                 0              0    0   0   \n",
       "653              0           0                 0              0    0   0   \n",
       "654              1           0                 1              0    0   0   \n",
       "655              0           0                 0              0    0   1   \n",
       "656              0           0                 1              0    1   0   \n",
       "657              0           0                 1              1    0   1   \n",
       "658              0           0                 0              0    0   0   \n",
       "659              0           0                 0              0    0   0   \n",
       "660              0           1                 1              1    0   0   \n",
       "661              0           1                 1              1    1   0   \n",
       "662              0           0                 0              0    0   0   \n",
       "663              0           0                 1              0    0   0   \n",
       "664              0           0                 0              0    0   0   \n",
       "665              0           0                 1              0    0   0   \n",
       "666              1           0                 0              0    0   0   \n",
       "667              0           0                 0              0    0   0   \n",
       "668              0           1                 1              0    1   0   \n",
       "669              0           1                 1              0    0   0   \n",
       "670              0           0                 0              0    0   1   \n",
       "671              1           0                 1              0    0   0   \n",
       "672              0           0                 0              0    0   0   \n",
       "673              0           1                 1              0    0   0   \n",
       "674              0           0                 0              0    0   0   \n",
       "675              0           0                 0              0    0   0   \n",
       "676              0           1                 0              0    0   0   \n",
       "677              0           0                 1              1    1   1   \n",
       "678              1           0                 1              1    1   1   \n",
       "679              0           0                 1              1    0   1   \n",
       "680              0           0                 1              0    0   0   \n",
       "681              0           1                 1              1    1   1   \n",
       "682              0           0                 1              0    0   0   \n",
       "683              0           0                 0              0    0   0   \n",
       "684              0           0                 1              0    0   0   \n",
       "685              1           0                 1              0    0   0   \n",
       "686              0           0                 0              0    0   0   \n",
       "687              0           0                 1              1    0   0   \n",
       "689              0           0                 0              0    0   0   \n",
       "690              0           0                 0              0    0   0   \n",
       "691              0           0                 0              0    0   0   \n",
       "692              0           1                 0              0    0   0   \n",
       "693              0           0                 1              0    0   1   \n",
       "694              1           0                 1              0    0   0   \n",
       "695              1           1                 1              0    0   0   \n",
       "696              0           0                 0              0    0   0   \n",
       "697              0           0                 0              0    0   0   \n",
       "698              0           1                 1              0    0   0   \n",
       "699              0           1                 0              0    0   0   \n",
       "700              0           0                 0              0    0   0   \n",
       "701              0           0                 1              0    1   1   \n",
       "702              0           0                 0              0    0   0   \n",
       "703              0           0                 1              0    0   0   \n",
       "704              0           1                 1              0    0   0   \n",
       "705              0           0                 0              0    0   0   \n",
       "706              0           0                 0              0    0   0   \n",
       "707              0           0                 0              0    0   0   \n",
       "708              0           0                 0              0    0   0   \n",
       "709              0           0                 0              0    0   0   \n",
       "710              0           0                 1              1    0   0   \n",
       "711              0           0                 0              0    0   0   \n",
       "712              1           0                 1              0    0   0   \n",
       "713              0           0                 1              0    0   1   \n",
       "714              0           0                 0              0    0   0   \n",
       "715              0           0                 0              0    0   0   \n",
       "716              0           1                 0              0    0   0   \n",
       "717              1           1                 1              0    0   0   \n",
       "718              0           1                 1              1    0   0   \n",
       "719              0           0                 0              0    0   0   \n",
       "720              0           0                 0              0    0   0   \n",
       "721              0           0                 0              0    0   0   \n",
       "722              0           0                 1              0    0   0   \n",
       "723              0           0                 1              1    0   0   \n",
       "724              0           0                 0              0    0   0   \n",
       "725              0           0                 0              0    0   0   \n",
       "726              0           0                 0              0    0   0   \n",
       "727              0           0                 0              0    0   0   \n",
       "728              0           0                 1              0    0   0   \n",
       "729              0           0                 0              0    0   0   \n",
       "730              0           0                 0              0    0   0   \n",
       "731              0           0                 1              0    1   1   \n",
       "732              0           0                 0              0    0   0   \n",
       "733              0           1                 0              0    0   0   \n",
       "734              1           0                 0              0    0   0   \n",
       "735              0           0                 1              0    0   1   \n",
       "736              0           0                 0              0    0   0   \n",
       "737              0           1                 1              0    0   0   \n",
       "738              1           0                 1              1    0   0   \n",
       "739              0           0                 0              0    0   0   \n",
       "740              0           0                 0              0    0   0   \n",
       "741              0           0                 1              0    0   1   \n",
       "742              0           0                 0              0    0   0   \n",
       "743              1           1                 1              1    0   0   \n",
       "744              0           0                 0              0    0   0   \n",
       "745              0           0                 1              0    0   1   \n",
       "746              0           0                 1              0    0   0   \n",
       "747              0           0                 1              1    1   1   \n",
       "748              0           0                 1              0    0   1   \n",
       "749              0           0                 1              0    0   1   \n",
       "753              1           1                 1              0    0   0   \n",
       "754              0           0                 1              1    0   0   \n",
       "755              0           0                 1              0    0   1   \n",
       "756              0           0                 1              1    0   0   \n",
       "757              0           1                 1              0    0   0   \n",
       "758              0           0                 0              0    0   0   \n",
       "759              0           0                 1              0    0   0   \n",
       "760              0           0                 1              0    0   0   \n",
       "762              0           0                 0              0    0   0   \n",
       "763              0           0                 1              0    0   0   \n",
       "764              0           0                 0              0    0   0   \n",
       "765              0           0                 1              0    0   1   \n",
       "766              0           0                 1              0    0   0   \n",
       "767              0           0                 1              0    0   0   \n",
       "768              1           1                 1              0    0   0   \n",
       "769              0           1                 0              0    0   0   \n",
       "770              0           1                 1              1    1   1   \n",
       "771              0           0                 1              0    0   0   \n",
       "772              0           0                 1              1    0   1   \n",
       "773              0           0                 1              0    0   0   \n",
       "774              0           0                 1              0    1   0   \n",
       "775              0           1                 0              0    0   1   \n",
       "776              1           1                 0              0    0   0   \n",
       "777              0           0                 1              0    1   1   \n",
       "778              1           1                 1              0    0   0   \n",
       "779              0           0                 0              0    0   0   \n",
       "783              1           1                 1              0    0   0   \n",
       "784              0           0                 1              0    0   0   \n",
       "785              0           0                 1              1    0   0   \n",
       "786              1           1                 1              0    0   0   \n",
       "787              1           0                 0              0    0   0   \n",
       "788              0           0                 0              0    0   0   \n",
       "789              0           0                 1              0    1   0   \n",
       "790              0           0                 1              0    0   0   \n",
       "791              0           1                 1              0    0   0   \n",
       "792              0           0                 1              1    1   1   \n",
       "793              0           0                 0              0    0   0   \n",
       "795              0           0                 1              0    0   0   \n",
       "796              0           0                 0              0    0   0   \n",
       "797              0           0                 0              0    0   0   \n",
       "798              0           0                 1              1    0   1   \n",
       "799              0           0                 1              0    1   0   \n",
       "800              0           0                 0              0    0   1   \n",
       "801              0           0                 0              0    0   0   \n",
       "802              0           0                 1              0    0   0   \n",
       "803              0           1                 1              0    0   0   \n",
       "804              1           1                 1              0    0   0   \n",
       "805              0           0                 1              0    0   0   \n",
       "806              0           0                 1              1    1   1   \n",
       "807              1           1                 1              0    1   0   \n",
       "808              0           0                 0              0    0   0   \n",
       "809              0           0                 1              0    0   0   \n",
       "813              0           0                 0              0    0   0   \n",
       "814              0           0                 1              0    0   0   \n",
       "815              0           0                 0              0    0   0   \n",
       "816              0           0                 1              0    1   1   \n",
       "817              0           0                 0              0    0   0   \n",
       "818              0           1                 0              0    0   0   \n",
       "819              0           0                 0              0    0   0   \n",
       "820              0           1                 1              1    0   0   \n",
       "821              0           0                 0              0    0   1   \n",
       "822              0           0                 1              0    0   0   \n",
       "823              0           0                 0              0    0   0   \n",
       "824              0           0                 1              1    1   1   \n",
       "825              0           0                 0              0    0   0   \n",
       "826              0           0                 1              0    0   0   \n",
       "827              0           0                 0              0    0   0   \n",
       "828              1           0                 0              0    0   0   \n",
       "829              0           0                 0              0    0   0   \n",
       "830              0           1                 0              0    0   0   \n",
       "831              0           1                 1              0    0   1   \n",
       "832              0           0                 0              0    1   0   \n",
       "833              0           0                 1              0    0   0   \n",
       "834              0           0                 0              0    0   0   \n",
       "\n",
       "     cloud_platforms  Intern  Junior_Associate  Senior  Staff_Principal  \\\n",
       "0                  0       0                 0       1                0   \n",
       "1                  0       0                 0       1                0   \n",
       "2                  0       0                 0       0                0   \n",
       "3                  0       0                 0       0                0   \n",
       "4                  0       0                 0       0                0   \n",
       "5                  0       0                 0       0                0   \n",
       "6                  0       0                 0       1                0   \n",
       "7                  0       0                 0       1                0   \n",
       "8                  0       1                 0       0                0   \n",
       "9                  0       1                 0       0                0   \n",
       "10                 0       1                 0       0                0   \n",
       "11                 0       0                 0       0                0   \n",
       "12                 0       0                 0       0                0   \n",
       "13                 1       0                 0       0                0   \n",
       "14                 0       0                 0       0                0   \n",
       "15                 0       0                 0       0                0   \n",
       "16                 0       0                 0       0                0   \n",
       "17                 0       0                 0       0                0   \n",
       "18                 0       1                 0       0                0   \n",
       "19                 0       0                 1       0                0   \n",
       "20                 0       0                 1       0                0   \n",
       "21                 0       0                 0       0                0   \n",
       "22                 0       1                 0       0                0   \n",
       "23                 1       0                 0       0                0   \n",
       "24                 0       1                 0       0                0   \n",
       "25                 0       0                 0       0                0   \n",
       "26                 0       0                 0       0                0   \n",
       "27                 0       0                 0       0                0   \n",
       "28                 0       0                 0       0                0   \n",
       "29                 0       0                 0       0                0   \n",
       "30                 0       0                 0       0                0   \n",
       "31                 0       0                 0       0                0   \n",
       "32                 0       0                 0       0                0   \n",
       "33                 1       0                 0       1                0   \n",
       "34                 0       0                 0       1                0   \n",
       "35                 0       0                 0       0                1   \n",
       "36                 0       0                 0       0                0   \n",
       "37                 0       0                 0       0                0   \n",
       "38                 1       0                 0       0                0   \n",
       "39                 0       0                 0       0                0   \n",
       "40                 0       0                 0       0                0   \n",
       "41                 0       0                 0       0                0   \n",
       "42                 1       0                 0       0                0   \n",
       "43                 0       0                 0       1                0   \n",
       "44                 0       0                 0       0                0   \n",
       "45                 0       0                 0       0                0   \n",
       "46                 0       0                 0       1                0   \n",
       "47                 0       0                 0       0                0   \n",
       "48                 0       0                 0       0                0   \n",
       "49                 0       0                 0       0                0   \n",
       "50                 0       0                 1       0                0   \n",
       "51                 0       0                 0       0                0   \n",
       "52                 0       0                 0       0                0   \n",
       "53                 0       0                 0       0                0   \n",
       "54                 0       0                 0       0                0   \n",
       "55                 0       0                 0       0                0   \n",
       "56                 1       0                 0       0                0   \n",
       "57                 0       0                 0       0                0   \n",
       "58                 0       0                 1       0                0   \n",
       "59                 0       0                 0       0                0   \n",
       "60                 0       0                 0       0                0   \n",
       "61                 0       0                 0       0                0   \n",
       "62                 0       0                 0       0                0   \n",
       "63                 1       0                 0       1                0   \n",
       "64                 0       0                 0       0                0   \n",
       "65                 0       0                 0       0                0   \n",
       "66                 0       0                 1       0                0   \n",
       "67                 0       0                 0       0                0   \n",
       "68                 0       0                 0       0                0   \n",
       "69                 0       0                 1       0                0   \n",
       "70                 0       1                 0       0                0   \n",
       "71                 0       0                 0       0                0   \n",
       "72                 0       0                 0       0                0   \n",
       "73                 0       0                 0       0                0   \n",
       "74                 1       0                 0       0                0   \n",
       "75                 0       0                 0       0                0   \n",
       "76                 0       0                 0       0                0   \n",
       "77                 1       0                 0       0                0   \n",
       "78                 0       0                 0       0                0   \n",
       "79                 0       0                 0       0                0   \n",
       "80                 0       0                 0       0                0   \n",
       "81                 0       1                 0       0                0   \n",
       "82                 1       0                 0       0                0   \n",
       "83                 0       0                 0       0                0   \n",
       "84                 0       0                 0       0                0   \n",
       "85                 0       0                 0       0                0   \n",
       "86                 0       0                 0       0                0   \n",
       "87                 0       0                 0       0                0   \n",
       "88                 0       0                 0       0                0   \n",
       "89                 0       0                 0       0                0   \n",
       "91                 0       0                 0       0                0   \n",
       "92                 0       0                 0       0                0   \n",
       "93                 0       0                 0       0                1   \n",
       "94                 0       0                 0       0                0   \n",
       "95                 0       0                 0       1                0   \n",
       "96                 0       0                 0       0                0   \n",
       "97                 0       0                 0       1                0   \n",
       "98                 0       1                 0       0                0   \n",
       "99                 0       0                 0       0                0   \n",
       "100                0       0                 0       0                0   \n",
       "101                0       0                 0       0                0   \n",
       "102                0       0                 0       0                0   \n",
       "103                0       0                 0       0                0   \n",
       "104                0       0                 0       1                0   \n",
       "105                0       0                 0       0                0   \n",
       "106                0       0                 0       0                0   \n",
       "107                1       0                 0       0                0   \n",
       "109                0       0                 0       0                0   \n",
       "110                0       0                 0       0                0   \n",
       "111                0       0                 0       0                0   \n",
       "112                0       0                 0       0                0   \n",
       "113                0       0                 0       1                0   \n",
       "114                0       0                 0       0                0   \n",
       "115                0       0                 1       0                0   \n",
       "116                0       0                 0       0                0   \n",
       "117                0       0                 0       0                0   \n",
       "118                0       0                 0       0                0   \n",
       "119                0       0                 0       0                0   \n",
       "121                1       0                 0       1                0   \n",
       "123                0       0                 0       0                0   \n",
       "124                0       0                 0       0                0   \n",
       "125                0       0                 0       0                0   \n",
       "127                0       0                 0       0                0   \n",
       "128                0       0                 0       0                0   \n",
       "129                0       0                 0       0                0   \n",
       "130                0       0                 0       0                0   \n",
       "131                0       0                 0       0                0   \n",
       "132                0       0                 0       0                0   \n",
       "133                0       0                 0       0                0   \n",
       "134                0       0                 0       0                0   \n",
       "135                0       0                 0       1                0   \n",
       "136                0       0                 0       0                0   \n",
       "137                0       0                 0       0                0   \n",
       "138                0       0                 0       0                0   \n",
       "139                0       0                 0       1                0   \n",
       "140                0       0                 1       0                0   \n",
       "141                0       0                 0       0                0   \n",
       "142                0       0                 0       1                0   \n",
       "143                1       0                 0       0                0   \n",
       "144                1       0                 0       0                0   \n",
       "145                0       0                 0       0                0   \n",
       "146                0       0                 0       0                0   \n",
       "147                0       0                 0       0                0   \n",
       "148                1       0                 0       0                0   \n",
       "149                0       0                 0       0                0   \n",
       "157                0       0                 0       0                0   \n",
       "158                0       0                 1       0                0   \n",
       "159                1       0                 0       0                0   \n",
       "160                0       0                 0       1                0   \n",
       "161                0       0                 0       0                0   \n",
       "162                0       0                 0       0                0   \n",
       "163                0       0                 1       0                0   \n",
       "164                0       0                 0       0                0   \n",
       "165                0       0                 0       0                0   \n",
       "166                0       0                 0       0                0   \n",
       "167                0       0                 0       0                0   \n",
       "168                0       0                 0       0                0   \n",
       "169                0       0                 0       0                0   \n",
       "170                0       0                 0       0                0   \n",
       "171                0       0                 0       0                0   \n",
       "172                0       0                 0       0                0   \n",
       "173                0       0                 0       0                0   \n",
       "174                0       0                 0       0                0   \n",
       "175                0       0                 0       0                0   \n",
       "176                0       0                 0       0                0   \n",
       "177                0       0                 0       0                0   \n",
       "178                0       0                 0       0                0   \n",
       "179                0       0                 0       0                0   \n",
       "180                0       0                 1       0                0   \n",
       "182                0       0                 0       0                0   \n",
       "183                0       0                 1       0                0   \n",
       "184                0       0                 0       0                0   \n",
       "185                1       0                 0       0                0   \n",
       "186                0       0                 0       0                0   \n",
       "187                0       0                 0       0                0   \n",
       "188                0       0                 0       1                0   \n",
       "189                0       0                 1       0                0   \n",
       "190                0       0                 0       0                0   \n",
       "191                0       0                 0       0                0   \n",
       "192                0       0                 0       0                0   \n",
       "193                0       0                 0       0                0   \n",
       "194                0       0                 0       0                0   \n",
       "195                0       0                 1       0                0   \n",
       "196                0       0                 0       0                0   \n",
       "197                0       0                 0       0                0   \n",
       "198                0       0                 0       0                0   \n",
       "199                0       0                 1       0                0   \n",
       "200                0       0                 0       0                0   \n",
       "201                0       0                 0       0                0   \n",
       "202                0       0                 0       0                0   \n",
       "203                0       0                 0       1                0   \n",
       "204                0       0                 0       0                0   \n",
       "205                1       0                 0       0                0   \n",
       "206                0       0                 0       0                0   \n",
       "207                0       0                 0       0                0   \n",
       "208                0       0                 0       0                0   \n",
       "209                0       0                 0       0                0   \n",
       "211                0       0                 0       0                0   \n",
       "215                0       0                 0       0                0   \n",
       "216                0       0                 0       0                0   \n",
       "217                0       0                 1       0                0   \n",
       "218                0       0                 0       1                0   \n",
       "219                0       0                 0       0                0   \n",
       "220                0       0                 0       0                0   \n",
       "221                0       0                 0       0                0   \n",
       "222                0       0                 0       0                0   \n",
       "223                0       0                 0       0                0   \n",
       "224                0       0                 0       0                0   \n",
       "225                0       0                 0       0                0   \n",
       "226                0       0                 0       0                0   \n",
       "227                0       0                 0       0                1   \n",
       "228                0       0                 0       0                0   \n",
       "229                0       0                 0       0                0   \n",
       "230                0       0                 1       0                0   \n",
       "231                0       0                 0       0                0   \n",
       "232                0       0                 0       0                0   \n",
       "233                0       0                 0       0                0   \n",
       "234                0       0                 0       0                0   \n",
       "235                0       0                 0       0                0   \n",
       "236                0       0                 0       0                0   \n",
       "237                0       0                 0       0                0   \n",
       "238                0       0                 0       0                0   \n",
       "239                0       0                 0       0                0   \n",
       "242                0       0                 0       0                0   \n",
       "243                0       0                 0       0                0   \n",
       "244                0       0                 0       0                0   \n",
       "245                0       0                 1       0                0   \n",
       "246                0       0                 0       0                0   \n",
       "247                0       0                 0       0                0   \n",
       "248                0       0                 0       0                0   \n",
       "249                0       1                 0       0                0   \n",
       "250                0       0                 0       1                0   \n",
       "251                0       0                 0       0                0   \n",
       "252                0       0                 0       0                0   \n",
       "253                0       1                 0       0                0   \n",
       "254                0       0                 0       0                0   \n",
       "255                0       0                 0       0                0   \n",
       "258                0       0                 0       0                0   \n",
       "259                1       0                 0       1                0   \n",
       "260                0       0                 0       0                0   \n",
       "261                0       0                 0       0                0   \n",
       "262                0       0                 0       0                0   \n",
       "263                0       0                 0       0                0   \n",
       "264                0       1                 0       0                0   \n",
       "265                0       0                 1       0                0   \n",
       "266                0       0                 0       0                0   \n",
       "267                0       0                 0       0                0   \n",
       "268                0       1                 0       0                0   \n",
       "269                0       0                 0       0                0   \n",
       "271                1       0                 0       1                0   \n",
       "276                0       0                 0       1                0   \n",
       "277                0       0                 0       0                0   \n",
       "278                0       0                 0       0                0   \n",
       "279                0       0                 0       1                0   \n",
       "280                0       0                 0       0                0   \n",
       "281                0       0                 0       0                0   \n",
       "282                0       0                 0       0                0   \n",
       "283                0       1                 0       0                0   \n",
       "284                0       0                 0       0                0   \n",
       "285                0       0                 0       0                0   \n",
       "286                0       0                 0       0                0   \n",
       "287                0       0                 0       0                0   \n",
       "288                0       0                 0       0                0   \n",
       "289                0       0                 0       0                0   \n",
       "290                0       0                 0       0                0   \n",
       "291                0       0                 0       1                0   \n",
       "292                0       0                 0       0                0   \n",
       "293                0       0                 0       0                0   \n",
       "294                1       0                 0       0                0   \n",
       "295                0       0                 0       0                0   \n",
       "296                0       0                 0       0                0   \n",
       "297                1       0                 0       0                0   \n",
       "298                0       0                 0       0                0   \n",
       "299                0       0                 0       0                0   \n",
       "300                0       0                 0       0                1   \n",
       "303                0       0                 0       0                0   \n",
       "304                1       0                 0       0                0   \n",
       "305                0       0                 0       0                0   \n",
       "306                0       1                 0       0                0   \n",
       "307                0       0                 1       0                0   \n",
       "308                0       0                 0       0                0   \n",
       "309                1       0                 0       0                0   \n",
       "310                0       0                 0       0                0   \n",
       "311                0       0                 0       0                0   \n",
       "312                0       0                 0       0                0   \n",
       "313                0       0                 0       0                0   \n",
       "314                0       0                 0       0                0   \n",
       "315                1       1                 0       0                0   \n",
       "316                0       0                 1       0                0   \n",
       "317                0       0                 0       0                0   \n",
       "318                0       0                 0       0                0   \n",
       "319                0       0                 1       0                0   \n",
       "320                0       0                 0       0                0   \n",
       "321                0       0                 0       0                0   \n",
       "322                1       0                 0       0                0   \n",
       "323                0       0                 0       1                0   \n",
       "324                0       0                 0       0                0   \n",
       "325                0       0                 0       0                0   \n",
       "326                0       0                 0       0                0   \n",
       "327                0       0                 0       0                0   \n",
       "328                0       0                 1       0                0   \n",
       "329                0       1                 0       0                0   \n",
       "330                0       0                 0       1                0   \n",
       "334                1       0                 0       1                0   \n",
       "335                0       0                 0       0                0   \n",
       "336                0       0                 0       0                0   \n",
       "337                0       0                 0       1                0   \n",
       "338                1       0                 0       0                0   \n",
       "339                0       0                 0       0                0   \n",
       "340                0       0                 0       1                0   \n",
       "341                0       0                 0       0                0   \n",
       "342                0       0                 0       0                0   \n",
       "343                0       0                 0       0                0   \n",
       "344                0       0                 0       0                0   \n",
       "345                0       0                 0       0                0   \n",
       "346                0       0                 0       0                0   \n",
       "347                0       0                 0       0                0   \n",
       "348                0       0                 0       0                0   \n",
       "349                0       0                 0       0                0   \n",
       "350                0       0                 0       0                0   \n",
       "351                0       0                 1       0                0   \n",
       "352                0       0                 1       0                0   \n",
       "353                0       0                 0       0                0   \n",
       "354                0       0                 0       0                0   \n",
       "355                0       1                 0       0                0   \n",
       "356                0       0                 0       0                0   \n",
       "357                0       0                 0       1                0   \n",
       "358                0       0                 0       0                0   \n",
       "359                0       0                 0       0                0   \n",
       "361                0       0                 0       0                0   \n",
       "362                0       0                 0       0                0   \n",
       "363                0       0                 0       0                0   \n",
       "364                1       0                 0       0                0   \n",
       "365                1       0                 0       0                0   \n",
       "366                0       0                 0       0                0   \n",
       "367                0       0                 0       0                0   \n",
       "368                0       0                 0       0                0   \n",
       "369                0       0                 0       1                0   \n",
       "370                0       0                 0       0                0   \n",
       "371                0       0                 0       0                0   \n",
       "372                0       0                 0       0                0   \n",
       "373                0       0                 0       0                0   \n",
       "374                0       0                 0       0                0   \n",
       "375                0       0                 0       0                1   \n",
       "376                0       0                 0       1                0   \n",
       "377                0       0                 0       0                0   \n",
       "378                0       0                 0       0                0   \n",
       "379                0       0                 0       0                0   \n",
       "380                0       0                 0       0                0   \n",
       "381                0       0                 0       0                0   \n",
       "382                0       0                 0       0                0   \n",
       "383                0       0                 0       0                0   \n",
       "384                0       0                 0       0                0   \n",
       "385                0       0                 0       0                0   \n",
       "386                0       0                 0       0                0   \n",
       "387                0       0                 0       1                0   \n",
       "388                1       0                 0       0                0   \n",
       "389                1       0                 0       0                0   \n",
       "392                0       0                 0       1                0   \n",
       "396                0       0                 0       0                0   \n",
       "397                0       0                 0       1                0   \n",
       "398                0       0                 0       1                0   \n",
       "399                0       0                 0       0                0   \n",
       "400                0       0                 0       0                0   \n",
       "402                0       0                 0       0                0   \n",
       "403                0       0                 0       0                0   \n",
       "404                0       0                 0       0                0   \n",
       "405                0       0                 0       0                0   \n",
       "406                0       0                 1       0                0   \n",
       "407                0       0                 0       1                0   \n",
       "408                0       0                 0       0                0   \n",
       "409                0       1                 0       0                0   \n",
       "410                0       0                 0       0                0   \n",
       "411                0       0                 0       1                0   \n",
       "412                0       0                 0       0                0   \n",
       "413                0       0                 0       0                0   \n",
       "414                1       0                 0       0                0   \n",
       "415                0       1                 0       0                0   \n",
       "416                0       0                 1       0                0   \n",
       "417                0       1                 0       0                0   \n",
       "418                1       0                 0       1                0   \n",
       "419                0       0                 0       0                0   \n",
       "423                0       0                 0       0                0   \n",
       "424                0       0                 0       0                0   \n",
       "425                0       1                 0       0                0   \n",
       "426                0       0                 0       0                0   \n",
       "427                0       0                 0       1                0   \n",
       "428                0       0                 0       0                0   \n",
       "429                1       0                 0       0                0   \n",
       "430                0       0                 0       0                0   \n",
       "431                0       0                 0       0                0   \n",
       "432                0       0                 0       0                0   \n",
       "433                0       0                 0       1                0   \n",
       "434                0       0                 0       0                0   \n",
       "435                0       0                 0       0                0   \n",
       "436                0       0                 0       0                0   \n",
       "437                0       0                 0       0                0   \n",
       "438                0       0                 0       1                0   \n",
       "439                0       0                 0       0                0   \n",
       "440                0       0                 0       0                0   \n",
       "441                0       0                 0       1                0   \n",
       "442                0       0                 0       0                0   \n",
       "443                1       0                 0       0                0   \n",
       "444                0       0                 0       0                0   \n",
       "445                1       0                 0       0                0   \n",
       "446                0       1                 0       0                0   \n",
       "447                0       1                 0       0                0   \n",
       "448                0       0                 0       0                0   \n",
       "449                0       0                 0       0                0   \n",
       "455                0       0                 0       0                0   \n",
       "456                0       0                 0       0                0   \n",
       "457                0       0                 0       0                0   \n",
       "458                0       0                 1       0                0   \n",
       "459                0       0                 0       0                0   \n",
       "460                0       0                 1       0                0   \n",
       "461                0       1                 0       0                0   \n",
       "462                0       0                 0       0                0   \n",
       "463                0       0                 0       1                0   \n",
       "464                0       0                 0       0                0   \n",
       "465                0       0                 0       0                0   \n",
       "466                0       0                 0       0                0   \n",
       "467                0       0                 0       0                0   \n",
       "468                0       0                 0       1                0   \n",
       "469                0       1                 0       0                0   \n",
       "470                1       0                 0       0                0   \n",
       "471                0       0                 0       0                0   \n",
       "472                0       0                 0       0                0   \n",
       "473                0       0                 0       0                0   \n",
       "474                0       0                 0       0                0   \n",
       "475                0       0                 0       0                0   \n",
       "476                0       0                 0       1                0   \n",
       "477                1       0                 0       0                0   \n",
       "478                0       0                 0       1                0   \n",
       "479                0       0                 0       0                0   \n",
       "484                0       0                 0       0                0   \n",
       "485                0       0                 0       0                0   \n",
       "486                0       0                 1       1                0   \n",
       "487                1       0                 0       0                0   \n",
       "488                0       0                 0       0                0   \n",
       "489                0       0                 0       0                0   \n",
       "491                0       1                 0       0                0   \n",
       "492                0       0                 0       0                0   \n",
       "493                0       0                 0       0                0   \n",
       "494                0       0                 0       0                0   \n",
       "495                0       0                 0       0                0   \n",
       "496                1       0                 0       1                0   \n",
       "497                0       0                 0       0                0   \n",
       "498                0       0                 0       0                0   \n",
       "499                1       0                 0       0                0   \n",
       "500                0       0                 0       0                0   \n",
       "501                0       0                 0       0                0   \n",
       "502                0       0                 0       0                0   \n",
       "503                0       0                 0       0                0   \n",
       "504                0       1                 0       0                0   \n",
       "505                0       0                 0       0                0   \n",
       "506                0       0                 0       0                0   \n",
       "507                0       0                 0       0                0   \n",
       "508                0       0                 0       0                0   \n",
       "509                0       0                 0       0                0   \n",
       "510                0       1                 0       0                0   \n",
       "511                0       0                 0       0                0   \n",
       "512                0       0                 0       0                0   \n",
       "513                0       0                 0       0                0   \n",
       "514                0       1                 0       0                0   \n",
       "515                0       0                 0       1                0   \n",
       "516                0       0                 1       0                0   \n",
       "517                0       0                 0       0                0   \n",
       "518                0       0                 0       0                0   \n",
       "519                0       0                 0       0                0   \n",
       "520                0       0                 0       1                0   \n",
       "521                1       0                 0       0                0   \n",
       "522                0       0                 0       1                0   \n",
       "523                0       0                 0       0                1   \n",
       "524                0       0                 0       0                0   \n",
       "525                0       0                 0       0                0   \n",
       "526                0       1                 0       0                0   \n",
       "527                0       0                 1       0                0   \n",
       "528                0       0                 0       0                0   \n",
       "529                1       0                 0       1                0   \n",
       "530                0       0                 0       1                0   \n",
       "531                0       0                 0       1                0   \n",
       "532                0       0                 0       0                0   \n",
       "534                0       0                 0       0                0   \n",
       "535                0       0                 0       0                1   \n",
       "536                0       1                 0       0                0   \n",
       "537                0       0                 0       0                0   \n",
       "538                0       0                 0       0                0   \n",
       "539                0       0                 0       0                0   \n",
       "543                0       0                 0       0                0   \n",
       "544                0       0                 0       0                0   \n",
       "545                0       0                 0       1                0   \n",
       "546                0       0                 0       0                0   \n",
       "547                0       1                 0       0                0   \n",
       "548                0       0                 0       1                0   \n",
       "549                0       0                 1       0                0   \n",
       "550                0       0                 0       0                0   \n",
       "551                0       1                 0       0                0   \n",
       "552                0       0                 0       0                0   \n",
       "553                0       0                 0       0                0   \n",
       "554                1       0                 0       0                0   \n",
       "555                0       0                 0       0                0   \n",
       "556                0       0                 0       0                0   \n",
       "557                0       0                 0       0                0   \n",
       "558                0       0                 1       1                0   \n",
       "559                0       0                 0       0                0   \n",
       "560                0       1                 0       0                0   \n",
       "561                0       0                 0       1                0   \n",
       "562                0       0                 0       0                0   \n",
       "563                0       0                 0       0                0   \n",
       "564                0       0                 0       0                0   \n",
       "565                0       0                 0       0                0   \n",
       "566                0       0                 0       0                0   \n",
       "567                0       0                 0       0                0   \n",
       "568                0       0                 0       1                0   \n",
       "569                0       0                 0       0                0   \n",
       "570                0       0                 1       0                0   \n",
       "571                1       0                 0       0                0   \n",
       "572                0       0                 0       0                0   \n",
       "573                0       0                 0       0                0   \n",
       "574                0       0                 0       0                0   \n",
       "575                0       0                 0       1                0   \n",
       "576                0       0                 0       0                0   \n",
       "577                0       0                 0       0                0   \n",
       "578                0       0                 0       0                0   \n",
       "579                0       0                 0       0                0   \n",
       "580                0       0                 0       0                0   \n",
       "581                0       0                 0       0                0   \n",
       "582                0       0                 0       0                0   \n",
       "583                0       0                 0       0                0   \n",
       "584                0       0                 0       0                0   \n",
       "585                1       0                 0       0                0   \n",
       "586                0       0                 0       0                0   \n",
       "587                1       0                 0       0                0   \n",
       "588                0       0                 0       0                0   \n",
       "589                0       0                 0       0                0   \n",
       "590                0       0                 0       0                0   \n",
       "591                0       0                 0       0                0   \n",
       "592                0       0                 0       1                0   \n",
       "593                0       0                 0       0                0   \n",
       "594                0       0                 0       0                0   \n",
       "595                1       0                 0       0                0   \n",
       "596                0       0                 1       0                0   \n",
       "597                0       0                 0       0                0   \n",
       "598                0       0                 0       0                0   \n",
       "599                0       0                 0       0                0   \n",
       "601                0       0                 0       0                0   \n",
       "602                0       0                 0       0                0   \n",
       "603                1       0                 0       0                0   \n",
       "604                0       0                 0       1                0   \n",
       "605                0       0                 0       1                0   \n",
       "606                0       0                 0       0                0   \n",
       "607                0       0                 0       0                0   \n",
       "608                0       0                 0       0                0   \n",
       "609                0       0                 0       0                0   \n",
       "610                0       0                 0       0                0   \n",
       "611                0       0                 0       0                0   \n",
       "612                0       0                 0       0                0   \n",
       "613                0       0                 0       1                0   \n",
       "614                0       0                 0       0                0   \n",
       "615                0       0                 1       0                0   \n",
       "616                0       0                 0       0                1   \n",
       "617                1       0                 0       0                0   \n",
       "618                1       0                 0       0                0   \n",
       "619                0       0                 0       0                1   \n",
       "620                0       0                 0       0                0   \n",
       "621                0       0                 0       0                0   \n",
       "622                0       0                 0       0                0   \n",
       "623                0       0                 0       0                0   \n",
       "624                1       0                 0       0                0   \n",
       "625                0       0                 0       1                0   \n",
       "626                0       0                 1       0                0   \n",
       "627                0       0                 0       0                0   \n",
       "628                0       0                 0       0                0   \n",
       "634                0       0                 0       0                0   \n",
       "635                0       0                 0       0                0   \n",
       "636                1       0                 0       0                1   \n",
       "637                0       0                 0       0                0   \n",
       "638                0       1                 0       0                0   \n",
       "639                0       0                 0       1                0   \n",
       "640                0       1                 0       0                0   \n",
       "642                0       0                 0       0                0   \n",
       "643                1       0                 0       0                0   \n",
       "644                0       0                 0       0                0   \n",
       "645                0       0                 0       0                0   \n",
       "646                0       0                 0       0                0   \n",
       "647                0       0                 0       1                0   \n",
       "648                0       0                 0       0                0   \n",
       "649                1       0                 0       0                0   \n",
       "650                1       0                 0       0                0   \n",
       "651                0       0                 0       1                0   \n",
       "652                0       0                 0       0                0   \n",
       "653                0       0                 0       1                1   \n",
       "654                0       0                 0       1                0   \n",
       "655                0       0                 0       0                0   \n",
       "656                0       0                 0       0                0   \n",
       "657                0       0                 0       0                0   \n",
       "658                0       0                 0       0                0   \n",
       "659                0       0                 1       0                0   \n",
       "660                0       0                 1       0                0   \n",
       "661                0       0                 0       0                0   \n",
       "662                0       0                 0       0                0   \n",
       "663                0       0                 0       0                0   \n",
       "664                0       0                 0       0                0   \n",
       "665                0       0                 0       0                0   \n",
       "666                0       0                 0       0                0   \n",
       "667                0       0                 0       1                0   \n",
       "668                1       0                 0       0                0   \n",
       "669                0       0                 0       0                0   \n",
       "670                0       0                 0       1                0   \n",
       "671                0       0                 1       0                0   \n",
       "672                0       0                 1       0                0   \n",
       "673                0       0                 0       0                0   \n",
       "674                0       0                 0       1                0   \n",
       "675                0       0                 0       1                0   \n",
       "676                0       0                 0       0                0   \n",
       "677                1       0                 0       1                0   \n",
       "678                0       0                 0       0                0   \n",
       "679                0       0                 0       0                0   \n",
       "680                0       0                 0       0                0   \n",
       "681                0       0                 0       1                0   \n",
       "682                0       0                 0       0                0   \n",
       "683                0       0                 0       0                0   \n",
       "684                0       0                 0       1                0   \n",
       "685                0       0                 0       0                0   \n",
       "686                0       0                 0       0                0   \n",
       "687                0       1                 0       0                0   \n",
       "689                0       0                 0       0                0   \n",
       "690                0       0                 0       0                0   \n",
       "691                0       0                 0       0                0   \n",
       "692                0       0                 0       0                0   \n",
       "693                0       0                 0       0                0   \n",
       "694                0       0                 0       1                0   \n",
       "695                0       0                 0       0                0   \n",
       "696                0       0                 0       0                1   \n",
       "697                0       0                 0       0                0   \n",
       "698                0       0                 0       0                0   \n",
       "699                0       0                 0       0                0   \n",
       "700                0       0                 0       0                1   \n",
       "701                1       0                 0       1                0   \n",
       "702                0       0                 0       0                0   \n",
       "703                1       0                 0       0                0   \n",
       "704                0       1                 0       0                0   \n",
       "705                0       0                 0       1                0   \n",
       "706                0       0                 1       0                0   \n",
       "707                0       0                 0       1                0   \n",
       "708                0       0                 0       0                0   \n",
       "709                0       0                 1       0                0   \n",
       "710                0       0                 0       0                0   \n",
       "711                0       0                 1       0                0   \n",
       "712                0       0                 1       0                0   \n",
       "713                0       0                 0       1                0   \n",
       "714                0       0                 1       0                0   \n",
       "715                0       0                 0       1                0   \n",
       "716                0       0                 0       1                0   \n",
       "717                0       0                 0       0                0   \n",
       "718                0       0                 0       0                0   \n",
       "719                0       0                 0       1                0   \n",
       "720                0       0                 0       0                0   \n",
       "721                0       0                 0       0                0   \n",
       "722                0       0                 0       0                0   \n",
       "723                0       0                 0       0                0   \n",
       "724                0       0                 0       0                0   \n",
       "725                1       0                 0       0                0   \n",
       "726                0       0                 0       0                0   \n",
       "727                0       0                 0       0                0   \n",
       "728                0       0                 0       0                0   \n",
       "729                0       0                 0       0                0   \n",
       "730                0       0                 0       0                0   \n",
       "731                0       0                 0       1                0   \n",
       "732                0       0                 0       0                0   \n",
       "733                0       0                 0       0                0   \n",
       "734                0       0                 0       0                1   \n",
       "735                0       0                 0       0                0   \n",
       "736                0       0                 0       1                0   \n",
       "737                0       0                 0       1                0   \n",
       "738                1       0                 0       0                0   \n",
       "739                0       0                 0       0                0   \n",
       "740                0       0                 0       0                0   \n",
       "741                0       0                 0       0                0   \n",
       "742                0       0                 0       0                0   \n",
       "743                0       0                 0       0                0   \n",
       "744                0       0                 0       0                1   \n",
       "745                1       0                 0       0                0   \n",
       "746                0       0                 0       1                0   \n",
       "747                1       0                 0       1                0   \n",
       "748                1       0                 0       0                0   \n",
       "749                0       0                 0       0                0   \n",
       "753                1       0                 0       0                0   \n",
       "754                0       0                 0       0                0   \n",
       "755                0       0                 1       0                0   \n",
       "756                0       0                 0       0                0   \n",
       "757                0       0                 0       0                0   \n",
       "758                0       0                 0       0                0   \n",
       "759                0       0                 0       0                0   \n",
       "760                0       0                 0       1                0   \n",
       "762                0       0                 1       0                0   \n",
       "763                0       0                 0       0                0   \n",
       "764                0       0                 0       0                1   \n",
       "765                0       0                 0       1                0   \n",
       "766                0       0                 0       0                0   \n",
       "767                0       0                 0       0                0   \n",
       "768                0       1                 0       0                0   \n",
       "769                0       0                 0       1                0   \n",
       "770                0       0                 1       0                0   \n",
       "771                0       0                 0       0                0   \n",
       "772                0       0                 0       0                0   \n",
       "773                0       0                 0       0                0   \n",
       "774                0       0                 0       0                0   \n",
       "775                0       0                 0       1                0   \n",
       "776                0       0                 0       0                0   \n",
       "777                0       0                 0       0                0   \n",
       "778                0       0                 0       0                0   \n",
       "779                0       0                 0       0                0   \n",
       "783                0       0                 0       0                0   \n",
       "784                0       0                 0       0                0   \n",
       "785                0       0                 0       0                0   \n",
       "786                0       0                 0       0                0   \n",
       "787                0       0                 0       0                0   \n",
       "788                0       0                 0       0                0   \n",
       "789                0       1                 0       0                0   \n",
       "790                1       0                 0       0                0   \n",
       "791                0       0                 0       1                0   \n",
       "792                1       0                 0       1                0   \n",
       "793                0       0                 0       1                0   \n",
       "795                0       0                 0       0                0   \n",
       "796                0       0                 0       0                0   \n",
       "797                0       0                 0       1                0   \n",
       "798                1       0                 0       1                0   \n",
       "799                0       0                 0       0                0   \n",
       "800                0       0                 0       1                0   \n",
       "801                0       0                 0       0                0   \n",
       "802                0       0                 0       0                0   \n",
       "803                0       0                 0       1                0   \n",
       "804                0       0                 0       0                1   \n",
       "805                1       0                 0       0                0   \n",
       "806                0       0                 0       0                0   \n",
       "807                0       0                 0       0                0   \n",
       "808                0       0                 0       0                0   \n",
       "809                0       1                 0       0                0   \n",
       "813                1       0                 0       1                0   \n",
       "814                0       0                 0       0                0   \n",
       "815                0       0                 0       0                0   \n",
       "816                1       0                 0       0                0   \n",
       "817                0       0                 0       1                0   \n",
       "818                0       0                 0       1                0   \n",
       "819                0       0                 0       0                0   \n",
       "820                0       0                 0       1                0   \n",
       "821                0       1                 0       0                0   \n",
       "822                0       0                 0       1                0   \n",
       "823                0       0                 0       0                0   \n",
       "824                1       0                 0       1                0   \n",
       "825                0       0                 0       0                0   \n",
       "826                0       0                 0       0                0   \n",
       "827                1       0                 0       1                0   \n",
       "828                0       0                 0       0                0   \n",
       "829                0       0                 0       1                0   \n",
       "830                0       0                 0       1                0   \n",
       "831                0       0                 0       0                0   \n",
       "832                0       0                 0       0                0   \n",
       "833                0       0                 0       0                0   \n",
       "834                0       0                 0       0                0   \n",
       "\n",
       "     Lead_Manager  ML_Engineer  Data_Scientist  Data_Analyst  \\\n",
       "0               0            0               1             0   \n",
       "1               0            0               1             0   \n",
       "2               0            1               0             0   \n",
       "3               1            0               1             0   \n",
       "4               0            1               1             1   \n",
       "5               0            0               0             0   \n",
       "6               1            0               0             0   \n",
       "7               0            0               0             0   \n",
       "8               0            0               0             1   \n",
       "9               0            0               1             0   \n",
       "10              0            0               1             0   \n",
       "11              0            0               1             0   \n",
       "12              0            0               1             0   \n",
       "13              0            0               1             0   \n",
       "14              0            0               1             0   \n",
       "15              0            0               1             0   \n",
       "16              0            0               1             0   \n",
       "17              0            0               1             0   \n",
       "18              0            0               1             0   \n",
       "19              0            0               1             0   \n",
       "20              0            0               1             0   \n",
       "21              0            0               1             1   \n",
       "22              0            0               0             0   \n",
       "23              0            0               1             0   \n",
       "24              0            0               1             0   \n",
       "25              0            0               1             0   \n",
       "26              1            0               1             0   \n",
       "27              0            0               1             0   \n",
       "28              0            0               1             0   \n",
       "29              0            0               1             0   \n",
       "30              0            0               1             0   \n",
       "31              0            0               1             0   \n",
       "32              1            1               0             0   \n",
       "33              0            1               0             0   \n",
       "34              0            1               0             0   \n",
       "35              0            0               0             0   \n",
       "36              0            0               1             0   \n",
       "37              0            0               1             0   \n",
       "38              0            0               1             0   \n",
       "39              0            0               1             0   \n",
       "40              0            0               1             0   \n",
       "41              0            0               1             0   \n",
       "42              0            0               0             0   \n",
       "43              0            0               1             0   \n",
       "44              0            0               1             0   \n",
       "45              0            0               0             0   \n",
       "46              0            0               1             0   \n",
       "47              0            0               1             0   \n",
       "48              0            0               1             0   \n",
       "49              0            0               1             0   \n",
       "50              0            0               1             0   \n",
       "51              0            0               1             0   \n",
       "52              0            0               1             0   \n",
       "53              0            0               1             0   \n",
       "54              0            0               1             0   \n",
       "55              0            0               1             0   \n",
       "56              0            0               1             0   \n",
       "57              0            0               1             0   \n",
       "58              0            0               1             0   \n",
       "59              0            0               1             0   \n",
       "60              0            1               1             0   \n",
       "61              0            0               0             1   \n",
       "62              0            1               0             1   \n",
       "63              0            1               0             0   \n",
       "64              0            0               0             0   \n",
       "65              0            0               1             0   \n",
       "66              0            0               1             0   \n",
       "67              0            0               1             1   \n",
       "68              0            0               1             0   \n",
       "69              0            0               1             0   \n",
       "70              0            0               1             0   \n",
       "71              0            0               1             0   \n",
       "72              0            0               1             0   \n",
       "73              0            0               1             0   \n",
       "74              0            0               1             0   \n",
       "75              0            0               1             0   \n",
       "76              0            0               1             0   \n",
       "77              0            0               1             0   \n",
       "78              0            0               1             0   \n",
       "79              0            0               1             0   \n",
       "80              0            0               1             0   \n",
       "81              0            0               1             0   \n",
       "82              0            0               1             0   \n",
       "83              0            0               1             0   \n",
       "84              0            0               1             0   \n",
       "85              0            0               1             0   \n",
       "86              0            0               1             0   \n",
       "87              0            0               1             0   \n",
       "88              0            0               1             0   \n",
       "89              0            0               0             0   \n",
       "91              0            0               1             0   \n",
       "92              0            0               1             0   \n",
       "93              0            0               1             0   \n",
       "94              0            0               1             0   \n",
       "95              0            0               1             0   \n",
       "96              0            0               1             0   \n",
       "97              0            0               1             0   \n",
       "98              0            0               1             0   \n",
       "99              0            0               1             0   \n",
       "100             0            0               1             0   \n",
       "101             0            0               1             0   \n",
       "102             0            0               1             0   \n",
       "103             0            0               1             0   \n",
       "104             0            0               1             0   \n",
       "105             0            0               1             0   \n",
       "106             0            0               1             0   \n",
       "107             0            0               1             0   \n",
       "109             0            0               1             0   \n",
       "110             0            0               1             0   \n",
       "111             0            0               1             0   \n",
       "112             0            1               1             0   \n",
       "113             0            0               1             0   \n",
       "114             0            0               1             0   \n",
       "115             0            0               1             0   \n",
       "116             0            0               1             0   \n",
       "117             0            0               1             0   \n",
       "118             0            0               1             1   \n",
       "119             0            0               1             0   \n",
       "121             0            0               1             0   \n",
       "123             0            0               1             0   \n",
       "124             0            0               1             0   \n",
       "125             0            0               1             0   \n",
       "127             0            0               1             0   \n",
       "128             0            0               1             0   \n",
       "129             0            0               1             0   \n",
       "130             0            0               1             0   \n",
       "131             0            0               1             0   \n",
       "132             0            0               1             0   \n",
       "133             0            1               0             0   \n",
       "134             0            0               1             0   \n",
       "135             0            0               1             0   \n",
       "136             0            0               1             0   \n",
       "137             0            0               1             0   \n",
       "138             0            0               1             0   \n",
       "139             0            0               1             0   \n",
       "140             0            1               0             0   \n",
       "141             0            0               1             0   \n",
       "142             0            0               1             0   \n",
       "143             0            0               1             0   \n",
       "144             0            0               1             0   \n",
       "145             0            0               1             1   \n",
       "146             0            0               1             0   \n",
       "147             0            0               1             0   \n",
       "148             0            1               1             0   \n",
       "149             1            0               1             0   \n",
       "157             0            0               1             0   \n",
       "158             0            0               1             0   \n",
       "159             0            0               1             0   \n",
       "160             0            0               1             0   \n",
       "161             0            0               1             0   \n",
       "162             0            0               1             0   \n",
       "163             0            0               1             0   \n",
       "164             0            0               1             0   \n",
       "165             0            0               1             0   \n",
       "166             0            0               1             0   \n",
       "167             0            0               1             0   \n",
       "168             0            0               1             0   \n",
       "169             0            0               1             0   \n",
       "170             0            0               1             0   \n",
       "171             0            0               1             0   \n",
       "172             0            0               1             0   \n",
       "173             0            0               1             0   \n",
       "174             0            0               1             0   \n",
       "175             0            0               1             0   \n",
       "176             0            0               0             1   \n",
       "177             0            0               1             0   \n",
       "178             0            1               0             0   \n",
       "179             0            0               1             0   \n",
       "180             0            0               1             0   \n",
       "182             0            0               1             0   \n",
       "183             0            0               1             0   \n",
       "184             0            0               1             0   \n",
       "185             0            0               1             0   \n",
       "186             0            0               1             0   \n",
       "187             0            0               1             0   \n",
       "188             0            0               1             0   \n",
       "189             0            0               1             0   \n",
       "190             0            0               1             0   \n",
       "191             0            0               1             0   \n",
       "192             0            0               1             0   \n",
       "193             0            0               1             0   \n",
       "194             0            0               1             0   \n",
       "195             0            0               1             0   \n",
       "196             0            0               1             0   \n",
       "197             0            0               1             0   \n",
       "198             0            0               1             0   \n",
       "199             0            0               0             1   \n",
       "200             0            0               1             0   \n",
       "201             0            0               1             0   \n",
       "202             0            0               1             0   \n",
       "203             0            0               1             0   \n",
       "204             0            0               1             0   \n",
       "205             0            0               1             0   \n",
       "206             0            0               1             0   \n",
       "207             0            0               1             1   \n",
       "208             0            0               0             1   \n",
       "209             0            0               1             1   \n",
       "211             0            0               0             1   \n",
       "215             0            0               1             0   \n",
       "216             0            0               1             0   \n",
       "217             0            0               1             0   \n",
       "218             0            0               1             0   \n",
       "219             0            0               1             0   \n",
       "220             0            0               1             0   \n",
       "221             0            0               1             0   \n",
       "222             0            0               1             0   \n",
       "223             0            0               1             0   \n",
       "224             0            0               1             0   \n",
       "225             0            0               1             0   \n",
       "226             0            0               1             1   \n",
       "227             0            0               1             0   \n",
       "228             0            0               1             0   \n",
       "229             0            0               1             0   \n",
       "230             0            0               1             0   \n",
       "231             0            0               1             0   \n",
       "232             0            0               1             0   \n",
       "233             0            0               1             0   \n",
       "234             0            0               1             0   \n",
       "235             0            0               1             0   \n",
       "236             0            0               1             0   \n",
       "237             0            1               1             1   \n",
       "238             0            0               1             0   \n",
       "239             0            0               1             0   \n",
       "242             0            0               1             0   \n",
       "243             0            0               1             0   \n",
       "244             0            0               1             0   \n",
       "245             0            0               1             0   \n",
       "246             0            0               1             0   \n",
       "247             0            0               1             0   \n",
       "248             0            0               1             0   \n",
       "249             0            0               1             0   \n",
       "250             0            0               1             0   \n",
       "251             0            0               1             0   \n",
       "252             0            0               1             0   \n",
       "253             0            0               0             0   \n",
       "254             0            0               1             0   \n",
       "255             0            0               1             0   \n",
       "258             0            0               1             0   \n",
       "259             0            0               1             0   \n",
       "260             0            0               1             0   \n",
       "261             0            0               1             0   \n",
       "262             0            0               1             0   \n",
       "263             0            0               1             0   \n",
       "264             0            0               1             0   \n",
       "265             0            0               1             0   \n",
       "266             0            0               1             0   \n",
       "267             0            0               1             0   \n",
       "268             0            0               0             0   \n",
       "269             0            0               1             0   \n",
       "271             0            0               1             0   \n",
       "276             0            0               0             0   \n",
       "277             0            0               1             0   \n",
       "278             0            0               0             1   \n",
       "279             0            0               1             0   \n",
       "280             0            0               1             0   \n",
       "281             0            0               1             0   \n",
       "282             0            0               1             0   \n",
       "283             0            0               1             0   \n",
       "284             0            0               0             1   \n",
       "285             0            0               1             0   \n",
       "286             0            0               1             0   \n",
       "287             0            0               1             0   \n",
       "288             0            0               1             0   \n",
       "289             0            0               1             0   \n",
       "290             0            0               1             0   \n",
       "291             0            0               1             0   \n",
       "292             1            0               1             0   \n",
       "293             0            0               1             0   \n",
       "294             0            1               1             0   \n",
       "295             0            0               1             0   \n",
       "296             0            0               1             0   \n",
       "297             0            0               1             0   \n",
       "298             0            0               1             0   \n",
       "299             0            0               1             0   \n",
       "300             0            0               1             0   \n",
       "303             0            0               1             0   \n",
       "304             0            0               1             0   \n",
       "305             0            0               1             0   \n",
       "306             0            0               1             0   \n",
       "307             0            0               1             0   \n",
       "308             0            0               1             0   \n",
       "309             0            0               1             0   \n",
       "310             0            0               1             0   \n",
       "311             0            1               0             0   \n",
       "312             0            0               1             0   \n",
       "313             0            0               1             0   \n",
       "314             0            1               0             1   \n",
       "315             0            0               1             0   \n",
       "316             0            0               0             0   \n",
       "317             0            0               1             1   \n",
       "318             0            0               1             0   \n",
       "319             0            0               0             1   \n",
       "320             0            0               1             0   \n",
       "321             0            0               1             0   \n",
       "322             0            0               1             0   \n",
       "323             0            0               1             0   \n",
       "324             0            0               1             0   \n",
       "325             0            0               1             0   \n",
       "326             0            0               0             1   \n",
       "327             0            0               1             0   \n",
       "328             0            0               1             0   \n",
       "329             0            0               0             1   \n",
       "330             0            0               1             0   \n",
       "334             0            0               1             0   \n",
       "335             0            0               1             0   \n",
       "336             0            0               1             0   \n",
       "337             0            0               1             0   \n",
       "338             0            0               1             0   \n",
       "339             0            0               0             0   \n",
       "340             0            0               1             0   \n",
       "341             0            0               1             0   \n",
       "342             0            0               1             0   \n",
       "343             0            0               1             0   \n",
       "344             0            0               1             0   \n",
       "345             0            0               1             0   \n",
       "346             0            0               1             0   \n",
       "347             0            0               1             0   \n",
       "348             0            0               1             0   \n",
       "349             0            0               0             0   \n",
       "350             0            0               0             1   \n",
       "351             0            0               1             0   \n",
       "352             0            0               1             0   \n",
       "353             0            0               1             0   \n",
       "354             0            0               1             0   \n",
       "355             0            0               1             0   \n",
       "356             0            0               1             0   \n",
       "357             0            0               1             0   \n",
       "358             0            0               1             0   \n",
       "359             0            0               1             0   \n",
       "361             0            0               1             0   \n",
       "362             0            0               1             0   \n",
       "363             0            0               1             0   \n",
       "364             0            0               1             0   \n",
       "365             0            0               1             0   \n",
       "366             0            0               1             0   \n",
       "367             0            0               1             1   \n",
       "368             0            0               1             1   \n",
       "369             0            0               1             0   \n",
       "370             0            0               1             0   \n",
       "371             0            0               0             0   \n",
       "372             0            0               1             0   \n",
       "373             0            0               1             0   \n",
       "374             0            0               1             0   \n",
       "375             0            0               1             0   \n",
       "376             0            0               1             0   \n",
       "377             0            0               0             1   \n",
       "378             0            0               1             0   \n",
       "379             0            0               1             0   \n",
       "380             0            0               1             0   \n",
       "381             0            0               1             0   \n",
       "382             0            0               0             1   \n",
       "383             0            0               1             0   \n",
       "384             0            0               1             0   \n",
       "385             0            0               0             0   \n",
       "386             0            0               1             0   \n",
       "387             0            0               1             0   \n",
       "388             0            0               1             0   \n",
       "389             0            0               1             0   \n",
       "392             1            0               0             1   \n",
       "396             0            0               1             0   \n",
       "397             0            0               1             0   \n",
       "398             0            0               1             0   \n",
       "399             0            0               1             0   \n",
       "400             0            0               1             0   \n",
       "402             0            0               1             0   \n",
       "403             0            0               1             0   \n",
       "404             0            1               1             0   \n",
       "405             0            0               1             0   \n",
       "406             0            0               0             0   \n",
       "407             0            0               1             0   \n",
       "408             0            0               1             0   \n",
       "409             0            1               0             0   \n",
       "410             0            0               1             0   \n",
       "411             0            0               1             0   \n",
       "412             0            0               1             0   \n",
       "413             0            0               1             0   \n",
       "414             0            0               1             0   \n",
       "415             0            0               1             0   \n",
       "416             0            0               0             0   \n",
       "417             0            0               1             0   \n",
       "418             0            0               1             0   \n",
       "419             0            0               1             0   \n",
       "423             1            0               1             0   \n",
       "424             0            0               1             0   \n",
       "425             0            0               0             0   \n",
       "426             0            0               1             0   \n",
       "427             0            0               1             0   \n",
       "428             0            0               1             0   \n",
       "429             0            0               1             0   \n",
       "430             0            1               0             0   \n",
       "431             0            0               1             0   \n",
       "432             0            0               1             0   \n",
       "433             0            0               1             0   \n",
       "434             0            1               0             0   \n",
       "435             0            0               1             0   \n",
       "436             0            0               1             0   \n",
       "437             0            0               0             0   \n",
       "438             0            0               1             0   \n",
       "439             0            0               1             0   \n",
       "440             0            0               1             0   \n",
       "441             0            0               1             0   \n",
       "442             1            0               0             0   \n",
       "443             0            0               1             0   \n",
       "444             0            0               1             0   \n",
       "445             0            1               0             0   \n",
       "446             0            0               1             0   \n",
       "447             0            0               0             0   \n",
       "448             0            0               1             0   \n",
       "449             0            0               1             0   \n",
       "455             0            0               1             0   \n",
       "456             0            1               1             0   \n",
       "457             1            1               1             0   \n",
       "458             0            1               0             0   \n",
       "459             0            1               1             0   \n",
       "460             0            0               0             0   \n",
       "461             0            0               1             0   \n",
       "462             1            0               1             0   \n",
       "463             0            0               1             0   \n",
       "464             0            0               1             1   \n",
       "465             0            0               0             1   \n",
       "466             1            0               1             0   \n",
       "467             0            0               1             0   \n",
       "468             0            0               1             0   \n",
       "469             0            0               1             0   \n",
       "470             0            0               1             0   \n",
       "471             0            0               1             0   \n",
       "472             0            0               1             0   \n",
       "473             0            0               1             0   \n",
       "474             0            0               1             0   \n",
       "475             0            0               1             0   \n",
       "476             0            0               1             0   \n",
       "477             0            0               1             0   \n",
       "478             0            0               1             0   \n",
       "479             0            0               1             0   \n",
       "484             0            0               1             1   \n",
       "485             0            0               1             0   \n",
       "486             0            0               1             0   \n",
       "487             0            0               1             0   \n",
       "488             0            0               1             0   \n",
       "489             0            0               1             0   \n",
       "491             0            0               0             0   \n",
       "492             0            0               1             0   \n",
       "493             0            0               1             0   \n",
       "494             0            0               1             0   \n",
       "495             0            0               1             0   \n",
       "496             0            0               1             0   \n",
       "497             0            0               1             0   \n",
       "498             0            0               0             0   \n",
       "499             0            0               1             0   \n",
       "500             0            0               1             0   \n",
       "501             0            0               1             0   \n",
       "502             0            0               1             1   \n",
       "503             0            0               1             0   \n",
       "504             0            0               1             0   \n",
       "505             0            0               1             0   \n",
       "506             0            0               1             0   \n",
       "507             0            0               1             0   \n",
       "508             0            0               0             0   \n",
       "509             0            0               1             0   \n",
       "510             0            0               0             0   \n",
       "511             0            1               1             0   \n",
       "512             0            0               1             0   \n",
       "513             0            0               1             0   \n",
       "514             0            0               1             0   \n",
       "515             0            0               1             0   \n",
       "516             0            0               1             0   \n",
       "517             0            0               1             0   \n",
       "518             0            0               1             0   \n",
       "519             0            0               1             0   \n",
       "520             0            0               1             0   \n",
       "521             0            0               1             0   \n",
       "522             1            0               1             0   \n",
       "523             0            0               1             0   \n",
       "524             0            0               1             0   \n",
       "525             1            0               1             0   \n",
       "526             0            0               1             0   \n",
       "527             0            0               1             0   \n",
       "528             0            0               1             0   \n",
       "529             0            0               1             0   \n",
       "530             0            0               1             0   \n",
       "531             0            0               1             0   \n",
       "532             1            0               1             1   \n",
       "534             0            0               0             0   \n",
       "535             0            0               0             0   \n",
       "536             0            0               0             0   \n",
       "537             0            0               1             0   \n",
       "538             0            0               1             0   \n",
       "539             0            0               1             0   \n",
       "543             0            0               1             0   \n",
       "544             0            0               1             0   \n",
       "545             0            0               1             0   \n",
       "546             0            0               1             0   \n",
       "547             0            0               0             0   \n",
       "548             0            0               1             0   \n",
       "549             0            0               1             0   \n",
       "550             0            0               1             0   \n",
       "551             0            0               0             0   \n",
       "552             0            0               0             1   \n",
       "553             0            0               1             0   \n",
       "554             0            0               1             0   \n",
       "555             0            0               0             1   \n",
       "556             0            0               1             0   \n",
       "557             0            0               1             0   \n",
       "558             0            0               1             0   \n",
       "559             0            0               1             0   \n",
       "560             0            0               1             0   \n",
       "561             0            0               1             0   \n",
       "562             0            0               1             0   \n",
       "563             0            0               0             0   \n",
       "564             0            0               1             0   \n",
       "565             0            1               1             0   \n",
       "566             0            0               1             0   \n",
       "567             0            0               1             0   \n",
       "568             0            0               1             0   \n",
       "569             0            0               1             0   \n",
       "570             0            0               1             0   \n",
       "571             0            0               1             0   \n",
       "572             0            0               1             0   \n",
       "573             0            0               1             0   \n",
       "574             0            0               1             0   \n",
       "575             0            0               1             0   \n",
       "576             0            0               1             0   \n",
       "577             0            0               1             1   \n",
       "578             0            0               1             0   \n",
       "579             0            0               1             0   \n",
       "580             0            0               1             0   \n",
       "581             0            0               1             0   \n",
       "582             0            0               1             0   \n",
       "583             0            0               0             1   \n",
       "584             0            0               1             0   \n",
       "585             0            0               1             0   \n",
       "586             0            0               1             0   \n",
       "587             0            0               1             0   \n",
       "588             0            0               0             0   \n",
       "589             0            0               1             0   \n",
       "590             0            0               1             0   \n",
       "591             0            0               1             0   \n",
       "592             0            0               1             0   \n",
       "593             0            0               1             0   \n",
       "594             0            0               1             0   \n",
       "595             0            0               1             0   \n",
       "596             0            0               0             1   \n",
       "597             0            0               1             0   \n",
       "598             0            0               1             0   \n",
       "599             0            0               0             0   \n",
       "601             0            0               1             0   \n",
       "602             0            1               0             0   \n",
       "603             0            0               1             0   \n",
       "604             0            0               1             0   \n",
       "605             0            0               0             0   \n",
       "606             0            0               0             1   \n",
       "607             0            0               1             0   \n",
       "608             0            0               1             0   \n",
       "609             0            0               1             0   \n",
       "610             0            0               1             0   \n",
       "611             0            0               1             0   \n",
       "612             0            0               1             0   \n",
       "613             0            0               1             0   \n",
       "614             0            0               1             0   \n",
       "615             0            0               1             0   \n",
       "616             0            0               1             0   \n",
       "617             0            0               1             0   \n",
       "618             1            0               1             0   \n",
       "619             0            0               1             0   \n",
       "620             0            0               1             0   \n",
       "621             0            0               1             0   \n",
       "622             0            0               1             0   \n",
       "623             0            0               1             0   \n",
       "624             0            0               1             0   \n",
       "625             0            0               1             0   \n",
       "626             0            0               1             0   \n",
       "627             0            0               1             0   \n",
       "628             0            0               1             1   \n",
       "634             0            1               0             0   \n",
       "635             0            0               1             0   \n",
       "636             0            0               1             0   \n",
       "637             0            0               1             0   \n",
       "638             0            0               1             0   \n",
       "639             0            0               1             0   \n",
       "640             0            0               0             0   \n",
       "642             0            0               1             0   \n",
       "643             1            0               1             0   \n",
       "644             0            0               1             1   \n",
       "645             0            0               1             0   \n",
       "646             1            0               0             0   \n",
       "647             0            0               1             0   \n",
       "648             1            0               1             0   \n",
       "649             0            1               0             0   \n",
       "650             1            0               1             0   \n",
       "651             0            0               1             0   \n",
       "652             0            0               1             1   \n",
       "653             0            0               1             0   \n",
       "654             0            0               1             0   \n",
       "655             0            0               0             0   \n",
       "656             0            1               0             0   \n",
       "657             0            0               1             0   \n",
       "658             0            0               1             0   \n",
       "659             0            0               0             1   \n",
       "660             0            0               1             0   \n",
       "661             0            0               1             0   \n",
       "662             0            0               1             0   \n",
       "663             0            0               1             0   \n",
       "664             1            0               1             0   \n",
       "665             0            0               1             0   \n",
       "666             0            0               1             0   \n",
       "667             0            0               1             0   \n",
       "668             0            0               1             0   \n",
       "669             0            1               0             0   \n",
       "670             0            1               1             0   \n",
       "671             1            0               1             0   \n",
       "672             0            0               0             0   \n",
       "673             1            0               1             0   \n",
       "674             0            0               1             0   \n",
       "675             0            0               1             0   \n",
       "676             0            0               1             0   \n",
       "677             0            1               1             0   \n",
       "678             0            0               0             0   \n",
       "679             0            0               1             0   \n",
       "680             0            1               0             0   \n",
       "681             0            0               1             0   \n",
       "682             0            0               1             0   \n",
       "683             0            0               1             0   \n",
       "684             0            0               1             0   \n",
       "685             1            0               1             0   \n",
       "686             0            0               0             0   \n",
       "687             0            0               0             0   \n",
       "689             0            0               1             0   \n",
       "690             0            0               1             0   \n",
       "691             0            0               1             0   \n",
       "692             0            0               1             0   \n",
       "693             0            0               0             0   \n",
       "694             0            0               1             0   \n",
       "695             0            0               1             0   \n",
       "696             0            0               1             0   \n",
       "697             0            0               1             1   \n",
       "698             0            0               0             0   \n",
       "699             1            0               1             0   \n",
       "700             0            1               0             0   \n",
       "701             0            0               1             0   \n",
       "702             0            1               1             0   \n",
       "703             0            0               1             0   \n",
       "704             0            0               0             0   \n",
       "705             0            0               1             0   \n",
       "706             0            0               0             1   \n",
       "707             0            0               1             0   \n",
       "708             1            0               0             0   \n",
       "709             0            0               1             0   \n",
       "710             0            0               0             0   \n",
       "711             0            0               1             0   \n",
       "712             0            0               1             0   \n",
       "713             0            0               1             0   \n",
       "714             0            0               0             0   \n",
       "715             0            0               1             0   \n",
       "716             0            0               1             0   \n",
       "717             0            0               1             1   \n",
       "718             0            1               0             0   \n",
       "719             0            0               1             0   \n",
       "720             0            0               1             0   \n",
       "721             0            0               1             0   \n",
       "722             0            1               0             0   \n",
       "723             0            1               0             0   \n",
       "724             0            1               0             0   \n",
       "725             0            1               0             0   \n",
       "726             0            0               1             0   \n",
       "727             0            0               0             0   \n",
       "728             0            0               0             0   \n",
       "729             0            0               1             0   \n",
       "730             0            0               1             0   \n",
       "731             0            0               1             0   \n",
       "732             0            0               0             0   \n",
       "733             0            0               1             0   \n",
       "734             0            0               1             0   \n",
       "735             0            1               0             0   \n",
       "736             0            0               1             0   \n",
       "737             0            0               1             0   \n",
       "738             0            0               0             0   \n",
       "739             0            1               0             0   \n",
       "740             0            0               1             0   \n",
       "741             0            1               0             0   \n",
       "742             0            0               0             0   \n",
       "743             0            0               1             0   \n",
       "744             0            0               1             0   \n",
       "745             0            1               0             0   \n",
       "746             0            0               1             0   \n",
       "747             0            0               1             0   \n",
       "748             0            1               0             0   \n",
       "749             0            0               0             0   \n",
       "753             0            0               0             1   \n",
       "754             0            1               0             0   \n",
       "755             0            0               0             0   \n",
       "756             0            0               1             0   \n",
       "757             0            0               1             0   \n",
       "758             1            0               1             0   \n",
       "759             0            1               1             0   \n",
       "760             0            0               1             0   \n",
       "762             0            0               0             0   \n",
       "763             0            0               0             0   \n",
       "764             0            0               1             0   \n",
       "765             0            0               1             0   \n",
       "766             0            1               0             0   \n",
       "767             0            0               1             0   \n",
       "768             0            0               1             0   \n",
       "769             0            0               1             0   \n",
       "770             0            1               1             0   \n",
       "771             0            0               1             1   \n",
       "772             0            1               0             0   \n",
       "773             0            1               0             0   \n",
       "774             0            1               0             0   \n",
       "775             0            0               1             0   \n",
       "776             0            0               1             0   \n",
       "777             0            0               1             0   \n",
       "778             0            0               1             0   \n",
       "779             0            0               0             1   \n",
       "783             0            0               1             1   \n",
       "784             0            0               1             0   \n",
       "785             0            0               1             0   \n",
       "786             0            0               1             0   \n",
       "787             0            0               0             1   \n",
       "788             0            0               1             0   \n",
       "789             0            0               1             0   \n",
       "790             0            1               0             0   \n",
       "791             0            0               1             0   \n",
       "792             0            0               1             0   \n",
       "793             0            0               1             0   \n",
       "795             0            1               0             0   \n",
       "796             0            0               1             0   \n",
       "797             0            0               1             0   \n",
       "798             0            0               1             0   \n",
       "799             0            1               0             0   \n",
       "800             0            0               0             0   \n",
       "801             0            0               1             0   \n",
       "802             0            1               0             0   \n",
       "803             0            0               0             0   \n",
       "804             0            0               1             0   \n",
       "805             0            0               1             1   \n",
       "806             0            1               0             0   \n",
       "807             0            0               1             0   \n",
       "808             0            0               1             1   \n",
       "809             0            1               0             0   \n",
       "813             0            0               1             0   \n",
       "814             0            0               1             0   \n",
       "815             0            0               0             0   \n",
       "816             0            1               0             0   \n",
       "817             0            0               1             0   \n",
       "818             0            0               1             0   \n",
       "819             0            1               1             0   \n",
       "820             0            0               1             0   \n",
       "821             0            0               0             0   \n",
       "822             0            0               1             0   \n",
       "823             0            0               1             0   \n",
       "824             0            0               1             0   \n",
       "825             0            1               0             0   \n",
       "826             1            0               1             0   \n",
       "827             0            0               1             0   \n",
       "828             0            0               1             0   \n",
       "829             0            0               1             0   \n",
       "830             0            0               1             0   \n",
       "831             0            1               0             0   \n",
       "832             0            0               1             0   \n",
       "833             0            1               1             0   \n",
       "834             0            1               0             0   \n",
       "\n",
       "     Salary_Source_Glassdoor  Salary_Source_Employer  Loc_Ahmedabad  \\\n",
       "0                          1                       0              0   \n",
       "1                          1                       0              0   \n",
       "2                          1                       0              0   \n",
       "3                          1                       0              0   \n",
       "4                          1                       0              0   \n",
       "5                          0                       1              0   \n",
       "6                          1                       0              0   \n",
       "7                          0                       1              0   \n",
       "8                          1                       0              0   \n",
       "9                          0                       1              0   \n",
       "10                         0                       1              0   \n",
       "11                         1                       0              0   \n",
       "12                         1                       0              0   \n",
       "13                         0                       1              0   \n",
       "14                         0                       1              0   \n",
       "15                         1                       0              0   \n",
       "16                         0                       1              0   \n",
       "17                         0                       1              0   \n",
       "18                         1                       0              0   \n",
       "19                         1                       0              0   \n",
       "20                         1                       0              0   \n",
       "21                         1                       0              0   \n",
       "22                         0                       1              0   \n",
       "23                         0                       1              0   \n",
       "24                         0                       1              0   \n",
       "25                         1                       0              0   \n",
       "26                         0                       1              0   \n",
       "27                         0                       1              0   \n",
       "28                         0                       1              0   \n",
       "29                         1                       0              0   \n",
       "30                         1                       0              0   \n",
       "31                         1                       0              0   \n",
       "32                         1                       0              0   \n",
       "33                         1                       0              0   \n",
       "34                         1                       0              0   \n",
       "35                         1                       0              0   \n",
       "36                         1                       0              0   \n",
       "37                         1                       0              0   \n",
       "38                         1                       0              0   \n",
       "39                         1                       0              0   \n",
       "40                         1                       0              0   \n",
       "41                         1                       0              0   \n",
       "42                         1                       0              0   \n",
       "43                         0                       1              0   \n",
       "44                         1                       0              0   \n",
       "45                         0                       1              0   \n",
       "46                         1                       0              0   \n",
       "47                         1                       0              0   \n",
       "48                         1                       0              0   \n",
       "49                         0                       1              0   \n",
       "50                         0                       1              0   \n",
       "51                         1                       0              0   \n",
       "52                         1                       0              0   \n",
       "53                         1                       0              0   \n",
       "54                         1                       0              0   \n",
       "55                         1                       0              0   \n",
       "56                         1                       0              0   \n",
       "57                         0                       1              0   \n",
       "58                         0                       1              0   \n",
       "59                         1                       0              0   \n",
       "60                         1                       0              0   \n",
       "61                         1                       0              0   \n",
       "62                         1                       0              0   \n",
       "63                         0                       1              0   \n",
       "64                         1                       0              0   \n",
       "65                         1                       0              0   \n",
       "66                         1                       0              0   \n",
       "67                         0                       1              0   \n",
       "68                         1                       0              0   \n",
       "69                         1                       0              0   \n",
       "70                         0                       1              0   \n",
       "71                         1                       0              0   \n",
       "72                         0                       1              0   \n",
       "73                         0                       1              0   \n",
       "74                         0                       1              0   \n",
       "75                         1                       0              0   \n",
       "76                         1                       0              0   \n",
       "77                         1                       0              0   \n",
       "78                         0                       1              0   \n",
       "79                         1                       0              0   \n",
       "80                         1                       0              0   \n",
       "81                         0                       1              0   \n",
       "82                         1                       0              0   \n",
       "83                         1                       0              0   \n",
       "84                         0                       1              0   \n",
       "85                         1                       0              0   \n",
       "86                         1                       0              0   \n",
       "87                         1                       0              0   \n",
       "88                         1                       0              0   \n",
       "89                         0                       1              0   \n",
       "91                         0                       1              0   \n",
       "92                         1                       0              0   \n",
       "93                         1                       0              0   \n",
       "94                         0                       1              0   \n",
       "95                         1                       0              0   \n",
       "96                         1                       0              0   \n",
       "97                         0                       1              0   \n",
       "98                         1                       0              0   \n",
       "99                         1                       0              0   \n",
       "100                        1                       0              0   \n",
       "101                        0                       1              0   \n",
       "102                        1                       0              0   \n",
       "103                        0                       1              0   \n",
       "104                        1                       0              0   \n",
       "105                        1                       0              0   \n",
       "106                        0                       1              0   \n",
       "107                        1                       0              0   \n",
       "109                        1                       0              0   \n",
       "110                        0                       1              0   \n",
       "111                        1                       0              0   \n",
       "112                        1                       0              0   \n",
       "113                        0                       1              0   \n",
       "114                        1                       0              0   \n",
       "115                        1                       0              0   \n",
       "116                        1                       0              0   \n",
       "117                        1                       0              0   \n",
       "118                        1                       0              0   \n",
       "119                        1                       0              0   \n",
       "121                        0                       1              0   \n",
       "123                        1                       0              0   \n",
       "124                        1                       0              0   \n",
       "125                        1                       0              0   \n",
       "127                        1                       0              0   \n",
       "128                        1                       0              0   \n",
       "129                        1                       0              0   \n",
       "130                        1                       0              0   \n",
       "131                        1                       0              0   \n",
       "132                        1                       0              0   \n",
       "133                        1                       0              0   \n",
       "134                        1                       0              0   \n",
       "135                        1                       0              0   \n",
       "136                        1                       0              0   \n",
       "137                        1                       0              0   \n",
       "138                        1                       0              0   \n",
       "139                        1                       0              0   \n",
       "140                        1                       0              0   \n",
       "141                        1                       0              1   \n",
       "142                        1                       0              0   \n",
       "143                        0                       1              0   \n",
       "144                        0                       1              0   \n",
       "145                        0                       1              0   \n",
       "146                        1                       0              0   \n",
       "147                        0                       1              0   \n",
       "148                        1                       0              0   \n",
       "149                        1                       0              0   \n",
       "157                        0                       1              0   \n",
       "158                        1                       0              0   \n",
       "159                        1                       0              0   \n",
       "160                        1                       0              0   \n",
       "161                        1                       0              0   \n",
       "162                        1                       0              0   \n",
       "163                        0                       1              0   \n",
       "164                        0                       1              0   \n",
       "165                        1                       0              0   \n",
       "166                        0                       1              0   \n",
       "167                        0                       1              0   \n",
       "168                        1                       0              0   \n",
       "169                        1                       0              0   \n",
       "170                        1                       0              0   \n",
       "171                        1                       0              0   \n",
       "172                        1                       0              0   \n",
       "173                        1                       0              0   \n",
       "174                        0                       1              0   \n",
       "175                        0                       1              0   \n",
       "176                        1                       0              0   \n",
       "177                        1                       0              0   \n",
       "178                        0                       1              0   \n",
       "179                        1                       0              0   \n",
       "180                        1                       0              0   \n",
       "182                        1                       0              0   \n",
       "183                        1                       0              0   \n",
       "184                        1                       0              0   \n",
       "185                        1                       0              0   \n",
       "186                        1                       0              0   \n",
       "187                        1                       0              0   \n",
       "188                        0                       1              0   \n",
       "189                        1                       0              0   \n",
       "190                        1                       0              0   \n",
       "191                        1                       0              0   \n",
       "192                        1                       0              0   \n",
       "193                        1                       0              0   \n",
       "194                        0                       1              0   \n",
       "195                        1                       0              0   \n",
       "196                        1                       0              0   \n",
       "197                        0                       1              0   \n",
       "198                        0                       1              0   \n",
       "199                        1                       0              0   \n",
       "200                        1                       0              0   \n",
       "201                        1                       0              0   \n",
       "202                        1                       0              0   \n",
       "203                        0                       1              0   \n",
       "204                        1                       0              0   \n",
       "205                        0                       1              0   \n",
       "206                        1                       0              0   \n",
       "207                        1                       0              0   \n",
       "208                        1                       0              0   \n",
       "209                        1                       0              0   \n",
       "211                        1                       0              0   \n",
       "215                        0                       1              0   \n",
       "216                        1                       0              0   \n",
       "217                        1                       0              0   \n",
       "218                        1                       0              0   \n",
       "219                        1                       0              0   \n",
       "220                        1                       0              0   \n",
       "221                        1                       0              0   \n",
       "222                        0                       1              0   \n",
       "223                        1                       0              0   \n",
       "224                        0                       1              0   \n",
       "225                        0                       1              0   \n",
       "226                        0                       1              0   \n",
       "227                        1                       0              0   \n",
       "228                        0                       1              0   \n",
       "229                        1                       0              0   \n",
       "230                        1                       0              0   \n",
       "231                        1                       0              0   \n",
       "232                        1                       0              0   \n",
       "233                        1                       0              0   \n",
       "234                        1                       0              0   \n",
       "235                        1                       0              0   \n",
       "236                        0                       1              0   \n",
       "237                        1                       0              0   \n",
       "238                        0                       1              0   \n",
       "239                        1                       0              0   \n",
       "242                        1                       0              0   \n",
       "243                        1                       0              0   \n",
       "244                        0                       1              0   \n",
       "245                        1                       0              0   \n",
       "246                        1                       0              0   \n",
       "247                        1                       0              0   \n",
       "248                        0                       1              1   \n",
       "249                        1                       0              0   \n",
       "250                        1                       0              0   \n",
       "251                        1                       0              0   \n",
       "252                        0                       1              0   \n",
       "253                        0                       1              0   \n",
       "254                        0                       1              0   \n",
       "255                        0                       1              0   \n",
       "258                        1                       0              0   \n",
       "259                        0                       1              0   \n",
       "260                        1                       0              0   \n",
       "261                        0                       1              0   \n",
       "262                        1                       0              0   \n",
       "263                        1                       0              0   \n",
       "264                        0                       1              0   \n",
       "265                        1                       0              0   \n",
       "266                        1                       0              0   \n",
       "267                        1                       0              0   \n",
       "268                        0                       1              0   \n",
       "269                        0                       1              0   \n",
       "271                        1                       0              0   \n",
       "276                        1                       0              0   \n",
       "277                        1                       0              0   \n",
       "278                        1                       0              0   \n",
       "279                        1                       0              0   \n",
       "280                        1                       0              0   \n",
       "281                        1                       0              0   \n",
       "282                        1                       0              0   \n",
       "283                        0                       1              0   \n",
       "284                        0                       1              0   \n",
       "285                        1                       0              0   \n",
       "286                        0                       1              0   \n",
       "287                        1                       0              0   \n",
       "288                        1                       0              0   \n",
       "289                        1                       0              0   \n",
       "290                        1                       0              0   \n",
       "291                        0                       1              0   \n",
       "292                        1                       0              0   \n",
       "293                        1                       0              0   \n",
       "294                        1                       0              0   \n",
       "295                        1                       0              0   \n",
       "296                        1                       0              0   \n",
       "297                        1                       0              0   \n",
       "298                        1                       0              0   \n",
       "299                        1                       0              0   \n",
       "300                        1                       0              0   \n",
       "303                        1                       0              0   \n",
       "304                        1                       0              0   \n",
       "305                        1                       0              0   \n",
       "306                        0                       1              0   \n",
       "307                        0                       1              0   \n",
       "308                        1                       0              0   \n",
       "309                        0                       1              0   \n",
       "310                        0                       1              0   \n",
       "311                        0                       1              0   \n",
       "312                        1                       0              0   \n",
       "313                        1                       0              0   \n",
       "314                        1                       0              0   \n",
       "315                        0                       1              0   \n",
       "316                        1                       0              0   \n",
       "317                        1                       0              0   \n",
       "318                        1                       0              0   \n",
       "319                        1                       0              0   \n",
       "320                        1                       0              0   \n",
       "321                        0                       1              0   \n",
       "322                        0                       1              0   \n",
       "323                        0                       1              0   \n",
       "324                        1                       0              1   \n",
       "325                        1                       0              0   \n",
       "326                        0                       1              0   \n",
       "327                        1                       0              0   \n",
       "328                        1                       0              0   \n",
       "329                        0                       1              0   \n",
       "330                        1                       0              0   \n",
       "334                        1                       0              0   \n",
       "335                        1                       0              0   \n",
       "336                        1                       0              0   \n",
       "337                        1                       0              0   \n",
       "338                        1                       0              0   \n",
       "339                        0                       1              0   \n",
       "340                        1                       0              0   \n",
       "341                        1                       0              0   \n",
       "342                        1                       0              0   \n",
       "343                        0                       1              0   \n",
       "344                        1                       0              0   \n",
       "345                        1                       0              0   \n",
       "346                        1                       0              0   \n",
       "347                        1                       0              0   \n",
       "348                        0                       1              0   \n",
       "349                        1                       0              0   \n",
       "350                        1                       0              0   \n",
       "351                        1                       0              0   \n",
       "352                        1                       0              0   \n",
       "353                        1                       0              0   \n",
       "354                        1                       0              0   \n",
       "355                        0                       1              0   \n",
       "356                        1                       0              0   \n",
       "357                        1                       0              0   \n",
       "358                        1                       0              0   \n",
       "359                        1                       0              0   \n",
       "361                        1                       0              0   \n",
       "362                        0                       1              0   \n",
       "363                        0                       1              1   \n",
       "364                        1                       0              0   \n",
       "365                        1                       0              0   \n",
       "366                        1                       0              0   \n",
       "367                        1                       0              0   \n",
       "368                        1                       0              0   \n",
       "369                        1                       0              0   \n",
       "370                        1                       0              0   \n",
       "371                        1                       0              0   \n",
       "372                        1                       0              0   \n",
       "373                        1                       0              0   \n",
       "374                        0                       1              0   \n",
       "375                        0                       1              0   \n",
       "376                        1                       0              0   \n",
       "377                        1                       0              0   \n",
       "378                        1                       0              0   \n",
       "379                        1                       0              0   \n",
       "380                        1                       0              0   \n",
       "381                        1                       0              0   \n",
       "382                        0                       1              0   \n",
       "383                        1                       0              0   \n",
       "384                        1                       0              0   \n",
       "385                        1                       0              0   \n",
       "386                        1                       0              0   \n",
       "387                        1                       0              0   \n",
       "388                        1                       0              0   \n",
       "389                        1                       0              0   \n",
       "392                        1                       0              0   \n",
       "396                        0                       1              0   \n",
       "397                        1                       0              0   \n",
       "398                        0                       1              0   \n",
       "399                        1                       0              0   \n",
       "400                        1                       0              0   \n",
       "402                        0                       1              0   \n",
       "403                        1                       0              0   \n",
       "404                        1                       0              0   \n",
       "405                        1                       0              0   \n",
       "406                        1                       0              0   \n",
       "407                        1                       0              0   \n",
       "408                        1                       0              0   \n",
       "409                        1                       0              0   \n",
       "410                        1                       0              0   \n",
       "411                        1                       0              0   \n",
       "412                        1                       0              0   \n",
       "413                        0                       1              0   \n",
       "414                        0                       1              0   \n",
       "415                        1                       0              0   \n",
       "416                        1                       0              0   \n",
       "417                        1                       0              0   \n",
       "418                        1                       0              0   \n",
       "419                        1                       0              0   \n",
       "423                        0                       1              0   \n",
       "424                        1                       0              0   \n",
       "425                        1                       0              0   \n",
       "426                        1                       0              0   \n",
       "427                        1                       0              0   \n",
       "428                        0                       1              0   \n",
       "429                        0                       1              1   \n",
       "430                        0                       1              0   \n",
       "431                        1                       0              0   \n",
       "432                        1                       0              0   \n",
       "433                        1                       0              0   \n",
       "434                        1                       0              0   \n",
       "435                        1                       0              0   \n",
       "436                        1                       0              0   \n",
       "437                        0                       1              0   \n",
       "438                        1                       0              0   \n",
       "439                        1                       0              0   \n",
       "440                        1                       0              0   \n",
       "441                        0                       1              0   \n",
       "442                        1                       0              0   \n",
       "443                        1                       0              0   \n",
       "444                        1                       0              0   \n",
       "445                        0                       1              0   \n",
       "446                        0                       1              0   \n",
       "447                        0                       1              0   \n",
       "448                        1                       0              0   \n",
       "449                        1                       0              0   \n",
       "455                        1                       0              0   \n",
       "456                        0                       1              0   \n",
       "457                        1                       0              0   \n",
       "458                        1                       0              0   \n",
       "459                        1                       0              0   \n",
       "460                        0                       1              0   \n",
       "461                        0                       1              0   \n",
       "462                        1                       0              0   \n",
       "463                        1                       0              0   \n",
       "464                        0                       1              0   \n",
       "465                        1                       0              0   \n",
       "466                        0                       1              0   \n",
       "467                        0                       1              0   \n",
       "468                        1                       0              0   \n",
       "469                        0                       1              0   \n",
       "470                        0                       1              0   \n",
       "471                        1                       0              0   \n",
       "472                        1                       0              0   \n",
       "473                        1                       0              0   \n",
       "474                        1                       0              0   \n",
       "475                        1                       0              0   \n",
       "476                        0                       1              0   \n",
       "477                        1                       0              0   \n",
       "478                        1                       0              0   \n",
       "479                        0                       1              0   \n",
       "484                        1                       0              0   \n",
       "485                        1                       0              0   \n",
       "486                        1                       0              0   \n",
       "487                        1                       0              0   \n",
       "488                        1                       0              0   \n",
       "489                        0                       1              0   \n",
       "491                        1                       0              0   \n",
       "492                        0                       1              1   \n",
       "493                        1                       0              0   \n",
       "494                        1                       0              0   \n",
       "495                        1                       0              0   \n",
       "496                        0                       1              0   \n",
       "497                        1                       0              0   \n",
       "498                        1                       0              0   \n",
       "499                        1                       0              0   \n",
       "500                        1                       0              0   \n",
       "501                        0                       1              0   \n",
       "502                        1                       0              0   \n",
       "503                        0                       1              0   \n",
       "504                        0                       1              0   \n",
       "505                        1                       0              0   \n",
       "506                        1                       0              0   \n",
       "507                        0                       1              0   \n",
       "508                        1                       0              0   \n",
       "509                        1                       0              0   \n",
       "510                        0                       1              0   \n",
       "511                        0                       1              0   \n",
       "512                        0                       1              0   \n",
       "513                        1                       0              0   \n",
       "514                        0                       1              0   \n",
       "515                        0                       1              0   \n",
       "516                        1                       0              0   \n",
       "517                        1                       0              0   \n",
       "518                        0                       1              0   \n",
       "519                        1                       0              0   \n",
       "520                        1                       0              0   \n",
       "521                        0                       1              0   \n",
       "522                        0                       1              0   \n",
       "523                        1                       0              0   \n",
       "524                        0                       1              0   \n",
       "525                        1                       0              0   \n",
       "526                        0                       1              0   \n",
       "527                        1                       0              0   \n",
       "528                        1                       0              0   \n",
       "529                        1                       0              0   \n",
       "530                        1                       0              0   \n",
       "531                        0                       1              0   \n",
       "532                        1                       0              0   \n",
       "534                        1                       0              0   \n",
       "535                        0                       1              0   \n",
       "536                        0                       1              0   \n",
       "537                        1                       0              0   \n",
       "538                        1                       0              0   \n",
       "539                        1                       0              0   \n",
       "543                        1                       0              0   \n",
       "544                        1                       0              0   \n",
       "545                        1                       0              0   \n",
       "546                        0                       1              0   \n",
       "547                        0                       1              0   \n",
       "548                        0                       1              0   \n",
       "549                        1                       0              0   \n",
       "550                        1                       0              0   \n",
       "551                        1                       0              0   \n",
       "552                        0                       1              0   \n",
       "553                        1                       0              0   \n",
       "554                        1                       0              0   \n",
       "555                        1                       0              0   \n",
       "556                        1                       0              0   \n",
       "557                        1                       0              0   \n",
       "558                        1                       0              0   \n",
       "559                        0                       1              0   \n",
       "560                        0                       1              0   \n",
       "561                        0                       1              0   \n",
       "562                        0                       1              0   \n",
       "563                        1                       0              0   \n",
       "564                        1                       0              0   \n",
       "565                        1                       0              0   \n",
       "566                        0                       1              0   \n",
       "567                        1                       0              0   \n",
       "568                        1                       0              0   \n",
       "569                        1                       0              0   \n",
       "570                        0                       1              0   \n",
       "571                        1                       0              0   \n",
       "572                        1                       0              0   \n",
       "573                        0                       1              0   \n",
       "574                        1                       0              0   \n",
       "575                        1                       0              0   \n",
       "576                        1                       0              1   \n",
       "577                        0                       1              0   \n",
       "578                        1                       0              0   \n",
       "579                        1                       0              0   \n",
       "580                        1                       0              0   \n",
       "581                        0                       1              0   \n",
       "582                        1                       0              0   \n",
       "583                        1                       0              0   \n",
       "584                        0                       1              0   \n",
       "585                        1                       0              0   \n",
       "586                        1                       0              0   \n",
       "587                        0                       1              0   \n",
       "588                        1                       0              1   \n",
       "589                        0                       1              0   \n",
       "590                        1                       0              0   \n",
       "591                        0                       1              0   \n",
       "592                        0                       1              0   \n",
       "593                        0                       1              0   \n",
       "594                        1                       0              0   \n",
       "595                        1                       0              0   \n",
       "596                        1                       0              0   \n",
       "597                        1                       0              0   \n",
       "598                        1                       0              0   \n",
       "599                        0                       1              0   \n",
       "601                        1                       0              0   \n",
       "602                        1                       0              0   \n",
       "603                        1                       0              0   \n",
       "604                        1                       0              0   \n",
       "605                        1                       0              0   \n",
       "606                        1                       0              0   \n",
       "607                        1                       0              0   \n",
       "608                        1                       0              0   \n",
       "609                        1                       0              0   \n",
       "610                        0                       1              0   \n",
       "611                        0                       1              0   \n",
       "612                        0                       1              0   \n",
       "613                        1                       0              0   \n",
       "614                        1                       0              0   \n",
       "615                        1                       0              1   \n",
       "616                        1                       0              0   \n",
       "617                        0                       1              0   \n",
       "618                        0                       1              0   \n",
       "619                        1                       0              0   \n",
       "620                        0                       1              0   \n",
       "621                        1                       0              0   \n",
       "622                        1                       0              0   \n",
       "623                        1                       0              0   \n",
       "624                        1                       0              0   \n",
       "625                        1                       0              0   \n",
       "626                        1                       0              0   \n",
       "627                        1                       0              0   \n",
       "628                        1                       0              0   \n",
       "634                        1                       0              0   \n",
       "635                        1                       0              0   \n",
       "636                        0                       1              0   \n",
       "637                        0                       1              0   \n",
       "638                        1                       0              0   \n",
       "639                        1                       0              0   \n",
       "640                        0                       1              0   \n",
       "642                        1                       0              0   \n",
       "643                        1                       0              0   \n",
       "644                        1                       0              0   \n",
       "645                        1                       0              0   \n",
       "646                        0                       1              0   \n",
       "647                        1                       0              0   \n",
       "648                        1                       0              0   \n",
       "649                        1                       0              0   \n",
       "650                        0                       1              0   \n",
       "651                        1                       0              0   \n",
       "652                        1                       0              0   \n",
       "653                        1                       0              0   \n",
       "654                        0                       1              0   \n",
       "655                        0                       1              0   \n",
       "656                        1                       0              0   \n",
       "657                        0                       1              0   \n",
       "658                        1                       0              0   \n",
       "659                        1                       0              0   \n",
       "660                        1                       0              0   \n",
       "661                        1                       0              0   \n",
       "662                        1                       0              0   \n",
       "663                        1                       0              1   \n",
       "664                        1                       0              0   \n",
       "665                        1                       0              0   \n",
       "666                        1                       0              0   \n",
       "667                        1                       0              0   \n",
       "668                        0                       1              0   \n",
       "669                        1                       0              0   \n",
       "670                        1                       0              0   \n",
       "671                        1                       0              0   \n",
       "672                        0                       1              0   \n",
       "673                        1                       0              0   \n",
       "674                        1                       0              0   \n",
       "675                        0                       1              1   \n",
       "676                        1                       0              0   \n",
       "677                        1                       0              0   \n",
       "678                        1                       0              0   \n",
       "679                        0                       1              0   \n",
       "680                        0                       1              0   \n",
       "681                        1                       0              0   \n",
       "682                        1                       0              1   \n",
       "683                        1                       0              0   \n",
       "684                        1                       0              0   \n",
       "685                        1                       0              1   \n",
       "686                        1                       0              0   \n",
       "687                        1                       0              0   \n",
       "689                        1                       0              0   \n",
       "690                        1                       0              0   \n",
       "691                        1                       0              0   \n",
       "692                        1                       0              0   \n",
       "693                        0                       1              0   \n",
       "694                        1                       0              0   \n",
       "695                        1                       0              0   \n",
       "696                        1                       0              0   \n",
       "697                        1                       0              0   \n",
       "698                        1                       0              0   \n",
       "699                        1                       0              0   \n",
       "700                        1                       0              0   \n",
       "701                        0                       1              0   \n",
       "702                        1                       0              0   \n",
       "703                        1                       0              0   \n",
       "704                        1                       0              0   \n",
       "705                        0                       1              0   \n",
       "706                        1                       0              0   \n",
       "707                        1                       0              0   \n",
       "708                        1                       0              0   \n",
       "709                        1                       0              0   \n",
       "710                        0                       1              0   \n",
       "711                        1                       0              0   \n",
       "712                        1                       0              0   \n",
       "713                        0                       1              0   \n",
       "714                        1                       0              0   \n",
       "715                        1                       0              0   \n",
       "716                        1                       0              0   \n",
       "717                        1                       0              0   \n",
       "718                        0                       1              0   \n",
       "719                        1                       0              0   \n",
       "720                        1                       0              0   \n",
       "721                        1                       0              0   \n",
       "722                        0                       1              0   \n",
       "723                        0                       1              0   \n",
       "724                        1                       0              0   \n",
       "725                        0                       1              0   \n",
       "726                        0                       1              0   \n",
       "727                        1                       0              0   \n",
       "728                        1                       0              0   \n",
       "729                        1                       0              0   \n",
       "730                        1                       0              0   \n",
       "731                        0                       1              0   \n",
       "732                        1                       0              0   \n",
       "733                        1                       0              0   \n",
       "734                        1                       0              0   \n",
       "735                        0                       1              0   \n",
       "736                        0                       1              0   \n",
       "737                        1                       0              0   \n",
       "738                        1                       0              0   \n",
       "739                        0                       1              0   \n",
       "740                        1                       0              0   \n",
       "741                        0                       1              0   \n",
       "742                        0                       1              0   \n",
       "743                        1                       0              0   \n",
       "744                        1                       0              0   \n",
       "745                        1                       0              0   \n",
       "746                        1                       0              0   \n",
       "747                        0                       1              0   \n",
       "748                        0                       1              0   \n",
       "749                        1                       0              0   \n",
       "753                        1                       0              0   \n",
       "754                        1                       0              0   \n",
       "755                        1                       0              0   \n",
       "756                        1                       0              0   \n",
       "757                        1                       0              0   \n",
       "758                        1                       0              0   \n",
       "759                        0                       1              0   \n",
       "760                        1                       0              0   \n",
       "762                        1                       0              0   \n",
       "763                        1                       0              0   \n",
       "764                        1                       0              0   \n",
       "765                        1                       0              0   \n",
       "766                        0                       1              0   \n",
       "767                        0                       1              0   \n",
       "768                        1                       0              0   \n",
       "769                        1                       0              0   \n",
       "770                        0                       1              0   \n",
       "771                        1                       0              0   \n",
       "772                        1                       0              0   \n",
       "773                        0                       1              0   \n",
       "774                        0                       1              0   \n",
       "775                        0                       1              0   \n",
       "776                        0                       1              0   \n",
       "777                        1                       0              0   \n",
       "778                        1                       0              0   \n",
       "779                        1                       0              0   \n",
       "783                        1                       0              0   \n",
       "784                        1                       0              1   \n",
       "785                        1                       0              0   \n",
       "786                        1                       0              0   \n",
       "787                        0                       1              0   \n",
       "788                        1                       0              0   \n",
       "789                        0                       1              0   \n",
       "790                        0                       1              0   \n",
       "791                        1                       0              0   \n",
       "792                        1                       0              0   \n",
       "793                        1                       0              0   \n",
       "795                        0                       1              0   \n",
       "796                        1                       0              0   \n",
       "797                        1                       0              0   \n",
       "798                        1                       0              0   \n",
       "799                        0                       1              0   \n",
       "800                        1                       0              0   \n",
       "801                        0                       1              0   \n",
       "802                        1                       0              0   \n",
       "803                        1                       0              0   \n",
       "804                        1                       0              0   \n",
       "805                        1                       0              0   \n",
       "806                        0                       1              0   \n",
       "807                        1                       0              0   \n",
       "808                        1                       0              0   \n",
       "809                        1                       0              0   \n",
       "813                        1                       0              0   \n",
       "814                        1                       0              0   \n",
       "815                        1                       0              0   \n",
       "816                        0                       1              0   \n",
       "817                        1                       0              0   \n",
       "818                        1                       0              0   \n",
       "819                        1                       0              0   \n",
       "820                        0                       1              0   \n",
       "821                        1                       0              0   \n",
       "822                        1                       0              0   \n",
       "823                        1                       0              0   \n",
       "824                        1                       0              0   \n",
       "825                        1                       0              0   \n",
       "826                        1                       0              0   \n",
       "827                        0                       1              0   \n",
       "828                        1                       0              0   \n",
       "829                        0                       1              0   \n",
       "830                        1                       0              0   \n",
       "831                        1                       0              0   \n",
       "832                        1                       0              0   \n",
       "833                        1                       0              0   \n",
       "834                        1                       0              0   \n",
       "\n",
       "     Loc_Bengaluru  Loc_Chennai  Loc_Gurgaon  Loc_Hyderābād  Loc_India  \\\n",
       "0                0            0            0              0          0   \n",
       "1                0            0            1              0          0   \n",
       "2                1            0            0              0          0   \n",
       "3                0            0            0              0          0   \n",
       "4                0            0            0              1          0   \n",
       "5                0            0            0              0          0   \n",
       "6                0            0            1              0          0   \n",
       "7                0            0            0              0          1   \n",
       "8                0            0            0              0          0   \n",
       "9                0            1            0              0          0   \n",
       "10               0            0            0              0          0   \n",
       "11               0            1            0              0          0   \n",
       "12               0            1            0              0          0   \n",
       "13               0            0            0              0          0   \n",
       "14               0            0            0              0          0   \n",
       "15               0            0            1              0          0   \n",
       "16               0            0            0              0          0   \n",
       "17               0            0            0              0          0   \n",
       "18               0            0            0              0          0   \n",
       "19               0            0            0              0          1   \n",
       "20               1            0            0              0          0   \n",
       "21               0            0            0              0          0   \n",
       "22               0            0            0              0          0   \n",
       "23               0            0            0              0          0   \n",
       "24               0            0            0              0          0   \n",
       "25               0            1            0              0          0   \n",
       "26               1            0            0              0          0   \n",
       "27               0            0            0              0          0   \n",
       "28               0            0            0              0          0   \n",
       "29               0            0            0              0          0   \n",
       "30               0            0            0              0          0   \n",
       "31               1            0            0              0          0   \n",
       "32               0            0            1              0          0   \n",
       "33               0            0            1              0          0   \n",
       "34               1            0            0              0          0   \n",
       "35               1            0            0              0          0   \n",
       "36               0            1            0              0          0   \n",
       "37               0            0            0              0          0   \n",
       "38               0            0            0              0          0   \n",
       "39               1            0            0              0          0   \n",
       "40               1            0            0              0          0   \n",
       "41               0            0            0              1          0   \n",
       "42               0            0            1              0          0   \n",
       "43               0            0            0              0          0   \n",
       "44               0            0            1              0          0   \n",
       "45               1            0            0              0          0   \n",
       "46               0            0            1              0          0   \n",
       "47               1            0            0              0          0   \n",
       "48               0            1            0              0          0   \n",
       "49               0            0            0              0          1   \n",
       "50               1            0            0              0          0   \n",
       "51               0            0            0              0          1   \n",
       "52               0            0            0              0          0   \n",
       "53               0            0            0              0          1   \n",
       "54               1            0            0              0          0   \n",
       "55               0            1            0              0          0   \n",
       "56               1            0            0              0          0   \n",
       "57               0            0            0              0          1   \n",
       "58               0            0            1              0          0   \n",
       "59               1            0            0              0          0   \n",
       "60               0            0            0              0          0   \n",
       "61               0            0            1              0          0   \n",
       "62               0            0            1              0          0   \n",
       "63               0            0            0              0          0   \n",
       "64               0            0            0              0          1   \n",
       "65               0            1            0              0          0   \n",
       "66               0            0            0              0          0   \n",
       "67               0            0            0              0          1   \n",
       "68               0            0            0              0          1   \n",
       "69               0            0            1              0          0   \n",
       "70               0            0            0              0          0   \n",
       "71               0            0            0              0          0   \n",
       "72               0            0            0              0          0   \n",
       "73               0            0            0              0          0   \n",
       "74               0            0            0              0          0   \n",
       "75               0            0            0              0          0   \n",
       "76               0            0            0              1          0   \n",
       "77               0            0            0              0          0   \n",
       "78               0            0            0              0          1   \n",
       "79               0            0            0              0          0   \n",
       "80               0            0            0              1          0   \n",
       "81               1            0            0              0          0   \n",
       "82               0            1            0              0          0   \n",
       "83               1            0            0              0          0   \n",
       "84               1            0            0              0          0   \n",
       "85               1            0            0              0          0   \n",
       "86               1            0            0              0          0   \n",
       "87               1            0            0              0          0   \n",
       "88               0            0            0              0          0   \n",
       "89               0            0            0              0          0   \n",
       "91               0            0            0              0          1   \n",
       "92               1            0            0              0          0   \n",
       "93               0            1            0              0          0   \n",
       "94               0            0            0              0          1   \n",
       "95               1            0            0              0          0   \n",
       "96               0            0            1              0          0   \n",
       "97               0            0            0              0          0   \n",
       "98               0            0            0              0          0   \n",
       "99               0            0            0              1          0   \n",
       "100              1            0            0              0          0   \n",
       "101              1            0            0              0          0   \n",
       "102              1            0            0              0          0   \n",
       "103              0            0            0              0          0   \n",
       "104              1            0            0              0          0   \n",
       "105              1            0            0              0          0   \n",
       "106              0            0            0              0          0   \n",
       "107              1            0            0              0          0   \n",
       "109              0            1            0              0          0   \n",
       "110              1            0            0              0          0   \n",
       "111              1            0            0              0          0   \n",
       "112              1            0            0              0          0   \n",
       "113              0            0            0              0          1   \n",
       "114              0            0            0              0          0   \n",
       "115              1            0            0              0          0   \n",
       "116              1            0            0              0          0   \n",
       "117              1            0            0              0          0   \n",
       "118              0            0            1              0          0   \n",
       "119              1            0            0              0          0   \n",
       "121              0            0            0              0          0   \n",
       "123              1            0            0              0          0   \n",
       "124              0            1            0              0          0   \n",
       "125              0            0            1              0          0   \n",
       "127              0            0            0              0          1   \n",
       "128              0            0            0              0          0   \n",
       "129              1            0            0              0          0   \n",
       "130              0            0            0              0          0   \n",
       "131              1            0            0              0          0   \n",
       "132              0            1            0              0          0   \n",
       "133              0            1            0              0          0   \n",
       "134              0            0            0              0          1   \n",
       "135              0            1            0              0          0   \n",
       "136              0            1            0              0          0   \n",
       "137              0            0            0              1          0   \n",
       "138              0            0            0              0          0   \n",
       "139              0            1            0              0          0   \n",
       "140              0            0            0              0          1   \n",
       "141              0            0            0              0          0   \n",
       "142              0            0            0              1          0   \n",
       "143              0            0            0              0          1   \n",
       "144              0            0            0              0          1   \n",
       "145              0            0            0              0          0   \n",
       "146              0            0            0              0          0   \n",
       "147              0            0            0              0          0   \n",
       "148              0            0            0              0          0   \n",
       "149              0            0            1              0          0   \n",
       "157              1            0            0              0          0   \n",
       "158              0            0            1              0          0   \n",
       "159              0            0            1              0          0   \n",
       "160              0            0            0              1          0   \n",
       "161              1            0            0              0          0   \n",
       "162              0            0            1              0          0   \n",
       "163              0            0            0              0          1   \n",
       "164              0            0            0              0          0   \n",
       "165              0            0            0              0          0   \n",
       "166              0            1            0              0          0   \n",
       "167              1            0            0              0          0   \n",
       "168              1            0            0              0          0   \n",
       "169              1            0            0              0          0   \n",
       "170              0            0            0              0          1   \n",
       "171              0            1            0              0          0   \n",
       "172              1            0            0              0          0   \n",
       "173              0            1            0              0          0   \n",
       "174              0            0            0              0          1   \n",
       "175              0            0            0              0          0   \n",
       "176              1            0            0              0          0   \n",
       "177              0            1            0              0          0   \n",
       "178              0            0            0              0          0   \n",
       "179              0            0            1              0          0   \n",
       "180              0            0            0              0          0   \n",
       "182              0            0            1              0          0   \n",
       "183              0            0            0              1          0   \n",
       "184              1            0            0              0          0   \n",
       "185              0            1            0              0          0   \n",
       "186              1            0            0              0          0   \n",
       "187              0            0            0              0          0   \n",
       "188              1            0            0              0          0   \n",
       "189              0            0            0              0          0   \n",
       "190              0            0            0              0          0   \n",
       "191              1            0            0              0          0   \n",
       "192              1            0            0              0          0   \n",
       "193              1            0            0              0          0   \n",
       "194              0            0            0              0          0   \n",
       "195              0            0            1              0          0   \n",
       "196              0            0            1              0          0   \n",
       "197              0            0            1              0          0   \n",
       "198              0            0            0              0          0   \n",
       "199              1            0            0              0          0   \n",
       "200              1            0            0              0          0   \n",
       "201              0            0            0              1          0   \n",
       "202              0            0            0              0          0   \n",
       "203              1            0            0              0          0   \n",
       "204              1            0            0              0          0   \n",
       "205              0            0            0              0          0   \n",
       "206              0            0            0              0          0   \n",
       "207              1            0            0              0          0   \n",
       "208              0            1            0              0          0   \n",
       "209              0            0            0              0          0   \n",
       "211              1            0            0              0          0   \n",
       "215              1            0            0              0          0   \n",
       "216              0            0            1              0          0   \n",
       "217              0            0            1              0          0   \n",
       "218              0            1            0              0          0   \n",
       "219              1            0            0              0          0   \n",
       "220              1            0            0              0          0   \n",
       "221              1            0            0              0          0   \n",
       "222              1            0            0              0          0   \n",
       "223              0            1            0              0          0   \n",
       "224              0            1            0              0          0   \n",
       "225              0            0            0              0          1   \n",
       "226              0            0            0              0          0   \n",
       "227              1            0            0              0          0   \n",
       "228              0            0            0              0          1   \n",
       "229              1            0            0              0          0   \n",
       "230              0            0            0              0          0   \n",
       "231              1            0            0              0          0   \n",
       "232              1            0            0              0          0   \n",
       "233              0            0            1              0          0   \n",
       "234              1            0            0              0          0   \n",
       "235              1            0            0              0          0   \n",
       "236              0            0            0              0          0   \n",
       "237              0            1            0              0          0   \n",
       "238              0            0            0              0          1   \n",
       "239              0            0            0              1          0   \n",
       "242              0            0            0              0          0   \n",
       "243              1            0            0              0          0   \n",
       "244              0            0            0              1          0   \n",
       "245              1            0            0              0          0   \n",
       "246              1            0            0              0          0   \n",
       "247              1            0            0              0          0   \n",
       "248              0            0            0              0          0   \n",
       "249              0            0            1              0          0   \n",
       "250              1            0            0              0          0   \n",
       "251              1            0            0              0          0   \n",
       "252              0            0            0              0          0   \n",
       "253              1            0            0              0          0   \n",
       "254              0            0            0              0          1   \n",
       "255              0            0            0              0          0   \n",
       "258              0            0            0              1          0   \n",
       "259              0            0            0              0          0   \n",
       "260              0            0            0              1          0   \n",
       "261              0            0            0              0          1   \n",
       "262              1            0            0              0          0   \n",
       "263              1            0            0              0          0   \n",
       "264              0            0            0              0          1   \n",
       "265              0            0            0              0          1   \n",
       "266              1            0            0              0          0   \n",
       "267              1            0            0              0          0   \n",
       "268              0            0            0              0          0   \n",
       "269              0            0            0              0          0   \n",
       "271              0            0            1              0          0   \n",
       "276              0            0            0              0          0   \n",
       "277              1            0            0              0          0   \n",
       "278              0            0            0              0          0   \n",
       "279              0            0            0              1          0   \n",
       "280              1            0            0              0          0   \n",
       "281              0            0            1              0          0   \n",
       "282              0            0            0              0          0   \n",
       "283              0            0            0              0          1   \n",
       "284              1            0            0              0          0   \n",
       "285              1            0            0              0          0   \n",
       "286              0            0            0              0          0   \n",
       "287              1            0            0              0          0   \n",
       "288              0            0            0              1          0   \n",
       "289              0            0            0              0          0   \n",
       "290              0            0            0              0          0   \n",
       "291              0            0            0              0          0   \n",
       "292              0            0            1              0          0   \n",
       "293              0            0            0              0          0   \n",
       "294              1            0            0              0          0   \n",
       "295              1            0            0              0          0   \n",
       "296              1            0            0              0          0   \n",
       "297              1            0            0              0          0   \n",
       "298              0            0            0              0          0   \n",
       "299              1            0            0              0          0   \n",
       "300              1            0            0              0          0   \n",
       "303              1            0            0              0          0   \n",
       "304              1            0            0              0          0   \n",
       "305              0            0            0              0          0   \n",
       "306              0            0            0              0          1   \n",
       "307              0            0            0              0          1   \n",
       "308              0            0            0              1          0   \n",
       "309              0            0            0              0          1   \n",
       "310              0            0            0              1          0   \n",
       "311              0            0            0              0          0   \n",
       "312              1            0            0              0          0   \n",
       "313              0            0            0              1          0   \n",
       "314              1            0            0              0          0   \n",
       "315              0            0            0              0          0   \n",
       "316              0            0            0              1          0   \n",
       "317              0            0            1              0          0   \n",
       "318              1            0            0              0          0   \n",
       "319              0            0            1              0          0   \n",
       "320              0            0            0              0          0   \n",
       "321              0            0            0              0          0   \n",
       "322              1            0            0              0          0   \n",
       "323              0            0            0              0          0   \n",
       "324              0            0            0              0          0   \n",
       "325              0            0            0              1          0   \n",
       "326              0            0            0              0          1   \n",
       "327              0            0            0              1          0   \n",
       "328              0            0            0              0          0   \n",
       "329              0            0            0              0          1   \n",
       "330              0            0            1              0          0   \n",
       "334              1            0            0              0          0   \n",
       "335              0            0            0              0          0   \n",
       "336              0            0            0              0          0   \n",
       "337              1            0            0              0          0   \n",
       "338              1            0            0              0          0   \n",
       "339              1            0            0              0          0   \n",
       "340              0            0            0              0          0   \n",
       "341              0            1            0              0          0   \n",
       "342              0            0            0              0          1   \n",
       "343              1            0            0              0          0   \n",
       "344              1            0            0              0          0   \n",
       "345              1            0            0              0          0   \n",
       "346              1            0            0              0          0   \n",
       "347              0            0            0              1          0   \n",
       "348              0            0            0              0          0   \n",
       "349              1            0            0              0          0   \n",
       "350              0            0            1              0          0   \n",
       "351              0            0            0              0          0   \n",
       "352              0            0            0              0          0   \n",
       "353              0            0            0              0          0   \n",
       "354              0            0            1              0          0   \n",
       "355              1            0            0              0          0   \n",
       "356              0            0            0              1          0   \n",
       "357              0            0            0              1          0   \n",
       "358              1            0            0              0          0   \n",
       "359              0            1            0              0          0   \n",
       "361              0            0            0              0          1   \n",
       "362              1            0            0              0          0   \n",
       "363              0            0            0              0          0   \n",
       "364              1            0            0              0          0   \n",
       "365              0            0            0              0          0   \n",
       "366              1            0            0              0          0   \n",
       "367              0            1            0              0          0   \n",
       "368              1            0            0              0          0   \n",
       "369              0            0            0              0          0   \n",
       "370              1            0            0              0          0   \n",
       "371              0            0            0              1          0   \n",
       "372              0            0            0              0          0   \n",
       "373              0            0            0              0          0   \n",
       "374              0            0            0              0          0   \n",
       "375              1            0            0              0          0   \n",
       "376              0            0            0              0          0   \n",
       "377              1            0            0              0          0   \n",
       "378              1            0            0              0          0   \n",
       "379              0            0            0              0          0   \n",
       "380              0            0            0              0          0   \n",
       "381              0            0            0              1          0   \n",
       "382              0            0            1              0          0   \n",
       "383              1            0            0              0          0   \n",
       "384              1            0            0              0          0   \n",
       "385              1            0            0              0          0   \n",
       "386              0            0            0              1          0   \n",
       "387              0            0            0              0          0   \n",
       "388              0            1            0              0          0   \n",
       "389              1            0            0              0          0   \n",
       "392              0            0            1              0          0   \n",
       "396              0            0            0              0          1   \n",
       "397              1            0            0              0          0   \n",
       "398              0            0            0              0          0   \n",
       "399              1            0            0              0          0   \n",
       "400              0            0            0              0          0   \n",
       "402              0            1            0              0          0   \n",
       "403              0            1            0              0          0   \n",
       "404              1            0            0              0          0   \n",
       "405              1            0            0              0          0   \n",
       "406              1            0            0              0          0   \n",
       "407              1            0            0              0          0   \n",
       "408              0            0            0              1          0   \n",
       "409              1            0            0              0          0   \n",
       "410              0            0            0              0          0   \n",
       "411              1            0            0              0          0   \n",
       "412              0            0            0              0          0   \n",
       "413              0            0            0              1          0   \n",
       "414              1            0            0              0          0   \n",
       "415              1            0            0              0          0   \n",
       "416              0            0            0              0          0   \n",
       "417              0            1            0              0          0   \n",
       "418              0            0            0              0          1   \n",
       "419              0            0            0              0          1   \n",
       "423              0            0            0              0          0   \n",
       "424              0            0            0              0          0   \n",
       "425              0            0            0              0          0   \n",
       "426              0            0            0              0          0   \n",
       "427              1            0            0              0          0   \n",
       "428              1            0            0              0          0   \n",
       "429              0            0            0              0          0   \n",
       "430              1            0            0              0          0   \n",
       "431              0            0            0              1          0   \n",
       "432              0            0            0              0          1   \n",
       "433              1            0            0              0          0   \n",
       "434              1            0            0              0          0   \n",
       "435              0            0            0              1          0   \n",
       "436              0            0            0              0          0   \n",
       "437              0            0            0              1          0   \n",
       "438              0            0            1              0          0   \n",
       "439              1            0            0              0          0   \n",
       "440              0            0            0              0          0   \n",
       "441              1            0            0              0          0   \n",
       "442              0            0            0              0          0   \n",
       "443              0            0            1              0          0   \n",
       "444              1            0            0              0          0   \n",
       "445              0            0            0              0          0   \n",
       "446              0            0            0              0          0   \n",
       "447              1            0            0              0          0   \n",
       "448              0            0            0              0          0   \n",
       "449              0            0            0              0          0   \n",
       "455              1            0            0              0          0   \n",
       "456              0            1            0              0          0   \n",
       "457              1            0            0              0          0   \n",
       "458              0            0            1              0          0   \n",
       "459              0            1            0              0          0   \n",
       "460              0            0            0              0          1   \n",
       "461              0            0            0              0          0   \n",
       "462              1            0            0              0          0   \n",
       "463              0            1            0              0          0   \n",
       "464              0            0            0              0          0   \n",
       "465              0            0            0              0          1   \n",
       "466              1            0            0              0          0   \n",
       "467              0            0            0              0          1   \n",
       "468              0            0            0              0          0   \n",
       "469              0            0            0              0          0   \n",
       "470              1            0            0              0          0   \n",
       "471              0            0            0              0          0   \n",
       "472              0            0            0              0          0   \n",
       "473              0            1            0              0          0   \n",
       "474              0            0            0              0          0   \n",
       "475              0            0            0              0          0   \n",
       "476              0            0            0              0          0   \n",
       "477              0            0            0              0          1   \n",
       "478              0            0            0              0          1   \n",
       "479              0            0            0              0          1   \n",
       "484              0            0            1              0          0   \n",
       "485              1            0            0              0          0   \n",
       "486              1            0            0              0          0   \n",
       "487              0            0            0              0          1   \n",
       "488              0            0            1              0          0   \n",
       "489              0            0            0              0          0   \n",
       "491              1            0            0              0          0   \n",
       "492              0            0            0              0          0   \n",
       "493              0            0            0              0          0   \n",
       "494              0            0            0              0          0   \n",
       "495              1            0            0              0          0   \n",
       "496              1            0            0              0          0   \n",
       "497              0            1            0              0          0   \n",
       "498              1            0            0              0          0   \n",
       "499              0            0            0              1          0   \n",
       "500              0            1            0              0          0   \n",
       "501              0            0            0              0          0   \n",
       "502              1            0            0              0          0   \n",
       "503              0            0            0              0          1   \n",
       "504              0            0            0              0          0   \n",
       "505              0            0            0              1          0   \n",
       "506              0            0            0              0          0   \n",
       "507              0            0            0              0          1   \n",
       "508              1            0            0              0          0   \n",
       "509              0            1            0              0          0   \n",
       "510              1            0            0              0          0   \n",
       "511              0            0            0              1          0   \n",
       "512              0            0            0              0          0   \n",
       "513              0            0            0              0          0   \n",
       "514              0            0            0              0          1   \n",
       "515              0            0            0              0          0   \n",
       "516              0            0            0              0          0   \n",
       "517              1            0            0              0          0   \n",
       "518              1            0            0              0          0   \n",
       "519              1            0            0              0          0   \n",
       "520              1            0            0              0          0   \n",
       "521              0            0            0              0          1   \n",
       "522              0            0            0              0          1   \n",
       "523              1            0            0              0          0   \n",
       "524              0            0            0              1          0   \n",
       "525              0            1            0              0          0   \n",
       "526              0            0            0              0          0   \n",
       "527              0            1            0              0          0   \n",
       "528              0            0            0              0          0   \n",
       "529              0            0            1              0          0   \n",
       "530              1            0            0              0          0   \n",
       "531              0            0            0              0          0   \n",
       "532              0            0            1              0          0   \n",
       "534              0            0            1              0          0   \n",
       "535              0            1            0              0          0   \n",
       "536              0            0            0              0          0   \n",
       "537              1            0            0              0          0   \n",
       "538              0            0            0              0          0   \n",
       "539              1            0            0              0          0   \n",
       "543              0            0            0              1          0   \n",
       "544              1            0            0              0          0   \n",
       "545              0            0            0              0          1   \n",
       "546              0            0            0              0          1   \n",
       "547              0            0            0              0          0   \n",
       "548              0            0            0              0          1   \n",
       "549              0            0            0              0          0   \n",
       "550              0            0            0              0          0   \n",
       "551              0            0            1              0          0   \n",
       "552              0            0            0              0          1   \n",
       "553              1            0            0              0          0   \n",
       "554              0            0            0              0          0   \n",
       "555              0            0            0              0          0   \n",
       "556              0            0            0              0          0   \n",
       "557              1            0            0              0          0   \n",
       "558              0            0            0              1          0   \n",
       "559              0            0            0              0          1   \n",
       "560              0            0            0              0          0   \n",
       "561              1            0            0              0          0   \n",
       "562              1            0            0              0          0   \n",
       "563              0            1            0              0          0   \n",
       "564              0            0            0              0          0   \n",
       "565              1            0            0              0          0   \n",
       "566              0            0            0              0          0   \n",
       "567              1            0            0              0          0   \n",
       "568              0            0            0              0          0   \n",
       "569              1            0            0              0          0   \n",
       "570              0            0            1              0          0   \n",
       "571              1            0            0              0          0   \n",
       "572              1            0            0              0          0   \n",
       "573              0            0            0              0          1   \n",
       "574              1            0            0              0          0   \n",
       "575              1            0            0              0          0   \n",
       "576              0            0            0              0          0   \n",
       "577              1            0            0              0          0   \n",
       "578              0            0            0              0          0   \n",
       "579              1            0            0              0          0   \n",
       "580              1            0            0              0          0   \n",
       "581              1            0            0              0          0   \n",
       "582              0            0            0              0          0   \n",
       "583              0            0            0              0          0   \n",
       "584              0            0            0              0          0   \n",
       "585              0            0            0              1          0   \n",
       "586              0            0            0              0          0   \n",
       "587              0            0            0              0          0   \n",
       "588              0            0            0              0          0   \n",
       "589              0            0            0              0          1   \n",
       "590              0            0            1              0          0   \n",
       "591              0            0            0              0          1   \n",
       "592              0            0            0              0          1   \n",
       "593              0            0            0              0          0   \n",
       "594              0            0            0              1          0   \n",
       "595              0            0            0              0          0   \n",
       "596              1            0            0              0          0   \n",
       "597              0            0            0              0          0   \n",
       "598              0            0            0              0          0   \n",
       "599              0            0            0              0          1   \n",
       "601              0            0            0              1          0   \n",
       "602              0            0            0              1          0   \n",
       "603              1            0            0              0          0   \n",
       "604              1            0            0              0          0   \n",
       "605              0            0            0              0          0   \n",
       "606              0            0            1              0          0   \n",
       "607              0            0            0              1          0   \n",
       "608              0            0            0              0          0   \n",
       "609              1            0            0              0          0   \n",
       "610              0            0            0              0          0   \n",
       "611              0            0            0              0          0   \n",
       "612              1            0            0              0          0   \n",
       "613              1            0            0              0          0   \n",
       "614              1            0            0              0          0   \n",
       "615              0            0            0              0          0   \n",
       "616              0            0            0              1          0   \n",
       "617              1            0            0              0          0   \n",
       "618              1            0            0              0          0   \n",
       "619              0            0            0              0          0   \n",
       "620              0            0            0              0          0   \n",
       "621              1            0            0              0          0   \n",
       "622              0            0            0              0          0   \n",
       "623              0            0            0              0          0   \n",
       "624              0            0            0              1          0   \n",
       "625              1            0            0              0          0   \n",
       "626              0            0            0              1          0   \n",
       "627              1            0            0              0          0   \n",
       "628              1            0            0              0          0   \n",
       "634              1            0            0              0          0   \n",
       "635              0            0            0              0          0   \n",
       "636              0            0            0              0          1   \n",
       "637              0            0            0              0          0   \n",
       "638              1            0            0              0          0   \n",
       "639              0            0            0              1          0   \n",
       "640              0            0            0              0          0   \n",
       "642              1            0            0              0          0   \n",
       "643              0            0            0              0          0   \n",
       "644              1            0            0              0          0   \n",
       "645              0            0            1              0          0   \n",
       "646              1            0            0              0          0   \n",
       "647              1            0            0              0          0   \n",
       "648              1            0            0              0          0   \n",
       "649              0            1            0              0          0   \n",
       "650              0            1            0              0          0   \n",
       "651              1            0            0              0          0   \n",
       "652              0            1            0              0          0   \n",
       "653              0            0            0              1          0   \n",
       "654              0            0            0              0          0   \n",
       "655              0            0            0              0          0   \n",
       "656              0            1            0              0          0   \n",
       "657              1            0            0              0          0   \n",
       "658              0            1            0              0          0   \n",
       "659              0            0            0              0          0   \n",
       "660              1            0            0              0          0   \n",
       "661              0            0            1              0          0   \n",
       "662              0            1            0              0          0   \n",
       "663              0            0            0              0          0   \n",
       "664              1            0            0              0          0   \n",
       "665              1            0            0              0          0   \n",
       "666              0            0            0              0          0   \n",
       "667              0            0            0              0          0   \n",
       "668              0            0            1              0          0   \n",
       "669              1            0            0              0          0   \n",
       "670              0            0            0              0          0   \n",
       "671              1            0            0              0          0   \n",
       "672              0            0            0              0          0   \n",
       "673              0            0            0              1          0   \n",
       "674              1            0            0              0          0   \n",
       "675              0            0            0              0          0   \n",
       "676              0            0            0              0          0   \n",
       "677              0            0            0              0          0   \n",
       "678              0            0            0              0          0   \n",
       "679              0            0            0              0          1   \n",
       "680              0            0            0              0          1   \n",
       "681              0            0            0              0          0   \n",
       "682              0            0            0              0          0   \n",
       "683              1            0            0              0          0   \n",
       "684              0            0            0              0          1   \n",
       "685              0            0            0              0          0   \n",
       "686              1            0            0              0          0   \n",
       "687              0            0            0              0          1   \n",
       "689              0            0            0              0          0   \n",
       "690              1            0            0              0          0   \n",
       "691              1            0            0              0          0   \n",
       "692              0            0            0              1          0   \n",
       "693              0            0            0              0          0   \n",
       "694              1            0            0              0          0   \n",
       "695              0            0            0              0          0   \n",
       "696              0            1            0              0          0   \n",
       "697              1            0            0              0          0   \n",
       "698              1            0            0              0          0   \n",
       "699              0            0            0              0          0   \n",
       "700              0            0            1              0          0   \n",
       "701              0            0            0              0          1   \n",
       "702              0            0            0              0          0   \n",
       "703              0            0            0              0          0   \n",
       "704              0            0            0              0          1   \n",
       "705              1            0            0              0          0   \n",
       "706              1            0            0              0          0   \n",
       "707              0            0            0              1          0   \n",
       "708              0            0            0              0          1   \n",
       "709              0            0            0              0          0   \n",
       "710              0            0            0              0          1   \n",
       "711              0            0            1              0          0   \n",
       "712              0            0            1              0          0   \n",
       "713              0            0            0              0          0   \n",
       "714              1            0            0              0          0   \n",
       "715              1            0            0              0          0   \n",
       "716              1            0            0              0          0   \n",
       "717              1            0            0              0          0   \n",
       "718              1            0            0              0          0   \n",
       "719              0            0            0              0          1   \n",
       "720              1            0            0              0          0   \n",
       "721              0            1            0              0          0   \n",
       "722              0            0            0              0          1   \n",
       "723              0            0            0              0          1   \n",
       "724              0            0            0              0          0   \n",
       "725              0            0            0              0          0   \n",
       "726              0            0            0              0          0   \n",
       "727              1            0            0              0          0   \n",
       "728              0            1            0              0          0   \n",
       "729              1            0            0              0          0   \n",
       "730              0            1            0              0          0   \n",
       "731              0            0            0              0          0   \n",
       "732              0            0            0              1          0   \n",
       "733              0            0            0              0          0   \n",
       "734              1            0            0              0          0   \n",
       "735              0            0            1              0          0   \n",
       "736              0            0            0              0          0   \n",
       "737              1            0            0              0          0   \n",
       "738              0            0            0              0          1   \n",
       "739              0            0            0              1          0   \n",
       "740              0            0            0              0          0   \n",
       "741              1            0            0              0          0   \n",
       "742              1            0            0              0          0   \n",
       "743              0            0            0              0          0   \n",
       "744              0            1            0              0          0   \n",
       "745              0            0            0              0          0   \n",
       "746              0            0            0              1          0   \n",
       "747              0            0            0              0          0   \n",
       "748              0            0            0              0          0   \n",
       "749              1            0            0              0          0   \n",
       "753              0            0            0              0          0   \n",
       "754              0            0            0              0          0   \n",
       "755              1            0            0              0          0   \n",
       "756              1            0            0              0          0   \n",
       "757              0            0            0              0          0   \n",
       "758              1            0            0              0          0   \n",
       "759              0            0            0              0          0   \n",
       "760              1            0            0              0          0   \n",
       "762              0            0            0              0          1   \n",
       "763              1            0            0              0          0   \n",
       "764              1            0            0              0          0   \n",
       "765              0            0            0              0          0   \n",
       "766              0            0            0              0          1   \n",
       "767              0            0            0              0          0   \n",
       "768              0            0            0              0          0   \n",
       "769              0            1            0              0          0   \n",
       "770              0            0            0              0          0   \n",
       "771              0            0            0              1          0   \n",
       "772              1            0            0              0          0   \n",
       "773              0            1            0              0          0   \n",
       "774              0            0            0              0          0   \n",
       "775              0            0            1              0          0   \n",
       "776              0            0            0              0          0   \n",
       "777              0            0            0              0          0   \n",
       "778              0            0            0              0          0   \n",
       "779              0            0            0              0          0   \n",
       "783              1            0            0              0          0   \n",
       "784              0            0            0              0          0   \n",
       "785              0            1            0              0          0   \n",
       "786              0            0            0              0          0   \n",
       "787              0            0            0              0          0   \n",
       "788              1            0            0              0          0   \n",
       "789              0            0            0              0          0   \n",
       "790              0            0            0              0          0   \n",
       "791              0            1            0              0          0   \n",
       "792              0            0            0              1          0   \n",
       "793              0            0            0              0          0   \n",
       "795              0            0            0              0          1   \n",
       "796              0            0            0              0          0   \n",
       "797              0            0            0              0          1   \n",
       "798              1            0            0              0          0   \n",
       "799              0            0            0              0          0   \n",
       "800              1            0            0              0          0   \n",
       "801              0            0            0              0          0   \n",
       "802              0            0            1              0          0   \n",
       "803              0            0            0              0          0   \n",
       "804              0            0            0              1          0   \n",
       "805              0            0            0              0          0   \n",
       "806              0            0            0              0          0   \n",
       "807              0            0            0              0          0   \n",
       "808              0            0            1              0          0   \n",
       "809              0            0            0              0          1   \n",
       "813              1            0            0              0          0   \n",
       "814              0            0            0              0          0   \n",
       "815              0            0            0              0          0   \n",
       "816              0            0            0              0          0   \n",
       "817              0            0            1              0          0   \n",
       "818              0            0            0              1          0   \n",
       "819              1            0            0              0          0   \n",
       "820              0            0            1              0          0   \n",
       "821              0            0            1              0          0   \n",
       "822              1            0            0              0          0   \n",
       "823              1            0            0              0          0   \n",
       "824              0            0            0              1          0   \n",
       "825              1            0            0              0          0   \n",
       "826              1            0            0              0          0   \n",
       "827              0            0            0              0          1   \n",
       "828              0            1            0              0          0   \n",
       "829              0            0            0              1          0   \n",
       "830              1            0            0              0          0   \n",
       "831              1            0            0              0          0   \n",
       "832              0            0            1              0          0   \n",
       "833              1            0            0              0          0   \n",
       "834              0            1            0              0          0   \n",
       "\n",
       "     Loc_Mumbai  Loc_Noida  Loc_Other  Loc_Pune  Loc_Remote  \n",
       "0             0          1          0         0           0  \n",
       "1             0          0          0         0           0  \n",
       "2             0          0          0         0           0  \n",
       "3             0          0          0         1           0  \n",
       "4             0          0          0         0           0  \n",
       "5             0          0          1         0           0  \n",
       "6             0          0          0         0           0  \n",
       "7             0          0          0         0           0  \n",
       "8             0          0          0         0           1  \n",
       "9             0          0          0         0           0  \n",
       "10            0          0          0         0           1  \n",
       "11            0          0          0         0           0  \n",
       "12            0          0          0         0           0  \n",
       "13            0          0          0         0           1  \n",
       "14            0          0          0         0           1  \n",
       "15            0          0          0         0           0  \n",
       "16            0          0          0         0           1  \n",
       "17            0          0          0         0           1  \n",
       "18            0          0          1         0           0  \n",
       "19            0          0          0         0           0  \n",
       "20            0          0          0         0           0  \n",
       "21            0          0          0         0           1  \n",
       "22            0          0          0         0           1  \n",
       "23            0          0          0         0           1  \n",
       "24            0          0          0         0           1  \n",
       "25            0          0          0         0           0  \n",
       "26            0          0          0         0           0  \n",
       "27            0          0          1         0           0  \n",
       "28            0          0          0         0           1  \n",
       "29            0          0          1         0           0  \n",
       "30            0          1          0         0           0  \n",
       "31            0          0          0         0           0  \n",
       "32            0          0          0         0           0  \n",
       "33            0          0          0         0           0  \n",
       "34            0          0          0         0           0  \n",
       "35            0          0          0         0           0  \n",
       "36            0          0          0         0           0  \n",
       "37            0          0          1         0           0  \n",
       "38            0          0          0         1           0  \n",
       "39            0          0          0         0           0  \n",
       "40            0          0          0         0           0  \n",
       "41            0          0          0         0           0  \n",
       "42            0          0          0         0           0  \n",
       "43            0          0          0         0           1  \n",
       "44            0          0          0         0           0  \n",
       "45            0          0          0         0           0  \n",
       "46            0          0          0         0           0  \n",
       "47            0          0          0         0           0  \n",
       "48            0          0          0         0           0  \n",
       "49            0          0          0         0           0  \n",
       "50            0          0          0         0           0  \n",
       "51            0          0          0         0           0  \n",
       "52            0          0          0         1           0  \n",
       "53            0          0          0         0           0  \n",
       "54            0          0          0         0           0  \n",
       "55            0          0          0         0           0  \n",
       "56            0          0          0         0           0  \n",
       "57            0          0          0         0           0  \n",
       "58            0          0          0         0           0  \n",
       "59            0          0          0         0           0  \n",
       "60            0          0          0         1           0  \n",
       "61            0          0          0         0           0  \n",
       "62            0          0          0         0           0  \n",
       "63            1          0          0         0           0  \n",
       "64            0          0          0         0           0  \n",
       "65            0          0          0         0           0  \n",
       "66            0          0          1         0           0  \n",
       "67            0          0          0         0           0  \n",
       "68            0          0          0         0           0  \n",
       "69            0          0          0         0           0  \n",
       "70            0          0          1         0           0  \n",
       "71            0          0          0         1           0  \n",
       "72            0          0          1         0           0  \n",
       "73            0          0          0         0           1  \n",
       "74            0          0          0         0           1  \n",
       "75            0          1          0         0           0  \n",
       "76            0          0          0         0           0  \n",
       "77            0          0          0         0           1  \n",
       "78            0          0          0         0           0  \n",
       "79            0          0          0         1           0  \n",
       "80            0          0          0         0           0  \n",
       "81            0          0          0         0           0  \n",
       "82            0          0          0         0           0  \n",
       "83            0          0          0         0           0  \n",
       "84            0          0          0         0           0  \n",
       "85            0          0          0         0           0  \n",
       "86            0          0          0         0           0  \n",
       "87            0          0          0         0           0  \n",
       "88            0          0          1         0           0  \n",
       "89            0          0          0         0           1  \n",
       "91            0          0          0         0           0  \n",
       "92            0          0          0         0           0  \n",
       "93            0          0          0         0           0  \n",
       "94            0          0          0         0           0  \n",
       "95            0          0          0         0           0  \n",
       "96            0          0          0         0           0  \n",
       "97            0          0          0         0           1  \n",
       "98            1          0          0         0           0  \n",
       "99            0          0          0         0           0  \n",
       "100           0          0          0         0           0  \n",
       "101           0          0          0         0           0  \n",
       "102           0          0          0         0           0  \n",
       "103           0          0          1         0           0  \n",
       "104           0          0          0         0           0  \n",
       "105           0          0          0         0           0  \n",
       "106           0          0          1         0           0  \n",
       "107           0          0          0         0           0  \n",
       "109           0          0          0         0           0  \n",
       "110           0          0          0         0           0  \n",
       "111           0          0          0         0           0  \n",
       "112           0          0          0         0           0  \n",
       "113           0          0          0         0           0  \n",
       "114           0          0          0         1           0  \n",
       "115           0          0          0         0           0  \n",
       "116           0          0          0         0           0  \n",
       "117           0          0          0         0           0  \n",
       "118           0          0          0         0           0  \n",
       "119           0          0          0         0           0  \n",
       "121           1          0          0         0           0  \n",
       "123           0          0          0         0           0  \n",
       "124           0          0          0         0           0  \n",
       "125           0          0          0         0           0  \n",
       "127           0          0          0         0           0  \n",
       "128           0          0          0         1           0  \n",
       "129           0          0          0         0           0  \n",
       "130           1          0          0         0           0  \n",
       "131           0          0          0         0           0  \n",
       "132           0          0          0         0           0  \n",
       "133           0          0          0         0           0  \n",
       "134           0          0          0         0           0  \n",
       "135           0          0          0         0           0  \n",
       "136           0          0          0         0           0  \n",
       "137           0          0          0         0           0  \n",
       "138           0          0          1         0           0  \n",
       "139           0          0          0         0           0  \n",
       "140           0          0          0         0           0  \n",
       "141           0          0          0         0           0  \n",
       "142           0          0          0         0           0  \n",
       "143           0          0          0         0           0  \n",
       "144           0          0          0         0           0  \n",
       "145           0          0          1         0           0  \n",
       "146           0          0          0         1           0  \n",
       "147           0          0          1         0           0  \n",
       "148           0          0          1         0           0  \n",
       "149           0          0          0         0           0  \n",
       "157           0          0          0         0           0  \n",
       "158           0          0          0         0           0  \n",
       "159           0          0          0         0           0  \n",
       "160           0          0          0         0           0  \n",
       "161           0          0          0         0           0  \n",
       "162           0          0          0         0           0  \n",
       "163           0          0          0         0           0  \n",
       "164           0          0          1         0           0  \n",
       "165           0          0          0         0           1  \n",
       "166           0          0          0         0           0  \n",
       "167           0          0          0         0           0  \n",
       "168           0          0          0         0           0  \n",
       "169           0          0          0         0           0  \n",
       "170           0          0          0         0           0  \n",
       "171           0          0          0         0           0  \n",
       "172           0          0          0         0           0  \n",
       "173           0          0          0         0           0  \n",
       "174           0          0          0         0           0  \n",
       "175           0          1          0         0           0  \n",
       "176           0          0          0         0           0  \n",
       "177           0          0          0         0           0  \n",
       "178           0          0          0         0           1  \n",
       "179           0          0          0         0           0  \n",
       "180           0          1          0         0           0  \n",
       "182           0          0          0         0           0  \n",
       "183           0          0          0         0           0  \n",
       "184           0          0          0         0           0  \n",
       "185           0          0          0         0           0  \n",
       "186           0          0          0         0           0  \n",
       "187           0          0          1         0           0  \n",
       "188           0          0          0         0           0  \n",
       "189           0          0          1         0           0  \n",
       "190           0          0          0         1           0  \n",
       "191           0          0          0         0           0  \n",
       "192           0          0          0         0           0  \n",
       "193           0          0          0         0           0  \n",
       "194           0          0          1         0           0  \n",
       "195           0          0          0         0           0  \n",
       "196           0          0          0         0           0  \n",
       "197           0          0          0         0           0  \n",
       "198           0          0          1         0           0  \n",
       "199           0          0          0         0           0  \n",
       "200           0          0          0         0           0  \n",
       "201           0          0          0         0           0  \n",
       "202           0          0          1         0           0  \n",
       "203           0          0          0         0           0  \n",
       "204           0          0          0         0           0  \n",
       "205           0          0          0         0           1  \n",
       "206           0          0          0         1           0  \n",
       "207           0          0          0         0           0  \n",
       "208           0          0          0         0           0  \n",
       "209           0          0          0         1           0  \n",
       "211           0          0          0         0           0  \n",
       "215           0          0          0         0           0  \n",
       "216           0          0          0         0           0  \n",
       "217           0          0          0         0           0  \n",
       "218           0          0          0         0           0  \n",
       "219           0          0          0         0           0  \n",
       "220           0          0          0         0           0  \n",
       "221           0          0          0         0           0  \n",
       "222           0          0          0         0           0  \n",
       "223           0          0          0         0           0  \n",
       "224           0          0          0         0           0  \n",
       "225           0          0          0         0           0  \n",
       "226           0          0          1         0           0  \n",
       "227           0          0          0         0           0  \n",
       "228           0          0          0         0           0  \n",
       "229           0          0          0         0           0  \n",
       "230           1          0          0         0           0  \n",
       "231           0          0          0         0           0  \n",
       "232           0          0          0         0           0  \n",
       "233           0          0          0         0           0  \n",
       "234           0          0          0         0           0  \n",
       "235           0          0          0         0           0  \n",
       "236           0          0          1         0           0  \n",
       "237           0          0          0         0           0  \n",
       "238           0          0          0         0           0  \n",
       "239           0          0          0         0           0  \n",
       "242           0          0          0         1           0  \n",
       "243           0          0          0         0           0  \n",
       "244           0          0          0         0           0  \n",
       "245           0          0          0         0           0  \n",
       "246           0          0          0         0           0  \n",
       "247           0          0          0         0           0  \n",
       "248           0          0          0         0           0  \n",
       "249           0          0          0         0           0  \n",
       "250           0          0          0         0           0  \n",
       "251           0          0          0         0           0  \n",
       "252           0          0          1         0           0  \n",
       "253           0          0          0         0           0  \n",
       "254           0          0          0         0           0  \n",
       "255           0          0          0         0           1  \n",
       "258           0          0          0         0           0  \n",
       "259           0          0          0         0           1  \n",
       "260           0          0          0         0           0  \n",
       "261           0          0          0         0           0  \n",
       "262           0          0          0         0           0  \n",
       "263           0          0          0         0           0  \n",
       "264           0          0          0         0           0  \n",
       "265           0          0          0         0           0  \n",
       "266           0          0          0         0           0  \n",
       "267           0          0          0         0           0  \n",
       "268           0          0          0         0           1  \n",
       "269           0          0          0         1           0  \n",
       "271           0          0          0         0           0  \n",
       "276           0          1          0         0           0  \n",
       "277           0          0          0         0           0  \n",
       "278           0          0          1         0           0  \n",
       "279           0          0          0         0           0  \n",
       "280           0          0          0         0           0  \n",
       "281           0          0          0         0           0  \n",
       "282           0          0          1         0           0  \n",
       "283           0          0          0         0           0  \n",
       "284           0          0          0         0           0  \n",
       "285           0          0          0         0           0  \n",
       "286           0          0          1         0           0  \n",
       "287           0          0          0         0           0  \n",
       "288           0          0          0         0           0  \n",
       "289           0          0          0         1           0  \n",
       "290           0          0          1         0           0  \n",
       "291           0          0          0         0           1  \n",
       "292           0          0          0         0           0  \n",
       "293           0          0          0         1           0  \n",
       "294           0          0          0         0           0  \n",
       "295           0          0          0         0           0  \n",
       "296           0          0          0         0           0  \n",
       "297           0          0          0         0           0  \n",
       "298           0          0          0         1           0  \n",
       "299           0          0          0         0           0  \n",
       "300           0          0          0         0           0  \n",
       "303           0          0          0         0           0  \n",
       "304           0          0          0         0           0  \n",
       "305           0          0          0         1           0  \n",
       "306           0          0          0         0           0  \n",
       "307           0          0          0         0           0  \n",
       "308           0          0          0         0           0  \n",
       "309           0          0          0         0           0  \n",
       "310           0          0          0         0           0  \n",
       "311           0          0          0         0           1  \n",
       "312           0          0          0         0           0  \n",
       "313           0          0          0         0           0  \n",
       "314           0          0          0         0           0  \n",
       "315           0          0          0         1           0  \n",
       "316           0          0          0         0           0  \n",
       "317           0          0          0         0           0  \n",
       "318           0          0          0         0           0  \n",
       "319           0          0          0         0           0  \n",
       "320           0          0          0         1           0  \n",
       "321           0          0          0         1           0  \n",
       "322           0          0          0         0           0  \n",
       "323           0          0          1         0           0  \n",
       "324           0          0          0         0           0  \n",
       "325           0          0          0         0           0  \n",
       "326           0          0          0         0           0  \n",
       "327           0          0          0         0           0  \n",
       "328           1          0          0         0           0  \n",
       "329           0          0          0         0           0  \n",
       "330           0          0          0         0           0  \n",
       "334           0          0          0         0           0  \n",
       "335           0          0          1         0           0  \n",
       "336           0          0          0         1           0  \n",
       "337           0          0          0         0           0  \n",
       "338           0          0          0         0           0  \n",
       "339           0          0          0         0           0  \n",
       "340           1          0          0         0           0  \n",
       "341           0          0          0         0           0  \n",
       "342           0          0          0         0           0  \n",
       "343           0          0          0         0           0  \n",
       "344           0          0          0         0           0  \n",
       "345           0          0          0         0           0  \n",
       "346           0          0          0         0           0  \n",
       "347           0          0          0         0           0  \n",
       "348           0          0          1         0           0  \n",
       "349           0          0          0         0           0  \n",
       "350           0          0          0         0           0  \n",
       "351           0          0          1         0           0  \n",
       "352           1          0          0         0           0  \n",
       "353           0          0          0         1           0  \n",
       "354           0          0          0         0           0  \n",
       "355           0          0          0         0           0  \n",
       "356           0          0          0         0           0  \n",
       "357           0          0          0         0           0  \n",
       "358           0          0          0         0           0  \n",
       "359           0          0          0         0           0  \n",
       "361           0          0          0         0           0  \n",
       "362           0          0          0         0           0  \n",
       "363           0          0          0         0           0  \n",
       "364           0          0          0         0           0  \n",
       "365           0          0          0         0           1  \n",
       "366           0          0          0         0           0  \n",
       "367           0          0          0         0           0  \n",
       "368           0          0          0         0           0  \n",
       "369           0          0          0         0           1  \n",
       "370           0          0          0         0           0  \n",
       "371           0          0          0         0           0  \n",
       "372           0          1          0         0           0  \n",
       "373           1          0          0         0           0  \n",
       "374           0          1          0         0           0  \n",
       "375           0          0          0         0           0  \n",
       "376           0          0          0         0           1  \n",
       "377           0          0          0         0           0  \n",
       "378           0          0          0         0           0  \n",
       "379           0          0          0         1           0  \n",
       "380           0          0          0         1           0  \n",
       "381           0          0          0         0           0  \n",
       "382           0          0          0         0           0  \n",
       "383           0          0          0         0           0  \n",
       "384           0          0          0         0           0  \n",
       "385           0          0          0         0           0  \n",
       "386           0          0          0         0           0  \n",
       "387           0          0          0         1           0  \n",
       "388           0          0          0         0           0  \n",
       "389           0          0          0         0           0  \n",
       "392           0          0          0         0           0  \n",
       "396           0          0          0         0           0  \n",
       "397           0          0          0         0           0  \n",
       "398           0          0          0         1           0  \n",
       "399           0          0          0         0           0  \n",
       "400           1          0          0         0           0  \n",
       "402           0          0          0         0           0  \n",
       "403           0          0          0         0           0  \n",
       "404           0          0          0         0           0  \n",
       "405           0          0          0         0           0  \n",
       "406           0          0          0         0           0  \n",
       "407           0          0          0         0           0  \n",
       "408           0          0          0         0           0  \n",
       "409           0          0          0         0           0  \n",
       "410           0          0          0         1           0  \n",
       "411           0          0          0         0           0  \n",
       "412           0          0          0         1           0  \n",
       "413           0          0          0         0           0  \n",
       "414           0          0          0         0           0  \n",
       "415           0          0          0         0           0  \n",
       "416           0          0          1         0           0  \n",
       "417           0          0          0         0           0  \n",
       "418           0          0          0         0           0  \n",
       "419           0          0          0         0           0  \n",
       "423           0          1          0         0           0  \n",
       "424           1          0          0         0           0  \n",
       "425           0          0          1         0           0  \n",
       "426           0          0          0         1           0  \n",
       "427           0          0          0         0           0  \n",
       "428           0          0          0         0           0  \n",
       "429           0          0          0         0           0  \n",
       "430           0          0          0         0           0  \n",
       "431           0          0          0         0           0  \n",
       "432           0          0          0         0           0  \n",
       "433           0          0          0         0           0  \n",
       "434           0          0          0         0           0  \n",
       "435           0          0          0         0           0  \n",
       "436           0          0          1         0           0  \n",
       "437           0          0          0         0           0  \n",
       "438           0          0          0         0           0  \n",
       "439           0          0          0         0           0  \n",
       "440           1          0          0         0           0  \n",
       "441           0          0          0         0           0  \n",
       "442           0          0          0         0           1  \n",
       "443           0          0          0         0           0  \n",
       "444           0          0          0         0           0  \n",
       "445           0          0          0         0           1  \n",
       "446           0          0          0         0           1  \n",
       "447           0          0          0         0           0  \n",
       "448           0          0          0         1           0  \n",
       "449           0          0          0         1           0  \n",
       "455           0          0          0         0           0  \n",
       "456           0          0          0         0           0  \n",
       "457           0          0          0         0           0  \n",
       "458           0          0          0         0           0  \n",
       "459           0          0          0         0           0  \n",
       "460           0          0          0         0           0  \n",
       "461           0          0          1         0           0  \n",
       "462           0          0          0         0           0  \n",
       "463           0          0          0         0           0  \n",
       "464           0          0          1         0           0  \n",
       "465           0          0          0         0           0  \n",
       "466           0          0          0         0           0  \n",
       "467           0          0          0         0           0  \n",
       "468           0          1          0         0           0  \n",
       "469           0          0          1         0           0  \n",
       "470           0          0          0         0           0  \n",
       "471           1          0          0         0           0  \n",
       "472           1          0          0         0           0  \n",
       "473           0          0          0         0           0  \n",
       "474           0          0          0         1           0  \n",
       "475           0          0          1         0           0  \n",
       "476           0          0          0         0           1  \n",
       "477           0          0          0         0           0  \n",
       "478           0          0          0         0           0  \n",
       "479           0          0          0         0           0  \n",
       "484           0          0          0         0           0  \n",
       "485           0          0          0         0           0  \n",
       "486           0          0          0         0           0  \n",
       "487           0          0          0         0           0  \n",
       "488           0          0          0         0           0  \n",
       "489           0          1          0         0           0  \n",
       "491           0          0          0         0           0  \n",
       "492           0          0          0         0           0  \n",
       "493           1          0          0         0           0  \n",
       "494           0          0          0         1           0  \n",
       "495           0          0          0         0           0  \n",
       "496           0          0          0         0           0  \n",
       "497           0          0          0         0           0  \n",
       "498           0          0          0         0           0  \n",
       "499           0          0          0         0           0  \n",
       "500           0          0          0         0           0  \n",
       "501           0          0          1         0           0  \n",
       "502           0          0          0         0           0  \n",
       "503           0          0          0         0           0  \n",
       "504           0          0          1         0           0  \n",
       "505           0          0          0         0           0  \n",
       "506           0          0          1         0           0  \n",
       "507           0          0          0         0           0  \n",
       "508           0          0          0         0           0  \n",
       "509           0          0          0         0           0  \n",
       "510           0          0          0         0           0  \n",
       "511           0          0          0         0           0  \n",
       "512           0          0          1         0           0  \n",
       "513           0          0          1         0           0  \n",
       "514           0          0          0         0           0  \n",
       "515           1          0          0         0           0  \n",
       "516           1          0          0         0           0  \n",
       "517           0          0          0         0           0  \n",
       "518           0          0          0         0           0  \n",
       "519           0          0          0         0           0  \n",
       "520           0          0          0         0           0  \n",
       "521           0          0          0         0           0  \n",
       "522           0          0          0         0           0  \n",
       "523           0          0          0         0           0  \n",
       "524           0          0          0         0           0  \n",
       "525           0          0          0         0           0  \n",
       "526           0          0          1         0           0  \n",
       "527           0          0          0         0           0  \n",
       "528           0          0          1         0           0  \n",
       "529           0          0          0         0           0  \n",
       "530           0          0          0         0           0  \n",
       "531           0          0          0         1           0  \n",
       "532           0          0          0         0           0  \n",
       "534           0          0          0         0           0  \n",
       "535           0          0          0         0           0  \n",
       "536           0          0          1         0           0  \n",
       "537           0          0          0         0           0  \n",
       "538           0          0          1         0           0  \n",
       "539           0          0          0         0           0  \n",
       "543           0          0          0         0           0  \n",
       "544           0          0          0         0           0  \n",
       "545           0          0          0         0           0  \n",
       "546           0          0          0         0           0  \n",
       "547           0          0          1         0           0  \n",
       "548           0          0          0         0           0  \n",
       "549           1          0          0         0           0  \n",
       "550           1          0          0         0           0  \n",
       "551           0          0          0         0           0  \n",
       "552           0          0          0         0           0  \n",
       "553           0          0          0         0           0  \n",
       "554           0          1          0         0           0  \n",
       "555           0          0          0         1           0  \n",
       "556           0          1          0         0           0  \n",
       "557           0          0          0         0           0  \n",
       "558           0          0          0         0           0  \n",
       "559           0          0          0         0           0  \n",
       "560           0          0          0         0           1  \n",
       "561           0          0          0         0           0  \n",
       "562           0          0          0         0           0  \n",
       "563           0          0          0         0           0  \n",
       "564           0          0          1         0           0  \n",
       "565           0          0          0         0           0  \n",
       "566           0          0          1         0           0  \n",
       "567           0          0          0         0           0  \n",
       "568           0          1          0         0           0  \n",
       "569           0          0          0         0           0  \n",
       "570           0          0          0         0           0  \n",
       "571           0          0          0         0           0  \n",
       "572           0          0          0         0           0  \n",
       "573           0          0          0         0           0  \n",
       "574           0          0          0         0           0  \n",
       "575           0          0          0         0           0  \n",
       "576           0          0          0         0           0  \n",
       "577           0          0          0         0           0  \n",
       "578           1          0          0         0           0  \n",
       "579           0          0          0         0           0  \n",
       "580           0          0          0         0           0  \n",
       "581           0          0          0         0           0  \n",
       "582           0          0          1         0           0  \n",
       "583           0          0          0         1           0  \n",
       "584           0          0          0         1           0  \n",
       "585           0          0          0         0           0  \n",
       "586           0          0          0         1           0  \n",
       "587           0          0          0         1           0  \n",
       "588           0          0          0         0           0  \n",
       "589           0          0          0         0           0  \n",
       "590           0          0          0         0           0  \n",
       "591           0          0          0         0           0  \n",
       "592           0          0          0         0           0  \n",
       "593           0          0          1         0           0  \n",
       "594           0          0          0         0           0  \n",
       "595           1          0          0         0           0  \n",
       "596           0          0          0         0           0  \n",
       "597           0          0          1         0           0  \n",
       "598           1          0          0         0           0  \n",
       "599           0          0          0         0           0  \n",
       "601           0          0          0         0           0  \n",
       "602           0          0          0         0           0  \n",
       "603           0          0          0         0           0  \n",
       "604           0          0          0         0           0  \n",
       "605           0          0          0         1           0  \n",
       "606           0          0          0         0           0  \n",
       "607           0          0          0         0           0  \n",
       "608           0          0          1         0           0  \n",
       "609           0          0          0         0           0  \n",
       "610           0          0          0         0           1  \n",
       "611           0          0          1         0           0  \n",
       "612           0          0          0         0           0  \n",
       "613           0          0          0         0           0  \n",
       "614           0          0          0         0           0  \n",
       "615           0          0          0         0           0  \n",
       "616           0          0          0         0           0  \n",
       "617           0          0          0         0           0  \n",
       "618           0          0          0         0           0  \n",
       "619           0          0          0         1           0  \n",
       "620           0          0          1         0           0  \n",
       "621           0          0          0         0           0  \n",
       "622           0          0          0         1           0  \n",
       "623           0          0          1         0           0  \n",
       "624           0          0          0         0           0  \n",
       "625           0          0          0         0           0  \n",
       "626           0          0          0         0           0  \n",
       "627           0          0          0         0           0  \n",
       "628           0          0          0         0           0  \n",
       "634           0          0          0         0           0  \n",
       "635           0          0          1         0           0  \n",
       "636           0          0          0         0           0  \n",
       "637           0          0          1         0           0  \n",
       "638           0          0          0         0           0  \n",
       "639           0          0          0         0           0  \n",
       "640           0          0          1         0           0  \n",
       "642           0          0          0         0           0  \n",
       "643           0          0          0         1           0  \n",
       "644           0          0          0         0           0  \n",
       "645           0          0          0         0           0  \n",
       "646           0          0          0         0           0  \n",
       "647           0          0          0         0           0  \n",
       "648           0          0          0         0           0  \n",
       "649           0          0          0         0           0  \n",
       "650           0          0          0         0           0  \n",
       "651           0          0          0         0           0  \n",
       "652           0          0          0         0           0  \n",
       "653           0          0          0         0           0  \n",
       "654           0          0          1         0           0  \n",
       "655           0          0          0         0           1  \n",
       "656           0          0          0         0           0  \n",
       "657           0          0          0         0           0  \n",
       "658           0          0          0         0           0  \n",
       "659           0          0          0         1           0  \n",
       "660           0          0          0         0           0  \n",
       "661           0          0          0         0           0  \n",
       "662           0          0          0         0           0  \n",
       "663           0          0          0         0           0  \n",
       "664           0          0          0         0           0  \n",
       "665           0          0          0         0           0  \n",
       "666           0          0          1         0           0  \n",
       "667           1          0          0         0           0  \n",
       "668           0          0          0         0           0  \n",
       "669           0          0          0         0           0  \n",
       "670           0          0          0         1           0  \n",
       "671           0          0          0         0           0  \n",
       "672           0          0          0         0           1  \n",
       "673           0          0          0         0           0  \n",
       "674           0          0          0         0           0  \n",
       "675           0          0          0         0           0  \n",
       "676           1          0          0         0           0  \n",
       "677           0          0          0         0           1  \n",
       "678           0          0          1         0           0  \n",
       "679           0          0          0         0           0  \n",
       "680           0          0          0         0           0  \n",
       "681           0          0          1         0           0  \n",
       "682           0          0          0         0           0  \n",
       "683           0          0          0         0           0  \n",
       "684           0          0          0         0           0  \n",
       "685           0          0          0         0           0  \n",
       "686           0          0          0         0           0  \n",
       "687           0          0          0         0           0  \n",
       "689           0          0          1         0           0  \n",
       "690           0          0          0         0           0  \n",
       "691           0          0          0         0           0  \n",
       "692           0          0          0         0           0  \n",
       "693           0          0          0         0           1  \n",
       "694           0          0          0         0           0  \n",
       "695           0          0          0         1           0  \n",
       "696           0          0          0         0           0  \n",
       "697           0          0          0         0           0  \n",
       "698           0          0          0         0           0  \n",
       "699           0          0          1         0           0  \n",
       "700           0          0          0         0           0  \n",
       "701           0          0          0         0           0  \n",
       "702           0          0          0         1           0  \n",
       "703           0          0          0         1           0  \n",
       "704           0          0          0         0           0  \n",
       "705           0          0          0         0           0  \n",
       "706           0          0          0         0           0  \n",
       "707           0          0          0         0           0  \n",
       "708           0          0          0         0           0  \n",
       "709           0          0          0         0           1  \n",
       "710           0          0          0         0           0  \n",
       "711           0          0          0         0           0  \n",
       "712           0          0          0         0           0  \n",
       "713           0          0          0         1           0  \n",
       "714           0          0          0         0           0  \n",
       "715           0          0          0         0           0  \n",
       "716           0          0          0         0           0  \n",
       "717           0          0          0         0           0  \n",
       "718           0          0          0         0           0  \n",
       "719           0          0          0         0           0  \n",
       "720           0          0          0         0           0  \n",
       "721           0          0          0         0           0  \n",
       "722           0          0          0         0           0  \n",
       "723           0          0          0         0           0  \n",
       "724           0          1          0         0           0  \n",
       "725           0          0          1         0           0  \n",
       "726           0          1          0         0           0  \n",
       "727           0          0          0         0           0  \n",
       "728           0          0          0         0           0  \n",
       "729           0          0          0         0           0  \n",
       "730           0          0          0         0           0  \n",
       "731           0          1          0         0           0  \n",
       "732           0          0          0         0           0  \n",
       "733           0          0          0         1           0  \n",
       "734           0          0          0         0           0  \n",
       "735           0          0          0         0           0  \n",
       "736           0          1          0         0           0  \n",
       "737           0          0          0         0           0  \n",
       "738           0          0          0         0           0  \n",
       "739           0          0          0         0           0  \n",
       "740           0          0          0         1           0  \n",
       "741           0          0          0         0           0  \n",
       "742           0          0          0         0           0  \n",
       "743           0          0          1         0           0  \n",
       "744           0          0          0         0           0  \n",
       "745           0          0          0         1           0  \n",
       "746           0          0          0         0           0  \n",
       "747           0          0          0         1           0  \n",
       "748           0          0          0         0           1  \n",
       "749           0          0          0         0           0  \n",
       "753           0          0          0         0           1  \n",
       "754           0          0          0         0           1  \n",
       "755           0          0          0         0           0  \n",
       "756           0          0          0         0           0  \n",
       "757           1          0          0         0           0  \n",
       "758           0          0          0         0           0  \n",
       "759           0          1          0         0           0  \n",
       "760           0          0          0         0           0  \n",
       "762           0          0          0         0           0  \n",
       "763           0          0          0         0           0  \n",
       "764           0          0          0         0           0  \n",
       "765           0          1          0         0           0  \n",
       "766           0          0          0         0           0  \n",
       "767           0          0          1         0           0  \n",
       "768           0          0          1         0           0  \n",
       "769           0          0          0         0           0  \n",
       "770           0          0          1         0           0  \n",
       "771           0          0          0         0           0  \n",
       "772           0          0          0         0           0  \n",
       "773           0          0          0         0           0  \n",
       "774           0          0          0         0           1  \n",
       "775           0          0          0         0           0  \n",
       "776           1          0          0         0           0  \n",
       "777           0          0          1         0           0  \n",
       "778           0          0          0         1           0  \n",
       "779           0          0          0         1           0  \n",
       "783           0          0          0         0           0  \n",
       "784           0          0          0         0           0  \n",
       "785           0          0          0         0           0  \n",
       "786           0          0          0         1           0  \n",
       "787           0          0          1         0           0  \n",
       "788           0          0          0         0           0  \n",
       "789           0          0          1         0           0  \n",
       "790           0          0          0         0           1  \n",
       "791           0          0          0         0           0  \n",
       "792           0          0          0         0           0  \n",
       "793           1          0          0         0           0  \n",
       "795           0          0          0         0           0  \n",
       "796           0          1          0         0           0  \n",
       "797           0          0          0         0           0  \n",
       "798           0          0          0         0           0  \n",
       "799           0          0          0         0           1  \n",
       "800           0          0          0         0           0  \n",
       "801           0          0          0         0           1  \n",
       "802           0          0          0         0           0  \n",
       "803           0          0          0         1           0  \n",
       "804           0          0          0         0           0  \n",
       "805           0          1          0         0           0  \n",
       "806           0          0          0         0           1  \n",
       "807           0          0          1         0           0  \n",
       "808           0          0          0         0           0  \n",
       "809           0          0          0         0           0  \n",
       "813           0          0          0         0           0  \n",
       "814           0          0          1         0           0  \n",
       "815           0          0          0         0           1  \n",
       "816           0          0          0         0           1  \n",
       "817           0          0          0         0           0  \n",
       "818           0          0          0         0           0  \n",
       "819           0          0          0         0           0  \n",
       "820           0          0          0         0           0  \n",
       "821           0          0          0         0           0  \n",
       "822           0          0          0         0           0  \n",
       "823           0          0          0         0           0  \n",
       "824           0          0          0         0           0  \n",
       "825           0          0          0         0           0  \n",
       "826           0          0          0         0           0  \n",
       "827           0          0          0         0           0  \n",
       "828           0          0          0         0           0  \n",
       "829           0          0          0         0           0  \n",
       "830           0          0          0         0           0  \n",
       "831           0          0          0         0           0  \n",
       "832           0          0          0         0           0  \n",
       "833           0          0          0         0           0  \n",
       "834           0          0          0         0           0  "
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.rename(columns={'Median_Salary_Standardized': 'Salary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bdd1d-cf39-4494-9f05-51973a04537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv(r'F:\\Data-Science\\Projects\\2.Data-Science-Salary-Project\\data\\data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c3400",
   "metadata": {},
   "source": [
    "## Data Transformation plans\n",
    "1. scale or normalize numerical values\n",
    "    - company_rating - range(1.0 - 5.0)\n",
    "    - median_salary - range(lakhs)\n",
    "    - other columns - boolean(0s and 1s)\n",
    "    - It is recommended to scale/normalize rating, salary features      \n",
    "2. train and test split\n",
    "## execute on .py scripts (src folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
